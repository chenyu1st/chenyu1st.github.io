<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>笑忘书</title>
      <link href="2021/06/27/Essay/%20lost-memories-with-smile/"/>
      <url>2021/06/27/Essay/%20lost-memories-with-smile/</url>
      
        <content type="html"><![CDATA[<p>再过3天就是我毕业满2年的日子了，这是一封写给自己的情书。</p><h1 id="两年前"><a href="#两年前" class="headerlink" title="两年前"></a>两年前</h1><p>两年前的今天，我前女友正陪我在看几间离公司的比较近的房子，确定要租房子之后，搬家，吃饭，晚上憧憬着美好的未来。</p><p>那时一位好兄弟跟我算了一笔账，假如房价这几年不涨，在武汉成家立业需要多少钱你算过没？大约100个，按三环内2个/平的均价，100平，30%首付（可以房子均价高点，面积小点）差不多60个左右，算上装修，车，彩礼，基本上就100个左右了。</p><p>我算了一下在当时的工资如果也一分钱不涨也一分钱不花，所有的钱都存下来，大概需要12年左右才能攒够这个数。</p><p>按照当时我的条件，我已经具备稳步向上（养老）的很多条，央企朝九晚五工作稳定轻松，有一个已经谈了3年的女朋友，家里虽然能赞助的有限，但是努力工作几年也能完成我之前的目标。当时给自己定的目标就是在30岁之前攒到这个数，然后结婚娶她。现在想想当时的自己是多么天真烂漫啊，因为现实远远比想象残酷。</p><h1 id="一年半前"><a href="#一年半前" class="headerlink" title="一年半前"></a>一年半前</h1><p>工作半年后，一次偶然的机会，前女友向我表达了她的不满和羡慕:她上班同事的男朋友都有房有车上下班接送很幸福，而我最多一个星期聚一次(虽然都在武汉，但是距离还是隔得有点远)。我那个时候只意识到了女生变物质、虚荣了，却没有仔细思考她表的的真正原因，以及自己对自己的定位是不是需要发生改变。</p><p>环境能改变一个人是实打实发生在我身上的，我看到了她的改变，但是没能力改变自己，加之马上爆发的疫情，那天我还记得我们是最后一次见面，我拿到公司的优秀新人奖，跟她开心的分享后回家过年，没想到那天晚上她再一次表达了对我这个奖的质疑:这个奖又没有米，没有米就什么都不是。</p><p>疫情期间，我们2个基本处于半分手状态，互相不联系不关心，而公司来年的发展也愈发不行，公司裁员，众人都惶恐不已，纷纷准备找退路。而那个时候我跟她的每一次通话都是一次不可逆转的折磨，我陷入了至今为止人生最黑暗的时候，爱情事业双双崩盘，我差一点就被现实打败了，想向自己妥协。</p><h1 id="一年前"><a href="#一年前" class="headerlink" title="一年前"></a>一年前</h1><p>后来的转机也是因为看到了<a href="https://www.bilibili.com/video/BV1FV411d7u7?from=search&seid=6731801181146737106" target="_blank" rel="noopener">后浪</a>，反复观看了几次，我认定这本该是属于我们的时代，应该由我们去创造引领这个时代的潮流。</p><p>然而我跟她再一次分享我的心得的时候她仍然不以为意，觉得我只是一时兴起，老说这些有的没的，这极大地侮辱了我的自尊。但是我已经找到了自己的方向，不想在武汉安于现状，强大的动力可以摧毁一切阻挡我脚步前进的任何东西。</p><p>最后结果是我成功地突破重围，当我告诉她我拿到的offer后，她下意识告诉我是不是被人骗了（言下之意不相信我能拿到）。直到我单枪匹马的杀到深圳，她才发现我确实做到了，她借此机会复合。</p><p>那时的我只想幼稚的想她证明:看你以后还看不看得起我，她说她来深圳找我，我故意同意，然后等她把所有的一切准备好，即将来深圳的前一天，我跟她残忍、绝情地提出分手，挂断电话后删除有关她的一切信息，心情别提有多愉快。</p><p>但是当你凝视深渊时，深渊也在凝视着你。</p><h1 id="此情可待成追忆-只是当时已惘然。"><a href="#此情可待成追忆-只是当时已惘然。" class="headerlink" title="此情可待成追忆,只是当时已惘然。"></a>此情可待成追忆,只是当时已惘然。</h1><p>几天前，一次偶然的机会，我们两人互通了电话，她找到了一个即将谈婚论嫁的大男孩，她骄傲地解读着她现任各项比我优越的条件，她现在的收米能力，以及她花了大半年赚的米给自己割双眼皮动刀子后的漂亮脸蛋。</p><p>说实话能看到她自己现在过的还不错我觉得真的挺好的，然后我们再回想起之前两人一起经历的种种后，我还是觉得在大学的那段时间过的最好，没有任何的杂念。</p><p>我满怀歉意地跟她道歉当初不应该分手那么决绝，但是她不接受我的道歉，还说她一辈子都不会忘记我当初的绝情。她认为她给别人做嫁衣了，我现在的发展都是因她而变得更好，此时我的声音开始大起来了，我说事件起因最初还不是因为她觉得我在武汉没啥钱途，但是她不为她当初瞧不起我的行为道歉，并且一再认为她有权利看不起一个没用的男朋友并对他进行指责，没过多久我们就开始骂骂咧咧互相”问候”。</p><p>这通电话后我几天内都没法平静，跟我的好几个朋友打过电话聊了这件事，大家的评判都不太一样，但是我其中一个好友的话点醒了我。</p><p>非风动，非幡动，仁者心动。</p><p>风吹过来，感受到的是风在动，感受不到的但是看见幡在动所以也知道是风在动，而只有大师才知道只有他们是心在动，看清事物的本质很重要。</p><p>两人在一起本质都想获得幸福，都想让彼此发展地更好，但是思想幼稚的我们都没有真正领会到各自的意图，而是被表象迷惑。</p><p>其实她只是想让我更上进，变得更强到能把她托付给我的人，而我只是想证明自己可以是让她托付终身的人。但是我们明明可以知道彼此的真心，缺把锋利的刀一刀刀去划掉它，直到划破为止。当初分手有我多快乐，现在我就有多难过，所有当初的伤害现在都返回给自己了。</p><p>当时的我们彼此都拥有最珍贵的爱情，但却缺没有好好珍惜。</p><p>现在再看前任三我真的感触挺大，不分手不能成长，成长后不能挽留。或许我们都已经成为了曾经憧憬未来各自的对象，但是我们却再也不在一起了。</p><h1 id="痛苦总是容易比幸福更让人难以忘却，既然不能笑着拥抱，那么笑着遗忘也好"><a href="#痛苦总是容易比幸福更让人难以忘却，既然不能笑着拥抱，那么笑着遗忘也好" class="headerlink" title="痛苦总是容易比幸福更让人难以忘却，既然不能笑着拥抱，那么笑着遗忘也好"></a>痛苦总是容易比幸福更让人难以忘却，既然不能笑着拥抱，那么笑着遗忘也好</h1><p>从开始哭着嫉妒</p><p>变成了笑着羡慕</p><p>时间是怎么样爬过了我皮肤</p><p>只有我自己最清楚</p><p>将这样的感触</p><p>写一封情书 送给我自己</p><p>感动得要哭</p><p>很久没哭</p><p>不失为天大的幸福</p><p>将这一份礼物</p><p>这一封情书 给自己祝福</p><p>可以不在乎</p><p>才能对别人在乎</p><h1 id="现在"><a href="#现在" class="headerlink" title="现在"></a>现在</h1><p>生活还是要朝前看，我也更加清楚的认定，男人这辈子不应该为了一套房一辆车一个女人而奋斗，而是为自己奋斗。</p><p>最后提醒未来的我以及能有幸看到这篇文章的你们，钱没了可以再赚，人没了什么都没了，珍惜来之不易的各种感情。</p><p>写到这里，我的心情已经释怀，文章也不太想改了，就这样吧，记录自己最真实的状态。</p>]]></content>
      
      
      <categories>
          
          <category> Essay </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Essay </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SRE实战之Gitlab事故发现、修复、反思</title>
      <link href="2021/02/01/sre/troubleshouting-gitlab/"/>
      <url>2021/02/01/sre/troubleshouting-gitlab/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>早上同事反馈gitlab登不进去，我进服务器发现机器的进程都挂掉了，但是gitlab-ctl status 都还是正常的，正在想怎么解决的时候，机器挂了，修好后没想到下午同事又反馈说gitlab ci有问题，提交代码不能触发pipline，我当时比较忙，就准备晚上解决，由于pipline仅仅是自动化测试，我临时将流程调整到jenkins上执行。</p><p>晚上来仔细研究下gitlab ci为什么不能工作了</p><h1 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h1><p>首先整理一下目前环境</p><ul><li>一台gitlab-V12.4.2（Ubuntu16.04）</li><li>两个gitlab-runner</li><li>三个不同项目的自动化CI</li></ul><p>gitlab机器配置有点拉胯</p><p>2c 16g 2T hdd 3年前的机器，没啥好说的，关机的时候去看机箱里面全是灰，生存环境很恶劣。</p><p>机器运行了gitlab和nexus</p><h2 id="问题处理一"><a href="#问题处理一" class="headerlink" title="问题处理一"></a>问题处理一</h2><p>早上同时反馈gitlab登不进去，我进服务器发现进程处于假死的情况，服务器负载正常，但是gitlab-ctl start 没有任何效果。</p><p>我谷歌无果后尝试重启</p><p>结果等了大概1分钟，还是不能ssh上去</p><p>我决定直接用显示器接入这台机器看看是什么情况</p><p>服务器可以进入bios，我检查了下各个组件状态，没有问题，退出后准备进入系统</p><p>结果磁盘自检时报错</p><p>如图所示</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Centos/fsck.jpg"  alt="fsck.jpg"></p><p>Google后执行修复命令</p><pre><code>fsck -y /dev/sda2</code></pre><p>经过漫长的等待修复后</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Centos/fscksucc.jpg"  alt="fscksucc.jpg"></p><p>成功</p><p>reboot后可以正常开机</p><h2 id="问题处理二"><a href="#问题处理二" class="headerlink" title="问题处理二"></a>问题处理二</h2><p>到了下午3点，同事突然告诉我说有个项目的自动化CI没触发构建。</p><p>我进服务器看，各个情况正常，我想是不是又是磁盘坏了，需要修复，然后重启，结果重启正常开机，开机自起gitlab没有任何问题，但是CI就是跑不了。</p><p>由于当时我还在修复另外一个问题，就跟研发说那个CI先手动执行吧，晚上我再看看。</p><p>到了晚上9点，夜深人静</p><p>我开始定位这台机器的真正的故障点</p><h3 id="控制变量"><a href="#控制变量" class="headerlink" title="控制变量"></a>控制变量</h3><p>联系了研发后得到一个结论</p><p>从下午3点后，除了这个项目，其他的项目CI能正常运行</p><p>我想这不就是ci.yaml的问题吗</p><p>但是gitlab查看这个这个项目都ci文件，2个月都没有改，凭借着项目不更新就永远没有BUG的定位思想，我将眼光放到了gitlab-runner</p><h3 id="Gitlab-Runner"><a href="#Gitlab-Runner" class="headerlink" title="Gitlab-Runner"></a>Gitlab-Runner</h3><p>Gitlab-Runner有2个，正好这个出问题的项目CI有一个独享的runner</p><p>我查看了runner的状态，没问题，而且重启runner后，CI仍然不能自动构建</p><p>然后我在一个正常CI的流水线上重新跑了一遍，runner能正常工作</p><p>OK，这问题就出在无法自动触发CI上了</p><p>然后我在这个流水线手动执行一个任务，发现gitlab页面报错500</p><h3 id="500"><a href="#500" class="headerlink" title="500"></a>500</h3><p>我尝试了3个不同的项目，有2个都可以手动执行任务，但是就是这个项目不行，最后我只有调后台日志测试看。</p><p>gitlab是用apt安装的，默认系统日志存放列表如下</p><pre><code>sudo cat /etc/gitlab/gitlab.rb |grep log_directory</code></pre><p>这台服务器存放在/var/log/gitlab下</p><pre><code>gitlab会将所有的操作记录成日志，方便进行分析，gitlab的日志系统分为以下几类：1、production.log：该日志位于/var/log/gitlab/gitlab-rails中，其作用是记录gitlab的每次请求的具体信息，包括请求的URL、ip地址、请求类型、以及此次请求所涉及的具体代码、SQL请求以及SQL请求消耗的时间。比如：2、application.log：此日志文件位于/var/log/gitlab/gitlab-rails中，其作用是记录创建用户、创建项目、移动项目等日志。3、githost.log：此日志文件位于/var/log/gitlab/gitlab-rails中，此日志的作用是记录对gitlab服务器的错误请求日志。4、sidekiq.log：此日志文件位于/var/log/gitlab/gitlab-rails中，gitlab中可能存在一些任务需要运行很长时间，因此会选择将这些任务在后台执行，sidekiq.log文件就是用来记录这一类任务的处理信息，此日志文件是一个软连接文件。5、gitlab-shell.log：此日志文件位于/var/log/gitlab/gitlab-shell中，该日志文件的作用是记录执行gitlab命令以及为项目添加ssh权限的日志文件6、unicorn\_stderr.log：此日志文件位于/var/log/gitlab/unicorn，该日志文件的作用是记录gitlab的web服务器的相关记录。7、repochec.log：此日志文件位于/var/log/gitlab/prometheus</code></pre><p>目录很多，Gitlab核心操作日志是/logs/gitlab-rails/production.log</p><p>查看日志发现报500的原因</p><pre><code>=&gt; /var/log/gitlab/gitlab-rails/production.log &lt;==Started POST &quot;/root/upstream/pipelines&quot; for 192.168.10.88 at 2021-01-20 23:45:41 +0800Processing by Projects::PipelinesController#create as HTML  Parameters: {&quot;utf8&quot;=&gt;&quot;✓&quot;, &quot;authenticity_token&quot;=&gt;&quot;[FILTERED]&quot;, &quot;pipeline&quot;=&gt;{&quot;ref&quot;=&gt;&quot;master&quot;}, &quot;namespace_id&quot;=&gt;&quot;root&quot;, &quot;project_id&quot;=&gt;&quot;upstream&quot;}Completed 500 Internal Server Error in 133ms (ActiveRecord: 45.9ms | Elasticsearch: 0.0ms)ActiveRecord::StatementInvalid (PG::IndexCorrupted: ERROR:  index &quot;index_ci_stages_on_project_id&quot; contains unexpected zero page at block 58HINT:  Please REINDEX it.: INSERT INTO &quot;ci_stages&quot; (&quot;project_id&quot;, &quot;pipeline_id&quot;, &quot;created_at&quot;, &quot;updated_at&quot;, &quot;name&quot;, &quot;status&quot;, &quot;position&quot;, &quot;lock_version&quot;) VALUES (10, 11638, &apos;2021-01-20 15:45:41.879264&apos;, &apos;2021-01-20 15:45:41.879264&apos;, &apos;pre-build&apos;, 0, 1, 0) RETURNING &quot;id&quot;):lib/gitlab/ci/pipeline/chain/create.rb:11:in `perform!&apos;lib/gitlab/ci/pipeline/chain/sequence.rb:19:in `block in build!&apos;lib/gitlab/ci/pipeline/chain/sequence.rb:16:in `each&apos;lib/gitlab/ci/pipeline/chain/sequence.rb:16:in `build!&apos;app/services/ci/create_pipeline_service.rb:50:in `execute&apos;app/controllers/projects/pipelines_controller.rb:61:in `create&apos;lib/gitlab/session.rb:11:in `with_session&apos;app/controllers/application_controller.rb:463:in `set_session_storage&apos;lib/gitlab/i18n.rb:55:in `with_locale&apos;lib/gitlab/i18n.rb:61:in `with_user_locale&apos;app/controllers/application_controller.rb:457:in `set_locale&apos;lib/gitlab/middleware/rails_queue_duration.rb:27:in `call&apos;lib/gitlab/metrics/rack_middleware.rb:17:in `block in call&apos;lib/gitlab/metrics/transaction.rb:62:in `run&apos;lib/gitlab/metrics/rack_middleware.rb:17:in `call&apos;lib/gitlab/request_profiler/middleware.rb:17:in `call&apos;lib/gitlab/middleware/go.rb:20:in `call&apos;lib/gitlab/etag_caching/middleware.rb:13:in `call&apos;lib/gitlab/middleware/correlation_id.rb:16:in `block in call&apos;lib/gitlab/middleware/correlation_id.rb:15:in `call&apos;lib/gitlab/middleware/multipart.rb:117:in `call&apos;lib/gitlab/middleware/read_only/controller.rb:48:in `call&apos;lib/gitlab/middleware/read_only.rb:18:in `call&apos;lib/gitlab/middleware/basic_health_check.rb:25:in `call&apos;lib/gitlab/request_context.rb:32:in `call&apos;lib/gitlab/metrics/requests_rack_middleware.rb:49:in `call&apos;lib/gitlab/middleware/release_env.rb:12:in `call&apos;==&gt; /var/log/gitlab/postgresql/current &lt;==2021-01-20_15:45:41.88022 ERROR:  index &quot;index_ci_stages_on_project_id&quot; contains unexpected zero page at block 582021-01-20_15:45:41.88023 HINT:  Please REINDEX it.2021-01-20_15:45:41.88023 STATEMENT:  INSERT INTO &quot;ci_stages&quot; (&quot;project_id&quot;, &quot;pipeline_id&quot;, &quot;created_at&quot;, &quot;updated_at&quot;, &quot;name&quot;, &quot;status&quot;, &quot;position&quot;, &quot;lock_version&quot;) VALUES (10, 11638, &apos;2021-01-20 15:45:41.879264&apos;, &apos;2021-01-20 15:45:41.879264&apos;, &apos;pre-build&apos;, 0, 1, 0) RETURNING &quot;id&quot;==&gt; /var/log/gitlab/nginx/gitlab_access.log &lt;==192.168.10.88 - - [20/Jan/2021:23:45:41 +0800] &quot;POST /root/upstream/pipelines HTTP/2.0&quot; 500 2926 &quot;https://gitlab.com/root/upstream/pipelines/new&quot; &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 11_1_0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.141 Safari/537.36&quot;</code></pre><p>这样一看还是比较清晰</p><p>重点是</p><pre><code>Completed 500 Internal Server Error in 133ms (ActiveRecord: 45.9ms </code></pre><p>以及</p><pre><code>ActiveRecord::StatementInvalid (PG::IndexCorrupted: ERROR:  index &quot;index_ci_stages_on_project_id&quot; contains unexpected zero page at block 58HINT:  Please REINDEX it.</code></pre><h3 id="深入了解"><a href="#深入了解" class="headerlink" title="深入了解"></a>深入了解</h3><p>进一步了解后发现，gitlab使用的是pgsql作为关系型数据库</p><pre><code>PG::IndexCorrupted: ERROR</code></pre><p>而pgsql底层最常见的数据结构是b-tree </p><p>根据官方说明，有以下几种情况会需要重建索引</p><ul><li>当由于软件bug或者硬件原因导致的索引不再可用，索引的数据不再可用；</li><li>当索引包含许多空的或者近似于空的页，这个在b-tree索引会发生。Reindex会腾出空间释放哪些无用的页(页就是存放数据的一个单位，类似于block)。</li><li>PostgreSql数据库系统修改了存储参数，需要重建不然就会失效(如修改了fillfactor参数)；</li><li>创建并发索引时失败，遗留了一个失效的索引。这样的索引不会被使用，但重构后能用。一个索引的重构不能并发的执行。</li></ul><p>这样联想起第一个报错，我不得不怀疑，即使在软件层将文件系统修复好，也未必不丢失这种数据</p><h3 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h3><p>先通过gitlab-ctl进入db控制台,重建索引即可</p><pre><code>root@gitlab:/# gitlab-rails dbconsolepsql (10.9)Type &quot;help&quot; for help.gitlabhq_production=&gt;REINDEX INDEX index_ci_stages_on_project_id;</code></pre><p>再次重启gitlab服务，CI流程恢复正常</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h2 id="硬盘问题"><a href="#硬盘问题" class="headerlink" title="硬盘问题"></a>硬盘问题</h2><p>这是我第二次遇见硬盘问题了，听同事反馈这台机器还不止挂过一次，用的机械硬盘，而且服务器长期暴露在外面，没有很好的保护起来。</p><p>扩展下硬盘相关知识:</p><h3 id="硬盘损坏"><a href="#硬盘损坏" class="headerlink" title="硬盘损坏"></a>硬盘损坏</h3><p>硬盘的损坏可以大致分为两大类，一类是硬损坏，一类是软损坏。</p><ul><li>硬损坏主要是磁头组件损坏、控制电路损坏、综合性损坏和扇区物理性损坏四种。</li></ul><p>磁头组件损坏：其主要指硬盘中磁头组件的某部分被损坏掉了，从而造成部分或者全部磁头无法正常读写的情况。磁头组件损坏的原因也有很多，主要还是磁头变脏、磨损、悬臂变形、磁线圈受损、移位等。</p><p>控制电路损坏：主要是指硬盘的电子线路板上，某一部分的线路断路或者短路，以及某些电气元件或者IC芯片损坏，从而导致了硬盘通电之后盘片不能正常起转以及起转之后磁头不能正确寻道。</p><p>综合性损坏：这一部分主要是一些微小的变化导致硬盘产生了种种的问题，比如在使用过程中因为发热导致部分芯片老化，或者是在受到震动后使得外壳或者盘面、马达主轴产生了微小的变化及位移，也有一些是硬盘本身就在设计上面有散热、摩擦、结构上的缺陷。这些种种原因导致了硬盘的不稳定，从而使得数据经常莫名其妙的丢失或者出现逻辑错误，不仅让电脑噪音变大，读写也开始变得缓慢。</p><p>扇区物理性损坏：扇区物理性损坏也被大家称为物理坏道。顾名思义，主要是因为碰撞、磁头摩擦等其他原因导致磁盘盘面出现物理性损坏，出现划伤、掉磁等现象。</p><ul><li>软损坏则包括：磁道伺服信息出错、系统信息区出错以及扇区逻辑错误。</li></ul><p>磁道伺服信息出错：因为某一个物理磁道的伺服信息受损或者失效导致物理磁道无法被访问。</p><p>系统信息区出错：硬盘的系统信息区在通电自检时读不出某些模块的信息或者校验不正常，从而导致硬盘无法进入准备状态。</p><p>扇区逻辑错误：因为校验错误（ECC错误和CRC错误）、扇区标志错误（IDNF错误）、地址信息错误（AMNF错误）、坏块标记错误（BBM）等原因导致此扇区失效。</p><p>当硬盘发生了损坏导致无法读取之后，一定要先停止继续读写避免损坏的更加严重，如果真的想要里面的资料，最好还是交由专业的数据恢复公司。</p><h3 id="硬盘修复"><a href="#硬盘修复" class="headerlink" title="硬盘修复"></a>硬盘修复</h3><p>软件问题</p><p>很多硬盘厂商发布的硬盘管理和维护软件都是具备修复硬盘软损坏能力的。对于扇区逻辑错误这样的问题，即使是低级的格式化软件也能修复好，但系统信息区出错就是比较难以修复的问题了，因为很多硬盘厂商对于自家产品的系统信息区内容和读取的指令代码并不公开。而且，同一家硬盘厂商生产出来的同一种型号的产品，其系统信息区也不一定相同。</p><p>硬件问题</p><p>第一是诊断问题，一般专业人士并不会用软件分析硬盘的故障，而是给损坏的硬盘接上电源，侦听其运作情况，硬盘会发出一些轻微的震动或者噪音，如果技术人员认为这块硬盘还可以再抢救一下的话，会进入第二个环节。</p><p>第二给损坏的硬盘接入一套测试系统，看其能否启动，以及能否得到一些数量值，是否能够进行读写操作，这部分主要是用来确定把这块急需抢救的硬盘交给SRS里面负责哪一部分的工作人员。</p><p>第三清除过滤器碎粒。在大多数3.5英寸硬盘里都有一个过滤器，因为其是在清洁的生产条件下装入硬盘中的，所以本身十分干净。如果这个过滤器和盘片表面有过接触，会使得过滤器沾上一些细小的碎粒变色，当工作人员除掉这些碎粒之后，这块硬盘还可以继续使用一段时间，抢救的过程一般也就到这里结束了。</p><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p><a href="https://www.zhihu.com/question/348571901" target="_blank" rel="noopener">按理说机械硬盘和固态硬盘使用得当寿命几乎一样长，但为什么网上传言机械硬盘更容易坏？</a></p><p>存机械更安全，这个说法成立，仅限以下三种条件的环境：</p><p>【1】你只有一个硬盘或SSD+仓库盘</p><p>【2】你没有任何其他备份手段</p><p>【3】你坏了硬盘真的会去送恢复公司</p><h2 id="待改善的地方"><a href="#待改善的地方" class="headerlink" title="待改善的地方"></a>待改善的地方</h2><p>这台机器已经用3年多接近4年了，配置现在看来特别拉胯，需要考虑更换整个机器了，包括cpu、内存、硬盘等，不止这台机器，其他机器也需要定期检查</p><p>没有很好的监控公共组件，导致同事反馈我才发现问题</p><p>数据备份特别重要，尤其在恢复的时候，基本上要到一天一备的水平，并验证备份恢复流程是否可行（光备份不实操恢复流程也等于睁眼说瞎话）</p><p>多深入学习一些常用的工具底层原理，对定位并解决突发问题有着重要作用</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://gitlab.com/gitlab-org/gitlab-foss/-/issues/30780" target="_blank" rel="noopener">Error 500 when trying to access gitlab page after upgrade to version 9.0.5</a></p><p><a href="https://gitlab.com/gitlab-org/gitlab-foss/-/issues/48462" target="_blank" rel="noopener">ActiveRecord::StatementInvalid: PG::IndexCorrupted when accessing Pipeline page</a></p><p><a href="https://www.bookstack.cn/read/pgsql-12-tw/reference-sql-commands-reindex.md" target="_blank" rel="noopener">https://www.bookstack.cn/read/pgsql-12-tw/reference-sql-commands-reindex.md</a></p><p><a href="https://docs.postgresql.tw/the-sql-language/index/index-types" target="_blank" rel="noopener">pqsql索引类别</a></p><p><a href="https://cloud.tencent.com/developer/article/1134953?from=information.detail.linux%E4%B8%8B%20%E7%A1%AC%E7%9B%98%E5%9D%8F%E9%81%93%E4%BF%AE%E5%A4%8D" target="_blank" rel="noopener">涨姿势 | 如何修复硬盘，以及如何避免硬盘损坏</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Sre </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Gitlab </tag>
            
            <tag> Sre </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维手册——Gitlab-Nexus迁移总结</title>
      <link href="2021/01/30/bug/gitlab-migrate/"/>
      <url>2021/01/30/bug/gitlab-migrate/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>由于gitlab的机器过于拉胯而导致的问题接连出现，我建议公司新买几台设备，然后把gitlab迁移一下，下面记录一下迁移过程。</p><h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><p>经过大量调研，准备新机器部署列表如下</p><table><thead><tr><th>旧机器</th><th>新机器</th></tr></thead><tbody><tr><td>2C</td><td>16C</td></tr><tr><td>8G</td><td>64G</td></tr><tr><td>2T 西数蓝盘HDD</td><td>1T 三星970EVO</td></tr><tr><td>Ubuntu16.04</td><td>Centos8.3</td></tr><tr><td>rpm安装</td><td>docker安装</td></tr><tr><td>集成安装</td><td>分布式组件安装</td></tr></tbody></table><ul><li>前提条件</li></ul><p>gitlab迁移必须要求2个gitlab版本一样（包括小版本）</p><p>nexus迁移需要只需要把数据拷贝即可</p><p>安装docker及docker-compose</p><ul><li>迁移顺序</li></ul><p>先迁移nexus,测试构建是否正常</p><p>后迁移gitlab，测试代码拉取、合并等功能是否正常</p><h1 id="迁移步骤"><a href="#迁移步骤" class="headerlink" title="迁移步骤"></a>迁移步骤</h1><h2 id="迁移nexus"><a href="#迁移nexus" class="headerlink" title="迁移nexus"></a>迁移nexus</h2><p>目录结构如下</p><pre><code>[root@gitlab opt]# lltotal 0drwxr-xr-x. 9 root root 163 Jan 24 11:46 nexus-3.19.1-01drwxr-xr-x. 3 root root  20 Jan 24 11:43 sonatype-work</code></pre><p>nexus目录为启动目录</p><p>sonatype-work是nexus运行及存储目录</p><p>先关闭nexus进程</p><pre><code>ps -axu|grep nexus|grep -v &quot;grep&quot;|awk &apos;{print $2}&apos;|xargs kill -9</code></pre><p>然后scp文件即可</p><p>注意:sonatype-work文件内容特别多，建议先压缩再scp，不建议直接scp，我就是这样做的，传输效率极低</p><p>进新服务器后，更改配置文件</p><pre><code>vim nexus-3.19.1-01/etc/nexus-default.properties</code></pre><p>将IP更改成本机IP<br>端口号可以不变<br>看个人需求</p><h2 id="迁移gitlab"><a href="#迁移gitlab" class="headerlink" title="迁移gitlab"></a>迁移gitlab</h2><p>本来gitlab是rpm安装的，我也想在新的centos上用rpm安装，结果查看gitlab提供的rpm与操作系统的对应关系后，我发现gitlab的版本并不能在新机器上部署</p><p>gitlab版本依赖对应如下</p><table><thead><tr><th align="left">OS Version</th><th align="left">First supported GitLab version</th><th align="left">Arch</th><th align="left">OS EOL</th><th align="left">Details</th></tr></thead><tbody><tr><td align="left">CentOS 7</td><td align="left">GitLab CE / GitLab EE 7.10.0</td><td align="left">x86_64</td><td align="left">June 2024</td><td align="left"><a href="https://wiki.centos.org/About/Product" target="_blank" rel="noopener">https://wiki.centos.org/About/Product</a></td></tr><tr><td align="left">CentOS 8</td><td align="left">GitLab CE / GitLab EE 12.8.1</td><td align="left">x86_64, aarch64</td><td align="left">Dec 2021</td><td align="left"><a href="https://wiki.centos.org/About/Product" target="_blank" rel="noopener">https://wiki.centos.org/About/Product</a></td></tr><tr><td align="left">Debian 9</td><td align="left">GitLab CE / GitLab EE 9.3.0</td><td align="left">amd64</td><td align="left">2022</td><td align="left"><a href="https://wiki.debian.org/DebianReleases#Production_Releases" target="_blank" rel="noopener">https://wiki.debian.org/DebianReleases#Production_Releases</a></td></tr><tr><td align="left">Debian 10</td><td align="left">GitLab CE / GitLab EE 12.2.0</td><td align="left">amd64</td><td align="left">TBD</td><td align="left"><a href="https://wiki.debian.org/DebianReleases#Production_Releases" target="_blank" rel="noopener">https://wiki.debian.org/DebianReleases#Production_Releases</a></td></tr><tr><td align="left">OpenSUSE 15.1</td><td align="left">GitLab CE / GitLab EE 12.4.0</td><td align="left">x86_64, aarch64</td><td align="left">Nov 2020</td><td align="left"><a href="https://en.opensuse.org/Lifetime" target="_blank" rel="noopener">https://en.opensuse.org/Lifetime</a></td></tr><tr><td align="left">SLES 12</td><td align="left">GitLab EE 9.0.0</td><td align="left">x86_64</td><td align="left">Oct 2027</td><td align="left"><a href="https://www.suse.com/lifecycle/" target="_blank" rel="noopener">https://www.suse.com/lifecycle/</a></td></tr><tr><td align="left">Ubuntu 16.04</td><td align="left">GitLab CE / GitLab EE 8.7.1</td><td align="left">amd64</td><td align="left">April 2021</td><td align="left"><a href="https://wiki.ubuntu.com/Releases" target="_blank" rel="noopener">https://wiki.ubuntu.com/Releases</a></td></tr><tr><td align="left">Ubuntu 18.04</td><td align="left">GitLab CE / GitLab EE 10.7.0</td><td align="left">amd64</td><td align="left">April 2023</td><td align="left"><a href="https://wiki.ubuntu.com/Releases" target="_blank" rel="noopener">https://wiki.ubuntu.com/Releases</a></td></tr><tr><td align="left">Ubuntu 20.04</td><td align="left">GitLab CE / GitLab EE 13.2.0</td><td align="left">amd64, arm64</td><td align="left">April 2025</td><td align="left"><a href="https://wiki.ubuntu.com/Releases" target="_blank" rel="noopener">https://wiki.ubuntu.com/Releases</a></td></tr><tr><td align="left">Raspbian Buster</td><td align="left">GitLab CE 12.2.0</td><td align="left">armhf</td><td align="left">2022</td><td align="left"><a href="https://wiki.debian.org/DebianReleases#Production_Releases" target="_blank" rel="noopener">https://wiki.debian.org/DebianReleases#Production_Releases</a></td></tr></tbody></table><p>操作系统越新，安装的gitlab版本也就越新</p><p>查看gitlab版本</p><pre><code>gitlab-rake gitlab:env:infoGitLab informationVersion:    12.4.2</code></pre><p>centos8最低都要安装gitlab-12.8.1版本</p><p>所以要么选择先升级gitlab到12.8.1再用物理机安装，要么另寻溪僻</p><p>思来想去，我还是准备用docker部署，反正都这么麻烦了，还不如用docker一步到位，至少以后迁移容易</p><h3 id="备份"><a href="#备份" class="headerlink" title="备份"></a>备份</h3><p>我和同事约好时间，这个时间段不操作gitlab，开始备份</p><p>进入gitlab旧机器</p><h4 id="备份数据"><a href="#备份数据" class="headerlink" title="备份数据"></a>备份数据</h4><pre><code>gitlab gitlab-rake gitlab:backup:create</code></pre><p>备份后的文件在/var/opt/gitlab/backups下</p><pre><code>1611539838_2021_01_25_12.4.2_gitlab_backup.tar</code></pre><h4 id="备份配置文件、密钥、证书"><a href="#备份配置文件、密钥、证书" class="headerlink" title="备份配置文件、密钥、证书"></a>备份配置文件、密钥、证书</h4><p>gitlab.rb是gitlab的各个配置</p><p>ca是gitlab里nginx和镜像仓库的ssl证书</p><p>ssh文件是服务器及研发的各个公钥</p><pre><code>/etc/gitlab/gitlab.rb/etc/gitlab/ca/var/opt/gitlab/.ssh</code></pre><h3 id="迁移"><a href="#迁移" class="headerlink" title="迁移"></a>迁移</h3><p>进入新机器</p><h4 id="下载镜像"><a href="#下载镜像" class="headerlink" title="下载镜像"></a>下载镜像</h4><p>找到dockerhub上gitlab的<a href="https://hub.docker.com/r/gitlab/gitlab-ce" target="_blank" rel="noopener">官方镜像</a>,下载对应版本</p><pre><code>docker pull gitlab/gitlab-ce:12.4.2-ce.0</code></pre><h4 id="创建挂载目录"><a href="#创建挂载目录" class="headerlink" title="创建挂载目录"></a>创建挂载目录</h4><pre><code>mkdir -pv /data/gitlab/{config,logs,data} </code></pre><h4 id="编写docker-compose"><a href="#编写docker-compose" class="headerlink" title="编写docker-compose"></a>编写docker-compose</h4><pre><code>vim /data/gitlab/docker-compose.yamlversion: &quot;3&quot;services:  gitlab:    image: gitlab/gitlab:12.4.2-ce.0    network_mode: bridge    user: root    ports:      - &quot;2222:22&quot;      - &quot;80:80&quot;      - &quot;443:443&quot;      - &quot;4567:4567&quot;    volumes:      - ./config:/etc/gitlab      - ./data:/var/opt/gitlab      - ./logs:/var/log/gitlab    container_name: gitlab    hostname: gitlab    restart: always    privileged: true</code></pre><p>端口号根据实际情况进行映射</p><p>注意！ssh容器不能使用22号端口，需要将端口映射到2222或其他端口，并且更改gitlab.rb文件</p><p>这个后面会讲到</p><h4 id="拷贝备份数据到本机"><a href="#拷贝备份数据到本机" class="headerlink" title="拷贝备份数据到本机"></a>拷贝备份数据到本机</h4><pre><code>gitlab.rb放在/data/gitlab/configssh和tar放在/data/gitlab/data</code></pre><h4 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h4><pre><code>cd /data/gitlabdocker-compose  up -d</code></pre><h4 id="恢复数据"><a href="#恢复数据" class="headerlink" title="恢复数据"></a>恢复数据</h4><pre><code>docker ps 等待gitlab状态是(healthy)时docker exec -it gitlab bashcd /var/opt/gitlabmv ***.tar backups/cd backupsgitlab-rake gitlab:backup:restore BACKUP=1611539838_2021_01_25_12.4.2 force=yes注：这边的文件名只取前缀，后面_gitlab_backup.tar忽略如果你看到 Restore task is done. 说明已经恢复成功了</code></pre><h1 id="后续优化"><a href="#后续优化" class="headerlink" title="后续优化"></a>后续优化</h1><p>迁移完成后，我准备重新做一套监控系统（以前都监控系统是通过gitlab集成的prom一套组件完成的</p><h2 id="将gitlab其他冗余组件关闭"><a href="#将gitlab其他冗余组件关闭" class="headerlink" title="将gitlab其他冗余组件关闭"></a>将gitlab其他冗余组件关闭</h2><p>将下列组件改为false并关闭注释</p><pre><code>grafana[&apos;enable&apos;] = falseprometheus[&apos;enable&apos;] = falsealertmanager[&apos;enable&apos;] = falsenode_exporter[&apos;enable&apos;] = falsepostgres_exporter[&apos;enable&apos;] = falseredis_exporter[&apos;enable&apos;] = falsegitlab_monitor[&apos;enable&apos;] = false</code></pre><h2 id="开启定时备份"><a href="#开启定时备份" class="headerlink" title="开启定时备份"></a>开启定时备份</h2><p>gitlab机器的3个脚本</p><ul><li>backup.sh:备份gitlab及nexus数据</li><li>backup-scp.sh:迁移gitlab、nexus数据及配置文件</li><li>backup-rm.sh:迁移后删除备份文件</li></ul><p>/opt/backups是备份nexus文件存放的URL</p><p>/data/gitlab/data/backups/是备份gitlab文件存放的URL(容器挂在的目录)</p><pre><code>vim backup.sh/usr/bin/docker exec -it gitlab gitlab-rake gitlab:backup:create/usr/bin/tar zcf /opt/backups/$(date &quot;+sonatype-work-%s.tar.gz&quot;)  /opt/sonatype-workvim backup-scp.shremote_url=root@xxx/backups/gitlab_backup_url=$(find /data/gitlab/data/backups -type f -mtime -1 -name &apos;*.tar&apos;)gitlab_etc_url=/data/gitlab/config/gitlab.rbgitlab_ssh_url=/data/gitlab/data/.ssh nexus-backup_url=$(find /opt/ -type f -mtime -1 -name &apos;*sonatype-work*.tar.gz&apos;)rsync -avzP $gitlab_ssh_url $gitlab_etc_url $gitlab_backup_url $nexus-backup_url $remote_urlvim backup-rm.shfind /data/gitlab/data/backups -mtime +7 -name &quot;*.tar&quot; -exec rm -rf {} \;find /opt/ -mtime +7 -name &quot;*sonatype-work*.tar.gz&quot; -exec rm -rf {} \;    crontab -e0 2 * * * /bin/bash /opt/backup.sh0 3 * * * /bin/bash /opt/backup-scp.sh0 0 * * 7 /bin/bash /opt/backup-rm.sh</code></pre><h1 id="报错总结"><a href="#报错总结" class="headerlink" title="报错总结"></a>报错总结</h1><h2 id="gitlab-pages启动报错"><a href="#gitlab-pages启动报错" class="headerlink" title="gitlab-pages启动报错"></a>gitlab-pages启动报错</h2><p>gitlab-pages会挂载静态页面在文件系统里</p><pre><code>gitlab-ctl tail gitlab-pages{&quot;error&quot;:&quot;Failed to bind mount /var/opt/gitlab/gitlab-rails/shared/pages on /tmp/gitlab-pages-1611628243600509859/pages. operation not permitted&quot;,&quot;level&quot;:&quot;info&quot;,&quot;msg&quot;:&quot;chroot failed&quot;,&quot;time&quot;:&quot;2021-01-26T02:30:43Z&quot;}</code></pre><p>解决方案：</p><p>由于是docker部署，需要在启动时加上–privileged ，rpm部署不会出现这个问题</p><h2 id="ssh拉取代码报错"><a href="#ssh拉取代码报错" class="headerlink" title="ssh拉取代码报错"></a>ssh拉取代码报错</h2><p>gitlab的sshd组件启动失败，原因是22号端口已经被占用</p><p>由于新机器gitlab是用docker部署的，如果直接采用22端口映射到22号端口，或者用host模式部署，都会出现一个问题，gitlab本身监听的22端口会和宿主机的22号端口冲突</p><p>所以必须采取映射方式，将外部ssh到gitlab的端口改为2222映射到内部22号端口的模式</p><p>这个一个问题是改了之后会导致研发通过ssh://git的方式拉取代码报错，提示密钥不对，如果密钥也正常的迁移到gitlab后，不会报这个错，而是因为他们git仓库的url需要更换</p><p>所以修改步骤如下</p><ul><li>删除自己本地~/.ssh/known_hosts下关于gitlab行的信息</li><li>git remote set-url origin ssh://git@gitlab.com:2222/xxx.git</li></ul><h2 id="版本不匹配问题"><a href="#版本不匹配问题" class="headerlink" title="版本不匹配问题"></a>版本不匹配问题</h2><pre><code>GitLab version mismatch:  Your current GitLab version (12.4.2) differs from the GitLab version in the backup!  Please switch to the following version and try again:  version: 13.2.0</code></pre><p>解决方案：</p><p>先升级旧机器版本，再备份数据，最后导入即可</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>至此，gitlab迁移完成，中间踩过的坑也很多，尤其是当遇见操作系统版本及gitlab版本冲突的时候，我才发现环境统一是及其有必要的（docker），早日将环境统一可以减少很多不必要的麻烦。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://blog.csdn.net/kidari/article/details/100059642" target="_blank" rel="noopener">maven nexus私有中央仓库搭建 docker nexus(sonatype/nexus3) 数据备份迁移 添加阿里云仓库</a></p><p><a href="https://www.chihiro.org.cn/archives/2019122418004138287" target="_blank" rel="noopener">Gitlab备份、迁移、恢复和升级</a></p><p><a href="https://packages.gitlab.com/gitlab/gitlab-ce" target="_blank" rel="noopener">Gitlab-CE-Packages-Download</a></p><p><a href="https://cloud.tencent.com/developer/article/1010390" target="_blank" rel="noopener">实现Shell脚本自动备份Gitlab档案并同步到远程</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Gitlab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operation Manual </tag>
            
            <tag> Gitlab </tag>
            
            <tag> Nexus </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>U盘安装Centos8</title>
      <link href="2021/01/23/linux/U-centos8-install/"/>
      <url>2021/01/23/linux/U-centos8-install/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>机器升级了，由于新主板（B460）没有centos7驱动，导致一直无法正常安装，但是centos8可以安装，一起来试试吧</p><h1 id="下载镜像并制作U盘启动盘"><a href="#下载镜像并制作U盘启动盘" class="headerlink" title="下载镜像并制作U盘启动盘"></a>下载镜像并制作U盘启动盘</h1><h2 id="下载centos镜像"><a href="#下载centos镜像" class="headerlink" title="下载centos镜像"></a>下载centos镜像</h2><p><a href="http://mirrors.aliyun.com/centos/8/isos/x86_64/CentOS-8.3.2011-x86_64-dvd1.iso" target="_blank" rel="noopener">阿里源</a></p><h2 id="UItraISO（软碟通）制作"><a href="#UItraISO（软碟通）制作" class="headerlink" title="UItraISO（软碟通）制作"></a>UItraISO（软碟通）制作</h2><p>下载UItraISO</p><p><a href="https://cn.ultraiso.net/xiazai.html" target="_blank" rel="noopener">https://cn.ultraiso.net/xiazai.html</a></p><ul><li>安装完成后点击 试用</li><li>点击文件，选择打开centos的iso文件</li><li>插好U盘</li><li>点击顶部菜单中的 启动  选择 写入硬盘映像</li><li>硬盘驱动器选择你的U盘 ，写入方式 usb+hdd+</li><li>点击写入</li></ul><p>等待制作启动盘</p><h1 id="U盘引导"><a href="#U盘引导" class="headerlink" title="U盘引导"></a>U盘引导</h1><p>注意：如果直接在已经存在的系统上装盘可能会导致异常，建议用一块新的盘或者直接把现有的盘格式化，利用老毛桃或者其他PE系统先格式化磁盘</p><ul><li>把U盘插在电脑上</li><li>开机</li><li>一般按f12或者del进入bios界面设置U盘启动</li><li>进入以下画面请将光标选择install 然后按e进行编辑</li><li>将”LABEL=Centos\x207\x20x\86_64 quiet”更换成”/dev/sda4” </li><li>操作后你的install信息如下： </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">inst.stage2&#x3D;hd:&#x2F;dev&#x2F;sda4 quiet</span><br></pre></td></tr></table></figure><ul><li>按ctrl+x安装即可进入centos安装界面</li></ul><h1 id="安装centos"><a href="#安装centos" class="headerlink" title="安装centos"></a>安装centos</h1><ul><li>语言选择英文</li><li>时区选择中国上海</li><li>安装源选择阿里源 <a href="http://mirrors.aliyun.com/centos/8/BaseOS/x86_64/os/" target="_blank" rel="noopener">http://mirrors.aliyun.com/centos/8/BaseOS/x86_64/os/</a></li><li>软件选择最小化安装</li><li>配置网络和主机名，固定一个ip并设置开机自动开启网络，根据你的实际场景来</li><li>磁盘分区 选择手动分区(I will configure partitioning)</li></ul><p>分区内容如下</p><table><thead><tr><th>目录</th><th>空间</th></tr></thead><tbody><tr><td>/boot</td><td>1024M</td></tr><tr><td>/boot/efi</td><td>200M</td></tr><tr><td>swap</td><td>2048M</td></tr><tr><td>/</td><td>剩余所有磁盘空间</td></tr></tbody></table><p>有的时候不需要分/boot/efi</p><ul><li>点击begin installation</li><li>配置root pswword</li></ul><p>等待</p><p>装好后重启即可进入centos了</p><h1 id="报错"><a href="#报错" class="headerlink" title="报错"></a>报错</h1><p>U盘启动时在install centos 7时报错</p><p>dracut-pre-udev[351]:modprobe :ERROR:could not insert ‘floppy’<br>dracut-pre-udev[351]:modprobe :ERROR:could not insert ‘edd’:No</p><p>网上找了很久</p><p>大部分说按e，修改inst.stage2=hd:LABEL=Centos\x207\x20x\86_64 quiet 为你真实U盘的设备名（/dev/sdc4或其他)</p><p>那怎么知道设备名呢</p><p>先将inst.stage2=hd:LABEL=Centos\x207\x20x\86_64 quiet改为</p><p>initrd=initrd.img linux dd quiet</p><p>按ctrl+x</p><p>可以进入主机设备界面，找到你现在的U盘的设备名</p><p>然后再重启，继续按e</p><p>修改inst.stage2=hd:LABEL=Centos\x207\x20x\86_64 quiet</p><p>为inst.stage2=hd:/dev/sdc4 quiet</p><p>按ctrl+x</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>对比centos7U盘安装，多了几个点。</p><ul><li>界面出现install的时候必须要选择U盘，nomodeset不起作用</li><li>安装时需要选择安装源，我一般就选择阿里源了</li></ul><p>以后可能centos8就慢慢普及了，就像cenots7代替centos6一样，现在学起来吧。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="hhttps://blog.csdn.net/u012798683/article/details/106645108">Centos 8 U盘安装以及安装问题处理</a></p><p><a href="https://www.cnblogs.com/iwalkman/p/11781234.html" target="_blank" rel="noopener">Centos8和7的区别（参照redhat）</a></p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Centos </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维手册——解决CI时间过长的问题</title>
      <link href="2021/01/18/bug/dbmate/"/>
      <url>2021/01/18/bug/dbmate/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近同事反馈说jenkins构建比以前慢很多很多，让我帮忙看看是什么原因导致的</p><h1 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h1><p>以前的项目开发测试环境自动构建基本上是10-20分钟以内（包含了自动化测试），生产环境构建不到1分钟（发布镜像）</p><p>现在看了jenkins几个项目的构建流程，自动化构建需要20-30分钟，生产环境构建需要10分钟左右，但是只有几个发布前端的项目还是速度不变</p><p>基本上排查下他们的区别就可以判断了</p><p>我自己测试了几次后发现速度慢在自动化执行sql这一步</p><h1 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h1><p>自动化执行sql用的工具是dbmate</p><p>如果你不知道dbmate是做什么的，那么请参考下面链接（包括但不限于）进行学习:</p><p><a href="https://github.com/amacneil/dbmate" target="_blank" rel="noopener">dbmate</a></p><p>dbmate在我如之前就已经在使用了，所以我并没有过多的关注这个组件。现在这个问题就是dbmate会执行一系列的sql（不管这些sql有没有被执行过）</p><p>按dbmate执行逻辑应该是dbmate会标记一系列sql在数据库里，如果执行过则直接跳过，速度大概在1-2秒内，特别快</p><p>我重新看了下官方文档并没看出什么问题</p><p>然后我准备做一个实验</p><h2 id="控制变量"><a href="#控制变量" class="headerlink" title="控制变量"></a>控制变量</h2><p>我在2台不同的机器上都重新下载相同版本的dbmate并配置相同的数据库及环境，测试2个不同的数据库dbmate的速度。</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><pre><code>$ sudo curl -fsSL -o /usr/local/bin/dbmate https://github.com/amacneil/dbmate/releases/latest/download/dbmate-linux-amd64$ sudo chmod +x /usr/local/bin/dbmate</code></pre><h2 id="dbmate命令及参数"><a href="#dbmate命令及参数" class="headerlink" title="dbmate命令及参数"></a>dbmate命令及参数</h2><h3 id="Commands"><a href="#Commands" class="headerlink" title="Commands"></a>Commands</h3><pre><code>dbmate --help    # print usage helpdbmate new       # generate a new migration filedbmate up        # create the database (if it does not already exist) and run any pending migrationsdbmate create    # create the databasedbmate drop      # drop the databasedbmate migrate   # run any pending migrationsdbmate rollback  # roll back the most recent migrationdbmate down      # alias for rollbackdbmate status    # show the status of all migrations (supports --exit-code and --quiet)dbmate dump      # write the database schema.sql filedbmate wait      # wait for the database server to become available</code></pre><h3 id="Command-Line-Options"><a href="#Command-Line-Options" class="headerlink" title="Command Line Options"></a>Command Line Options</h3><p>The following options are available with all commands. You must use command line arguments in the order dbmate [global options] command [command options]. Most options can also be configured via environment variables (and loaded from your .env file, which is helpful to share configuration between team members).</p><ul><li>–url, -u “protocol://host:port/dbname” - specify the database url directly. (env: $DATABASE_URL)</li><li>–env, -e “DATABASE_URL” - specify an environment variable to read the database connection URL from.</li><li>–migrations-dir, -d “./db/migrations” - where to keep the migration files. (env: $DBMATE_MIGRATIONS_DIR)</li><li>–migrations-table “schema_migrations” - database table to record migrations in. (env: $DBMATE_MIGRATIONS_TABLE)</li><li>–schema-file, -s “./db/schema.sql” - a path to keep the schema.sql file. (env: $DBMATE_SCHEMA_FILE)</li><li>–no-dump-schema - don’t auto-update the schema.sql file on migrate/rollback (env: $DBMATE_NO_DUMP_SCHEMA)</li><li>–wait - wait for the db to become available before executing the subsequent command (env: $DBMATE_WAIT)</li><li>–wait-timeout 60s - timeout for –wait flag (env: $DBMATE_WAIT_TIMEOUT)</li></ul><h2 id="实验流程"><a href="#实验流程" class="headerlink" title="实验流程"></a>实验流程</h2><p>先创建一个文件夹test以及子文件夹db,在test目录下添加一个数据库的配置信息,将sql放到db目录下，然后执行dbmate自动化语句</p><pre><code>mkdir -pv test/dbcd testvim .envDATABASE_URL=&quot;mysql://user:passwd@xxx:3306/Databases&quot;cp *.sql ./db/dbmate -s db/schema-dev.sql migrate</code></pre><h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>实际上发现新机器并没有问题，执行速度1-2秒，而只有旧机器有问题</p><p>这么问题来，旧机器是多了什么呢才导致dbmate执行这么慢呢</p><h2 id="进一步分析"><a href="#进一步分析" class="headerlink" title="进一步分析"></a>进一步分析</h2><p>我将这台故障的机器重新启动，发现仍然不行，然后我再次执行的时候后台监控进程</p><p>问题出来了</p><pre><code>ps -aux|grep dbmatemysqldump --opt --routines --no-data --skip-dump-date --skip-add-drop-table --host=mysql.com --port=3306 --user=dbmate --password=x xxxxxxxxxxxxxx mysql</code></pre><p>后台居然在执行mysqldump</p><p>我再回过头看这两台机器的区别</p><p>一台装了mysql-client 一台没有装</p><p>而装mysql-clinet是我在jenkins这台机器执行定时备份时安装的，没有想到影响了构建速度</p><h1 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h1><p>再回过头看dbmate的额外参数</p><p>其中有一项</p><p>–no-dump-schema - don’t auto-update the schema.sql file on migrate/rollback (env: $DBMATE_NO_DUMP_SCHEMA)</p><p>加上这个参数后便不执行更新schema.sql文件（写到本地）</p><p>在自动化脚本里添加这个参数后即解决构建慢的问题</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>其实dbmate默认是需要更新schema.sql文件，由于插件不带mysql-client，所以旧机器一直不能执行罢了，并不是新增的功能。</p><p>再由于最初技术选型时研发人员没有深入研究便使用技术，导致故障发生时定位过慢。</p><p>好在这个问题并没有影响生产环境，只是影响构建速度，所以造成的影响并不大。</p><p>最后总结2点</p><ul><li>技术选型时一定要慎重，尤其是用于生产环境（不管是构建流程还是应用流程）除了最重要的技术功能外，细节也不应该忽略</li><li>接手其他人的项目时一定要重新复习你不太清楚的技术，即使什么流程都没有更改，但是你需要保证流程的稳定性，你有责任掌控一切</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://github.com/amacneil/dbmate" target="_blank" rel="noopener">dbmate</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
            <tag> Operation Manual </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Centos7安装Matlab2017a</title>
      <link href="2021/01/18/gpu/matlab-install/"/>
      <url>2021/01/18/gpu/matlab-install/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>公司有图像处理的项目需要安装Matlab，开始学习下Matlab相关知识</p><h1 id="Matlab"><a href="#Matlab" class="headerlink" title="Matlab"></a>Matlab</h1><p>MATLAB（Matrix Laboratory，矩阵实验室）是由美国The MathWorks公司出品的商业数学软件。MATLAB是一种用于算法开发、数据可视化、数据分析以及数值计算的高级技术计算语言和交互式环境。除矩阵运算、绘制函数/数据图像等常用功能外，MATLAB还可用来创建用户界面，以及调用其它语言（包括C、C++、Java、Python、FORTRAN）编写的程序。</p><p>MATLAB主要用于数值运算，但利用为数众多的附加工具箱，它也适合不同领域的应用，例如控制系统设计与分析、影像处理、深度学习、信号处理与通讯、金融建模和分析等。另外还有配套软件包Simulink提供可视化开发环境，常用于系统模拟、动态/嵌入式系统开发等方面。</p><p>在R2017b后的MATLAB版本更发布了深度学习的工具，使其能够可视化的快速创建AI模型，并透过各种转码器，部属于嵌入式硬件之中。</p><p>截至2020年，MATLAB在全球拥有超过400万用户。MATLAB用户来自工程，科学和经济学领域。</p><h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><ul><li>Matlab文件</li></ul><p>R2017a_glnxa64_dvd1.iso</p><p>R2017a_glnxa64_dvd2.iso</p><p>Matlab 2017a Linux64 Crack.tar.gz</p><p>文件自行百度，这里不提供</p><ul><li>ISO存储目录</li></ul><p>/opt/2017a</p><ul><li>安装进行时目录</li></ul><p>/opt/matlab</p><ul><li>存储目录</li></ul><p>/opt/MATLAB</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><h2 id="下载文件到下面目录"><a href="#下载文件到下面目录" class="headerlink" title="下载文件到下面目录"></a>下载文件到下面目录</h2><pre><code>ll /opt/2017alicense_standalone.liclibmwservices.soR2017a_glnxa64_dvd1.isoR2017a_glnxa64_dvd2.iso activate.ini activate.int文件内容isSilent=trueactivateCommand=activateOfflinelicenseFile=/opt/2017a/license_standalone.lic   </code></pre><h2 id="挂载ISO文件"><a href="#挂载ISO文件" class="headerlink" title="挂载ISO文件"></a>挂载ISO文件</h2><pre><code>mkdir /opt/matlabsudo mount -t auto -o loop /opt/2017a/R2017a_glnxa64_dvd1.iso /opt/matlab</code></pre><h2 id="静默安装"><a href="#静默安装" class="headerlink" title="静默安装"></a>静默安装</h2><h3 id="安装iso1"><a href="#安装iso1" class="headerlink" title="安装iso1"></a>安装iso1</h3><pre><code>/opt/matlab/install -destinationFolder /opt/MATLAB/R2017a -fileInstallationKey 09806-07443-53955-64350-21751-41297 -agreeToLicense yes -outputFile /opt/2017a/matlab_install.log -mode silent -activationPropertiesFile  -licensePath /opt/2017a/license_standalone.lic</code></pre><h3 id="安装iso2"><a href="#安装iso2" class="headerlink" title="安装iso2"></a>安装iso2</h3><p>安装过程中提示Info: Eject DVD 1 and insert DVD 2 to continue.</p><p>再开一个终端执行</p><pre><code>sudo mount -t auto -o loop /opt/2017a/R2017a_glnxa64_dvd2.iso /opt/matlab</code></pre><h3 id="安装成功"><a href="#安装成功" class="headerlink" title="安装成功"></a>安装成功</h3><pre><code>Exiting with status 0End - Successful.Finished</code></pre><h2 id="激活"><a href="#激活" class="headerlink" title="激活"></a>激活</h2><pre><code>cp /opt/2017a/libmwservices.so /opt/MATLAB/R2017a/bin/glnxa64//opt/MATLAB/R2017a/bin/activate_matlab.sh -propertiesFile /opt/2017a/activate.ini </code></pre><h2 id="测试验证"><a href="#测试验证" class="headerlink" title="测试验证"></a>测试验证</h2><pre><code>vim test.mdisp(&quot;hello, world!&quot;)disp(argument1)执行shell命令:matlab -nodisplay -r &quot;argument1=10010;test&quot;输出结果hello, world!   10010</code></pre><h2 id="添加环境变量"><a href="#添加环境变量" class="headerlink" title="添加环境变量"></a>添加环境变量</h2><pre><code>vim /etc/profileexport MATLAB_HOME=/opt/2017aexport PATH=$PATH:$MATLAB_HOME/binexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$MATLAB_HOME/runtime/glnxa64source /etc/profile</code></pre><h1 id="matlab报错总结"><a href="#matlab报错总结" class="headerlink" title="matlab报错总结"></a>matlab报错总结</h1><h2 id="lib64-libstdc-so-6-version-CXXABI-1-3-8’-not-found"><a href="#lib64-libstdc-so-6-version-CXXABI-1-3-8’-not-found" class="headerlink" title="/lib64/libstdc++.so.6: version `CXXABI_1.3.8’ not found"></a>/lib64/libstdc++.so.6: version `CXXABI_1.3.8’ not found</h2><pre><code>[main] org.apache.hadoop.mapred.YarnChild: Error running child : java.lang.UnsatisfiedLinkError: /data/2017a/bin/glnxa64/libnativedl.so: /lib64/libstdc++.so.6: version `CXXABI_1.3.8&apos; not found (required by /data/2017a/bin/glnxa64/libnativedl.so)</code></pre><p>问题分析</p><p>因为与MATLAB一起打包的该特定库的版本和Linux操作系统随附的版本对比要旧一些，这会导致兼容性问题。</p><p>解决方案</p><p>使用conda的lib包作为系统默认的包或者去网上下载libstdc++的最新源码编译后更换现有的包</p><p>注意:由于操作系统、系统lib包、conda的安装目录可能不相同，请不要随意用网上的so文件或直接照搬命令里的绝对路径</p><p>例如下面是centos7的绝对路径</p><pre><code>cp /opt/anaconda3/lib/libstdc++.so.6.0.26 /usr/lib64/ln -sf  /usr/lib64/libstdc++.so.6.0.26  /usr/lib64/libstdc++.so.6</code></pre><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://blog.csdn.net/weixin_43839173/article/details/103232861" target="_blank" rel="noopener">centos 7安装matlab的两种方法（桌面安装和命令行安装）</a></p><p><a href="https://zh.wikipedia.org/wiki/MATLAB" target="_blank" rel="noopener">MATLAB百科</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Matlab </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Matlab </tag>
            
            <tag> C </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Centos7安装opencv</title>
      <link href="2021/01/16/gpu/opencv-install-centos7/"/>
      <url>2021/01/16/gpu/opencv-install-centos7/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>由于服务器更换操作系统，所以需要重新部署一套C环境</p><h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><ul><li>操作系统：centos7</li><li>opencv版本：3.3.1</li><li>conda版本：4.8.2</li><li>python版本：3.7.6</li></ul><h1 id="下载与安装"><a href="#下载与安装" class="headerlink" title="下载与安装"></a>下载与安装</h1><h2 id="安装Conda及Python"><a href="#安装Conda及Python" class="headerlink" title="安装Conda及Python"></a>安装Conda及Python</h2><pre><code>wget https://repo.anaconda.com/archive/Anaconda3-2020.02-Linux-x86_64.shchmod +x Anaconda3-2020.02-Linux-x86_64.sh#安装时已经自动添加到环境变量中#export PATH=$HOME/anaconda3/bin/:$PATH# 安装 python 3.7.6conda install python=3.7.6$ pythonPython 3.7.6 (default, Jan  8 2020, 19:59:22)[GCC 7.3.0] :: Anaconda, Inc. on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt;$ which pip/data/anaconda3/bin/pip</code></pre><h2 id="安装opencv"><a href="#安装opencv" class="headerlink" title="安装opencv"></a>安装opencv</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;codeload.github.com&#x2F;opencv&#x2F;opencv&#x2F;tar.gz&#x2F;3.3.1   -O opencv3.3.1.tar.gz &amp;&amp; tar -zxvf opencv-3.3.1.tar.gz</span><br><span class="line">mkdir opencv-3.3.1&#x2F;build</span><br></pre></td></tr></table></figure><h2 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h2><h3 id="安装opencv相关库"><a href="#安装opencv相关库" class="headerlink" title="安装opencv相关库"></a>安装opencv相关库</h3><pre><code>sudo yum install -y cmake gcc gcc-c++ gtk+-devel gimp-devel gimp-devel-tools gimp-help-browser zlib-devel libtiff-devel libjpeg-devel libpng-devel gstreamer-devel libavc1394-devel libraw1394-devel libdc1394-devel jasper-devel jasper-utils swig python libtool nasmyum install ffmpeg-devel --失败，需要下载源码编译安装或者通过第三方yum源安装。</code></pre><p>下面介绍通过第三方yum源安装</p><pre><code>yum install epel-releaseyum localinstall --nogpgcheck https://download1.rpmfusion.org/free/el/rpmfusion-free-release-7.noarch.rpmyum install ffmpeg ffmpeg-develffmpeg -versionffmpeg version 3.4.8 Copyright (c) 2000-2020 the FFmpeg developersbuilt with gcc 4.8.5 (GCC) 20150623 (Red Hat 4.8.5-39)</code></pre><h2 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h2><p>注意：不要随便执行make -j，可能会把服务器跑挂</p><p>参考你自己机器点CPU和内存大小去选择-j的数量</p><p>编译失败需要build目录执行make clean 再cmake和make</p><p>或者直接删除build目录，再重头来遍</p><pre><code>cd opencv-3.3.1/build/cmake -D CMAKE_BUILD_TYPE=RELEASE -D  CMAKE_INSTALL_PREFIX=/data/anaconda3 -D CMAKE_CXX_FLAGS:STRING=-fpermissive  INSTALL_PYTHON_EXAMPLES=ON  -D INSTALL_C_EXAMPLES=OFF  -D  PYTHON_EXCUTABLE=/data/anaconda3/bin/python -D WITH_TBB=ON -D WITH_V4L=ON   -D WITH_GTK=ON  -D WITH_OPENGL=ON -D BUILD_EXAMPLES=ON ..make -j2</code></pre><h2 id="安装及动态库链接"><a href="#安装及动态库链接" class="headerlink" title="安装及动态库链接"></a>安装及动态库链接</h2><pre><code>sudo make installsudo ldconfig</code></pre><h2 id="安装eigen"><a href="#安装eigen" class="headerlink" title="安装eigen"></a>安装eigen</h2><pre><code>yum install eigen3-devel -y</code></pre><h2 id="验证成功"><a href="#验证成功" class="headerlink" title="验证成功"></a>验证成功</h2><p>执行python，引入cv2不报错即可完成</p><pre><code>$ pythonPython 3.7.6 (default, Jan  8 2020, 19:59:22)[GCC 7.3.0] :: Anaconda, Inc. on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import cv2&gt;&gt;&gt;</code></pre><h1 id="报错总结"><a href="#报错总结" class="headerlink" title="报错总结"></a>报错总结</h1><h2 id="添加动态链接库失败"><a href="#添加动态链接库失败" class="headerlink" title="添加动态链接库失败"></a>添加动态链接库失败</h2><p>ldconfig后 python import cv2报错找不到opencv编译后的几个包</p><pre><code>ldconfig -p |grep libopencv_core.so.3.3找不到动态链接库</code></pre><p>解决问题</p><pre><code>vim /etc/ld.so.conf添加一行opencv的lib路径/opt/opencv-3.3.1/build/lib/ldconfigldconfig -p |grep libopencv_core.so.3.3libopencv_core.so.3.3 (libc6,x86-64) =&gt; /opt/opencv-3.3.1/build/lib/libopencv_core.so.3.3</code></pre><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>centos7对比之前ubuntu16安装opencv轻松很多，也是第一次踩过坑之后基本上没啥报错就能成功安装。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://linuxize.com/post/how-to-install-ffmpeg-on-centos-7/" target="_blank" rel="noopener">How to Install and Use FFmpeg on CentOS 7</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> OpenCV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C </tag>
            
            <tag> OpenCV </tag>
            
            <tag> Conda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维手册——Centos7网络超时断开(后传)</title>
      <link href="2021/01/04/bug/network-timeout-2/"/>
      <url>2021/01/04/bug/network-timeout-2/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>上篇已经介绍了，Centos7网卡中断，到最后都没有解决完成。</p><p>这个问题在最近又开始出现了，我这次换了一个思路来解决。</p><h1 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h1><p>现在的机器是一台12c 64g的服务器，性能比之前那台高不要太多，但是发现这台机器还是经常出现之前的报错：网卡中断，只能重启解决。</p><p>经过持续1个月的跟踪，我发现引发的问题的关键在nginx，无论我把nginx部署在哪台机器，都可能引发这个问题。</p><p>因为现象特别难复现，我专门蹲点（当有人喊xxx不能用的时候我就去那台机器调试）去尝试解决。</p><p>根据我部署的监控大盘数据分析，我得出了一个结论，这台机器的网络流量达到200-300MBS的时候就可能出现网卡中断的情况，但是机器并不是在峰值的时候就网卡中断，而是在峰值过后一段时间才出现这种情况。</p><h1 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h1><h2 id="Nginx调优"><a href="#Nginx调优" class="headerlink" title="Nginx调优"></a>Nginx调优</h2><p>我用的是我自己优化的一套配置方案，用了很久，我现在质疑我现在的优化是否存在问题，对比如下</p><ul><li>优化前</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">worker_processes  1;</span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections  1024;</span><br><span class="line">&#125;</span><br><span class="line">http &#123;</span><br><span class="line">    include       mime.types;</span><br><span class="line">    default_type  application&#x2F;octet-stream;</span><br><span class="line">    sendfile        on;</span><br><span class="line">    keepalive_timeout  65;</span><br></pre></td></tr></table></figure><ul><li>优化后</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">user root;</span><br><span class="line">worker_processes auto;</span><br><span class="line">worker_cpu_affinity auto;</span><br><span class="line">worker_rlimit_nofile 65535;</span><br><span class="line">error_log &#x2F;var&#x2F;log&#x2F;nginx&#x2F;error.log;</span><br><span class="line">pid &#x2F;run&#x2F;nginx.pid;</span><br><span class="line"></span><br><span class="line">include &#x2F;usr&#x2F;share&#x2F;nginx&#x2F;modules&#x2F;*.conf;</span><br><span class="line"></span><br><span class="line">events &#123;</span><br><span class="line">    use epoll;</span><br><span class="line">    worker_connections 65535;</span><br><span class="line">    multi_accept on;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">    log_format  main  &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39;</span><br><span class="line">                      &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39;</span><br><span class="line">                      &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;;</span><br><span class="line"></span><br><span class="line">    access_log  &#x2F;var&#x2F;log&#x2F;nginx&#x2F;access.log  main;</span><br><span class="line"></span><br><span class="line">    sendfile            on;</span><br><span class="line">    tcp_nopush          on;</span><br><span class="line">    tcp_nodelay         on;</span><br><span class="line">    keepalive_timeout   65;</span><br><span class="line">    types_hash_max_size 2048;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    include             &#x2F;etc&#x2F;nginx&#x2F;mime.types;</span><br><span class="line">    default_type        application&#x2F;octet-stream;</span><br><span class="line"></span><br><span class="line">    gzip on;</span><br><span class="line">    gzip_min_length 1k;</span><br><span class="line">    gzip_buffers 4 16k;</span><br><span class="line">    gzip_http_version 1.1;</span><br><span class="line">    gzip_comp_level 2;</span><br><span class="line">    gzip_types text&#x2F;css text&#x2F;xml application&#x2F;javascript;</span><br><span class="line">    gzip_vary on;</span><br><span class="line"></span><br><span class="line">    include &#x2F;etc&#x2F;nginx&#x2F;com&#x2F;*.conf;</span><br></pre></td></tr></table></figure><p>我的调优参数主要添加了</p><ul><li>CPU多核优化</li><li>epoll I/O多路复用模型</li><li>TCP优化</li><li>链接参数优化</li><li>Gzip压缩</li></ul><p>经过测试，我发现不调优的Nginx出现问题的频率更高（还是需要调优的）</p><h2 id="Nginx并发和带宽瓶颈"><a href="#Nginx并发和带宽瓶颈" class="headerlink" title="Nginx并发和带宽瓶颈"></a>Nginx并发和带宽瓶颈</h2><p>经过查询资料发现</p><p>Nginx的CPU,内存和IO的利用方面是非常高效的</p><p>通过监控图也看出来来，基本占用不了很高的资源</p><p>下面看看并发和带宽的影响</p><h3 id="并发"><a href="#并发" class="headerlink" title="并发"></a>并发</h3><p>max_clients</p><p>这个参数没有出现在nginx的配置文件中</p><p>查资料发现</p><p>作为http web服务器角色的nginx能够处理的最大连接数就是最大客户端连接数。</p><p>最大客户端连接数计算公式为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">max_clients &#x3D; worker_processes * worker_connections;</span><br></pre></td></tr></table></figure><p>作为反向代理服务器角色的nginx，用户发送请求到nginx，nginx发送请求到后端被代理服务器，后端服务器响应给nginx，nginx将内容返回给用户。nginx需要保持2个链接，所以最大的客户端连接数为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">max_clients &#x3D; worker_processes * worker_connections&#x2F;2;</span><br></pre></td></tr></table></figure><p>而目前这台机器是6c，主要功能也是反向代理，所以理论上它的并发是6*65535/2=196,605</p><p>而通过监控和日志，每秒钟并发也就50-300</p><p>远远低于nginx的最大并发</p><p>所以并发这块我认为没什么问题</p><h3 id="带宽"><a href="#带宽" class="headerlink" title="带宽"></a>带宽</h3><p>我开始查询Nginx带宽限流策略，抓住几个主要流量的server进行调试</p><p>限流算法主要思想如下：</p><p>令牌桶算法</p><ul><li>令牌以固定速率产生，并缓存到令牌桶中；</li><li>令牌桶放满时，多余的令牌被丢弃；</li><li>请求要消耗等比例的令牌才能被处理；</li><li>令牌不够时，请求被缓存。</li></ul><p>漏桶算法</p><ul><li>水（请求）从上方倒入水桶，从水桶下方流出（被处理）；</li><li>来不及流出的水存在水桶中（缓冲），以固定速率流出；</li><li>水桶满后水溢出（丢弃）。</li><li>这个算法的核心是：缓存请求、匀速处理、多余的请求直接丢弃。</li></ul><p>从作用上来说，漏桶和令牌桶算法最明显的区别就是是否允许突发流量(burst)的处理，漏桶算法能够强行限制数据的实时传输（处理）速率，对突发流量不做额外处理；而令牌桶算法能够在限制数据的平均传输速率的同时允许某种程度的突发传输。</p><p>Nginx按请求速率限速模块使用的是漏桶算法，即能够强行保证请求的实时处理速度不会超过设置的阈值。</p><p>但是我们的场景应该需要令牌桶算法，不允许超过一个带宽值，但是又不能丢弃一个请求。</p><p>不过我测试配置了Nginx限流，多出的请求会返回503，影响用户体验。</p><h2 id="操作系统带宽"><a href="#操作系统带宽" class="headerlink" title="操作系统带宽"></a>操作系统带宽</h2><p>没办法，看看能不能从操作系统的级别来限制带宽。</p><p>经过查询资料，通过限制网卡的速率来达到限流</p><pre><code>限速百兆:ethtool -s enp10s0 speed 100 autoneg off恢复千兆:ethtool -s enp10s0 speed 1000 autoneg on</code></pre><p>执行限速百兆后，我明显感觉所有项目速度变慢</p><p>没办法，还是恢复吧，比起中断，一直慢速的体验会令人感到更差</p><h1 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h1><h2 id="非根本解决法"><a href="#非根本解决法" class="headerlink" title="非根本解决法"></a>非根本解决法</h2><p>查了一圈我表示以我目前的能力很难解决问题，先来个自动重启脚本吧</p><h3 id="编写脚本"><a href="#编写脚本" class="headerlink" title="编写脚本"></a>编写脚本</h3><p>172.31.20.1是路由器</p><p>172.31.20.2是DNS服务器</p><p>如果这2个机器我都不能ping通即可说明这台机器已经和局域网失去了连接</p><p>并且可能存在某些异常情况导致服务器不能上网的时候，我要在启动这个脚本前留足缓冲时间，以便自己操作，时间设为600秒</p><pre><code>vim /opt/ping-check.sh#!/bin/bashsleep 600while truedo   ping -c 3 -w 5 172.31.20.1   if [[ $? != 0 ]];then         ping -c 3 -w 5 172.31.20.2         if [[ $? != 0 ]];then              echo `date +&quot;%Y-%m-%d %H:%M:%S&quot;` &gt;&gt; /opt/restart.log              reboot         fi   fi   sleep 20donechmod +x /opt/ping-check.sh</code></pre><h3 id="将脚本加入system并开机自启"><a href="#将脚本加入system并开机自启" class="headerlink" title="将脚本加入system并开机自启"></a>将脚本加入system并开机自启</h3><pre><code>cd /usr/lib/systemd/systemvim ping-check.service[Unit]Description=check networkAfter=network.target remote-fs.target nss-lookup.target[Service]Type=forkingExecStart=/bin/bash -c &apos;nohup /bin/bash  /opt/ping-check.sh  &amp; echo $! &gt; /opt/ping-check.pid&apos;ExecStop=/bin/bash -c &apos;cat /opt/ping-check.pid |xargs kill -9&apos;[Install]WantedBy=multi-user.targetchmod 644 ping-check.servicesystemctl start ping-check.servicesystemctl enable ping-check.servicesystemctl status ping-check.service</code></pre><h2 id="根本解决问题"><a href="#根本解决问题" class="headerlink" title="根本解决问题"></a>根本解决问题</h2><p>编写完脚本后，感觉服务器不用自己重启了很方便，但是经过1个多星期的观察，平均服务器每天都要重启3-5次，在高峰的时候甚至刚刚启动就断网。</p><p>最后想了下，换网卡吧。</p><p>都是千兆网卡，我把这台机器的服务换到公司配置最高的服务器上，观察一段时间没问题。</p><p>那台机器还做了双网卡绑定，带宽更高。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>最终把这个问题解决了，持续跟踪了近2个月，收获不少，恶补了很多知识。</p><p>以后遇见这个问题直接换网卡或者采用多网卡绑定即可，软件层面太难啦。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://blog.csdn.net/sole_cc/article/details/52433353" target="_blank" rel="noopener">nginx最大并发连接数的思考</a></p><p><a href="https://serverfault.com/questions/422613/does-this-prove-a-network-bandwidth-bottleneck" target="_blank" rel="noopener">Does this prove a network bandwidth bottleneck?</a></p><p><a href="https://www.cnblogs.com/chanix/p/12743504.html" target="_blank" rel="noopener">linux 限制带宽方案</a></p><p><a href="https://www.cnblogs.com/hukey/p/10498544.html" target="_blank" rel="noopener">Nginx - 限制并发、限制访问速率、限制流量</a></p><p><a href="https://www.cnblogs.com/biglittleant/p/8979915.html" target="_blank" rel="noopener">死磕nginx系列–nginx 限流配置</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operation Manual </tag>
            
            <tag> Centos </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>年终总结(2020)</title>
      <link href="2020/12/31/summary/summary-2020-all/"/>
      <url>2020/12/31/summary/summary-2020-all/</url>
      
        <content type="html"><![CDATA[<p>2020年无疑是改变我命运的一年。</p><p>安于现状，主动思考，付诸行动，收获回报。</p><p>以上四个状态能大体反应我今年的个人走势。</p><p>总结什么呢？</p><p>也许在我看来，最重要的就是思考吧。</p><p>人活一辈子，如果连自己独立思考的能力都没有，岂不是和行尸走肉无异？</p><p>何其不幸，我当了22年的行尸走肉;何其有幸，我才刚刚新生！</p><p>思考自己该如何学习，如何进步，如何买房买车，如何进入大城市，如何完成自己的梦想，并能思考出一套切实可行的方案并有条不紊地执行。</p><p>第二重要的即收获。</p><p>收获不仅仅是物质上的，更多的是自己的格局、知识、人脉。</p><p>在疫情期间换工作，我付出了相当大的努力，也最终获得了相应地收获，这使我更加坚信努力一定有回报。</p><p>来到深圳，我看到了年轻人热血拼搏地一面，看到了资本市场涌动的一面，看到了离实现自己梦想最近的一面。</p><p>我加入了一个非常年轻、强韧、包容的团队，这个团队能给我挑战自我的机会，能给我证明自己价值的机会。</p><p>不到半年的时间，我帮助团队建设了一套相对完整但不完善的运维体系，致力于提升每个人的工作效率，保证公司站点的可靠性，为公司尽我所能节省一切资源开销。</p><p>在我看来，不单单是我单方面地付出,公司也成就了我。</p><p>我的缺点在公司被同事及时指出。</p><p>我的责任意识在公司得到明显地增强。</p><p>我的能力在公司发挥的淋漓尽致。</p><p>一个包容的团队是能给你很多失错的机会，但是在SRE眼中，每一次试错都可能让公司蒙受重大损失。这个指标来源我自己的定位，公司虽然没有要求，但是我必须保证在我能力范围内的万无一失，经历了这么多事情后，我也学会了敬畏、冷静、尊重。</p><p>感谢Bees360，能加入是我的荣幸，未来请多指教。</p><p>年底回武汉，我下了很大的决心把户口、档案、社保、公积金全部转到深圳，即使想到未来可能在深圳混不下去，到时候再滚回武汉也无所谓，但是我一定要我现在全力以赴地为了扎根深圳，破釜沉舟！</p><p>后来又找了以前的老朋友、同事，一起吃饭聊天，回想起当初一起成长的时光，感叹时光流逝真快，我们更应该珍惜当下来之不易的感情。</p><p>然后大病一场，感冒发烧打针2天，最后检查不是新冠，我也就松了口气。</p><p>2021，我的本命年。</p><p>我的愿望是在本命年，吃尽可能多的亏，挨尽可能毒的打，并坚强地活过去。</p><p>因为我才刚刚新生啊，不吃苦中苦，难为人上人。这23年以来我吃的苦真的太少了。</p><p>最后总结下一个感悟：</p><p>世界上只有一种真正的英雄主义，那就是在认清生活的真相后，依然热爱生活。</p>]]></content>
      
      
      <categories>
          
          <category> 个人总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 个人总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu16.04安装opencv</title>
      <link href="2020/12/28/gpu/opencv-install/"/>
      <url>2020/12/28/gpu/opencv-install/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>公司有图像处理的项目需要安装opencv，基本都是C相关的组件（我的盲区），开始学习下opencv相关知识</p><h1 id="简单了解"><a href="#简单了解" class="headerlink" title="简单了解"></a>简单了解</h1><h2 id="Conda"><a href="#Conda" class="headerlink" title="Conda"></a>Conda</h2><p>Conda是一个开源跨平台语言无关的包管理与环境管理系统。由“连续统分析”（Continuum Analytics）基于BSD许可证发布。</p><p>Conda允许用户方便地安装不同版本的二进制软件包与该计算平台需要的所有库。还允许用户在不同版本的包之间切换、从一个软件仓库下载包并安装。</p><p>Conda是用Python语言开发，但能管理其他编程语言的项目（如R语言），包括多语言项目。 Conda可安装Python语言的包，类似于其他基于Python的跨平台包管理器（如wheel 页面存档备份，存于互联网档案馆或pip）。</p><h2 id="opencv"><a href="#opencv" class="headerlink" title="opencv"></a>opencv</h2><p>opencv的全称是：Open Source Computer Vision Library</p><p>opencv是Intel开源计算机视觉库。它由一系列 C 函数和少量 C++ 类构成，实现了图像处理和计算机视觉方面的很多通用算法。</p><h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><ul><li>操作系统：ubuntu16.04</li><li>opencv版本：3.3.1</li><li>conda版本：4.8.2</li><li>python版本：3.7.6</li></ul><h1 id="下载与安装"><a href="#下载与安装" class="headerlink" title="下载与安装"></a>下载与安装</h1><h2 id="安装Conda及Python"><a href="#安装Conda及Python" class="headerlink" title="安装Conda及Python"></a>安装Conda及Python</h2><pre><code>wget https://repo.anaconda.com/archive/Anaconda3-2020.02-Linux-x86_64.shchmod +x Anaconda3-2020.02-Linux-x86_64.sh#安装时已经自动添加到环境变量中#export PATH=$HOME/anaconda3/bin/:$PATH# 安装 python 3.7.6conda install python=3.7.6$ pythonPython 3.7.6 (default, Jan  8 2020, 19:59:22)[GCC 7.3.0] :: Anaconda, Inc. on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt;$ which pip/home/ubuntu/anaconda3/bin/pip</code></pre><h2 id="安装opencv"><a href="#安装opencv" class="headerlink" title="安装opencv"></a>安装opencv</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;codeload.github.com&#x2F;opencv&#x2F;opencv&#x2F;tar.gz&#x2F;3.3.1   -O opencv3.3.1.tar.gz &amp;&amp; tar -zxvf opencv-3.3.1.tar.gz</span><br><span class="line">mkdir opencv-3.3.1&#x2F;build</span><br></pre></td></tr></table></figure><h2 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h2>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">  ## 安装opencv相关库</span><br><span class="line">  sudo apt-get update</span><br><span class="line">  sudo apt-get install build-essential pkg-config cmake cmake-gui \</span><br><span class="line">python-devel checkinstall yasm gfortran git \</span><br><span class="line">ffmpeg x264 v4l-utils \</span><br><span class="line">libgtk-3-dev libjpeg8-dev libtiff5-dev \</span><br><span class="line">libavcodec-dev libavformat-dev libswscale-dev \</span><br><span class="line">libavresample-dev libgphoto2-dev libtiff-dev \</span><br><span class="line">libdc1394-22-dev libxine2-dev libv4l-dev \</span><br><span class="line">libqt4-dev libgtk2.0-dev libtbb-dev \</span><br><span class="line">libatlas-base-dev libfaac-dev libmp3lame-dev \</span><br><span class="line">libtheora-dev libvorbis-dev libxvidcore-dev \</span><br><span class="line">libopencore-amrnb-dev libopencore-amrwb-dev libxvidcore4</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  ## 安装python相关库</span><br><span class="line">  pip install numpy scipy matplotlib scikit-image scikit-learn</span><br></pre></td></tr></table></figure><h2 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h2><p>注意：不要随便执行make -j，可能会把服务器跑挂</p><p>参考你自己机器点CPU和内存大小去选择-j的数量</p><p>编译失败需要build目录执行make clean 再cmake和make</p><p>或者直接删除build目录，再重头来遍</p><pre><code>cd opencv-3.3.1/build/cmake -D CMAKE_BUILD_TYPE=RELEASE -D  CMAKE_INSTALL_PREFIX=/home/ubuntu/anaconda3 -D CMAKE_CXX_FLAGS:STRING=-fpermissive  INSTALL_PYTHON_EXAMPLES=ON  -D INSTALL_C_EXAMPLES=OFF  -D  PYTHON_EXCUTABLE=/home/ubuntu/anaconda3/bin/python -D WITH_TBB=ON -D WITH_V4L=ON   -D WITH_GTK=ON  -D WITH_OPENGL=ON -D BUILD_EXAMPLES=ON ..make -j2</code></pre><h2 id="安装及动态库链接"><a href="#安装及动态库链接" class="headerlink" title="安装及动态库链接"></a>安装及动态库链接</h2><pre><code>sudo make installsudo ldconfig</code></pre><h2 id="安装eigen"><a href="#安装eigen" class="headerlink" title="安装eigen"></a>安装eigen</h2><pre><code>sudo apt-get install libeigen3-dev</code></pre><h2 id="验证成功"><a href="#验证成功" class="headerlink" title="验证成功"></a>验证成功</h2><p>执行python，引入cv2不报错即可完成</p><pre><code>$ pythonPython 3.7.6 (default, Jan  8 2020, 19:59:22)[GCC 7.3.0] :: Anaconda, Inc. on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import cv2&gt;&gt;&gt;</code></pre><h1 id="报错总结"><a href="#报错总结" class="headerlink" title="报错总结"></a>报错总结</h1><h2 id="pip报错"><a href="#pip报错" class="headerlink" title="pip报错"></a>pip报错</h2><p>不管是执行pip还是pip3 install 或者-v 都返回下面的错误</p><pre><code>Traceback (most recent call last):File &quot;/home/myuser/.local/bin/pip&quot;, line 7, in &lt;module&gt;from pip._internal import mainImportError: No module named &apos;pip._internal&apos;</code></pre><p>解决方法</p><pre><code>python2 -m pip install --user --upgrade pippython3 -m pip install --user --upgrade pip</code></pre><h2 id="cmake缺包"><a href="#cmake缺包" class="headerlink" title="cmake缺包"></a>cmake缺包</h2><pre><code>-- checking for module &apos;gstreamer-base-1.0&apos;--   package &apos;gstreamer-base-1.0&apos; not found-- checking for module &apos;gstreamer-video-1.0&apos;--   package &apos;gstreamer-video-1.0&apos; not found</code></pre><p>解决方法</p><pre><code>apt-get install 包名</code></pre><p>注意有些包的包名不一定是报错的包名</p><p>例如：</p><p>“libavresample libgphoto2”<br>的实际安装包名为<br>“libavresample-dev libgphoto2-dev”</p><h2 id="编译报错"><a href="#编译报错" class="headerlink" title="编译报错"></a>编译报错</h2><h3 id="内存不足"><a href="#内存不足" class="headerlink" title="内存不足"></a>内存不足</h3><pre><code>[ 87%] Built target example_tracking_tutorial_multitrackerScanning dependencies of target gen_opencv_python_source[ 87%] Generate files for Python bindings and documentationNote: Class Feature2D has more than 1 base class (not supported by Python C extensions)Bases: cv::Algorithm, cv::class, cv::Feature2D, cv::AlgorithmOnly the first base class will be used[ 87%] Built target gen_opencv_python_sourceScanning dependencies of target opencv_python3[ 87%] Building CXX object modules/python3/CMakeFiles/opencv_python3.dir//src2/cv2.cpp.oc++: internal compiler error: Killed (program cc1plus)Please submit a full bug report,with preprocessed source if appropriate.See file:///usr/share/doc/gcc-6/README.Bugs for instructions.modules/python3/CMakeFiles/opencv_python3.dir/build.make:62: recipe for target &apos;modules/python3/CMakeFiles/opencv_python3.dir//src2/cv2.cpp.o&apos; failedmake[2]: *** [modules/python3/CMakeFiles/opencv_python3.dir/__/src2/cv2.cpp.o] Error 4CMakeFiles/Makefile2:24789: recipe for target &apos;modules/python3/CMakeFiles/opencv_python3.dir/all&apos; failedmake[1]: *** [modules/python3/CMakeFiles/opencv_python3.dir/all] Error 2Makefile:160: recipe for target &apos;all&apos; failedmake: *** [all] Error 2</code></pre><p>解决方法</p><p>开线程数少点</p><pre><code>make -j2</code></pre><h3 id="undefined-reference-to-TIFFReadDirectory-LIBTIFF-4-0’"><a href="#undefined-reference-to-TIFFReadDirectory-LIBTIFF-4-0’" class="headerlink" title="undefined reference to `TIFFReadDirectory@LIBTIFF_4.0’"></a>undefined reference to `TIFFReadDirectory@LIBTIFF_4.0’</h3><pre><code>[ 61%] Building CXX object modules/features2d/CMakeFiles/opencv_features2d.dir/src/kaze/KAZEFeatures.cpp.o../../lib/libopencv_imgcodecs.so.3.3.1: undefined reference to `TIFFReadDirectory@LIBTIFF_4.0&apos;../../lib/libopencv_imgcodecs.so.3.3.1: undefined reference to `TIFFWriteEncodedStrip@LIBTIFF_4.0&apos;../../lib/libopencv_imgcodecs.so.3.3.1: undefined reference to `TIFFIsTiled@LIBTIFF_4.0&apos;../../lib/libopencv_imgcodecs.so.3.3.1: undefined reference to `TIFFOpen@LIBTIFF_4.0&apos;../../lib/libopencv_imgcodecs.so.3.3.1: undefined reference to `TIFFReadEncodedStrip@LIBTIFF_4.0&apos;../../lib/libopencv_imgcodecs.so.3.3.1: undefined reference to `TIFFSetField@LIBTIFF_4.0&apos;../../lib/libopencv_imgcodecs.so.3.3.1: undefined reference to `TIFFWriteScanline@LIBTIFF_4.0&apos;../../lib/libopencv_imgcodecs.so.3.3.1: undefined reference to `TIFFGetField@LIBTIFF_4.0&apos;../../lib/libopencv_imgcodecs.so.3.3.1: undefined reference to `TIFFScanlineSize@LIBTIFF_4.0&apos;../../lib/libopencv_imgcodecs.so.3.3.1: undefined reference to `TIFFNumberOfStrips@LIBTIFF_4.0&apos;../../lib/libopencv_imgcodecs.so.3.3.1: undefined reference to `TIFFSetWarningHandler@LIBTIFF_4.0&apos;../../lib/libopencv_imgcodecs.so.3.3.1: undefined reference to `TIFFSetErrorHandler@LIBTIFF_4.0&apos;../../lib/libopencv_imgcodecs.so.3.3.1: undefined reference to `TIFFReadEncodedTile@LIBTIFF_4.0&apos;../../lib/libopencv_imgcodecs.so.3.3.1: undefined reference to `TIFFReadRGBATile@LIBTIFF_4.0&apos;../../lib/libopencv_imgcodecs.so.3.3.1: undefined reference to `TIFFClose@LIBTIFF_4.0&apos;../../lib/libopencv_imgcodecs.so.3.3.1: undefined reference to `TIFFRGBAImageOK@LIBTIFF_4.0&apos;../../lib/libopencv_imgcodecs.so.3.3.1: undefined reference to `TIFFClientOpen@LIBTIFF_4.0&apos;../../lib/libopencv_imgcodecs.so.3.3.1: undefined reference to `TIFFReadRGBAStrip@LIBTIFF_4.0&apos;collect2: error: ld returned 1 exit statusapps/annotation/CMakeFiles/opencv_annotation.dir/build.make:99: recipe for target &apos;bin/opencv_annotation&apos; failedmake[2]: *** [bin/opencv_annotation] Error 1CMakeFiles/Makefile2:7557: recipe for target &apos;apps/annotation/CMakeFiles/opencv_annotation.dir/all&apos; failedmake[1]: *** [apps/annotation/CMakeFiles/opencv_annotation.dir/all] Error 2make[1]: *** Waiting for unfinished jobs....</code></pre><p>解决方案</p><p>安装依赖</p><pre><code>sudo apt install libtiff-dev</code></pre><h2 id="maltab运行报错"><a href="#maltab运行报错" class="headerlink" title="maltab运行报错"></a>maltab运行报错</h2><pre><code>failed to adjust boundary on projectId 123456 ... Matlab M-code Stack Trace ...com.mathworks.toolbox.javabuilder.MWException: Invalid MEX-file &apos;/home/ubuntu/.mcrCache9.2/bounda0/matlab_demo/myplot.mexa64&apos;: Missing dependent shared libraries:&apos;libopencv_core.so.3.3&apos; required by &apos;/home/ubuntu/.mcrCache9.2/bounda0/matlab_demo/myplot.mexa64&apos;&apos;libopencv_imgproc.so.3.3&apos; required by &apos;/home/ubuntu/.mcrCache9.2/bounda0/matlab_demo/myplot.mexa64&apos;&apos;libopencv_imgcodecs.so.3.3&apos; required by &apos;/home/ubuntu/.mcrCache9.2/bounda0/matlab_demo/myplot.mexa64&apos;</code></pre><p>编译完成后，程序仍然报错</p><p>执行</p><pre><code>locate libopencv_core.so.3.3/home/ubuntu/anaconda3/lib/libopencv_core.so.3.3/home/ubuntu/anaconda3/lib/libopencv_core.so.3.3.1/home/ubuntu/opencv-3.3.1/build/lib/libopencv_core.so.3.3/home/ubuntu/opencv-3.3.1/build/lib/libopencv_core.so.3.3.1</code></pre><p>看样子matlab找不到lib包的位置，而不是这些包不存在</p><p>解决方案</p><p>软链接报错的库到系统库里</p><pre><code>sudo ln -s /home/ubuntu/opencv-3.3.1/build/lib/libopencv_core.so.3.3 /usr/local/lib/libopencv_core.so.3.3</code></pre><h2 id="lib-x86-64-linux-gnu-libz-so-1-version-ZLIB-1-2-9’-not-found"><a href="#lib-x86-64-linux-gnu-libz-so-1-version-ZLIB-1-2-9’-not-found" class="headerlink" title="/lib/x86_64-linux-gnu/libz.so.1: version `ZLIB_1.2.9’ not found"></a>/lib/x86_64-linux-gnu/libz.so.1: version `ZLIB_1.2.9’ not found</h2><p>缺少ZLIB_1.2.9的包</p><p>解决方案</p><p>下载ZLIB_1.2.9的包</p><p><a href="https://sourceforge.net/projects/libpng/files/zlib/1.2.9/zlib-1.2.9.tar.gz/download" target="_blank" rel="noopener">Download</a></p><pre><code>tar -xvf ~/Downloads/zlib-1.2.9.tar.gzcd zlib-1.2.9sudo -s./configure; make; make installcd /lib/x86_64-linux-gnuln -s -f /usr/local/lib/libz.so.1.2.9/lib libz.so.1cd ~rm -rf zlib-1.2.9</code></pre><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>兜兜转转，花了2天才安装完opencv，主要问题在于编译的报错，出现各种莫名其妙的错误</p><p>而且相同机器（配置、版本、文件路径全部一样）报错能不一样，我人傻了</p><p>一共安装了4台，感觉就是折磨</p><p>由于这台机器上不止需要部署opencv，还有很多其他的C组件，而组件之间的版本依赖及服务依赖很强</p><p>后期我需要好好理一下之间的关系，将这台机器的服务docker化</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://blog.csdn.net/zhanghai4155/article/details/104215198" target="_blank" rel="noopener">Anaconda系列：conda是什么？conda与pip的区别是什么？</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> OpenCV </category>
          
      </categories>
      
      
        <tags>
            
            <tag> C </tag>
            
            <tag> OpenCV </tag>
            
            <tag> Conda </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>随笔——二刷赛格广场</title>
      <link href="2020/12/21/Essay/SEG-Plaza/"/>
      <url>2020/12/21/Essay/SEG-Plaza/</url>
      
        <content type="html"><![CDATA[<blockquote><p>du lange in einen Abgrund blickst, blickt der Abgrund auch in dich hinein. </p></blockquote><p>周末去了一次赛格广场，还记得第一次去赛格广场的时候是3年前我参加学校的创新创业营第一次来深圳时去的。</p><p>那个时候赛格广场给我的就一个感觉，人山人海，电子产品琳琅满目，我依稀记得在赛格广场一个卖电脑硬盘的商贩，大概20岁左右，操着一口流利的粤语和别人交谈，转眼间，来了两个老外，他又马上切换成英语跟别人对话。</p><p>那时的我感觉到，能在这个地方扎根还得会英语，这群人真厉害。</p><p>最后买了一块品胜的充电宝，用到现在还能用，好像不到50块钱，质量很好。</p><p>周末，第二次来到这个地方，从华强南走到华新，我感觉人没有以前多了，再进到赛格广场，门口贴满了广告，大多是卖挖矿机的和出租、转让门面的。</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Essay/seg.jpg"  alt="seg.jpg"></p><p>我走进一家卖矿机的门面，机箱里展示着他的镇店之宝”挖矿利器”一台超大服务器搭16张1080TI的显卡，挂着低价处理的牌子，看样子是已经挖不动了，但是也没接盘侠。</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Essay/kuangka.jpg"  alt="kuangka.jpg"></p><p>我又走进一家卖Apple的产品的门面，老板正在交货，一堆工人从里面拖箱子，估计箱子里装的都是Airpods pro，我问老板这个多少钱，他说199，我说这是仿制品吗。</p><p>老板饶有趣味地告诉我</p><ul><li>低情商：假货、仿制品</li><li>高情商：几乎和真品一样的体验，抄底(超低)的价格</li></ul><p>然后他拿了一副给我试试，开盖自动连接iphone，并且手机上也显示是Airpods pro<br>正好我带了mac，想测试下能不能无缝iphone和mac切换，老板直接说还没做到这点</p><p>我又试了下降噪的功能，由于没有真的airpods pro，我拿我的studio3带上对比下了，差距还是很明显的，完全不是一个产品，但是这款有降噪功能，比普通耳机应该会好点。</p><p>我问老板保质期多少，他说3个月，我说那这个耳机就只能用3个月吗，他说你用坏了可以来这修，3个月内直接换新的，超过3个月就要花钱。</p><p>我把耳机还给他，摇了摇头，他说要不149卖你，我说我再看看吧。</p><p>后来陆陆续续走了几家店</p><ul><li>iphone8s plus 799</li><li>iphonexr 1399</li><li>iphone12 4399</li></ul><p>就连我前段时间想买的ipad air4 这里只要2799，那老板直接跟我说，小作坊逆向研发的产品，先把硬件缝合好，然后开机改爱思和一些第三方平台的数据，然后装机，出售，他说有的ipad用的甚至是3000毫安的电池，有的cpu都给换了，各种破解，缝合，让我瞠目结舌。</p><p>二手的苹果基本都被拆过，没拆的价格基本上闲鱼、转转也可能淘到。</p><p>后面又转了一会，我准备买个手机壳，有家店卖手机壳，直接说批发价5块，还送一个钢化膜，说着时，一辆货拉拉的车停过来了，下来了3 5个人开始般手机壳，我问老板这个手机壳运到哪，他说淘宝的商家啊，他们卖出去就要10-20多不等了，现在淘宝没以前赚钱了，需求也没以前大，我准备卖到过年就关门。</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Essay/huolala.jpg"  alt="huolala.jpg"></p><p>走出赛格广场，外面货拉拉的车停满了，进出广场的除了搬货的工人，还有大量的黄蓝骑手，向我这种散客很少。</p><p>这里的价值观，用一张图展示</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Essay/jiazhi.jpg"  alt="jiazhi.jpg"></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>两次来赛格广场的感受完全不一样，这里已没有当年的风光</p><p>这一路走来我在想个问题，为什么这些店家越来越少，生意越来越难做，但卖假货还在大肆敛财，互联网的发展带来的真的是大量失业吗？</p><p>这些值得我们深思</p>]]></content>
      
      
      <categories>
          
          <category> Essay </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Essay </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>elasticsearch启动报错</title>
      <link href="2020/12/11/bug/elasticsearch-permission-denied/"/>
      <url>2020/12/11/bug/elasticsearch-permission-denied/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近搭建了EKF测试日志的稳定性，全部用Docker部署，把中间出现的一些ES相关的报错总结下</p><h1 id="问题一：启动报错"><a href="#问题一：启动报错" class="headerlink" title="问题一：启动报错"></a>问题一：启动报错</h1><h2 id="启动命令"><a href="#启动命令" class="headerlink" title="启动命令"></a>启动命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo mkdir -p &#x2F;data&#x2F;elasticsearch&#x2F;data</span><br><span class="line">sudo mkdir -p &#x2F;data&#x2F;elasticsearch&#x2F;logs</span><br><span class="line">sudo docker run --privileged&#x3D;true  -p 9200:9200 -p 9300:9300 -v   &#x2F;data&#x2F;elasticsearch&#x2F;logs&#x2F;:&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;logs&#x2F;  -v   &#x2F;data&#x2F;elasticsearch&#x2F;data&#x2F;:&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;data&#x2F;  --name   elasticsearch -e &quot;discovery.type&#x3D;single-node&quot; -d   docker.elastic.co&#x2F;elasticsearch&#x2F;elasticsearch:7.6.1</span><br></pre></td></tr></table></figure><h2 id="报错如下"><a href="#报错如下" class="headerlink" title="报错如下"></a>报错如下</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Error: Could not create the Java Virtual Machine.</span><br><span class="line">Error: A fatal exception has occurred. Program will exit.</span><br><span class="line">[0.001s][error][logging] Error opening log file &#39;logs&#x2F;gc.log&#39;: Permission denied</span><br><span class="line">[0.001s][error][logging] Initialization of output &#39;file&#x3D;logs&#x2F;gc.log&#39; using options &#39;filecount&#x3D;32,filesize&#x3D;64m&#39; failed.</span><br></pre></td></tr></table></figure><h2 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h2><p>直接创建的文件夹没有给容器的写权限</p><h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 777 -R &#x2F;data&#x2F;</span><br></pre></td></tr></table></figure><p>再重启容器即可</p><h1 id="问题二：迁移es数据报错"><a href="#问题二：迁移es数据报错" class="headerlink" title="问题二：迁移es数据报错"></a>问题二：迁移es数据报错</h1><p>我在部署完EFK并试运行1个星期后，觉得比较稳定了，然后我准备把EKF迁移到一台单独的机器上。</p><h2 id="迁移操作"><a href="#迁移操作" class="headerlink" title="迁移操作"></a>迁移操作</h2><ul><li>中断ES容器</li><li>拷贝elasticsearch/data下文件到新机器上（相对路径不变）</li><li>相同的命令启动es</li><li>报错</li></ul><h2 id="报错如下-1"><a href="#报错如下-1" class="headerlink" title="报错如下"></a>报错如下</h2><p>es起不来的原因是</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">java.lang.IllegalStateException: failed to obtain node locks, tried [[&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;data]] with lock id [0]; maybe these locations are not writable or multiple nodes were started without increasing [node.max_local_storage_nodes] (was [1])?</span><br></pre></td></tr></table></figure><h2 id="分析问题"><a href="#分析问题" class="headerlink" title="分析问题"></a>分析问题</h2><p>Google到一个案例的解释</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">这是由于目录权限错误（不是Elasticsearch用户所有）引起的。</span><br><span class="line"></span><br><span class="line">目前，存储库nodes在卸载时不会删除目录，但是会删除elasticsearch拥有该目录的用户&#x2F;组。因此，当重新安装Elasticsearch时，将elasticsearch创建一个新的不同的用户&#x2F;组，从而使旧nodes目录仍然存在，但由旧的UID &#x2F; GID拥有。然后这会发生冲突并导致错误。</span><br></pre></td></tr></table></figure><p>这个是物理机安装的，不是docker安装的，但是也可以看到一个文档，就是es的权限设置不对。</p><p>由于数据迁移，两台机器都是root用户启动的，所以我感觉应该不是用户组的关系</p><p>但是尝试chown -R elasticsearch:elasticsearch /data</p><p>启动成功了</p><h2 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h2><p>授权/data目录的es账号权限即可</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://stackoverflow.com/questions/28932178/elasticsearch-failed-to-obtain-node-lock-is-the-following-location-writable" target="_blank" rel="noopener">Elasticsearch, Failed to obtain node lock, is the following location writable</a></p>]]></content>
      
      
      <categories>
          
          <category> Elasticsearch </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operation Manual </tag>
            
            <tag> Elasticsearch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维手册——kubernetes节点重启无法加入集群</title>
      <link href="2020/12/09/bug/kubelet-docker-cgroup/"/>
      <url>2020/12/09/bug/kubelet-docker-cgroup/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近大楼检查消防验收，验收时公司会断电，我提前写好ansbile自动安全关机及开机自启脚本，结果验收后开机自启时，有2台k8s node节点没有加入到集群里，一起来看看什么情况吧。</p><h1 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h1><p>开机后检查集群情况</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@20-52-k8s-node ~]# kubectl get nodes</span><br><span class="line">172.30.20.21   Ready      etcd,lb,master   21d   v1.15.5</span><br><span class="line">172.30.20.22   Ready      etcd,lb,master   21d   v1.15.5</span><br><span class="line">172.30.20.23   Ready      etcd,lb,master   21d   v1.15.5</span><br><span class="line">172.30.20.31   Ready      worker           21d   v1.15.5</span><br><span class="line">172.30.20.41   Ready      worker           21d   v1.15.5</span><br><span class="line">172.30.20.51   Ready      worker           21d   v1.15.5</span><br><span class="line">172.30.20.52   NotReady   worker           15d   v1.15.5</span><br><span class="line">172.30.20.53   NotReady   worker           15d   v1.15.5</span><br></pre></td></tr></table></figure><p>有2台机器not ready</p><p>进服务器看，正常开机，但是容器一个没启动,而且kubelet也没启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@20-52-k8s-node ~]# docker ps -a</span><br><span class="line">3dd7230db6c8        registry.aliyuncs.com&#x2F;google_containers&#x2F;pause:3.2              &quot;&#x2F;pause&quot;                 6 days ago          Exited (0) 30 hours ago                         k8s_POD_bees360ai-7d8bc48896-g77np_test_76f32465-7a9a-4c74-a609-c929f8ec2f3b_0</span><br><span class="line">d49a621b255e        4e9f801d2217                                                   &quot;&#x2F;opt&#x2F;bin&#x2F;flanneld -…&quot;   2 weeks ago         Exited (137) 30 hours ago                       k8s_kube-flannel_kube-flannel-ds-amd64-kbqhs_kube-system_cd1d68d1-40ef-4f29-9cc7-f7032a38a2ee_0</span><br><span class="line">17d8fdf6a663        registry.cn-shanghai.aliyuncs.com&#x2F;kubeadm-ha&#x2F;coreos_flannel    &quot;cp -f &#x2F;etc&#x2F;kube-fla…&quot;   2 weeks ago         Exited (0) 2 weeks ago                          k8s_install-cni_kube-flannel-ds-amd64-kbqhs_kube-system_cd1d68d1-40ef-4f29-9cc7-f7032a38a2ee_0</span><br><span class="line">2db691e5fbc3        registry.aliyuncs.com&#x2F;google_containers&#x2F;kube-proxy             &quot;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;kube…&quot;   2 weeks ago         Exited (2) 30 hours ago                         k8s_kube-proxy_kube-proxy-kk97x_kube-system_d7d38aa3-c4c5-4009-a8d7-8ed8d47b1a1a_0</span><br><span class="line">101d2d7e6fff        registry.aliyuncs.com&#x2F;google_containers&#x2F;pause:3.2              &quot;&#x2F;pause&quot;                 2 weeks ago         Exited (0) 30 hours ago                         k8s_POD_kube-flannel-ds-amd64-kbqhs_kube-system_cd1d68d1-40ef-4f29-9cc7-f7032a38a2ee_0</span><br><span class="line">551d3f12bc19        registry.aliyuncs.com&#x2F;google_containers&#x2F;pause:3.2              &quot;&#x2F;pause&quot;                 2 weeks ago         Exited (0) 30 hours ago                         k8s_POD_kube-proxy-kk97x_kube-system_d7d38aa3-c4c5-4009-a8d7-8ed8d47b1a1a_0</span><br><span class="line">[root@20-52-k8s-node ~]# ps -aux|grep kubelet</span><br><span class="line">root     12470  0.0  0.0 112812   968 pts&#x2F;0    S+   16:10   0:00 grep --color&#x3D;auto kubelet</span><br></pre></td></tr></table></figure><h1 id="分析问题"><a href="#分析问题" class="headerlink" title="分析问题"></a>分析问题</h1><p>我第一反应，开启docker自启后容器没有restart？ </p><p>然后我尝试重启docker服务和再次重启机器，仍然没用</p><p>尝试执行docker start 容器</p><p>报错</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@20-52-k8s-node ~]# docker start k8s_install-cni_kube-flannel-ds-amd64-kbqhs_kube-system_cd1d68d1-40ef-4f29-9cc7-f7032a38a2ee_0</span><br><span class="line">Error response from daemon: cgroup-parent for systemd cgroup should be a valid slice named as &quot;xxx.slice&quot;</span><br></pre></td></tr></table></figure><p>查看kubelet的日志</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@20-52-k8s-node ~]# journalctl -u kubelet &gt; kubelet.log</span><br><span class="line">[root@20-52-k8s-node ~]# cat kubelet.log|grep cgroup</span><br><span class="line">Dec 09 15:37:29 20-52-k8s-node kubelet[10326]: F1209 15:37:29.940824   10326 server.go:273] failed to run Kubelet: failed to create kubelet: misconfiguration: kubelet cgroup driver: &quot;cgroupfs&quot; is different from docker cgroup driver: &quot;systemd&quot;</span><br></pre></td></tr></table></figure><p>google有类似问题的解决方案</p><ul><li>docker<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">If you update the docker daemon.json for different cgroupdriver you should update the kubelet parameters too .</span><br></pre></td></tr></table></figure></li><li>kubelet<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Check on the worker nodes file &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;kubeadm-flags.env and in KUBELET_KUBEADM_ARGS I had --cgroup-driver&#x3D;cgroupfs. Changed to systemd and kubelet started working again.</span><br></pre></td></tr></table></figure></li></ul><p>查看docker的daemon.json里cgroupdriver</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@20-52-k8s-node ~]# cat &#x2F;etc&#x2F;docker&#x2F;daemon.json |grep cgroup</span><br><span class="line">  &quot;exec-opts&quot;: [&quot;native.cgroupdriver&#x3D;systemd&quot;],</span><br></pre></td></tr></table></figure><p>查看kubelet的cgroupdriver</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@20-52-k8s-node ~]# cat &#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;kubeadm-flags.env |grep cgroup</span><br><span class="line">KUBELET_KUBEADM_ARGS&#x3D;&quot;--cgroup-driver&#x3D;cgroupfs --hostname-override&#x3D;172.30.20.52 --network-plugin&#x3D;cni --pod-infra-container-image&#x3D;registry.aliyuncs.com&#x2F;google_containers&#x2F;pause:3.2 --root-dir&#x3D;&#x2F;var&#x2F;lib&#x2F;kubelet&quot;</span><br></pre></td></tr></table></figure><p>对比后发现 果然不一样</p><h1 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h1><p>修改/var/lib/kubelet/kubeadm-flags.env的cgroup-driver=systemd即可</p><p>重启后服务陆陆续续地启动成功了</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这问题仔细Google后发现是由于Kubelet中使用了Cgroup驱动程序。Kubelet和Docker应该使用Systemd驱动程序或Cgroupfs运行。建议使用Systemd。</p><p>但是不知道什么原因导致kubelet的cgroup更换了，因为我在其他的node节点上看的就是systemd</p><p>不追究这个问题了，解决完就好。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://github.com/kubernetes/kubernetes/issues/89682" target="_blank" rel="noopener">kubernetes/issues/89682</a></p><p><a href="https://github.com/kubernetes/kubernetes/issues/43805" target="_blank" rel="noopener">kubernetes/issues/43805</a></p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operation Manual </tag>
            
            <tag> Kubernetes </tag>
            
            <tag> Kubelet </tag>
            
            <tag> Cgroup </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Automatic expansion function of Kubernetes application</title>
      <link href="2020/12/09/kubernetes/Kubernetes-pod-hpa-test/"/>
      <url>2020/12/09/kubernetes/Kubernetes-pod-hpa-test/</url>
      
        <content type="html"><![CDATA[<p>Disclaimer: This is what I learned after entering the second Internet company after graduating from university</p><hr><h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p>Recently, some of the company’s test environment applications have been migrated to Kubernetes. In order to migrate production environment applications to Kubernetes and ensure the stability of the system, we will perform stress tests on these projects.</p><h1 id="Prepare"><a href="#Prepare" class="headerlink" title="Prepare"></a>Prepare</h1><h2 id="System"><a href="#System" class="headerlink" title="System"></a>System</h2><table><thead><tr><th>ENV</th><th>Version</th></tr></thead><tbody><tr><td>Kubernetes</td><td>V1.15</td></tr><tr><td>Heapster</td><td>V1.5.4</td></tr><tr><td>Influxdb</td><td>V1.5.2</td></tr><tr><td>Grafana</td><td>V5.0.4</td></tr></tbody></table><h2 id="Deployment"><a href="#Deployment" class="headerlink" title="Deployment"></a>Deployment</h2><ul><li>Containers</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">- args:</span><br><span class="line">  - -jar</span><br><span class="line">  - -Xms16384m</span><br><span class="line">  - -Xmx16384m</span><br><span class="line">  - -Xmn258m</span><br><span class="line">  - -Xss256k</span><br><span class="line">  - -XX:+DisableExplicitGC</span><br><span class="line">  - -XX:+UseConcMarkSweepGC</span><br><span class="line">  - -XX:+UseParNewGC</span><br><span class="line">  - -XX:+CMSParallelRemarkEnabled</span><br><span class="line">  - -XX:+CMSClassUnloadingEnabled</span><br><span class="line">  - -XX:LargePageSizeInBytes&#x3D;128m</span><br><span class="line">  - -XX:+UseFastAccessorMethods</span><br><span class="line">  - -XX:+UseCMSInitiatingOccupancyOnly</span><br><span class="line">  - -XX:CMSInitiatingOccupancyFraction&#x3D;80</span><br><span class="line">  - -XX:SoftRefLRUPolicyMSPerMB&#x3D;0</span><br><span class="line">  - -XX:+PrintClassHistogram</span><br><span class="line">  - -Dfile.encoding&#x3D;UTF8</span><br><span class="line">  - -Dsun.jnu.encoding&#x3D;UTF8</span><br><span class="line">  - app.jar</span><br><span class="line">  command:</span><br><span class="line">  - java</span><br></pre></td></tr></table></figure><ul><li>resources</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">requests:</span><br><span class="line">  cpu: 0.1</span><br><span class="line">  memory: 1024Mi</span><br><span class="line">limits:</span><br><span class="line">  cpu: 4</span><br><span class="line">  memory: 16834Mi</span><br></pre></td></tr></table></figure><h2 id="HPA-HorizontalPodAutoscaler"><a href="#HPA-HorizontalPodAutoscaler" class="headerlink" title="HPA(HorizontalPodAutoscaler)"></a>HPA(HorizontalPodAutoscaler)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">minReplicas: 2</span><br><span class="line">maxReplicas: 3</span><br><span class="line">metrics:</span><br><span class="line">- type: Resource</span><br><span class="line">  resource:</span><br><span class="line">    name: cpu</span><br><span class="line">    target:</span><br><span class="line">      type: Utilization</span><br><span class="line">      averageUtilization: 80</span><br></pre></td></tr></table></figure><h2 id="Plan"><a href="#Plan" class="headerlink" title="Plan"></a>Plan</h2><p>I’m going to get the optimal configuration file for this application by controlling variables.</p><p>And I want to test the peak resource usage of the application.</p><ul><li>Control variable</li></ul><table><thead><tr><th>Example</th><th>1</th><th>2</th><th>3</th><th>4</th></tr></thead><tbody><tr><td>JVM(Xms/Xmx)</td><td>4096</td><td>8192m</td><td>8192m</td><td>16384m</td></tr><tr><td>MAX Resources</td><td>1C 4G</td><td>1C 8G</td><td>2C 8G</td><td>4C 16G</td></tr><tr><td>MIN/MAX Replicas</td><td>4/6</td><td>4/6</td><td>2/3</td><td>2/3</td></tr></tbody></table><p>I asked my colleague to help send 100 grpc requests and 200 https requests.</p><h1 id="Start-pressure-test"><a href="#Start-pressure-test" class="headerlink" title="Start pressure test"></a>Start pressure test</h1><p>protocol </p><ul><li>grpc:Data Transmission</li><li>https:Data Analysis and Demonstration</li></ul><h2 id="Steps"><a href="#Steps" class="headerlink" title="Steps"></a>Steps</h2><ul><li>In the first step</li></ul><p>we send 10 grpc requests,  then increase the number of requests to 100 and observe the status of pods</p><ul><li>In the second step</li></ul><p>we send 20 https requests, then increase the number of requests to 200 and  observe the status of pods</p><ul><li>Finally</li></ul><p>we send 10 grpc and 20 https requests,  then increase to 100 grpc requests and 200 https and observe the status of pods</p><h2 id="Pressure-test-phenomenon"><a href="#Pressure-test-phenomenon" class="headerlink" title="Pressure test phenomenon"></a>Pressure test phenomenon</h2><p>When the request is within 10 grpc or 20 https</p><p>The number of pods in normal operation is 4 </p><hr><blockquote><p>When only grpc requests increase, kubernetes starts to automatically expand the number of pods to 6</p></blockquote><blockquote><p>Then only when grpc request is reduced, kubernetes starts to automatically reduces the number of pods to 4</p></blockquote><blockquote><p>But only when https requests increase, kubernetes does not show automatic horizontal expansion</p></blockquote><blockquote><p>Then when the gprc request is 100, the https request is 200, pods become unavailable</p></blockquote><h2 id="Pressure-test-analysis"><a href="#Pressure-test-analysis" class="headerlink" title="Pressure test analysis"></a>Pressure test analysis</h2><h3 id="First-conclusion"><a href="#First-conclusion" class="headerlink" title="First conclusion"></a>First conclusion</h3><p>By observing the grafana Dashboard,I found that when grpc requests increase, although the pods have been expanded, the CPU and Memory of only one pod will continue to rise, and other pods do not seem to have this situation.</p><p>After querying the information through Google, I found that the default load balancing of Kubernetes usually cannot be used with grpc.</p><p>So I came to the first conclusion:</p><p>Without changing the logic of grpc in the code or using  additional special load balancer, HPA seems to be useful but actually useless</p><h3 id="Second-conclusion"><a href="#Second-conclusion" class="headerlink" title="Second conclusion"></a>Second conclusion</h3><p>Through the controlled variable method, I carefully compared the monitoring charts of the 4 groups of examples.</p><p>Then I found that the 3 group of examples and the 4 group of examples have almost the same phenomenon.</p><p>The test results found that the CPU upper limit of the pod in these two sets of examples is between 1.5 cores and 2 cores,but the memory increases as the resource limit increases</p><ul><li>The monitoring of example 3 is shown in the figure below</li></ul><p>Pod (2C 8G) Replicas 2</p><p>The CPU upper limit of the pod has been increased 1.5 cores,the memory upper limit of the pod has been increased 8 Gb</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Kubernetes/kubernetes-hpa-test-1.jpg"  alt="kubernetes-hpa-test-1.jpg"></p><ul><li>The monitoring of example 4 is shown in the figure below</li></ul><p>Pod (4C 16G) Replicas 2 </p><p>The CPU upper limit of the pod has been increased 2 cores,the memory upper limit of the pod has been increased 16 Gb</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Kubernetes/kubernetes-hpa-test-3.jpg"  alt="kubernetes-hpa-test-3.jpg"></p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Kubernetes/kubernetes-hpa-test-4.jpg"  alt="kubernetes-hpa-test-4.jpg"></p><p>So I came to the second conclusion:</p><p>The upper limit of CPU usage of this application 2 cores is enough, but its upper limit of memory usage can grow indefinitely.</p><p>I tell the developers the conclusion, let them check their code and locate the reason why the application memory is not released.</p><h3 id="Third-conclusion"><a href="#Third-conclusion" class="headerlink" title="Third conclusion"></a>Third conclusion</h3><p>For the second conclusion, the upper limit of the CPU usage of the application is only 2 cores and the processing time is longer,, which surprised the development.</p><p>Because developers say that the processing logic of their code is multithreaded, but the phenomenon is different from what they imagined.</p><p>Then I checked the application log and found that although it is multi-threaded processing, the request in a pod is blocked. In fact, data transmission is processed one request by one, resulting in a long processing time and low CPU usage limit.</p><p>So I came to the third conclusion:</p><p>Either increase the gprc load balancer at the operation and maintenance level, or modify the programming logic at the code level to improve application resource utilization and work efficiency</p><p>I think both must be changed, and the code logic is mainly changed.</p><h2 id="Tuned-template"><a href="#Tuned-template" class="headerlink" title="Tuned template"></a>Tuned template</h2><p>According to the current situation</p><ul><li>JVM(Xms/Xmx):8192m</li><li>MAX Resources: CPU:2C 8192m</li><li>MIN/MAX Replicas: 2/3</li></ul><p>After solving those problems in the future</p><ul><li>JVM(Xms/Xmx):8192m</li><li>MAX Resources: CPU:4C 8192m</li><li>MIN/MAX Replicas: 4/8</li></ul><h1 id="In-conclusion"><a href="#In-conclusion" class="headerlink" title="In conclusion"></a>In conclusion</h1><p>The pressure test was quite successful, and many problems were found in the test environment. </p><p>For SRE, the sooner the problem is exposed, the better. I don’t want to see the problems appear after the application in the production environment is migrated to Kubernetes, so pre-research in advance is a good habit.</p><h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://kubernetes.io/blog/2018/11/07/grpc-load-balancing-on-kubernetes-without-tears/" target="_blank" rel="noopener">gRPC Load Balancing on Kubernetes without Tears</a></p><p>Copyright Notice:</p><p>Originality is not easy, but it is shameful to wash text. Unless otherwise specified, all articles in this blog are original. Please indicate the address of this article in the form of a link.</p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
            <tag> HPA </tag>
            
            <tag> GRPC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>个人总结(2020.11)</title>
      <link href="2020/12/07/summary/summary-2020-11/"/>
      <url>2020/12/07/summary/summary-2020-11/</url>
      
        <content type="html"><![CDATA[<h1 id="个人能力价值的体现"><a href="#个人能力价值的体现" class="headerlink" title="个人能力价值的体现"></a>个人能力价值的体现</h1><p>1个月的调整，给公司创造了如下价值</p><ul><li>降配、删除生产环境部分机器，将公司的服务器对比上月永久（注意是永久）减少接近300美金/月</li><li>更新公司VPN、电信宽带设备</li><li>重新设计服务器资源规划，加装服务器内存条磁盘、迁移各种数据</li><li>回收各种账号密码、密钥，删除冗余及存在风险的密码、密钥</li><li>建立内网DNS、堡垒机、EKF集群、高可用负载均衡集群、虚拟化集群、K8S集群、GPU集群</li><li>第一次压测业务性能，做一份压测报告</li></ul><h1 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h1><p>学习 堡垒机、K8S、EKF、VPN、NVIDIA、Python、GRPC 相关技术</p><p>主攻fluentd输入输出流及正则表达式、Python的自动化应用</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这个月工作内容很多，除了EKF集群的告警系统还没实现，其他任务都完成的很好。</p><p>本期有点水，只想说学习的东西太多了，自己还有很多不会。</p><p>除了技术以外，值得一说的就是</p><ul><li>我参与了github的一个开源项目，准备成为开源贡献者了，哈哈哈，虽然还没提交代码，但是能参与一个我喜欢的项目，去设计及写代码真的太爽了。</li><li>我想了很久很久，终于在月底买了一台最新的macbook air (M1 16g 256) ，准备把这台机器当作我的生产力工具，顺便学习下苹果的生态。</li><li>和很多大佬交流过后写了一篇关于对坚持的理解文章，目前置顶了，我认为是我自己到目前为止总结最好的一篇文章没有之一。</li></ul><p>继续加油吧</p>]]></content>
      
      
      <categories>
          
          <category> 个人总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 个人总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《SRE：Google运维解密》读书心得(四)——SRE团队指导思想（下）</title>
      <link href="2020/12/06/sre/google-sre-4/"/>
      <url>2020/12/06/sre/google-sre-4/</url>
      
        <content type="html"><![CDATA[<blockquote><p>好书不怕读的晚，就怕明知道读的晚仍然还不去读。   - 宇神之息 </p></blockquote><h1 id="总体思想"><a href="#总体思想" class="headerlink" title="总体思想"></a>总体思想</h1><p>SRE的总体思想我归纳为以下7点：</p><ul><li>评估、管理风险，以及利用错误的预算手段来推进中立性的服务运维</li><li>服务质量指标（SLI）、目标（SLO）、协议（SLA）</li><li>消除琐事</li><li>稳定的监控系统</li><li>自动化工作的方法论</li><li>高效发布</li><li>技术迭代，整体环境更新，简化系统</li></ul><p>本篇总结后3个思想</p><h1 id="自动化工作的方法论"><a href="#自动化工作的方法论" class="headerlink" title="自动化工作的方法论"></a>自动化工作的方法论</h1><p>“黑科技”之外，就只剩自动化和机械化了。</p><h2 id="自动化的价值"><a href="#自动化的价值" class="headerlink" title="自动化的价值"></a>自动化的价值</h2><ul><li>机器能准确地做好一件事，而人不一定能像机器一样永远保持一致。</li><li>自动化能扩展成平台级，相对来看，不进行自动化既不符合成本收益，也无法扩展。</li><li>自动化系统修复速度比人快，人不可能一直盯着某些事，但是只要一个正确的自动化系统能够始终运行，那么就可以降低一些常见故障的平均修复时间。</li><li>执行速度（通过规则判定）比人间歇性地手动点击“运行系统继续运行”的按钮更快。</li><li>节约时间，一旦你用自动化封装了某个任务，任何人都可以执行它们。因此，时间的节省适用于该自动化适用的所有人。</li></ul><h2 id="自动化分类的层次结构"><a href="#自动化分类的层次结构" class="headerlink" title="自动化分类的层次结构"></a>自动化分类的层次结构</h2><p>SRE讨厌手动操作，所以我们尽力创造不需要他们的系统。</p><p>集群故障转移自动化是一个经典的例子：故障转移可能每隔几个月甚至更长的时间才会发生一次，导致每次执行的都不一致。</p><p>自动化的演进遵循以下路径：</p><ul><li>没有自动化</li></ul><p>手动将数据库主进程在多个位置进行转移</p><ul><li>外部维护的系统的特定自动化系统</li></ul><p>SRE在主目录保存了一份故障转移脚本</p><ul><li>外部维护的通用的自动化系统</li></ul><p>SRE将数据库支持添加到了每个人都在使用的“通用故障转移”脚本</p><ul><li>内部维护的系统特定的自动化</li></ul><p>数据库自己发布故障转移脚本</p><ul><li>不需要任何自动化的系统</li></ul><p>数据库注意到问题的发生，在无须人工干预的情况下进行故障转移</p><h2 id="专业化倾向"><a href="#专业化倾向" class="headerlink" title="专业化倾向"></a>专业化倾向</h2><p>自动化程序的不同体现在三个方面：</p><ul><li>能力，即准确性</li><li>延迟，开始执行后，执行所有步骤需要多久</li><li>相关性，自动化所涵盖的实际流程比例</li></ul><p>通过消除运维相关服务的团队维护和运行自动化代码的责任，我们创造了一个不合理的组织奖励机制：</p><ul><li>某个最主要任务是加速现存的集群上线的团队是没有动力去减少服务运维团队在生产流程后期运维服务产生的技术负债的</li><li>一个不亲自运行自动化的团队是没有动力去建设一个能够很容易自动化的系统的</li><li>一个产品经理的时间表如果不受低质量的自动化影响，他将永远优先新功能的开发，而不是简化和自动化</li></ul><p>最可用的工具通常是由那些每天使用它们的人写成的。</p><h2 id="集群自动化进化遵循这样一个路径"><a href="#集群自动化进化遵循这样一个路径" class="headerlink" title="集群自动化进化遵循这样一个路径"></a>集群自动化进化遵循这样一个路径</h2><p>1.操作人员手动操作（无自动化）</p><p>2.操作人员编写，系统特定化的自动化</p><p>3.外部维护的通用自动化</p><p>4.内部维护，系统特定的自动化</p><p>5.不需要认为干预的自治系统</p><p>其中不管是任何一个阶段，可靠性都是最基本的功能，并且自主性、弹性行为是达到这一特征的有效途径。</p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>自动化提供的不仅仅是对时间的节省，所以在单纯的时间花费和时间节省的计算之外也值得实施。</p><p>但是最有效的方法其实在设计阶段：更快地交付和更快地迭代可能会帮助你更快地实现功能，但是缺很难形成一个有弹性的系统。</p><p>这也是项目从特殊化到普遍化演变中很难的一环，对足够强大的系统来说，软件工程的良好标准的做法将会有很大的帮助：解耦子系统，引入API，最大限度地减少副作用等。</p><h1 id="高效发布"><a href="#高效发布" class="headerlink" title="高效发布"></a>高效发布</h1><p>发布工程是软件工程内部一个较新、发展较快的学科。</p><p>简单来说，这个学科专注于构建和交付软件。</p><p>发布工程师通常对源代码管理、编译器、构建配置语言、自动化构建工具、包管理器和安装器等非常了解。</p><p>SRE定义发布过程中的全部步骤——包括软件是如何存储于源代码仓库中的，构建时是如何执行编译的，如何测试、打包，最终进行部署的。</p><h2 id="发布工程哲学"><a href="#发布工程哲学" class="headerlink" title="发布工程哲学"></a>发布工程哲学</h2><p>发布工程师的日常工作是由下列4个主要的工程与服务哲学指导的</p><h3 id="自服务模型"><a href="#自服务模型" class="headerlink" title="自服务模型"></a>自服务模型</h3><p>为了应对大规模扩张，每个团队必须能够自给自足。</p><p>发布工程师开发工具，制定最佳实践，以便让产品研发团队可以自己掌控和执行自己的发布流程。</p><h3 id="追求速度"><a href="#追求速度" class="headerlink" title="追求速度"></a>追求速度</h3><p>面向用户的软件组件重新构建非常频繁，因为我们的目标是让用户可见的功能越快上线越好。</p><h3 id="密闭性"><a href="#密闭性" class="headerlink" title="密闭性"></a>密闭性</h3><p>构建工具必须确保一致性和可重复性。</p><p>如果两个通常是试图在两台不同的机器上基于同一个源代码版本构建同一个产品，构建结果应该是相同的。</p><h3 id="强调策略和流程"><a href="#强调策略和流程" class="headerlink" title="强调策略和流程"></a>强调策略和流程</h3><p>多层安全和访问控制机制可以确保在发布过程中只有指定的人才能执行指定的操作。</p><p>我们主要关注的操作有以下几项:</p><ul><li>批准源代码改动——通过源代码仓库中的配置文件决定</li><li>指定发布流程中需要执行的具体动作</li><li>创建新的发布版本</li><li>批准初始的集成请求以及后续的cherry picking请求</li><li>实际部署某个发布版本</li><li>修改某个项目的配置文件</li></ul><p>几乎所有对源代码的修改都需要进行代码评审，这与我们日常开发工作流程完美结合的。</p><p>我们的自动化发布系统可以提供每个发布中包含的所有改动的报告，与其他的构建结果一起归档。</p><p>SRE可以了解每个发布中包含的具体改动，以便在发布出现问题的时候可以更快地进行在线调试。</p><h2 id="持续构建与部署"><a href="#持续构建与部署" class="headerlink" title="持续构建与部署"></a>持续构建与部署</h2><p>Google开发了一个自动化发布系统：Rapid。该系统利用一系列Google内部技术执行可扩展的、密闭的、可靠的发布流程。</p><h3 id="Rapid系统"><a href="#Rapid系统" class="headerlink" title="Rapid系统"></a>Rapid系统</h3><p>Rapid是用Blueprint文件配置的。Blueprint文件是一种利用Google内部配置语言写成的，用来定义构建目标和测试目标、部署规则，以及一些管理用信息（例如项目负责人信息）。</p><p>基于角色的访问控制列表可以决定谁能执行哪些操作。</p><p>Rapid可以管理发布分支与Cheery Picking。每个具体的Cherry Picking请求可以被单独的批准或拒绝</p><p>典型的发布流程按如下顺序进行：</p><ul><li>Rapid使用集成版本号（通常自动从CI流程获取）创建新的发布分支</li><li>Rapid利用Blaze编译所有二进制文件，同时执行所有的单元测试，这两个过程通常是并发进行的。编译和测试各自在独立的环境中进行，而非Rapid工作流运行的环境中。</li><li>构建结果随后可以用来运行系统级集成测试，同时进行测试部署。典型的测试部署过程是在系统检测完成之后，在生产环境启动一系列Borg任务</li><li>每一步的结果都有日志记录。另外产生一份与上次发布对比包含的所有新的改动列表的报告</li></ul><p>下面具体描述Google内部的软件生命周期。</p><h3 id="CI-Continuous-Integration"><a href="#CI-Continuous-Integration" class="headerlink" title="CI(Continuous Integration)"></a>CI(Continuous Integration)</h3><p>Blaze是Google的构建工具，它的开源版本为Bazel。</p><p>构建目标（二进制文件，以及对应的测试等）定义在Rapid的项目配置文件中。</p><p>某个项目特有的功能开关，例如一些特有的构建标识符等，会由Rapid传递给Blaze。</p><p>所有二进制文件都支持用一个命令显示自身的构建时间、构建源代码版本以及构建标识符，这样我们就可以很容易将一个二进制文件与构建过程对应起来。</p><h4 id="分支"><a href="#分支" class="headerlink" title="分支"></a>分支</h4><p>所有的代码都默认提交到主分支上。然而，大部分的项目都不会直接从主分支上进行直接发布。</p><p>我们会基于主分支的某一个版本创建新分支，新分支内容永远不会合并到主分支。</p><p>BUG修复先提交到主分支，再Cherry Picking到发布分支上。</p><p>这种方式可以避免在第一次构建之后，再引入主分支上的其他的无关改动。</p><h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><p>一个持续测试系统会在每个主分支改动提交之后运行测试单元，这样我们可以快速检测构建错误和测试错误。</p><p>建议使用项目中定义的构建目标及测试目标的执行结果来决定是否发布某个版本。</p><p>建议使用最后一个测试全部通过的软件版本来进行最新的发布。</p><p>这些方法可以降低在真正发布时由于主分支上其他无关改动造成问题的几率。</p><h4 id="打包"><a href="#打包" class="headerlink" title="打包"></a>打包</h4><p>软件通过Midas Package Manager（MPM）系统分发到生产机器上。MPM基于Blaze规则中列出的构建结果和权限信息构建MPM包。</p><p>每个包有固定的名称，记录构建结果的哈希值并加入签名以确保真实完整性。</p><p>MPM同时支持给某个版本的包打标签。</p><p>Rapid也会加入一个构建ID标签，确保某个包可以用名字和这个标签来唯一识别。</p><h3 id="CD-Continuous-Deployment"><a href="#CD-Continuous-Deployment" class="headerlink" title="CD(Continuous Deployment)"></a>CD(Continuous Deployment)</h3><p>Sisyphus是Google SRE开发的一个通用的自动发布框架，来执行更为负载的部署任务。</p><p>Sisyphus提供了一系列可扩展的Python类，以支持任意部署流程。</p><p>同时，它还有一个监控台，可以用来详细控制每个发布的执行，以及监控发布流程。</p><h4 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h4><p>一个发布是由一个或者多个任务组成的一个逻辑工作单元。</p><p>在典型的集成流程中，Rapid在某个Sisyphus系统中创建一个新的发布。Rapid知道自己构建的MPM包的build标签，可以在创建发布时指定这个标签。Sisyphus可以利用这个build标签来指定究竟使用哪个MPM版本进行部署。</p><p>我们的目标是让部署流程与服务的风险承受能力相结合。在开发环境或者预发布环境中，我们可能会每个小时构建一次，同时在所有测试通过之后自动发布更新。</p><p>对于生产环境来说，我们可能会先更新一个集群，再以指数速度更新其他集群直到全部完成。</p><p>对于更敏感的基础设施服务来说，我们可能会将发布扩展到几天内完成，根据这些实例所在的地理位置交替进行。</p><h4 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h4><p>配置管理是发布工程师与SRE紧密合作的一个区域。虽然初看起来，配置管理可能很简单，但是这其实是不稳定性的一个重要来源。</p><p>项目负责人需要分发和管理配置文件，SRE为其提供了多种选择方式</p><h5 id="使用主分支版本配置文件"><a href="#使用主分支版本配置文件" class="headerlink" title="使用主分支版本配置文件"></a>使用主分支版本配置文件</h5><p>使用这个模型，开发和SRE可以同时修改主分支的配置文件。这些修改经过代码评审后会应用到正在运行的系统上。</p><p>这种方式经常会造成提交的版本和实际运行的配置文件不一致，因为任务必须要经过更新才应用这些变更。</p><h5 id="将配置文件与二进制文件打包在同一个MPM包中"><a href="#将配置文件与二进制文件打包在同一个MPM包中" class="headerlink" title="将配置文件与二进制文件打包在同一个MPM包中"></a>将配置文件与二进制文件打包在同一个MPM包中</h5><p>使用这个模型，对于没有多少配置文件的项目或者是每次发布都不会改变配置的项目来说，配置文件和二进制文件放在一个MPM包里。简化了部署，因为这仅仅只需要安装一个包。</p><p>但是在灵活性上有一定限制</p><h5 id="将配置文件打成MPM包"><a href="#将配置文件打成MPM包" class="headerlink" title="将配置文件打成MPM包"></a>将配置文件打成MPM包</h5><p>使用这个模型，我们可以将密闭原则应用到配置管理上。二进制配置文件一般与某个二进制版本紧密相关，我们也可以利用编译系统和打包系统来发布配置文件。</p><p>最佳实践：</p><p>某个实现了新功能的变更可以与配置该功能的配置文件一起发布。通过打包两个MPM包，一个二进制文件，一个配置文件，可以对两个包进行单独修改。</p><p>如果某个功能的配置文件出错，我们可以Cherry Picking新的配置文件，并重新构建配置包，再实际部署。这种方式可以避免再构建一次二进制文件。</p><p>我们可以利用MPM的标签功能选择哪些MPM包应该被配置，也就是说一个二进制的MPM包可以同时获取两个配置文件包的版本。但是由于每个MPM命名空间内部都是唯一的，只有最后一个包才能被用到。</p><h5 id="从外部存储服务中读取配置文件"><a href="#从外部存储服务中读取配置文件" class="headerlink" title="从外部存储服务中读取配置文件"></a>从外部存储服务中读取配置文件</h5><p>某项目的配置文件需要经常改变，或者动态改变（在二进制文件运行时）。这些文件可以存放在Chubby、Bigtable、或者Google自己的基于源代码仓库的文件系统中</p><h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><p>当采用合适的工具、合理的自动化方式，以及合理的政策时，开发团队和SRE都无需担心如何发布软件。发布过程可以像按一个按钮那么简单。</p><p>发布工程经常是“事后诸葛亮”，随着平台和服务的规模与复杂度不断增加，这种理念一定需要改变。</p><p>团队应该在开发流程开始时就留出一定资源进行发布工程工作。尽早采用最佳实践和最佳流程可以降低成本，以免未来重新改动这些系统。</p><p>每个具体的项目团队需要决定何时进行发布工程。因此，当应用发布工程最佳实践时，一定要考虑到它在整个产品生命周期的地位，尤其是在项目早期。</p><h1 id="简单化"><a href="#简单化" class="headerlink" title="简单化"></a>简单化</h1><p>软件系统本质上是动态的和不稳定的。</p><p>如果我们不再修改代码，就不会引入新的BUG。</p><p>如果底层硬件或者类库永远不变，这些组件也不会引入BUG。</p><p>如果冻结当前用户群，我们将永远不必扩展系统。</p><p>一个对SRE管理系统的方法不错的总结是：我们的工作最终是在系统的灵活性和稳定性上维持平衡。</p><h2 id="系统的稳定性与灵活性"><a href="#系统的稳定性与灵活性" class="headerlink" title="系统的稳定性与灵活性"></a>系统的稳定性与灵活性</h2><p>SRE通过创造流程、实践以及工具，来通过提高软件的可靠性。</p><p>而可靠的流程会提高研发人员的灵活性：快速、可靠的产品发布使得生产系统的变化显而易见。</p><p>这样一旦出现错误，找到和改成错误的实践会更少。</p><h2 id="乏味是一种美德"><a href="#乏味是一种美德" class="headerlink" title="乏味是一种美德"></a>乏味是一种美德</h2><p>与生活的其他东西不同，对于软件而言，“乏味”实际上是非常正面的态度！我们不想要自发性的和有趣的程序；我们希望这些程序按设计执行，可以预见性地完成商业目的。</p><p>为了最小化意外复杂度，SRE团队应该：</p><ul><li>在他们所负责的系统中引入意外复杂度，并及时提出抗议。</li><li>不断地努力消除正在接手的和已经负责运维的系统的复杂度。</li></ul><h2 id="我绝对不放弃我的代码"><a href="#我绝对不放弃我的代码" class="headerlink" title="我绝对不放弃我的代码"></a>我绝对不放弃我的代码</h2><p>SRE推崇保证所有的代码都必须存在有目的的实践。例如，审查代码以确保它符合商业目标，定期删除无用代码，并且在各级测试中增加代码膨胀检测。</p><h3 id="“负代码行”作为一个指标"><a href="#“负代码行”作为一个指标" class="headerlink" title="“负代码行”作为一个指标"></a>“负代码行”作为一个指标</h3><p>“软件膨胀”用来描述软件随着实践的推移不停地增加新功能而变得更慢和更大的趋势。</p><p>较小的项目更容易理解，也更容易测试，通常缺陷也少。</p><p>从这一观点出发，我曾经做过一些最令人满意的工作就是删除了数千行已经没用的代码。</p><h3 id="最小API"><a href="#最小API" class="headerlink" title="最小API"></a>最小API</h3><p>书写一个明确的、最小的API是管理软件系统管理简单性必要的部分。我们向API提高的方法和参数越少，这些API就越容易理解。</p><h3 id="模块化"><a href="#模块化" class="headerlink" title="模块化"></a>模块化</h3><p>在API与单个二进制文件以外，适用于面向对象编程的许多经验法则也适用于分布式系统的设计。</p><h2 id="发布简单化"><a href="#发布简单化" class="headerlink" title="发布简单化"></a>发布简单化</h2><p>简单的发布流程总的来说要比复杂的发布流程更好。测量和理解单一变化的影响要比同时应对一系列变化更加容易。</p><h2 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h2><p>软件的简单些是可靠性的前提条件。当我们考虑如何简化一个给定的任务的每一步时，我们并不是在偷懒。相反，我们是在在明确实际上要完成的任务是上面，以及如何更容易地做到。</p><p>我们对新功能说“不”的时候，不是在限制创新，是在保持环境整洁，以免分心。</p><p>这样我们可以持续关注创新，并且可以进行真正的工程工作。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>取自《SRE：Google运维解密》60-88页，总结归纳的心得。</p><p>本篇总结了SRE的3个核心的思想：</p><ul><li>自动化工作的方法论</li><li>高效发布</li><li>技术迭代，整体环境更新，简化系统</li></ul><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Sre </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Sre </tag>
            
            <tag> Google </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>顶级理解之坚持</title>
      <link href="2020/12/04/king/king-persistence/"/>
      <url>2020/12/04/king/king-persistence/</url>
      
        <content type="html"><![CDATA[<blockquote><p>没有所谓的坚持，只有内心真正的动力   - 宇神之息  </p></blockquote><p>声明: 顶级理解系列全部是本人的主观看法，也许在你看来以我现在的阅历不能对某些事物有着精准的判断，望不喜勿喷，求同存异。</p><hr><p>最近我与各种人才交流后收获很多，反思了两个星期，将我所收获的写篇文章。</p><h1 id="百度解释"><a href="#百度解释" class="headerlink" title="百度解释"></a>百度解释</h1><p>坚持（名词、形容词、动词），即意志坚强，坚韧不拔，持即持久，有耐性。坚持意思是不改变不动摇，始终如一。坚持是意志力的完美表现。坚持也是有毅力的一种表现。</p><h1 id="我的解释"><a href="#我的解释" class="headerlink" title="我的解释"></a>我的解释</h1><p>我认为百度解释的坚持较为表面，因为能让人坚持做某一件事一定是有真正的动力，如果那个动力消失了，坚持也就不复存在了。</p><p>比如说你看到一个人坚持做一件事，那么心中一定有一个或多个动力存在，动力分很多种，无外乎这两大类</p><ul><li>生活（生存/求生）的欲望</li><li>纯粹地喜欢、热爱</li></ul><p>有的人坚持画画20年，有的人坚持弹钢琴20年，其实到最后没有这些个动力，他们不可能做一辈子。</p><p>小时候我也报过各种兴趣班，画画、足球、乒乓球，一晃十几年过去了，现在几乎不会进行这些活动，因为我不是纯粹地喜欢，它们也不能成为我生活的欲望，我也就不会坚持进行这些活动。</p><p>但是反观现在从事各行各业的人，有多少人是从小到大在坚持做一件事。</p><p>比如，一个画家，从小画画到大，最后靠卖画为生，你可以说他坚持，但是画家内心的动力呢，可能很小的时候就是天生的喜欢，长大后还是很喜欢，但是人要生存的，没办法，画画这门手艺就成为他生存的工具，而且很可能画家会去做其他的事情来生存，但是可能他既不喜欢，也不想做，倒不如就用一直“坚持”的画画来生存。</p><p>再比如，一个电竞选手，从小玩游戏到大，由于技术厉害，打成了职业选手，参加世界大赛，获奖，取得成就，拿到百万千万的签约费，人生赢家。在别人看起来，他成功，年少有为，财务自由，因为这和他坚持了10年的电竞生涯有关。但是大家都往往忽略了一个问题，就是他为什么能坚持。</p><p>可能他小时候只是单纯的喜欢玩，玩一个游戏成为领域的强者，但是成为职业选手后，不得不的承认的就是，他不能再天生的喜欢了，因为他知道，他必须要把游戏当成工作（打出成绩/直播），除了游戏，他很难再从事其他行业来生存，并且也没有游戏更赚钱。</p><p>我举得的例子其实就想证明一点，由于我们大多数人只能看到这种坚持的表象，从而可能对他们的表面坚持感到莫名的崇拜，赞叹别人的坚持，但其实没有这个必要。</p><p>因为世上没有纯粹坚持的东西。</p><p>你喜欢的，你自然而然的就会把时间花在这个上面。</p><p>为了生活，你自然而然的也会把时间花在这个上面。（不然老板哪给你发工资）</p><p>而那些你不喜欢的，你不能把这件事情当作你生活的必需品时，你看到别人一直在做，你才会说别人在坚持。</p><h1 id="坚持正面积极的作用"><a href="#坚持正面积极的作用" class="headerlink" title="坚持正面积极的作用"></a>坚持正面积极的作用</h1><p>我认为坚持的最核心的积极作用就在于如何寻找到真正的动力。</p><p>比如你想考研，考驾照，考各种各样的证的时候，你如果单纯只想坚持，那是没有意义的，因为你如果真的找不到这个动力，再怎么坚持也是白费力气、浪费时间。</p><p>反而，如果你已经真正想清楚了你到底想要什么，自然而然在内心就产生一个动力了。</p><p>比如你要考的这个证能给你带来很高的收入、社会地位的认可，当你带着这个动力去努力，再去翻开那些枯燥无味却要考试的书，不可能读不进去。</p><p>这个动力在旁人看起来，你只是在坚持地考证，很努力，而实际上你只不过是找到了考证的动力而已，因为你已经想清楚了你就是需要考这个证。</p><p>说到这，我要拿到我自己的亲生经历举例，这种动力一旦真正形成那就是摧枯拉朽的力量。</p><h2 id="找工作"><a href="#找工作" class="headerlink" title="找工作"></a>找工作</h2><p>在我大四即将春招结束（大概4月中旬）的时候，我还没有找到一家很好的工作，给我发offer的公司在我看来都是不值得去的。</p><p>我当时的思想就是，宁可我今年找不到工作，我再去考研或者回家我也不会去这种公司，这种破釜沉舟的思想是一个高人给我灌输的，我特别感谢他，因此我心里有了坚定的目标，那就是找到合适的工作为止并且坚定一定能找到这样的公司。我不断的复习，投简历，最后我去到了那个阶段对我个人综合能力的提升非常巨大的公司。</p><p>然后在今年疫情结束后，我自发地（没有人教我要换公司）想换公司了（具体原因可以看我之前的总结），我认为现在公司给我工资远远不能配置我创造的价值，我内心的求生欲望激发我要赚更多的钱，创造更大的价值，所以我开始准备换工作的事情。</p><p>而这次换工作的经历，告诉我这将是我从小到大自发形成的第一大动力（比在学校参加中考、高考付出的努力更加值得我回忆）</p><p>我从4月底下定决心换公司就开始给自己准备各种资料，复习线路，有计划地执行，本来是打算9、10月份正式找工作，由于公司的变动导致我这个计划不得不提前到7月，我还记得在我7月的时候，面试接踵而来，早上面试，中午复习面试语音，总结，晚上再面试，再总结，背面试题背到睡着。</p><p>我第一次体验到了自发形成动力的强大，这是一种让我无限向往的力量。</p><p>一样地，当时我收到了很多offer，通过对比这些公司的平台发展、工资等等，我并不是很满意这些offer，但我还是拿出了破釜沉舟的思想，不找到合适的公司我宁可原地不动，我也不去那些我认为不值得去的公司。最后和之前春招一样，我找到了在现阶段非常满意的公司。</p><p>在我很多朋友看来，4月份的计划我坚持并且成功了，其实他们只看到了表面，看不到我在为换工作这件事中付出超过常人的努力，看不到我内心真正的驱动力。</p><h2 id="写博客"><a href="#写博客" class="headerlink" title="写博客"></a>写博客</h2><p>不知不觉，我的博客已经写了76篇了，算是这篇77篇。</p><p>从4月份建站到现在，我几乎每个月都发几篇博客，其实这个动力不是来自求生的欲望，就是我单纯的喜欢，我喜欢分享，记录我的经验，希望能帮助到更多的人，而且我认为总结能让我更加进步，仅此而已。</p><p>纯粹地喜欢记录自己的生活历程。</p><p>正因为我发自内心喜欢写博客，经常下班后在家写到半夜，总结案例，写感悟，孜孜不倦。</p><p>在我很多朋友看来，我只是一个坚持写博客的程序员。</p><p>他们理解的坚持只不过是自己做不到这点罢了，当然我没有说他们一定要写博客，所有能对自己有提升的事都值得去做。</p><p>而他们说上班很忙，没有时间总结、学习，实际上他们回到家躺在床上，刷抖音，刷微博，看直播，看剧而已。</p><p>其实这都是借口，他们只不过还没找到总结、学习的动力而已。</p><p>他们只不过不想获得更高的收入，不想更进一步，已经满足现状了而已。</p><h2 id="玩游戏"><a href="#玩游戏" class="headerlink" title="玩游戏"></a>玩游戏</h2><p>我是一个从小玩到大的重度游戏爱好者，从小学玩电脑游戏直到我工作，整整17年。</p><p>可以说我认为我是一个比较会玩的人，而且玩的很认真。</p><p>所有那些教我玩各种游戏的师傅们基本上都被我超越了，甚至要反带他们游戏。</p><p>这个不是吹牛，了解我游戏经历的都懂。</p><p>但是就在来深圳后的这段时间，我莫名其妙地不爱玩游戏了。很多朋友说我变了，居然没有那么爱玩游戏了，感觉比太阳从西边升起还意外。</p><p>以前回到家，无聊的时候必须来几把LOL，下棋吃鸡，一个人玩的也很有意思，但是时代变了，我的内心告诉我现在已经不能和年轻时一样那么玩了。</p><p>所以现在回到家，我即使没有什么事，我就不会玩游戏（除非有朋友一起喊我，5黑局或者LOL开无限火力之类），从内心克制住自己是需要动力的。因为我明白现在对于我来说，努力学习更多的技术赚更多钱是我现在要做的事。</p><p>在我上学那会，经常说戒网瘾最好的方法转移注意力，去谈场恋爱，去旅游，实际上我在热恋期过后还是喜欢去玩游戏，甚至在旅游的时候等火车的情况也会去网吧打几把游戏。</p><p>因为游戏就是我天生喜欢的，发自内心的，可即使是这种发自内心的动力，也敌不过求生的动力。</p><h2 id="学英语"><a href="#学英语" class="headerlink" title="学英语"></a>学英语</h2><p>我的英语很差很差，并且不想学，大学4年，每次考4级的时候都会临时抱佛脚，然后考试不会，经过了2次后，我直接不考了。</p><p>总当我想告诉自己下次考级不能这样的时候，我又会象征性的看几天四级词汇，然后又开始玩了。并且看到连曾经英语跟我差不多水平的人都过了4级，我还是没激起真正的动力去学习。</p><p>我坚持2天了，那不叫坚持，那就是烂，放弃。</p><p>直到我上班后，发现很多同事，都是直接看英文文档无压力，起初我还以为别人是装逼，故意看英文的，后来才直到别人是在学习底层的技术，看国外的文献。</p><p>慢慢地，我发现也国内很多讲技术原理的文章都是水文，你抄我我抄你，很难快速找到对自己有益的文章，这个时候，直接看那些开技术的官方文献才是最快、最全、最深地了解技术的方法。</p><p>但是除了Google、AWS等大型公司以外，大部分技术文献全是英文不支持翻译，纯靠翻译软件很难去看懂文章的，而且也很难学习到文章的精髓。</p><p>从那刻起，我学习英语动力慢慢地形成了，我自发的学起了英语，虽然还不够强大，但是我会每天都学一下英语，并且越难看的文章我越想去看懂（征服的欲望）。</p><p>问了几个读研读博的朋友，学习下别人学英语的经验，其实他们都觉得学英语很简单，一直看英语就行了，有的大佬说他学校实验室的器材的说明书全是英文的，不会英文根本动不了手，而他在大学时就基本可以轻松地阅读任何英文说明书以及国外的大部分文献。</p><p>对他们来说，根本没有坚持这个概念，因为很早他们就已经知道自己一定要学会这门语言，心里有动力，何来坚持学英语这一说？</p><h1 id="为什么有的人不能“坚持”"><a href="#为什么有的人不能“坚持”" class="headerlink" title="为什么有的人不能“坚持”"></a>为什么有的人不能“坚持”</h1><p>其实所有说到坚持带来正面作用的前提都是能找到内心真正的动力，而内心的动力的港湾需要我们自己搭建，添砖加瓦装饰，去花时间去完成的。</p><p>而平常我们不管是刷抖音，还是看名人名言、心灵鸡汤、视频文章，这些只不过是在外面找很多的素材，装进我们大脑的临时存放点而已，还没有加装到动力的港湾。</p><p>所以很多人平常说要少看毒鸡汤、少看成功人士的励志事迹，他们的理由都是因为他们只看也只能看到这些素材的表面，并没有给动力的港湾真正地添砖加瓦。</p><p>短时间上，你看到了某些励志事件，你可能会说，我要努力，我要考研，我要考证，但是你没有真正读懂那些事件并将它装饰到你内心动力的港湾上。</p><p>这样时间一长，这些表面的东西反而发霉发烂，成为了赃物质，我们就忘了，我们一事无成，并且觉得心灵鸡汤没有什么用。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>最后总结一下。</p><ul><li>在没有找到内心的动力之前，一定不要去做一件让人看似是一件值得“坚持”的事，最好什么都不要做，先想明白。</li><li>不求效果不看效率的勤奋比懒惰更可怕！伴随着驱动力，你还需要一个清晰的计划去执行。</li><li>以后从大脑中删除“坚持”这个词，没有所谓的坚持，只有内心真正的动力。</li></ul><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> 顶级理解 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 顶级理解 </tag>
            
            <tag> 坚持 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维手册——Ubuntu自动更新导致Docker挂掉</title>
      <link href="2020/12/01/bug/ubuntu-stop-docker/"/>
      <url>2020/12/01/bug/ubuntu-stop-docker/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近研发告诉我es的接口有问题，让我看看有什么异常，我进入服务器发现docker莫名其妙的关闭了，一起来看看什么情况吧。</p><h1 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h1><p>进入服务器执行docker ps</p><p>报错Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?</p><p>什么情况？docker居然挂了</p><p>然后我启动docker</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker ps </span><br><span class="line">efe0e0e6afb6        docker.elastic.co&#x2F;elasticsearch&#x2F;elasticsearch:7.6.1   &quot;&#x2F;usr&#x2F;local&#x2F;bin&#x2F;dock…&quot;   5 months ago        Exited (143) 8 minutes ago          0.0.0.0:9200-&gt;9200&#x2F;tcp, 0.0.0.0:9300-&gt;9300&#x2F;tcp   elasticsearch</span><br></pre></td></tr></table></figure><p>es还没加入docker自启，没办法，再手动执行下启动。</p><p>然后让研发去看业务情况</p><p>已恢复正常</p><p>docker莫名其妙挂掉是我从认识docker到现在第一次遇见的问题（又是一个很好的案例）</p><p>我开始排查问题了</p><h1 id="分析问题"><a href="#分析问题" class="headerlink" title="分析问题"></a>分析问题</h1><p>这台机器运行很久了es，按道理来说不会出现很大的问题，但是我还是先看看es的日志</p><h2 id="查看es的日志"><a href="#查看es的日志" class="headerlink" title="查看es的日志"></a>查看es的日志</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">docker logs --since&#x3D;10m elasticsearch</span><br><span class="line">&#123;&quot;type&quot;: &quot;server&quot;, &quot;timestamp&quot;: &quot;2020-12-01T06:12:13,007Z&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;component&quot;: &quot;o.e.n.Node&quot;, &quot;cluster.name&quot;: &quot;docker-cluster&quot;, &quot;node.name&quot;: &quot;a46b64546571&quot;, &quot;message&quot;: &quot;stopping ...&quot;, &quot;cluster.uuid&quot;: &quot;szpCxH1aSs-_lhcrNkWsHA&quot;, &quot;node.id&quot;: &quot;gqNUYDc3Q3-GEHODoSu_Hw&quot;  &#125;</span><br><span class="line">&#123;&quot;type&quot;: &quot;server&quot;, &quot;timestamp&quot;: &quot;2020-12-01T06:12:13,031Z&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;component&quot;: &quot;o.e.x.w.WatcherService&quot;, &quot;cluster.name&quot;: &quot;docker-cluster&quot;, &quot;node.name&quot;: &quot;a46b64546571&quot;, &quot;message&quot;: &quot;stopping watch service, reason [shutdown initiated]&quot;, &quot;cluster.uuid&quot;: &quot;szpCxH1aSs-_lhcrNkWsHA&quot;, &quot;node.id&quot;: &quot;gqNUYDc3Q3-GEHODoSu_Hw&quot;  &#125;</span><br><span class="line">&#123;&quot;type&quot;: &quot;server&quot;, &quot;timestamp&quot;: &quot;2020-12-01T06:12:13,033Z&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;component&quot;: &quot;o.e.x.w.WatcherLifeCycleService&quot;, &quot;cluster.name&quot;: &quot;docker-cluster&quot;, &quot;node.name&quot;: &quot;a46b64546571&quot;, &quot;message&quot;: &quot;watcher has stopped and shutdown&quot;, &quot;cluster.uuid&quot;: &quot;szpCxH1aSs-_lhcrNkWsHA&quot;, &quot;node.id&quot;: &quot;gqNUYDc3Q3-GEHODoSu_Hw&quot;  &#125;</span><br><span class="line">&#123;&quot;type&quot;: &quot;server&quot;, &quot;timestamp&quot;: &quot;2020-12-01T06:12:13,222Z&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;component&quot;: &quot;o.e.x.m.p.l.CppLogMessageHandler&quot;, &quot;cluster.name&quot;: &quot;docker-cluster&quot;, &quot;node.name&quot;: &quot;a46b64546571&quot;, &quot;message&quot;: &quot;[controller&#x2F;107] [Main.cc@150] Ml controller exiting&quot;, &quot;cluster.uuid&quot;: &quot;szpCxH1aSs-_lhcrNkWsHA&quot;, &quot;node.id&quot;: &quot;gqNUYDc3Q3-GEHODoSu_Hw&quot;  &#125;</span><br><span class="line">&#123;&quot;type&quot;: &quot;server&quot;, &quot;timestamp&quot;: &quot;2020-12-01T06:12:13,223Z&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;component&quot;: &quot;o.e.x.m.p.NativeController&quot;, &quot;cluster.name&quot;: &quot;docker-cluster&quot;, &quot;node.name&quot;: &quot;a46b64546571&quot;, &quot;message&quot;: &quot;Native controller process has stopped - no new native processes can be started&quot;, &quot;cluster.uuid&quot;: &quot;szpCxH1aSs-_lhcrNkWsHA&quot;, &quot;node.id&quot;: &quot;gqNUYDc3Q3-GEHODoSu_Hw&quot;  &#125;</span><br><span class="line">&#123;&quot;type&quot;: &quot;server&quot;, &quot;timestamp&quot;: &quot;2020-12-01T06:12:13,254Z&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;component&quot;: &quot;o.e.n.Node&quot;, &quot;cluster.name&quot;: &quot;docker-cluster&quot;, &quot;node.name&quot;: &quot;a46b64546571&quot;, &quot;message&quot;: &quot;stopped&quot;, &quot;cluster.uuid&quot;: &quot;szpCxH1aSs-_lhcrNkWsHA&quot;, &quot;node.id&quot;: &quot;gqNUYDc3Q3-GEHODoSu_Hw&quot;  &#125;</span><br><span class="line">&#123;&quot;type&quot;: &quot;server&quot;, &quot;timestamp&quot;: &quot;2020-12-01T06:12:13,254Z&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;component&quot;: &quot;o.e.n.Node&quot;, &quot;cluster.name&quot;: &quot;docker-cluster&quot;, &quot;node.name&quot;: &quot;a46b64546571&quot;, &quot;message&quot;: &quot;closing ...&quot;, &quot;cluster.uuid&quot;: &quot;szpCxH1aSs-_lhcrNkWsHA&quot;, &quot;node.id&quot;: &quot;gqNUYDc3Q3-GEHODoSu_Hw&quot;  &#125;</span><br><span class="line">&#123;&quot;type&quot;: &quot;server&quot;, &quot;timestamp&quot;: &quot;2020-12-01T06:12:13,283Z&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;component&quot;: &quot;o.e.n.Node&quot;, &quot;cluster.name&quot;: &quot;docker-cluster&quot;, &quot;node.name&quot;: &quot;a46b64546571&quot;, &quot;message&quot;: &quot;closed&quot;, &quot;cluster.uuid&quot;: &quot;szpCxH1aSs-_lhcrNkWsHA&quot;, &quot;node.id&quot;: &quot;gqNUYDc3Q3-GEHODoSu_Hw&quot;  &#125;</span><br><span class="line">OpenJDK 64-Bit Server VM warning: Option UseConcMarkSweepGC was deprecated in version 9.0 and will likely be removed in a future release.</span><br><span class="line">&#123;&quot;type&quot;: &quot;server&quot;, &quot;timestamp&quot;: &quot;2020-12-01T06:20:32,884Z&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;component&quot;: &quot;o.e.e.NodeEnvironment&quot;, &quot;cluster.name&quot;: &quot;docker-cluster&quot;, &quot;node.name&quot;: &quot;a46b64546571&quot;, &quot;message&quot;: &quot;using [1] data paths, mounts [[&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;data (&#x2F;dev&#x2F;xvda1)]], net usable_space [115.9gb], net total_space [290.7gb], types [ext4]&quot; &#125;</span><br><span class="line">&#123;&quot;type&quot;: &quot;server&quot;, &quot;timestamp&quot;: &quot;2020-12-01T06:20:32,887Z&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;component&quot;: &quot;o.e.e.NodeEnvironment&quot;, &quot;cluster.name&quot;: &quot;docker-cluster&quot;, &quot;node.name&quot;: &quot;a46b64546571&quot;, &quot;message&quot;: &quot;heap size [989.8mb], compressed ordinary object pointers [true]&quot; &#125;</span><br><span class="line">&#123;&quot;type&quot;: &quot;server&quot;, &quot;timestamp&quot;: &quot;2020-12-01T06:20:33,107Z&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;component&quot;: &quot;o.e.n.Node&quot;, &quot;cluster.name&quot;: &quot;docker-cluster&quot;, &quot;node.name&quot;: &quot;a46b64546571&quot;, &quot;message&quot;: &quot;node name [a46b64546571], node ID [gqNUYDc3Q3-GEHODoSu_Hw], cluster name [docker-cluster]&quot; &#125;</span><br><span class="line">&#123;&quot;type&quot;: &quot;server&quot;, &quot;timestamp&quot;: &quot;2020-12-01T06:20:33,107Z&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;component&quot;: &quot;o.e.n.Node&quot;, &quot;cluster.name&quot;: &quot;docker-cluster&quot;, &quot;node.name&quot;: &quot;a46b64546571&quot;, &quot;message&quot;: &quot;version[7.6.1], pid[1], build[default&#x2F;docker&#x2F;aa751e09be0a5072e8570670309b1f12348f023b&#x2F;2020-02-29T00:15:25.529771Z], OS[Linux&#x2F;4.4.0-1107-aws&#x2F;amd64], JVM[AdoptOpenJDK&#x2F;OpenJDK 64-Bit Server VM&#x2F;13.0.2&#x2F;13.0.2+8]&quot; &#125;</span><br><span class="line">&#123;&quot;type&quot;: &quot;server&quot;, &quot;timestamp&quot;: &quot;2020-12-01T06:20:33,108Z&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;component&quot;: &quot;o.e.n.Node&quot;, &quot;cluster.name&quot;: &quot;docker-cluster&quot;, &quot;node.name&quot;: &quot;a46b64546571&quot;, &quot;message&quot;: &quot;JVM home [&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;jdk]&quot; &#125;</span><br><span class="line">&#123;&quot;type&quot;: &quot;server&quot;, &quot;timestamp&quot;: &quot;2020-12-01T06:20:33,108Z&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;component&quot;: &quot;o.e.n.Node&quot;, &quot;cluster.name&quot;: &quot;docker-cluster&quot;, &quot;node.name&quot;: &quot;a46b64546571&quot;, &quot;message&quot;: &quot;JVM arguments [-Des.networkaddress.cache.ttl&#x3D;60, -Des.networkaddress.cache.negative.ttl&#x3D;10, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless&#x3D;true, -Dfile.encoding&#x3D;UTF-8, -Djna.nosys&#x3D;true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe&#x3D;true, -Dio.netty.noKeySetOptimization&#x3D;true, -Dio.netty.recycler.maxCapacityPerThread&#x3D;0, -Dio.netty.allocator.numDirectArenas&#x3D;0, -Dlog4j.shutdownHookEnabled&#x3D;false, -Dlog4j2.disable.jmx&#x3D;true, -Djava.locale.providers&#x3D;COMPAT, -Xms1g, -Xmx1g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction&#x3D;75, -XX:+UseCMSInitiatingOccupancyOnly, -Djava.io.tmpdir&#x3D;&#x2F;tmp&#x2F;elasticsearch-10754764247634730824, -XX:+HeapDumpOnOutOfMemoryError, -XX:HeapDumpPath&#x3D;data, -XX:ErrorFile&#x3D;logs&#x2F;hs_err_pid%p.log, -Xlog:gc*,gc+age&#x3D;trace,safepoint:file&#x3D;logs&#x2F;gc.log:utctime,pid,tags:filecount&#x3D;32,filesize&#x3D;64m, -Des.cgroups.hierarchy.override&#x3D;&#x2F;, -XX:MaxDirectMemorySize&#x3D;536870912, -Des.path.home&#x3D;&#x2F;usr&#x2F;share&#x2F;elasticsearch, -Des.path.conf&#x3D;&#x2F;usr&#x2F;share&#x2F;elasticsearch&#x2F;config, -Des.distribution.flavor&#x3D;default, -Des.distribution.type&#x3D;docker, -Des.bundled_jdk&#x3D;true]&quot; &#125;</span><br><span class="line">&#123;&quot;type&quot;: &quot;server&quot;, &quot;timestamp&quot;: &quot;2020-12-01T06:20:35,100Z&quot;, &quot;level&quot;: &quot;INFO&quot;, &quot;component&quot;: &quot;o.e.p.PluginsService&quot;, &quot;cluster.name&quot;: &quot;docker-cluster&quot;, &quot;node.name&quot;: &quot;a46b64546571&quot;, &quot;message&quot;: &quot;loaded module [aggs-matrix-stats]&quot; &#125;</span><br></pre></td></tr></table></figure><p>没有发现异常的报错</p><p>在06:12:13 es shutdown initiated，然后就是在我重启es时候的启动日志</p><h2 id="查看系统日志"><a href="#查看系统日志" class="headerlink" title="查看系统日志"></a>查看系统日志</h2><p>其实docker服务端挂了应该查看系统日志的，由于该系统是ubuntu，系统日志和centos的文件名不一样</p><ul><li>ubuntu:/var/log/syslog</li><li>centos:/var/log/message</li></ul><p>查看系统日志</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">Dec  1 06:12:06 ip-172-31-9-211 systemd[1]: Starting Daily apt upgrade and clean activities...</span><br><span class="line">Dec  1 06:12:12 ip-172-31-9-211 systemd[1]: Stopping Docker Application Container Engine...</span><br><span class="line">Dec  1 06:12:12 ip-172-31-9-211 dockerd[9207]: time&#x3D;&quot;2020-12-01T06:12:12.888077281Z&quot; level&#x3D;info msg&#x3D;&quot;Processing signal &#39;terminated&#39;&quot;</span><br><span class="line">Dec  1 06:12:13 ip-172-31-9-211 containerd[9012]: time&#x3D;&quot;2020-12-01T06:12:13.644972637Z&quot; level&#x3D;info msg&#x3D;&quot;shim reaped&quot; id&#x3D;a46b645465716f6a73d53e469e5309374203ac66a22a8cb24e580fa5e323bf94</span><br><span class="line">Dec  1 06:12:13 ip-172-31-9-211 dockerd[9207]: time&#x3D;&quot;2020-12-01T06:12:13.656582665Z&quot; level&#x3D;info msg&#x3D;&quot;ignoring event&quot; module&#x3D;libcontainerd namespace&#x3D;moby topic&#x3D;&#x2F;tasks&#x2F;delete type&#x3D;&quot;*events.TaskDelete&quot;</span><br><span class="line">Dec  1 06:12:13 ip-172-31-9-211 kernel: [16150387.556365] docker0: port 1(veth0648dd7) entered disabled state</span><br><span class="line">Dec  1 06:12:13 ip-172-31-9-211 kernel: [16150387.556413] vetha405001: renamed from eth0</span><br><span class="line">Dec  1 06:12:13 ip-172-31-9-211 kernel: [16150387.602825] docker0: port 1(veth0648dd7) entered disabled state</span><br><span class="line">Dec  1 06:12:13 ip-172-31-9-211 kernel: [16150387.605100] device veth0648dd7 left promiscuous mode</span><br><span class="line">Dec  1 06:12:13 ip-172-31-9-211 kernel: [16150387.605102] docker0: port 1(veth0648dd7) entered disabled state</span><br><span class="line">Dec  1 06:12:13 ip-172-31-9-211 dockerd[9207]: time&#x3D;&quot;2020-12-01T06:12:13.891197598Z&quot; level&#x3D;info msg&#x3D;&quot;stopping event stream following graceful shutdown&quot; error&#x3D;&quot;&lt;nil&gt;&quot; module&#x3D;libcontainerd namespace&#x3D;moby</span><br><span class="line">Dec  1 06:12:13 ip-172-31-9-211 systemd[1]: Stopped Docker Application Container Engine.</span><br><span class="line">Dec  1 06:12:13 ip-172-31-9-211 systemd[1]: Stopping containerd container runtime...</span><br><span class="line">Dec  1 06:12:13 ip-172-31-9-211 systemd[1]: Closed Docker Socket for the API.</span><br><span class="line">Dec  1 06:12:13 ip-172-31-9-211 containerd[9012]: time&#x3D;&quot;2020-12-01T06:12:13.897714411Z&quot; level&#x3D;info msg&#x3D;&quot;Stop CRI service&quot;</span><br><span class="line">Dec  1 06:12:13 ip-172-31-9-211 systemd[1]: Stopped containerd container runtime.</span><br><span class="line">Dec  1 06:12:15 ip-172-31-9-211 systemd[1]: Reloading.</span><br><span class="line">Dec  1 06:12:15 ip-172-31-9-211 systemd[1]: Started ACPI event daemon.</span><br><span class="line">Dec  1 06:12:15 ip-172-31-9-211 systemd[1]: Reloading.</span><br><span class="line">Dec  1 06:12:15 ip-172-31-9-211 systemd[1]: Started ACPI event daemon.</span><br><span class="line">Dec  1 06:12:16 ip-172-31-9-211 systemd[1]: Reloading.</span><br><span class="line">Dec  1 06:12:16 ip-172-31-9-211 systemd[1]: Started ACPI event daemon.</span><br><span class="line">Dec  1 06:12:16 ip-172-31-9-211 systemd[1]: Starting containerd container runtime...</span><br><span class="line">Dec  1 06:12:16 ip-172-31-9-211 systemd[1]: Started containerd container runtime.</span><br><span class="line">Dec  1 06:12:16 ip-172-31-9-211 containerd[23029]: time&#x3D;&quot;2020-12-01T06:12:16.488707190Z&quot; level&#x3D;info msg&#x3D;&quot;starting containerd&quot; revision&#x3D; version&#x3D;&quot;1.2.6-0ubuntu1~16.04.5&quot;</span><br><span class="line">Dec  1 06:12:16 ip-172-31-9-211 containerd[23029]: time&#x3D;&quot;2020-12-01T06:12:16.489313544Z&quot; level&#x3D;info msg&#x3D;&quot;loading plugin &quot;io.containerd.content.v1.content&quot;...&quot; type&#x3D;io.containerd.content.v1</span><br><span class="line">Dec  1 06:12:16 ip-172-31-9-211 containerd[23029]: time&#x3D;&quot;2020-12-01T06:12:16.489354448Z&quot; level&#x3D;info msg&#x3D;&quot;loading plugin &quot;io.containerd.snapshotter.v1.btrfs&quot;...&quot; type&#x3D;io.containerd.snapshotter.v1</span><br><span class="line">Dec  1 06:12:16 ip-172-31-9-211 containerd[23029]: time&#x3D;&quot;2020-12-01T06:12:16.489512243Z&quot; level&#x3D;warning msg&#x3D;&quot;failed to load plugin io.containerd.snapshotter.v1.btrfs&quot; error&#x3D;&quot;path &#x2F;var&#x2F;lib&#x2F;containerd&#x2F;io.containerd.snapshotter.v1.btrfs must be a btrfs filesystem to be used with the btrfs snapshotter&quot;</span><br><span class="line">Dec  1 06:12:16 ip-172-31-9-211 containerd[23029]: time&#x3D;&quot;2020-12-01T06:12:16.489526672Z&quot; level&#x3D;info msg&#x3D;&quot;loading plugin &quot;io.containerd.snapshotter.v1.aufs&quot;...&quot; type&#x3D;io.containerd.snapshotter.v1</span><br><span class="line">Dec  1 06:12:16 ip-172-31-9-211 containerd[23029]: time&#x3D;&quot;2020-12-01T06:12:16.491827595Z&quot; level&#x3D;info msg&#x3D;&quot;loading plugin &quot;io.containerd.snapshotter.v1.native&quot;...&quot; type&#x3D;io.containerd.snapshotter.v1</span><br><span class="line">Dec  1 06:12:16 ip-172-31-9-211 containerd[23029]: time&#x3D;&quot;2020-12-01T06:12:16.491861430Z&quot; level&#x3D;info msg&#x3D;&quot;loading plugin &quot;io.containerd.snapshotter.v1.overlayfs&quot;...&quot; type&#x3D;io.containerd.snapshotter.v1</span><br><span class="line">Dec  1 06:12:16 ip-172-31-9-211 containerd[23029]: time&#x3D;&quot;2020-12-01T06:12:16.492928937Z&quot; level&#x3D;info msg&#x3D;&quot;loading plugin &quot;io.containerd.snapshotter.v1.zfs&quot;...&quot; type&#x3D;io.containerd.snapshotter.v1</span><br><span class="line">Dec  1 06:12:16 ip-172-31-9-211 containerd[23029]: time&#x3D;&quot;2020-12-01T06:12:16.493102743Z&quot; level&#x3D;warning msg&#x3D;&quot;failed to load plugin io.containerd.snapshotter.v1.zfs&quot; error&#x3D;&quot;path &#x2F;var&#x2F;lib&#x2F;containerd&#x2F;io.containerd.snapshotter.v1.zfs must be a zfs filesystem to be used with the zfs snapshotter&quot;</span><br><span class="line">Dec  1 06:12:16 ip-172-31-9-211 containerd[23029]: time&#x3D;&quot;2020-12-01T06:12:16.493123074Z&quot; level&#x3D;info msg&#x3D;&quot;loading plugin &quot;io.containerd.metadata.v1.bolt&quot;...&quot; type&#x3D;io.containerd.metadata.v1</span><br><span class="line">Dec  1 06:12:16 ip-172-31-9-211 containerd[23029]: time&#x3D;&quot;2020-12-01T06:12:16.493137475Z&quot; level&#x3D;warning msg&#x3D;&quot;could not use snapshotter zfs in metadata plugin&quot; error&#x3D;&quot;path &#x2F;var&#x2F;lib&#x2F;containerd&#x2F;io.containerd.snapshotter.v1.zfs must be a zfs filesystem to be used with the zfs snapshotter&quot;</span><br><span class="line">Dec  1 06:12:16 ip-172-31-9-211 containerd[23029]: time&#x3D;&quot;2020-12-01T06:12:16.493161028Z&quot; level&#x3D;warning msg&#x3D;&quot;could not use snapshotter btrfs in metadata plugin&quot; error&#x3D;&quot;path &#x2F;var&#x2F;lib&#x2F;containerd&#x2F;io.containerd.snapshotter.v1.btrfs must be a btrfs filesystem to be used with the btrfs snapshotter&quot;</span><br></pre></td></tr></table></figure><p>果然发现问题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Starting Daily apt upgrade and clean activities</span><br><span class="line">Stopping Docker Application Container Engine</span><br></pre></td></tr></table></figure><p>问了下专业玩ubuntu的研发，他说这个是ubuntu的自动更新，默认ubuntu是开启了这个自动更新</p><p>但是他也不明白为什么自动更新会关闭Docker </p><p>google发现网上有很多吐槽ubuntu自动更新的。。。</p><p>网上随便截几个例子</p><ul><li><p>自动更新导致Mysql关闭</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">May 17 06:53:19 campaygn-production systemd[1]: Starting Daily apt upgrade and clean activities...</span><br><span class="line">May 17 06:53:27 campaygn-production systemd[1]: Reloading.</span><br><span class="line">May 17 06:53:27 campaygn-production systemd[1]: Started ACPI event daemon.</span><br><span class="line">May 17 06:53:27 campaygn-production systemd[1]: Stopping MySQL Community Server...</span><br><span class="line">May 17 06:53:36 campaygn-production systemd[1]: Stopped MySQL Community Server.</span><br></pre></td></tr></table></figure></li><li><p>自动更新导致系统时区会莫名其妙的变成美国时区</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Jan  3 06:39:19 s1 systemd[1]: Starting Daily apt upgrade and clean activities...</span><br><span class="line">Jan  3 06:39:39 s1 systemd[1]: Started Daily apt upgrade and clean activities.</span><br></pre></td></tr></table></figure><p>这样看起来，至少我认为生产环境不应该开启自动更新。。。</p><h2 id="刨根问底"><a href="#刨根问底" class="headerlink" title="刨根问底"></a>刨根问底</h2><p>到底是自动更新了什么，导致docker重启？</p><p>google了ubuntu的更新日志存放位置为/var/log/apt/</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">$:&#x2F;var&#x2F;log&#x2F;apt# ll -rth</span><br><span class="line">total 112K</span><br><span class="line">-rw-r-----  1 root adm    1.3K Dec 17  2019 term.log.12.gz</span><br><span class="line">-rw-r--r--  1 root root    464 Dec 17  2019 history.log.12.gz</span><br><span class="line">-rw-r-----  1 root adm    2.1K Jan 29  2020 term.log.11.gz</span><br><span class="line">-rw-r--r--  1 root root    811 Jan 29  2020 history.log.11.gz</span><br><span class="line">-rw-r-----  1 root adm    1.9K Feb 25  2020 term.log.10.gz</span><br><span class="line">-rw-r--r--  1 root root    602 Feb 25  2020 history.log.10.gz</span><br><span class="line">-rw-r-----  1 root adm    1.5K Mar 26  2020 term.log.9.gz</span><br><span class="line">-rw-r--r--  1 root root    480 Mar 26  2020 history.log.9.gz</span><br><span class="line">-rw-r-----  1 root adm    1.9K Apr 30  2020 term.log.8.gz</span><br><span class="line">-rw-r--r--  1 root root    659 Apr 30  2020 history.log.8.gz</span><br><span class="line">-rw-r-----  1 root adm    2.1K May 29  2020 term.log.7.gz</span><br><span class="line">-rw-r--r--  1 root root    767 May 29  2020 history.log.7.gz</span><br><span class="line">-rw-r-----  1 root adm    1.7K Jun 29 06:51 term.log.6.gz</span><br><span class="line">-rw-r--r--  1 root root    545 Jun 29 06:51 history.log.6.gz</span><br><span class="line">-rw-r-----  1 root adm    2.2K Jul 31 06:42 term.log.5.gz</span><br><span class="line">-rw-r--r--  1 root root    701 Jul 31 06:42 history.log.5.gz</span><br><span class="line">-rw-r-----  1 root adm    2.1K Aug 28 06:16 term.log.4.gz</span><br><span class="line">-rw-r--r--  1 root root    735 Aug 28 06:16 history.log.4.gz</span><br><span class="line">-rw-r-----  1 root adm    1.8K Sep 23 06:27 term.log.3.gz</span><br><span class="line">-rw-r--r--  1 root root    585 Sep 23 06:27 history.log.3.gz</span><br><span class="line">-rw-r-----  1 root adm    2.4K Oct 30 06:42 term.log.2.gz</span><br><span class="line">-rw-r--r--  1 root root    864 Oct 30 06:42 history.log.2.gz</span><br><span class="line">-rw-r-----  1 root adm    1.2K Dec  1 06:12 term.log.1.gz</span><br><span class="line">-rw-r--r--  1 root root    556 Dec  1 06:12 history.log.1.gz</span><br><span class="line">-rw-r-----  1 root adm     782 Dec  1 08:29 term.log</span><br><span class="line">-rw-r--r--  1 root root    164 Dec  1 08:29 history.log</span><br></pre></td></tr></table></figure><p>我的天，都从2019年更新到现在了，太牛了</p><p>看下Dec  1 06:12的日志</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Start-Date: 2020-12-01  06:12:11</span><br><span class="line">Commandline: &#x2F;usr&#x2F;bin&#x2F;unattended-upgrade</span><br><span class="line">Upgrade: containerd:amd64 (1.2.6-0ubuntu1~16.04.4, 1.2.6-0ubuntu1~16.04.5)</span><br><span class="line">End-Date: 2020-12-01  06:12:16</span><br></pre></td></tr></table></figure><p>containerd ？？？</p><p>这个不是CNCF的毕业项目——标准的容器进行时吗</p><p>为了防止docker一家独大，docker当年的实现被拆分出了几个标准化的模块，标准化的目的是模块是可被其他实现替换的，不由任何一个厂商控制。</p><p>docker由 docker-client ,dockerd,containerd,docker-shim,runc组成，所以containerd是docker的基础组件之一</p><p>如果你不知道containerd是做什么的，那么请参考下面链接（包括但不限于）进行学习：</p><p><a href="https://github.com/containerd/containerd" target="_blank" rel="noopener">github-containerd</a></p><p>然后我去看github上的项目发现它刚刚更新了，虽然是10多个小时前更新的，但是要把稳定的包上传到apt源上应该还需要一定时间，这样就对上了。</p><h1 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h1><p>为了保证生产环境系统的稳定性，建议关闭自动更新，有需求时可以手动执行apt update</p><p>关闭命令如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get remove unattended-upgrades</span><br><span class="line">sudo systemctl stop apt-daily.timer</span><br><span class="line">sudo systemctl disable apt-daily.timer</span><br><span class="line">sudo systemctl disable apt-daily.service</span><br><span class="line">sudo systemctl daemon-reload</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本次案例从发现问题到本能解决问题花了8分钟，如果按一天的可靠性来算，我只能达到2个9的标准，监控体系正在构建中，我太难了啊。</p><p>加油吧。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://superuser.com/questions/1327884/how-to-disable-daily-upgrade-and-clean-on-ubuntu-16-04" target="_blank" rel="noopener">How to disable daily upgrade and clean on Ubuntu 16.04</a></p>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operation Manual </tag>
            
            <tag> Docker </tag>
            
            <tag> Ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维手册——Centos7内核软死锁</title>
      <link href="2020/11/29/bug/kernel-soft-lockup/"/>
      <url>2020/11/29/bug/kernel-soft-lockup/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近准备做虚拟化，经过分析公司现有的设备后我选择了其中配置一样的两台机器并加装内存。</p><p>加装后配置如下</p><ul><li>CPU:I5-9600KF</li><li>内存:64G 2666MHZ</li><li>磁盘:1THDD</li></ul><p>创建了几台虚拟机并稳定运行一段时间</p><p>随着我把项目慢慢迁移到虚拟机上发现有一天突然所有机器都“似乎”挂掉了，一起来看看怎么回事吧。</p><h1 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h1><p>研发人员有天突然发现有个服务挂了，让我查下原因，然后我发现有台机器上的pod状态处于Terminating 状态</p><p>而且删除还没用</p><p>google了一下出现Terminating的情况有以下几种</p><ul><li>磁盘空间不足</li><li>存在 “i” 文件属性</li><li>Docker 17 版本 bug</li><li>存在 Finalizers</li><li>低版本 kubelet list-watch 的 bug</li><li>Dockerd 与 containerd 状态不同步</li><li>Daemonset Controller Bug</li></ul><p>可惜发现目前的问题还不是由上面情况造成的</p><p>后来观察了下，我又发现所有Terminating的pod都是一台机器上的</p><p>然后执行kuberctl get nodes的时候发现</p><p>这台机器的状态是notready</p><p>好家伙，看来是服务器挂了，结果发现不仅这台机器挂了，还有几台机器我也ssh不进去了。</p><p>它们又都是一台服务器虚拟化出来的机器</p><h1 id="分析问题"><a href="#分析问题" class="headerlink" title="分析问题"></a>分析问题</h1><p>差不多定位到问题了，主机有问题，它虚拟化的机器当然有问题。</p><p>我先ping这台机器，发现能通</p><p>然后远程连接发现这台机器的CPU已经百分之100，然后一直恐怖地持续了1个多小时了。</p><p>我在控制台上看虚拟机的界面都开启了，但实际上没有一台机器能运行</p><p>目前这台机器跑了4台虚拟机</p><p>我杀掉一台负载最高的一台虚拟机</p><p>结果发现其他3台虚拟机又迅速把CPU吃满</p><p>直到我杀掉所有进程</p><p>把4台虚拟机释放，这才好起来了</p><p>然后我了一台机器，正常运行</p><p>进入这台机器看系统日志，发现报错如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: NMI watchdog: BUG: soft lockup - CPU#1 stuck for 23s! [kubelet:73052]</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: Modules linked in: veth vxlan ip6_udp_tunnel udp_tunnel xt_statistic xt_physdev xt_nat ip6table_nat nf_conntrack_ipv6 nf_defrag_ipv6 nf_nat_ipv6 ip6_tables xt_comment xt_mark xt_conntrack ipt_MASQUERADE nf_nat_masquerade_ipv4 nf_conntrack_netlink nfnetlink xt_addrtype iptable_filter iptable_nat nf_nat_ipv4 nf_nat overlay(T) vmw_vsock_vmci_transport vsock iosf_mbi crc32_pclmul ghash_clmulni_intel ppdev aesni_intel vmw_balloon lrw gf128mul glue_helper ablk_helper cryptd joydev pcspkr sg vmw_vmci i2c_piix4 parport_pc parport nf_conntrack_ipv4 nf_defrag_ipv4 br_netfilter bridge stp llc ip_vs_sh ip_vs_wrr ip_vs_rr ip_vs nf_conntrack sunrpc ip_tables xfs libcrc32c sr_mod cdrom sd_mod crc_t10dif crct10dif_generic ata_generic pata_acpi vmwgfx drm_kms_helper syscopyarea sysfillrect sysimgblt fb_sys_fops</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: ttm ata_piix drm nfit libata libnvdimm mptspi crct10dif_pclmul crct10dif_common scsi_transport_spi crc32c_intel mptscsih e1000 mptbase serio_raw drm_panel_orientation_quirks dm_mirror dm_region_hash dm_log dm_mod</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: CPU: 1 PID: 73052 Comm: kubelet Kdump: loaded Tainted: G               ------------ T 3.10.0-1127.el7.x86_64 #1</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: Hardware name: VMware, Inc. VMware Virtual Platform&#x2F;440BX Desktop Reference Platform, BIOS 6.00 02&#x2F;27&#x2F;2020</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: task: ffff88a5fe3862a0 ti: ffff88a60aaec000 task.ti: ffff88a60aaec000</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: RIP: 0010:[&lt;ffffffff9d716f62&gt;]  [&lt;ffffffff9d716f62&gt;] generic_exec_single+0x102&#x2F;0x1c0</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: RSP: 0000:ffff88a60aaefb60  EFLAGS: 00000202</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: RAX: 0000000000000080 RBX: ffff88a60aaefb30 RCX: 0000000000000003</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: RDX: ffffffff9de13b10 RSI: 0000000000000080 RDI: 0000000000000286</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: RBP: ffff88a60aaefba8 R08: ffffffff9de13b08 R09: ffffd4859e961580</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: R10: 0000000000004b35 R11: fffffffffffffffa R12: 0000000000000002</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: R13: ffff88a63ffd9008 R14: 0000000000000000 R15: 000000031d65acc0</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: FS:  00007f8c97fff700(0000) GS:ffff88a61d640000(0000) knlGS:0000000000000000</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: CS:  0010 DS: 0000 ES: 0000 CR0: 0000000080050033</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: CR2: 00007f8cac560ee0 CR3: 0000000818c9a000 CR4: 00000000003607e0</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: Call Trace:</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: [&lt;ffffffff9d67e730&gt;] ? leave_mm+0x120&#x2F;0x120</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: [&lt;ffffffff9d67e730&gt;] ? leave_mm+0x120&#x2F;0x120</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: [&lt;ffffffff9d67e730&gt;] ? leave_mm+0x120&#x2F;0x120</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: [&lt;ffffffff9d71707f&gt;] smp_call_function_single+0x5f&#x2F;0xa0</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: [&lt;ffffffff9d984ee5&gt;] ? cpumask_next_and+0x35&#x2F;0x50</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: [&lt;ffffffff9d71762b&gt;] smp_call_function_many+0x22b&#x2F;0x270</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: [&lt;ffffffff9d67e8f8&gt;] native_flush_tlb_others+0xb8&#x2F;0xc0</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: [&lt;ffffffff9d67ea94&gt;] flush_tlb_page+0x54&#x2F;0xa0</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: [&lt;ffffffff9d8077f8&gt;] ptep_clear_flush+0x68&#x2F;0xa0</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: [&lt;ffffffff9d7ef345&gt;] wp_page_copy.isra.73+0x335&#x2F;0x5b0</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: [&lt;ffffffff9d7f176b&gt;] do_wp_page+0xfb&#x2F;0x720</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: [&lt;ffffffff9d871054&gt;] ? mntput+0x24&#x2F;0x40</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: [&lt;ffffffff9d85e266&gt;] ? path_openat+0x176&#x2F;0x5a0</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: [&lt;ffffffff9d7f5e02&gt;] handle_mm_fault+0xb22&#x2F;0xfb0</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: [&lt;ffffffff9dd8d653&gt;] __do_page_fault+0x213&#x2F;0x500</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: [&lt;ffffffff9dd8d975&gt;] do_page_fault+0x35&#x2F;0x90</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: [&lt;ffffffff9dd89778&gt;] page_fault+0x28&#x2F;0x30</span><br><span class="line">Nov 27 11:02:10 vm-20-41-k8s-node kernel: Code: 89 de 48 03 14 c5 e0 0f 35 9e 48 89 df e8 17 51 28 00 84 c0 75 53 45 85 ed 74 16 f6 43 20 01 74 10 0f 1f 84 00 00 00 00 00 f3 90 &lt;f6&gt; 43 20 01 75 f8 31 c0 48 8b 7c 24 28 65 48 33 3c 25 28 00 00</span><br></pre></td></tr></table></figure><p>网上查了下资料发现这个报错叫作内核软死锁</p><h2 id="内核软死锁"><a href="#内核软死锁" class="headerlink" title="内核软死锁"></a>内核软死锁</h2><p>这个bug没有让系统彻底死机，但是若干个进程（或者kernel thread）被锁死在了某个状态（一般在内核区域），很多情况下这个是由于内核锁的使用的问题。  </p><p>Linux内核对于每一个cpu都有一个监控进程，在技术界这个叫做watchdog（看门狗）。通过ps –ef | grep watchdog能够看见，进程名称大概是watchdog/X（数字：cpu逻辑编号1/2/3/4之类的）。</p><p>这个进程或者线程每一秒钟运行一次，否则会睡眠和待机。这个进程运行会收集每一个cpu运行时使用数据的时间并且存放到属于每个cpu自己的内核数据结构。在内核中有很多特定的中断函数。</p><p>这些中断函数会调用soft lockup计数，他会使用当前的时间戳与特定（对应的）cpu的内核数据结构中保存的时间对比，如果发现当前的时间戳比对应cpu保存的时间大于设定的阀值，他就假设监测进程或看门狗线程在一个相当可观的时间还没有执。</p><p>Cpu软锁为什么会产生，是怎么产生的？如果linux内核是经过精心设计安排的CPU调度访问，那么怎么会产生cpu软死锁？那么只能说由于用户开发的或者第三方软件引入，看我们服务器内核panic的原因就是qmgr进程引起。</p><p>因为每一个无限的循环都会一直有一个cpu的执行流程（qmgr进程示一个后台邮件的消息队列服务进程），并且拥有一定的优先级。</p><p>Cpu调度器调度一个驱动程序来运行，如果这个驱动程序有问题并且没有被检测到，那么这个驱动程序将会暂用cpu的很长时间。</p><p>根据前面的描述，看门狗进程会抓住（catch）这一点并且抛出一个软死锁（soft lockup）错误。软死锁会挂起cpu使你的系统不可用。</p><h2 id="软死锁的原因"><a href="#软死锁的原因" class="headerlink" title="软死锁的原因"></a>软死锁的原因</h2><ul><li>服务器电源供电不足，导致CPU电压不稳导致CPU死锁</li><li>虚机所在的宿主机的CPU太忙或磁盘IO太高</li><li>BIOS KVM开启以后的相关bug，关闭KVM可解决，但关闭以后物理机不支持虚拟化</li><li>VM网卡驱动存在bug，处理高水位流量时存在bug导致CPU死锁</li><li>BIOS开启了超频，导致超频时电压不稳，容易出现CPU死锁</li><li>Linux kernel存在bug</li><li>KVM存在bug</li></ul><h2 id="监控"><a href="#监控" class="headerlink" title="监控"></a>监控</h2><p>万事离不开监控，通过我之前安装的K8S的监控可以清晰的发现，在之前Terminating的容器的生命周期里，最后CPU达到百分之100（2C），出现了2个这样Terminating的容器</p><p>那么显而易见，这台虚拟机的进程把CPU跑满，导致这台虚拟机所在宿主机的CPU太慢，从而影响整个虚拟机集群</p><h1 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h1><p>目前这台宿主机上虚拟化的4台配置如下</p><p>三台2c 4g </p><p>一台6c 48g</p><p>而这台宿主机刚刚开始介绍说了是CPU I5-9600KF 只能虚拟化出来6c</p><p>怪我当初太贪了，我想的是那3台机器应该占用不了2c，但是提高cpu上限能增加突发情况的CPU处理速度</p><p>结果没考虑到当所有的机器都需要大量计算时，整体虚拟机的CPU核心数上限（12c）已经远远超过宿主机的CPU核心数（6c）</p><p>最后我将这些机器老老实实改成3台1c的和一台3c的机器了，然后再更改pod的模板，将上限调低到1.2c 最多有2个容器在这个虚拟机上跑</p><p>经过几天的测试后发现之前的问题已经不存在。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>总结其实没少好说的，贪了一手，毕竟我比较机智，目前只将部分测试环境的服务迁移到这些虚拟机上</p><p>这个事件再次印证了一个道理，上生产之前一定要经过大量的测试，每一次暴露的问题都能让你少在生产重犯一些失误，敬畏你的工作——SRE。</p><p>PS：至于为什么用酷睿的CPU，其实不是我想用，而是公司还剩很多主机，并且没有额外的服务器，只能拿主机当服务器使用了，就这么简单，我也想用至强的啊。。。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://cloud.tencent.com/document/product/457/43238" target="_blank" rel="noopener">Pod 一直处于 Terminating 状态</a></p><p><a href="https://www.cnblogs.com/RXDXB/p/12605529.html" target="_blank" rel="noopener">报错kernel:NMI watchdog: BUG: soft lockup - CPU#0 stuck for 22s</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operation Manual </tag>
            
            <tag> Centos </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《SRE：Google运维解密》读书心得(三)——SRE团队指导思想（上）</title>
      <link href="2020/11/29/sre/google-sre-3/"/>
      <url>2020/11/29/sre/google-sre-3/</url>
      
        <content type="html"><![CDATA[<blockquote><p>好书不怕读的晚，就怕明知道读的晚仍然还不去读。   - 宇神之息 </p></blockquote><h1 id="总体思想"><a href="#总体思想" class="headerlink" title="总体思想"></a>总体思想</h1><p>SRE的总体思想我归纳为以下7点：</p><ul><li>评估、管理风险，以及利用错误的预算手段来推进中立性的服务运维</li><li>服务质量指标（SLI）、目标（SLO）、协议（SLA）</li><li>消除琐事</li><li>稳定的监控系统</li><li>自动化工作的方法论</li><li>高效发布</li><li>技术迭代，整体环境更新，简化系统</li></ul><p>本篇总结前4个思想</p><h1 id="拥抱风险"><a href="#拥抱风险" class="headerlink" title="拥抱风险"></a>拥抱风险</h1><p>SRE旨在寻求快速创新和高效的服务运营业务之间的风险平衡，而不是简单的将服务在线时间最大化。</p><h2 id="管理风险"><a href="#管理风险" class="headerlink" title="管理风险"></a>管理风险</h2><p>在构建系统的过程中，可靠性进一步提升的成本并不是线性增加的——可靠性的下一个改进可能比之前的改进成本高100倍。主要有以下2点：</p><ul><li>资源成本：需要更多的硬件设备，提供CPU、内存、磁盘等，增加系统稳定性</li><li>机会成本：工程师不能花更多时间从事为终端用户设计新功能，而是承担旧项目可靠性的更新迭代工作</li></ul><h2 id="度量服务的风险"><a href="#度量服务的风险" class="headerlink" title="度量服务的风险"></a>度量服务的风险</h2><p>从两个维度去度量风险</p><ul><li>基于时间的可用性</li></ul><p>可用性=系统正常运行时间/（系统正常运行时间+停机时间）</p><p>一个可用性目标为99.99%的系统在一年中最多停机52.56分钟</p><ul><li>合计可用性</li></ul><p>可用性=成功请求数/总请求数</p><p>一个每天可用性目标为99.99%的系统，一天要接受2.5M个请求。它每天出现少于250个错误即可以达到预计的可用性目标</p><h2 id="服务的风险容忍度"><a href="#服务的风险容忍度" class="headerlink" title="服务的风险容忍度"></a>服务的风险容忍度</h2><p>主要分两大块：</p><ul><li>用户服务（消费者使用产品功能）</li><li>应用服务（服务器状态）</li></ul><p>从用户角度评估风险主要有4点</p><ul><li>需要的可用性水平是什么？</li><li>不同类型的失败对服务有不同的影响吗？</li><li>我们如何使用服务成本来帮助在风险曲线上定位这个服务？</li><li>有哪些其他重要的服务指标需要考虑</li></ul><p>对于Google的服务而言，服务可用性目标通常取决于它提供的功能，以及市场上的定位。</p><ul><li>用户期望的服务水平是什么</li><li>这项服务是否直接关系到收入（我们的收入或我们客户的收入）</li><li>这是一个有偿服务，还是一个免费服务</li><li>如果市场上有竞争对手，那些竞争对手提供的服务水平如何？</li><li>这项服务是针对消费者还是企业的？</li></ul><p>故障类型</p><ul><li>业务对于服务的停机容忍度有多高？</li><li>持续的低故障率或者偶尔发生的全网中断哪个会更糟糕？</li></ul><p>成本</p><ul><li>构建和运维可用性再多一个“9”的系统，收益会增加多少</li><li>额外收入是否能够抵消为了达到这一可靠性水平所付出的成本？</li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>Google的目标是：明确地将运维风险和业务风险对应起来，提高一项服务的可靠性，但不会超过该服务需要的可靠性。</p><h1 id="服务质量指标、目标、协议"><a href="#服务质量指标、目标、协议" class="headerlink" title="服务质量指标、目标、协议"></a>服务质量指标、目标、协议</h1><p>如果不详细了解服务重各种行为的重要程度，并且不去度量这些行为的正确性的话，就无法正确运维这个系统，更不要说可靠地运维了。</p><p>所以不管是对外还是对内，我们都需要制定一个针对用户的服务质量目标并努力地去达到这个质量目标。</p><p>在这个过程中，我们定义了一些服务质量指标（SLI）、服务质量目标（SLO）、以及服务质量协议（SLA）</p><h2 id="SLI"><a href="#SLI" class="headerlink" title="SLI"></a>SLI</h2><p>SLI是指服务质量指标——该服务的某项服务质量的一个具体量化指标。</p><p>指标一般包括以下三点</p><ul><li>请求延迟</li><li>TPS</li><li>可用性、持久性</li></ul><p>运维行业经常用9的数量来描述可用程度。例如，99%可用性被称为2个“9”。</p><p>100%的可用性是不可能实现的</p><h2 id="SLO"><a href="#SLO" class="headerlink" title="SLO"></a>SLO</h2><p>SLO是服务质量目标：服务某个SLI的目标值，或目标范围</p><p>SLO定义是SLI ≤ 目标值，或者范围下限 ≤ SLI ≤ 范围上线</p><p>选择一个合适的SLO是非常复杂的过程。困难点主要在于无法确定一个具体的值。</p><p>解决方法：指定平均指标，鼓励开发优化满足达到指标。</p><h2 id="SLA"><a href="#SLA" class="headerlink" title="SLA"></a>SLA</h2><p>SLA是服务质量协议：指服务与用户之间一个明确的、或者不明确的协议，描述了在没有达到SLO之后的后果。</p><p>这些后果可能是退款、或者其他补偿。</p><h2 id="指标在实践中的应用"><a href="#指标在实践中的应用" class="headerlink" title="指标在实践中的应用"></a>指标在实践中的应用</h2><h3 id="运维人员和最终用户各关心什么"><a href="#运维人员和最终用户各关心什么" class="headerlink" title="运维人员和最终用户各关心什么"></a>运维人员和最终用户各关心什么</h3><ul><li>用户可见的服务系统：比如服务是否能正常请求，每个请求花费的时间是多少？有多少请求能正常处理？</li><li>存储系统：延迟、可用性和数据持久性。比如读写数据需要多久？我们是否可以随时访问数据？数据是否一段时间内还能读取？</li><li>大数据系统：关心吞吐量和端到端的延迟。</li><li>系统的健康程度：是否返回了正确的回复、读取了正确的数据、进行了正确的数据分析操作。</li></ul><h3 id="指标的收集、汇总和标准化"><a href="#指标的收集、汇总和标准化" class="headerlink" title="指标的收集、汇总和标准化"></a>指标的收集、汇总和标准化</h3><ul><li>监控系统收集各种信息</li><li>简化和使数据更可用</li><li>定义一些常见的SLI，避免以后重新评估</li></ul><p>例如：</p><ul><li>汇总间隔：每1分钟汇总一次</li><li>汇总范围：集群中的全部任务</li><li>度量频率：每10秒一次</li><li>包含哪些请求：从黑盒监控发来的HTTP GET请求</li><li>数据如何获取：从监控系统获取服务端信息</li><li>数据访问延迟：从收到请求到最后一个字节被发除</li></ul><h2 id="目标在实践中的应用"><a href="#目标在实践中的应用" class="headerlink" title="目标在实践中的应用"></a>目标在实践中的应用</h2><h3 id="目标的选择"><a href="#目标的选择" class="headerlink" title="目标的选择"></a>目标的选择</h3><ul><li>不要仅以目前状态为基础选择目标</li><li>保持简单</li><li>避免绝对值</li><li>SLO越少越好</li><li>不要追求完美</li></ul><p>SLO可以成为也应该成为 SRE和产品团队划分工作的优先级参考，因为SLO代表了用户的体验程度。</p><h3 id="建立用户预期"><a href="#建立用户预期" class="headerlink" title="建立用户预期"></a>建立用户预期</h3><ul><li>留出一定的安全区</li></ul><p>对内使用更高的SLO，对外使用稍低的SLO可以留出一些时间用来响应问题。</p><ul><li>实际的SLO也不要过高</li></ul><h2 id="协议在实践中的应用"><a href="#协议在实践中的应用" class="headerlink" title="协议在实践中的应用"></a>协议在实践中的应用</h2><p>起草一份SLA需要业务部门和法务部门选择合适的后果条款。</p><h2 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h2><p>事先选择好合适的指标有助于在故障发生时帮助SRE进行更好地决策，同时也为SRE团队判断系统是否正常提供帮助。</p><h1 id="减少琐事"><a href="#减少琐事" class="headerlink" title="减少琐事"></a>减少琐事</h1><p>如果系统正常运转中需要人工干预，应该将此视为一种BUG。</p><p>“正常”的定义会随系统的进步而不断改变。</p><h2 id="琐事的定义"><a href="#琐事的定义" class="headerlink" title="琐事的定义"></a>琐事的定义</h2><p>琐事就是运维服务中手动性的，重复性的，可以被自动化的，战术性，没有持久价值的工作。</p><ul><li>手动性：如果能运行一个脚本可能比手动执行脚本的每一步要快，那么你手动执行的过程就认为是琐事。</li><li>重复性：如果某件事是不停地反复做的工作，就算琐事。</li><li>可以被自动化的：如果计算机可以和人类一样能够很好地完成某个任务，或者通过某种设计变更来彻底消除对某项任务的需求，这项任务就是琐事。</li><li>战术性的：处理紧急报警是琐事。我们可能无法永远消除，但是我们必须继续努力减少它。</li><li>没有持久价值：如果你完成了某项任务后，服务状态没有改变，这项任务很有可能就是琐事。</li><li>与服务同步线性增长：如果工作中设计的业务、服务大小、流量或用户数量呈线性增长关系，但是你没有办法避免用同样的时间去处理，这项任务就被认为是琐事。</li></ul><h2 id="为什么琐事越少越好"><a href="#为什么琐事越少越好" class="headerlink" title="为什么琐事越少越好"></a>为什么琐事越少越好</h2><p>如果不加以控制，琐事会变得越来越多，以至于迅速占据我们每个人100%的时间。减少琐事和扩大服务规模的工作就是SRE中的E（Engineering）</p><p>SRE的公开目标就是保持每个SRE的工作时间重琐事的比例低于50%，并至少花50%的时间在工程项目上，来减少未来的琐事或增加服务功能。</p><h2 id="琐事繁多的危害"><a href="#琐事繁多的危害" class="headerlink" title="琐事繁多的危害"></a>琐事繁多的危害</h2><h3 id="职业停滞"><a href="#职业停滞" class="headerlink" title="职业停滞"></a>职业停滞</h3><p>如果花在工程项目上的时间太少，你的职业发展会变慢、甚至停滞。</p><p>Google确实会奖励那些愿意做脏活累活的人，但是仅仅是该工作是不可避免，并有巨大的正面影响时才会这样做。</p><p>没有人可以通过不停地做脏活累活满足自己的职业发展。</p><h3 id="士气低落"><a href="#士气低落" class="headerlink" title="士气低落"></a>士气低落</h3><p>每个人对自己可以承担的琐事限度有所不同，但是一定有个限度。</p><p>过多的琐事会导致过度劳累、厌倦和不满。</p><h3 id="造成误解"><a href="#造成误解" class="headerlink" title="造成误解"></a>造成误解</h3><p>我们努力确保每个SRE以及每个于SRE一起工作的人都理解SRE是一个工程组织。</p><p>如果个人或者团队过度参与琐事，会让人以为SRE就是处理琐事的职业，造成误解。</p><p>有点类似于外行认为网络工程师即“网管”、程序员是修电脑的角色。</p><h3 id="进展缓慢"><a href="#进展缓慢" class="headerlink" title="进展缓慢"></a>进展缓慢</h3><p>琐事过多会导致团队生产力下降。如果SRE团队忙于为人工操作和导出数据救火，新功能的发布就会变慢。</p><h3 id="开创先例"><a href="#开创先例" class="headerlink" title="开创先例"></a>开创先例</h3><p>如果SRE过于愿意承担琐事，研发同事就更倾向于加入更多的琐事，有时候甚至将本来应该由研发团队承担的运维工作转交给SRE来承担。其他团队也会开始指望SRE接受这样的工作，这显然是不好的。</p><h3 id="促进摩擦产生"><a href="#促进摩擦产生" class="headerlink" title="促进摩擦产生"></a>促进摩擦产生</h3><p>即使你对琐事没有怨言，并不代表你现在的或未来的队友没有怨言。</p><p>如果团队中引入了太多琐事，其实就是在鼓励团队里最好的工程师开始寻找其他地方提供的更有价值的工作（言外之意是他可能离职或者换岗）</p><h3 id="违反承诺"><a href="#违反承诺" class="headerlink" title="违反承诺"></a>违反承诺</h3><p>那些为了项目工程工作而新入职的员工，以及转入SRE的老员工会有被欺骗的感觉，明明是很高大上的工作，结果是专门过来处理琐事，这非常不利于公司的士气。</p><h2 id="小结-2"><a href="#小结-2" class="headerlink" title="小结"></a>小结</h2><p>如果我们都致力于每一周通过软件开发消除一些琐事，就可以持续性地整顿服务。</p><p>让我们多创新，少干琐事吧。</p><h1 id="分布式系统的监控"><a href="#分布式系统的监控" class="headerlink" title="分布式系统的监控"></a>分布式系统的监控</h1><p>监控与报警可以让一个系统在发生故障时主动通知我们，或者能够告诉我们即将发生什么。我们不应该仅仅因为“某些东西看起来有点问题就报警”。高效的报警系统应该提供足够的信息，并且误报率非常低。</p><h2 id="为什么要监控"><a href="#为什么要监控" class="headerlink" title="为什么要监控"></a>为什么要监控</h2><h3 id="分析长期趋势"><a href="#分析长期趋势" class="headerlink" title="分析长期趋势"></a>分析长期趋势</h3><p>例如数据库目前的数据量以及增长速度，或者每日活跃用户的数量增长的速度</p><h3 id="报警"><a href="#报警" class="headerlink" title="报警"></a>报警</h3><p>某项东西出现故障了，需要有人立即修复！或者某项东西可能很快出现故障，需要有人尽快查看</p><h3 id="构建监控台页面"><a href="#构建监控台页面" class="headerlink" title="构建监控台页面"></a>构建监控台页面</h3><p>大视报页面应该可以查看有关服务的一些基本问题，通常包括常见的4个“黄金指标”（后面会讨论4个黄金指标</p><h3 id="临时性的回溯分析（在线调试）"><a href="#临时性的回溯分析（在线调试）" class="headerlink" title="临时性的回溯分析（在线调试）"></a>临时性的回溯分析（在线调试）</h3><p>我们临时增加请求量了，看看有没有其他的现象会同时发生？</p><h2 id="黑盒监控与白盒监控"><a href="#黑盒监控与白盒监控" class="headerlink" title="黑盒监控与白盒监控"></a>黑盒监控与白盒监控</h2><ul><li>黑盒监控是面向现象的，代表了目前正在发生的——而非预测会发生的问题，即“系统现在的故障”</li><li>白盒监控则大量依赖对系统内部信息的检测，如系统日志、抓取提供指标信息的HTTP节点等。白盒监控系统因此可以检测到即将发生的问题以及那些重试所掩盖的问题等</li></ul><h2 id="监控的4个黄金指标"><a href="#监控的4个黄金指标" class="headerlink" title="监控的4个黄金指标"></a>监控的4个黄金指标</h2><p>如果我们度量所有这4个黄金指标，同时在某个指标出现故障时发出警报（对于饱和度来说，快要发生故障时），能做到这些就说明服务的监控差不多了。</p><h3 id="延迟"><a href="#延迟" class="headerlink" title="延迟"></a>延迟</h3><p>服务处理某个请求所需要的时间。这里区分成功请求和失败请求很重要。例如，某些错误的HTTP500错误延迟很低，但是计算总体延迟时如果带上了这些错误请求次数就可能产生误导性的结果。</p><h3 id="流量"><a href="#流量" class="headerlink" title="流量"></a>流量</h3><p>使用系统中的某个高层次的指标针对系统负载需求所进行的度量。<br>对WEB服务器来说，该指标通常是每秒HTTP请求数量，同时可能按请求分类（静态请求和动态请求）</p><h3 id="错误"><a href="#错误" class="headerlink" title="错误"></a>错误</h3><p>请求失败的速率，要么是显示失败（例如HTTP500），要么是隐式失败（例如HTTP200返回了错误的内容），或者是策略原因导致的失败（例如，如果要求回复在1s内发出，任何超过1s的请求就都是失败请求）。</p><h3 id="饱和度"><a href="#饱和度" class="headerlink" title="饱和度"></a>饱和度</h3><p>服务容器有多“满”。通常是系统中目前最为受限的某种资源或某个具体指标的度量。在内存受限的系统中，即为内存；在I/O受限的系统中，即为I/O）这里要注意，很多系统在到达100%利用率之前性能就会严重下降，增加一个利用率目标也是很重要的。</p><h2 id="度量指标时采用合适的精度"><a href="#度量指标时采用合适的精度" class="headerlink" title="度量指标时采用合适的精度"></a>度量指标时采用合适的精度</h2><ul><li>观察一份针内CPU平均负载可能会错失导致长尾延迟过高的某种较长时间的CPU峰值现象。</li><li>对于一个每年停机时间小于9小时的Web服务来说，每分钟检测1次或2次的监控频率可能过于频繁</li><li>对目标可用率为百分之99.9的某个服务每1分钟或每2分钟检查一次硬盘剩余空间可能也是没必要的</li></ul><h2 id="简化，直到不能再简化"><a href="#简化，直到不能再简化" class="headerlink" title="简化，直到不能再简化"></a>简化，直到不能再简化</h2><p>简化思想</p><ul><li>那些最能反映真实故障的规则应该越简单越好，可预测性强，非常可靠</li><li>那些不常用的数据收集、汇总，以及报警配置应该定时删除</li><li>收集到的信息，但是没有暴露给任何监控平台，或者被任何报警规则使用的应该定时删除</li></ul><h2 id="小结-3"><a href="#小结-3" class="headerlink" title="小结"></a>小结</h2><p>健康的监控和报警系统应该是非常简单、易于理解的。紧急报警应该关注于现象，针对原因的一些启发性分析应该作为调试过程的补充，而不应该进行报警。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>取自《SRE：Google运维解密》23-59页，总结归纳的心得。</p><p>本篇总结了SRE的4个核心的思想：</p><ul><li>拥抱风险</li><li>定义服务质量指标、目标、协议</li><li>减少琐事</li><li>分布式系统的监控</li></ul><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Sre </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Sre </tag>
            
            <tag> Google </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维手册——Centos7网络超时断开(前传)</title>
      <link href="2020/11/28/bug/network-timeout-1/"/>
      <url>2020/11/28/bug/network-timeout-1/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近重装一台服务器做内网Nginx，但是我发现这台机器不稳定，经常断网，一起来看看怎么回事吧。</p><h1 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h1><p>首先这台机器是我用U盘引导常规流程安装的Centos7，里面只装了Nginx和docker，然后第二天下午连续断网2次</p><p>这个断网很诡异，和局域网断了，访问不到网关，也不能访问外网</p><p>起初我以为是网线被人动了，因为机房太小，我把这台机器放在一个没人坐的工位下</p><p>我在想是不是有人动了网线，然后我插拔网线发现这台机器仍然不能上网</p><p>然后本能地认为网络服务出问题，试了下systemctl restart network发现仍然不行</p><p>接下来就是电脑常规重试的操作了——重启解决百分之90的问题</p><p>重启完成后成功，我以为可能是个偶然的情况就没注意</p><p>结果过了几个小时后又断网一次，我这下意识到应该不是偶然，而是哪里出了问题！</p><h1 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h1><p>首先还是网卡配置，我对比了这台机器和另外一台也是用U盘引导安装机器的网卡配置</p><h2 id="网卡配置分析"><a href="#网卡配置分析" class="headerlink" title="网卡配置分析"></a>网卡配置分析</h2><p>直接上一下网卡的区别吧</p><ul><li>问题机器</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">$ cat &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-enp9s0</span><br><span class="line">TYPE&#x3D;Ethernet</span><br><span class="line">PROXY_METHOD&#x3D;none</span><br><span class="line">BROWSER_ONLY&#x3D;no</span><br><span class="line">BOOTPROTO&#x3D;static</span><br><span class="line">DEFROUTE&#x3D;yes</span><br><span class="line">IPV4_FAILURE_FATAL&#x3D;yes</span><br><span class="line">IPV6INIT&#x3D;yes</span><br><span class="line">IPV6_AUTOCONF&#x3D;yes</span><br><span class="line">IPV6_DEFROUTE&#x3D;yes</span><br><span class="line">IPV6_FAILURE_FATAL&#x3D;no</span><br><span class="line">IPV6_ADDR_GEN_MODE&#x3D;stable-privacy</span><br><span class="line">NAME&#x3D;enp9s0</span><br><span class="line">UUID&#x3D;xxxxx</span><br><span class="line">DEVICE&#x3D;enp9s0</span><br><span class="line">ONBOOT&#x3D;yes</span><br><span class="line">IPADDR&#x3D;192.168.20.100</span><br><span class="line">NETMASK&#x3D;255.255.255.0</span><br><span class="line">GATEWAY&#x3D;192.168.20.1</span><br><span class="line">DNS&#x3D;114.114.114.114</span><br><span class="line">IPV6_PRIVACY&#x3D;no</span><br></pre></td></tr></table></figure><ul><li>正常机器</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">$ cat &#x2F;etc&#x2F;sysconfig&#x2F;network-scripts&#x2F;ifcfg-enp9s0</span><br><span class="line">TYPE&#x3D;Ethernet</span><br><span class="line">PROXY_METHOD&#x3D;none</span><br><span class="line">BROWSER_ONLY&#x3D;no</span><br><span class="line">BOOTPROTO&#x3D;static</span><br><span class="line">DEFROUTE&#x3D;yes</span><br><span class="line">IPV4_FAILURE_FATAL&#x3D;no</span><br><span class="line">IPV6INIT&#x3D;yes</span><br><span class="line">IPV6_AUTOCONF&#x3D;yes</span><br><span class="line">IPV6_DEFROUTE&#x3D;yes</span><br><span class="line">IPV6_FAILURE_FATAL&#x3D;no</span><br><span class="line">IPV6_ADDR_GEN_MODE&#x3D;stable-privacy</span><br><span class="line">NAME&#x3D;enp9s0</span><br><span class="line">UUID&#x3D;xxxxx</span><br><span class="line">DEVICE&#x3D;enp9s0</span><br><span class="line">ONBOOT&#x3D;yes</span><br><span class="line">IPADDR&#x3D;192.168.20.140</span><br><span class="line">NETMASK&#x3D;255.255.255.0</span><br><span class="line">GATEWAY&#x3D;192.168.20.1</span><br><span class="line">DNS&#x3D;114.114.114.114</span><br><span class="line">IPV6_PRIVACY&#x3D;no</span><br></pre></td></tr></table></figure><p>除了IP和MAC不同以外，就只剩IPV4_FAILURE_FATAL=no和yes的区别了</p><p>google一下发现关于这个参数的资料较少</p><p>有一篇博客解释了这个参数的意思</p><hr><p>If both IPv4 and IPv6 configuration is enabled, failing IPv4 configuration of activated device means that activation is considered as failing overall (which corresponds to Require IPv4 addressing for this connection to complete checked in nm-c-e or IPV4_FAILURE_FATAL=yes in ifcfg file).</p><p>翻译过来大概的意思就是说</p><p>IPV4_FAILURE_FATAL使用后，如果IPV4地址获取失败，结束本网卡获取地址的过程，因此，关闭IPV4_FAILURE_FATA配置，即可防止IPV4获取失败导致IPV6地址也获取不到的情况。</p><p>但是我寻思IPV6也没有开啊，而且IPV4的IP已经获取到了且设置成静态IP，也不会说突然结束网卡程序的问题。</p><p>但是我还是抱着尝试的态度改了这个参数，重启network，reboot</p><p>这下开机后到第二天都是正常的，就在我认为OK的情况，昨天又又又断了！</p><h2 id="寻找问题的根源"><a href="#寻找问题的根源" class="headerlink" title="寻找问题的根源"></a>寻找问题的根源</h2><p>我在想是不是网卡有问题，执行查看网卡信息的命令发现也没问题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">$ ethtool enp9s0</span><br><span class="line">Settings for enp9s0:</span><br><span class="line">Supported ports: [ TP AUI BNC MII FIBRE ]</span><br><span class="line">Supported link modes:   10baseT&#x2F;Half 10baseT&#x2F;Full </span><br><span class="line">                        100baseT&#x2F;Half 100baseT&#x2F;Full </span><br><span class="line">                        1000baseT&#x2F;Full </span><br><span class="line">Supported pause frame use: No</span><br><span class="line">Supports auto-negotiation: Yes</span><br><span class="line">Supported FEC modes: Not reported</span><br><span class="line">Advertised link modes:  10baseT&#x2F;Half 10baseT&#x2F;Full </span><br><span class="line">                        100baseT&#x2F;Half 100baseT&#x2F;Full </span><br><span class="line">                        1000baseT&#x2F;Full </span><br><span class="line">Advertised pause frame use: No</span><br><span class="line">Advertised auto-negotiation: Yes</span><br><span class="line">Advertised FEC modes: Not reported</span><br><span class="line">Link partner advertised link modes:  10baseT&#x2F;Half 10baseT&#x2F;Full </span><br><span class="line">                                     100baseT&#x2F;Half 100baseT&#x2F;Full </span><br><span class="line">                                     1000baseT&#x2F;Full </span><br><span class="line">Link partner advertised pause frame use: Symmetric Receive-only</span><br><span class="line">Link partner advertised auto-negotiation: Yes</span><br><span class="line">Link partner advertised FEC modes: Not reported</span><br><span class="line">Speed: 1000Mb&#x2F;s</span><br><span class="line">Duplex: Full</span><br><span class="line">Port: MII</span><br><span class="line">PHYAD: 0</span><br><span class="line">Transceiver: internal</span><br><span class="line">Auto-negotiation: on</span><br><span class="line">Supports Wake-on: pumbg</span><br><span class="line">Wake-on: d</span><br><span class="line">Current message level: 0x00000033 (51)</span><br><span class="line">       drv probe ifdown ifup</span><br><span class="line">Link detected: yes</span><br></pre></td></tr></table></figure><h2 id="查看系统日志"><a href="#查看系统日志" class="headerlink" title="查看系统日志"></a>查看系统日志</h2><p>这个时候我才想到查看系统日志，不看不知道一看吓一跳</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">vim &#x2F;var&#x2F;log&#x2F;message</span><br><span class="line">Nov  9  11:03:57 nginx kernel: WARNING: CPU: 0 PID: 0 at net&#x2F;sched&#x2F;sch_generic.c:356 dev_watchdog+0x248&#x2F;0x260</span><br><span class="line">Nov  9  11:03:57 nginx kernel: NETDEV WATCHDOG: enp1s0 (r8169): transmit queue 0 timed out</span><br><span class="line">Nov  9  11:03:57 nginx kernel: Modules linked in: xt_set xt_multiport ip_set_hash_ip xt_CHECKSUM ipt_MASQUERADE nf_nat_masquerade_ipv4 tun devlink rpcsec_gss_krb5 auth_rpcgss nfsv4 dns_resolver nfs lockd grace fscache ip6t_rpfilter ip6t_REJECT nf_reject_ipv6 ipt_REJECT nf_reject_ipv4 xt_conntrack ebtable_nat ebtable_broute bridge stp llc ip6table_nat nf_conntrack_ipv6 nf_defrag_ipv6 nf_nat_ipv6 ip6table_mangle ip6table_security ip6table_raw iptable_nat nf_conntrack_ipv4 nf_defrag_ipv4 nf_nat_ipv4 nf_nat iptable_mangle iptable_security iptable_raw nf_conntrack ip_set nfnetlink ebtable_filter ebtables ip6table_filter ip6_tables iptable_filter sunrpc ext4 vfat fat mbcache jbd2 intel_powerclamp coretemp intel_rapl kvm_intel kvm irqbypass crc32_pclmul ghash_clmulni_intel snd_soc_rt298 snd_soc_rt286 snd_soc_rl6347a snd_soc_core</span><br><span class="line">Nov  9  11:03:57 nginx kernel: snd_compress snd_seq snd_seq_device aesni_intel sg lrw gf128mul snd_pcm glue_helper ablk_helper cryptd pcspkr wdat_wdt i2c_i801 snd_timer snd soundcore pcc_cpufreq tpm_crb ip_tables xfs libcrc32c i915 sd_mod crc_t10dif crct10dif_generic i2c_algo_bit iosf_mbi drm_kms_helper syscopyarea sysfillrect sysimgblt fb_sys_fops ahci drm libahci sdhci_pci nvme cqhci sdhci libata mmc_core crct10dif_pclmul crct10dif_common crc32c_intel nvme_core r8169 drm_panel_orientation_quirks uas i2c_hid video usb_storage dm_mirror dm_region_hash dm_log dm_mod</span><br><span class="line">Nov  9  11:03:57 nginx kernel: CPU: 0 PID: 0 Comm: swapper&#x2F;0 Kdump: loaded Not tainted 3.10.0-1062.4.3.el7.x86_64 #1</span><br><span class="line">Nov  9  11:03:57 nginx kernel: Hardware name: GIGABYTE MZGLKAP-00&#x2F;MZGLKAP-00, BIOS F1 12&#x2F;21&#x2F;2017</span><br><span class="line">Nov  9  11:03:57 nginx kernel: Call Trace:</span><br><span class="line">Nov  9  11:03:57 nginx kernel: &lt;IRQ&gt; [&lt;ffffffffa0779ba4&gt;] dump_stack+0x19&#x2F;0x1b</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa009b958&gt;] __warn+0xd8&#x2F;0x100</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa009b9df&gt;] warn_slowpath_fmt+0x5f&#x2F;0x80</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa067bf88&gt;] dev_watchdog+0x248&#x2F;0x260</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa067bd40&gt;] ? dev_deactivate_queue.constprop.27+0x60&#x2F;0x60</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa00ac358&gt;] call_timer_fn+0x38&#x2F;0x110</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa067bd40&gt;] ? dev_deactivate_queue.constprop.27+0x60&#x2F;0x60</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa00ae7bd&gt;] run_timer_softirq+0x24d&#x2F;0x300</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa00a5305&gt;] __do_softirq+0xf5&#x2F;0x280</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa079042c&gt;] call_softirq+0x1c&#x2F;0x30</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa002f715&gt;] do_softirq+0x65&#x2F;0xa0</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa00a5685&gt;] irq_exit+0x105&#x2F;0x110</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa07919d8&gt;] smp_apic_timer_interrupt+0x48&#x2F;0x60</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa078defa&gt;] apic_timer_interrupt+0x16a&#x2F;0x170</span><br><span class="line">Nov  9  11:03:57 nginx kernel: &lt;EOI&gt; [&lt;ffffffffa05c10f7&gt;] ? cpuidle_enter_state+0x57&#x2F;0xd0</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa05c10ed&gt;] ? cpuidle_enter_state+0x4d&#x2F;0xd0</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa05c124e&gt;] cpuidle_idle_call+0xde&#x2F;0x230</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa0037c6e&gt;] arch_cpu_idle+0xe&#x2F;0xc0</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa0100d3a&gt;] cpu_startup_entry+0x14a&#x2F;0x1e0</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa0768b57&gt;] rest_init+0x77&#x2F;0x80</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa0d881cb&gt;] start_kernel+0x450&#x2F;0x471</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa0d87b7b&gt;] ? repair_env_string+0x5c&#x2F;0x5c</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa0d87120&gt;] ? early_idt_handler_array+0x120&#x2F;0x120</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa0d8772f&gt;] x86_64_start_reservations+0x24&#x2F;0x26</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa0d87885&gt;] x86_64_start_kernel+0x154&#x2F;0x177</span><br><span class="line">Nov  9  11:03:57 nginx kernel: [&lt;ffffffffa00000d5&gt;] start_cpu+0x5&#x2F;0x14</span><br><span class="line">Nov  9  11:03:57 nginx kernel: ---[ end trace 48f07bcd9213d5ea ]---</span><br></pre></td></tr></table></figure><p>然后google到一个和我这个场景极其相似的案例</p><p>它的例子大概说明情况是：</p><p>网络接口可以正常工作，没有问题，但是经过随机间隔（有时是几天……有时只有几个小时……但可能在进入“空闲”之后），内核将吐出调试消息，然后网络接口将停止传输数据。需要重新启动机器才能恢复网络操作。</p><p>我的天，几乎就对上了。</p><p>看看这个案例的解决过程</p><p>大概说的是需要修复一个内核补丁，或者直接升级内核</p><p>好家伙，内核相关的知识是我的盲区，有了思路开始准备解决了</p><h1 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h1><h2 id="升级内核"><a href="#升级内核" class="headerlink" title="升级内核"></a>升级内核</h2><p>当前内核版本为3.10.0-1127.el7.x86_64</p><h3 id="安装-ELRepo-最新版本"><a href="#安装-ELRepo-最新版本" class="headerlink" title="安装 ELRepo 最新版本"></a>安装 ELRepo 最新版本</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">## 载入公钥</span><br><span class="line">$ rpm --import https:&#x2F;&#x2F;www.elrepo.org&#x2F;RPM-GPG-KEY-elrepo.org</span><br><span class="line"></span><br><span class="line">## 安装 ELRepo 最新版本</span><br><span class="line">$ yum install -y https:&#x2F;&#x2F;www.elrepo.org&#x2F;elrepo-release-7.el7.elrepo.noarch.rpm</span><br></pre></td></tr></table></figure><h3 id="列出可以使用的-kernel-版本"><a href="#列出可以使用的-kernel-版本" class="headerlink" title="列出可以使用的 kernel 版本"></a>列出可以使用的 kernel 版本</h3><p>lt：长期维护版<br>ml：最新稳定版</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ yum list available --disablerepo&#x3D;* --enablerepo&#x3D;elrepo-kernel</span><br><span class="line"></span><br><span class="line">kernel-lt.x86_64                            4.4.218-1.el7.elrepo              elrepo-kernel</span><br><span class="line">kernel-lt-devel.x86_64                      4.4.218-1.el7.elrepo              elrepo-kernel</span><br><span class="line">kernel-lt-doc.noarch                        4.4.218-1.el7.elrepo              elrepo-kernel</span><br><span class="line">kernel-lt-headers.x86_64                    4.4.218-1.el7.elrepo              elrepo-kernel</span><br><span class="line">kernel-lt-tools.x86_64                      4.4.218-1.el7.elrepo              elrepo-kernel</span><br><span class="line">kernel-lt-tools-libs.x86_64                 4.4.218-1.el7.elrepo              elrepo-kernel</span><br><span class="line">kernel-lt-tools-libs-devel.x86_64           4.4.218-1.el7.elrepo              elrepo-kernel</span><br><span class="line">kernel-ml.x86_64                            5.6.3-1.el7.elrepo                elrepo-kernel</span><br><span class="line">kernel-ml-devel.x86_64                      5.6.3-1.el7.elrepo                elrepo-kernel</span><br><span class="line">kernel-ml-doc.noarch                        5.6.3-1.el7.elrepo                elrepo-kernel</span><br><span class="line">kernel-ml-headers.x86_64                    5.6.3-1.el7.elrepo                elrepo-kernel</span><br><span class="line">kernel-ml-tools.x86_64                      5.6.3-1.el7.elrepo                elrepo-kernel</span><br><span class="line">kernel-ml-tools-libs.x86_64                 5.6.3-1.el7.elrepo                elrepo-kernel</span><br><span class="line">kernel-ml-tools-libs-devel.x86_64           5.6.3-1.el7.elrepo                elrepo-kernel</span><br><span class="line">perf.x86_64                                 5.6.3-1.el7.elrepo                elrepo-kernel</span><br></pre></td></tr></table></figure><p>安装指定的 kernel 版本：</p><p>4.4 或者 5.6 的内核都可，稳定就选4.4，求新就安装5.6</p><p>具体安装内核</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yum install -y kernel-lt-4.4.218-1.el7.elrepo --enablerepo&#x3D;elrepo-kernel</span><br></pre></td></tr></table></figure><p>设置开启系统启动时使用的内核版本：</p><h3 id="查看系统可用内核"><a href="#查看系统可用内核" class="headerlink" title="查看系统可用内核"></a>查看系统可用内核</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ cat &#x2F;boot&#x2F;grub2&#x2F;grub.cfg | grep menuentry</span><br><span class="line"></span><br><span class="line">menuentry &#39;CentOS Linux (4.4.218-1.el7.elrepo.x86_64) 7 (Core)&#39; --class centos ...</span><br><span class="line">menuentry &#39;CentOS Linux (3.10.0-1062.el7.x86_64) 7 (Core)&#39; --class centos</span><br></pre></td></tr></table></figure><h3 id="设置开机从新内核启动"><a href="#设置开机从新内核启动" class="headerlink" title="设置开机从新内核启动"></a>设置开机从新内核启动</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ grub2-set-default &quot;CentOS Linux (4.4.218-1.el7.elrepo.x86_64) 7 (Core)&quot;</span><br></pre></td></tr></table></figure><h3 id="查看内核启动项"><a href="#查看内核启动项" class="headerlink" title="查看内核启动项"></a>查看内核启动项</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ grub2-editenv list</span><br><span class="line"></span><br><span class="line">saved_entry&#x3D;CentOS Linux (4.4.218-1.el7.elrepo.x86_64) 7 (Core)</span><br></pre></td></tr></table></figure><h3 id="重启系统使内核生效"><a href="#重启系统使内核生效" class="headerlink" title="重启系统使内核生效"></a>重启系统使内核生效</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure><h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p>结果重启后机器直接不能识别网卡</p><p>？？？</p><p>看系统日志报错</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Failed to start LSB: Bring up&#x2F;down networking</span><br></pre></td></tr></table></figure><p>网上找了下资料发现是网卡驱动和内核不兼容的原因</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">注意： 关于安装驱动这个问题，elrepo也有给出相关包和方法：http:&#x2F;&#x2F;elrepo.org&#x2F;tiki&#x2F;DeviceIDs， https:&#x2F;&#x2F;centos.pkgs.org&#x2F;7&#x2F;elrepo-x86_64&#x2F;kmod-r8168-8.048.00-1.el7_7.elrepo.x86_64.rpm.html</span><br><span class="line">可是实践后发现对我没有用，还是老实到官网找最新的驱动吧</span><br></pre></td></tr></table></figure><p>如果将内核切会3.10则可以正常上网</p><p>我真的服了，这BUG跟套娃一样，一个接一个。</p><h2 id="重装系统"><a href="#重装系统" class="headerlink" title="重装系统"></a>重装系统</h2><p>后来很烦，发现问题越来越多，索性重装系统</p><p>结果，发现一天后又出问题了。</p><h2 id="重启解决90-的问题，重装系统解决剩下9-，那么还剩1-…"><a href="#重启解决90-的问题，重装系统解决剩下9-，那么还剩1-…" class="headerlink" title="重启解决90%的问题，重装系统解决剩下9%，那么还剩1%….."></a>重启解决90%的问题，重装系统解决剩下9%，那么还剩1%…..</h2><p>放弃这台机器</p><p>对，你没听错</p><p>我又感觉是网卡的问题了，那么机器要换主板，公司没有多的主板，要换还得从网上定一块3年前淘汰的主板</p><p>有人推荐用无线网卡，但是我感觉对于服务器来说不是很稳定，因为公司的AP每天凌晨重启。</p><p>然后发现公司还有一台机器，用那台重装nginx算了，最后那台机器用到现在也没出问题</p><p>伤不起啊伤不起</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这个问题可能是我第一个没有从根本上解决的问题，我最后反思了一下，关于这种硬件驱动和Linux内核的问题，像我现在水平还无法准确的定位到了，就算解决了也没有多少实际价值，还不如直接用简单的方法——换机器。</p><p>这个事还是浪费了我比较久的时间，网上学习了不少关于system告警和内核相关知识，但是还远远不够，虽然这次问题是换电脑解决的，不过我相信这次经验告诉我一个道理</p><p>没有一个人能解决所有的问题，有些事不需要刨根问底，虽然这种精神是好的，但是也有可能浪费过多的时间来解决无谓的问题。</p><h1 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h1><p>后面继续又出现了相似的问题，问题介绍已转到下一篇。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://bugs.centos.org/view.php?id=16815" target="_blank" rel="noopener">lCentos Bug Tracker</a></p><p><a href="http://www.mydlq.club/article/79/" target="_blank" rel="noopener">Centos7升级内核版本</a></p><p><a href="https://blog.csdn.net/hnufun/article/details/106409560" target="_blank" rel="noopener">CentOS7升级内核3.10到5.6后，无法识别网卡</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operation Manual </tag>
            
            <tag> Centos </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>包夜随笔——2020.11.20</title>
      <link href="2020/11/21/Essay/Sangfor/"/>
      <url>2020/11/21/Essay/Sangfor/</url>
      
        <content type="html"><![CDATA[<blockquote><p>du lange in einen Abgrund blickst, blickt der Abgrund auch in dich hinein. </p></blockquote><p>今天又又又包夜了，但是不是公司的问题，而是万恶的Sangfor，让我非常不爽。</p><p>作为国内第一大安全厂商，基本上全国的大型VPN服务都来自于Sangfor，但我就不明白了，为什么Sangfor不专注自己的技术发财，而专门让销售搞一些花里胡哨的东西，为了提高Sangfor业绩，吸小公司的血，下面让我一一道来。</p><p>截至2020.11.20日 Sangfor收盘价 208.57 市值853.1亿。</p><h1 id="首见"><a href="#首见" class="headerlink" title="首见"></a>首见</h1><p>新公司入职1个月的时候，我被告知公司VPN还有2个月到期，而且搬家时候需要换电信专线，切断VPN，我联系到上一位离职的运维工程师，他推给我了一个微信，暂称他小马吧。跟小马简单聊了下需求后，他说需要续费VPN就行了，然后又看了下公司，缺少硬件防火墙，又跟我讲了一下安全云云，其实就是购买他的设备，我草草回复说目前公司还用不上，他只能作罢。</p><h1 id="二见"><a href="#二见" class="headerlink" title="二见"></a>二见</h1><p>公司搬家前一个星期，我提醒他搬家的那天需要安排个人来，因为搬家需要迁移专线，VPN需要断，我需要一个技术支持来现场帮忙配置，结果他给我找了一个超级不靠谱的人，暂称他为王麻子。</p><p>我们拉了个微信群，王麻子在群里面说迁移简单，开机重启就行了，我说公司还牵了一条ADSL，他说配置很简单，我没继续跟他讲。等到专线迁移的那天，他人找不到了，我在群里面问他，他说等半个小时，然后半个小时后装死，把我气的。没办法他们又安排了一个人来现场，暂称他为赖哥，帮我处理问题，赖哥跟我聊的特别投机，技术也很扎实，调试了1个多小时就搞定了，为了感谢他我还请他吃饭，吃饭的时候才知道，Sangfor的组织结构极其复杂。</p><p>Sangfor分研发基地和总代两大组织。</p><p>研发基地就是研发VPN、防火墙等产品的纯技术人员。</p><p>总代就是Sangfor内部的售前+售后。</p><p>小马属于售前。</p><p>赖哥和王麻子都是售后。</p><p>然后Sangfor在全国有很多家代理，外面的客户必须从代理商那买产品，而不能通过Sangfor直销，但是听说有几个国家级的项目是直销。</p><p>我们公司也找的一个代理，那个代理联系的售前就是小马。</p><p>Sangfor的组织结构极其重要，后面详细讲下这种暴利的营销模式。</p><h1 id="三见"><a href="#三见" class="headerlink" title="三见"></a>三见</h1><p>处理完这个VPN重连的问题后，重头戏来了——续费。</p><p>去年公司买Sangfor VPN做3条线路一共花了9W，包括一个硬件设备和两个虚拟机的镜像及VPN的服务。</p><p>因为之前公司是一条专线既做办公网又做服务器网，我来了之后觉得网络结构有问题，提出了将专线只供服务器网使用，办公网改为ADSL即可，并且VPN不需要建3条线路，只用建一条即可。</p><p>我和老板讨论最后定了一套网络拓扑图准备大刀阔斧的改革了。</p><p>我让小马来公司详谈续费的事，他说明天早上来。</p><p>第二天早上他来公司，我跟他谈减少线路的事，他感觉不是很乐意，说了一堆安全云云，我直接回复他根本没安全的事，多的2条线路就是浪费钱的，后来不记得聊了什么，感觉不是很愉快。</p><p>没想到当天中午他给我打了通电话，让我晚上出来吃个饭，我心想肯定是鸿门宴啊，不能去。但是他挂电话前说了一句让我能称之为典中典的话：兄弟，看你年龄应该毕业没多久吧，我们为什么来深圳，不就是为了多打份工多赚点钱吗，老板不给你涨工资你要学会自己给自己涨工资，我不会让你白选择我这家代理的，事成之后我会给你反一定的点数，你好我的好大家好。</p><p>我当时懵了，我以为这种情况只会出现在电视剧里，诸如银行、保险行业，没想到这个行业也充斥着这样的人。</p><h1 id="鸿门宴"><a href="#鸿门宴" class="headerlink" title="鸿门宴"></a>鸿门宴</h1><p>晚上我去了，吃火锅，花费大概500多块钱，看来是下了血本啊。</p><p>吃饭的时候，他一口一个陈总，疯狂给我夹菜，然后开门见山</p><hr><blockquote><p> 我知道可能对你来说接受不了，我刚开始的时候也是这样，认为学校里学的都是正确的，结果到了社会才发现上学学的都他妈是狗屁道理，在深圳的销售行业，你清高，你廉洁，你就眼巴巴地看着别人大把大把的捞钱，然后你就拿着那个死工资，还完租房的钱，吃吃喝喝后还是买不起房买不起车，被人鄙视。</p></blockquote><blockquote><p> 直到我花了半年的时间适应这个游戏规则，我现在特别习惯并且感觉没什么不好的</p></blockquote><blockquote><p> 真的，要学会为自己活，老板不给你涨工资，要自己给自己涨工资</p></blockquote><blockquote><p> 我这研究了一套独门秘方，在你采购的时候我可以帮你找同行业最低的2家供应商，然后我这边出比这2家还低的钱，这样你对上也有交代（货比三家得出的最优价），然后事成后我会以现金的方式反你，没有银行转账，都是现金，不可能被发现。</p></blockquote><blockquote><p> 就算被人发现，你可以说你之前能力不行，大不了就是丢了这个饭碗，出去找工作咬死是你前公司的问题，一样不影响</p></blockquote><blockquote><p> 你去外面找任何一个Sangfor的代理都是这样，层层拿回扣，不然公司怎么能赚钱，其实技术做出来了，成本价很低，要的就是销售去提价，越高越好，大家都有钱赚</p></blockquote><p>好吧，到这里我确实被震惊到了，我问他能反多少，他说我完全可以按照去年的方式，还是9w，直接反我10个点，就是9000，你就直接跟老板说今年按去年的方式走，为什么要改呢？</p><p>我问他，上个运维是不是也拿了，他还洋洋得意说肯定要拿了，而且我还宰了他一刀（黑吃黑），不知道具体什么情况</p><p>我说现在的线路有问题啊，肯定是要砍的，然后他又开始打感情牌了，说他这个月销量不好云云，要冲业绩。</p><p>说到这我感觉怎么说都说不过他，我直接说，到时候回去跟领导说下，肯定会用你们的。</p><p>走之前，他抢先结账，我说要不AA，他拒绝，他还说第一次请客就是销售的规矩，被说出去就没法混，我尴尬的笑了下，走了。</p><h1 id="救赎"><a href="#救赎" class="headerlink" title="救赎"></a>救赎</h1><p>还没回到家，微信又提示一条消息：20个点最多了。</p><p>1w8，这个钱该不该要呢？字以签，动动手指头，钱就到了</p><p>问了几个之前的同事</p><p>有的说，不能做，万一被查出来了怎么办。</p><p>有的说，应该做，该拿的钱要拿，他把这个称之为该拿的钱。</p><p>有的说，我觉得这个人很上路，你跟着他应该会发财。</p><p>有的说，君子爱财，取之有道，你这次贪了以后肯定一条道走到黑。</p><p>还有的说，这个钱你不赚我来赚，你把这个合同上写我的名字，我去签，钱分你一半，风险我担着。</p><p>问了几个亲人</p><p>有的说，这个事很正常，大家都在做的时候你就应该跟大家一样，不能坏了规矩，这是老话。</p><p>有的说，这个事看风险，出门在外，做个精致的利己主义者才是对的，如果能拿不被发现，就拿，风险太大就撤。</p><p>问了我的前导师</p><p>他不做评论，这个事需要我自己来定，可能关系到我未来的路，他没办法帮我做决定，他只提醒我，做了之后不要后悔。</p><p>综合各方意见和我自己内心的争斗，我总结了一下几点</p><ul><li>如果我不改革，我认为就是对我技术的否定，我不能接受。就像一个BUG，已经上线了一年，你明明发现了，并且有能力解决，由于这个BUG可以让你多赚一点钱，而你视若无睹。作为茫茫众多的打工人的一员，我称不上道德高尚，但是我认为这是一个打工人的职业操守。</li><li>1w8不到我一个月的工资，不能改变我贫穷的现状，我觉得没有必要为了这个钱出卖自己的良心</li><li>贪官没有一个好下场</li></ul><h1 id="上报"><a href="#上报" class="headerlink" title="上报"></a>上报</h1><p>大晚上睡不着，想来想去还是，当日事当日毕，直接跟大领导打电话阐明事情原委。</p><p>领导表扬我做的好：做技术就应该凭自己的真本事赚钱，而不是搞这些歪门邪道，并且他很感谢我。</p><p>2天后我把这个事的处理结果再告诉了之前我问的那些人</p><p>有的说，你清高，你伟大，你是道德模范，你公司把你招过去真要把你当菩萨供着，但是我做不到这点</p><p>有的说，老板就这？口头表扬有什么用，不如1w8拿在手里多舒服</p><p>有的说，我觉得你老板说的很对，还是要靠真本事赚钱</p><p>有的说，你吃饭不做事，不太地道</p><p>最多的就是问我后悔没，我统一回复，不后悔。</p><h1 id="四见"><a href="#四见" class="headerlink" title="四见"></a>四见</h1><p>说到底，最后方案拍板的还是领导，其实我就是一个提供参考方案的大头兵而已，我佯装跟小马说，我方案报上去了，但是领导觉得还是贵了，今年要缩减，我这边也没办法。</p><p>最终砍价到1w4，给公司省了7w6。</p><p>他打电话和我约好时间来公司签合同。</p><p>走之前他说这单生意赚不到钱，但是还是分我10个点，这就是规矩，以后有发财的机会随时恭候。</p><h1 id="包夜"><a href="#包夜" class="headerlink" title="包夜"></a>包夜</h1><p>故事到这里差不多结束了。</p><p>合同签完后，小马又给我安排了一个技术支持，结果由于Sangfor和AWS的合作出现的问题，新授权码的镜像不能上传到AWS上，一拖就是2个星期，已经超过了VPN本身合同的到期时间，我询问他，他也说Sangfor内部确实很慢，拖拖拉拉。</p><p>直到今天，授权码终于下来了，然后由于需要更换2台WOC设备的授权码，Sangfor的技术支持把虚拟机的型号搞错了，授权码不能使用。但是另外一端的授权码已经更新，导致现在生产环境VPN中断，业务影响。</p><p>说实话，虽然是外部因素造成VPN中断，但是对于一个想成为SRE的人来说，更换VPN可能造成生产环境业务中断的风险我没有很好的通知到我的团队，我对此表示深深的自责，直到现在，我的同事还在家里处理生产环境几个问题（VPN断掉后暴露的额外问题）</p><p>等到Sangfor的技术重新申请授权码，到重新更新WOC的授权码，VPN重新连接，重启服务让业务正常Work，总共花了6个小时。</p><p>国内最大的VPN提供厂商就这水平？</p><p>其实我不管销售拿回扣多少，这种效率的技术厂商如果在未来不改进自己的商业模式和服务态度，我认为迟早会被替代。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这个事我很早就想写文章了，今天被Sangfor的人强行搞成包夜，一边盯着服务器一边写作，虽然本篇没什么华丽的辞藻，也不想通过这篇文章说明自己多么高尚，就是简单的想记录下来此时我的所做所想而已。</p><p>我没有去批判之前那些说要贪钱的朋友或者亲人，也许在他们的认知里，这个世界的规律就是如此，存在即合理。</p><p>最后，我对有幸能看到我这篇随笔的人说几句，出门在外，做事不愧于心、不后悔就好了，不需要在意别人的看法。</p>]]></content>
      
      
      <categories>
          
          <category> Essay </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Essay </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>利用LVM将磁盘二合一</title>
      <link href="2020/11/21/storage/disk-combined-into-one/"/>
      <url>2020/11/21/storage/disk-combined-into-one/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>公司有需求存储大量数据，需要将生产环境文件同步到线下，但是存储是个问题，最近发现公司还有一台服务器有2块7.3T的磁盘，正好派上用场，来看看怎么添加存储的吧。</p><h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><ul><li>操作系统：ubuntu 16.04</li><li>lvm版本：lvm2</li><li>文件系统：xfs</li><li>需要挂载的数据盘</li></ul><p>/dev/sda： 7.3T</p><p>/dev/sdb： 7.3T</p><ul><li>挂载目录：/s3proxy</li></ul><h1 id="实现方法"><a href="#实现方法" class="headerlink" title="实现方法"></a>实现方法</h1><p>要想实现此需求，可使用LVM逻辑卷管理来做到。</p><p>如果你不知道LVM是做什么的，那么请参考下面链接（包括但不限于）进行学习：</p><p><a href="https://wiki.ubuntu.com/Lvm" target="_blank" rel="noopener">LVM</a></p><p><a href="https://wiki.archlinux.org/index.php/LVM" target="_blank" rel="noopener">LVM-WIKI</a></p><p><a href="https://cloud.tencent.com/developer/article/1582568" target="_blank" rel="noopener">LVM基础操作步骤梳理</a></p><h1 id="查看资源与安装基础软件包"><a href="#查看资源与安装基础软件包" class="headerlink" title="查看资源与安装基础软件包"></a>查看资源与安装基础软件包</h1><h2 id="查看xfs是否安装"><a href="#查看xfs是否安装" class="headerlink" title="查看xfs是否安装"></a>查看xfs是否安装</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ modinfo xfs</span><br><span class="line">filename:       &#x2F;lib&#x2F;modules&#x2F;4.15.0-122-generic&#x2F;kernel&#x2F;fs&#x2F;xfs&#x2F;xfs.ko</span><br><span class="line">license:        GPL</span><br><span class="line">description:    SGI XFS with ACLs, security attributes, realtime, no debug enabled</span><br><span class="line">author:         Silicon Graphics, Inc.</span><br><span class="line">alias:          fs-xfs</span><br><span class="line">srcversion:     051B2E34F6018A435EC6D00</span><br><span class="line">depends:        libcrc32c</span><br><span class="line">retpoline:      Y</span><br><span class="line">intree:         Y</span><br><span class="line">name:           xfs</span><br><span class="line">vermagic:       4.15.0-122-generic SMP mod_unload</span><br></pre></td></tr></table></figure><h2 id="安装lvm系统及xfs文件系统并加载，如果已安装则可以忽略"><a href="#安装lvm系统及xfs文件系统并加载，如果已安装则可以忽略" class="headerlink" title="安装lvm系统及xfs文件系统并加载，如果已安装则可以忽略"></a>安装lvm系统及xfs文件系统并加载，如果已安装则可以忽略</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install lvm2  xfsprogs</span><br><span class="line">sudo systemctl enable lvm2-lvmetad.service</span><br><span class="line">sudo systemctl enable lvm2-lvmetad.socket</span><br><span class="line">sudo systemctl start lvm2-lvmetad.service</span><br><span class="line">sudo systemctl start lvm2-lvmetad.socket</span><br><span class="line">sudo modprobe -v xfs</span><br></pre></td></tr></table></figure><p>查看磁盘</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ fdisk -l</span><br><span class="line">Disk &#x2F;dev&#x2F;sda: 7.3 TiB, 8001563222016 bytes, 15628053168 sectors</span><br><span class="line">Units: sectors of 1 * 512 &#x3D; 512 bytes</span><br><span class="line">Sector size (logical&#x2F;physical): 512 bytes &#x2F; 4096 bytes</span><br><span class="line">I&#x2F;O size (minimum&#x2F;optimal): 4096 bytes &#x2F; 4096 bytes</span><br><span class="line"></span><br><span class="line">Disk &#x2F;dev&#x2F;sdb: 7.3 TiB, 8001563222016 bytes, 15628053168 sectors</span><br><span class="line">Units: sectors of 1 * 512 &#x3D; 512 bytes</span><br><span class="line">Sector size (logical&#x2F;physical): 512 bytes &#x2F; 4096 bytes</span><br><span class="line">I&#x2F;O size (minimum&#x2F;optimal): 4096 bytes &#x2F; 4096 bytes</span><br></pre></td></tr></table></figure><h1 id="合并步骤"><a href="#合并步骤" class="headerlink" title="合并步骤"></a>合并步骤</h1><h2 id="磁盘分区"><a href="#磁盘分区" class="headerlink" title="磁盘分区"></a>磁盘分区</h2><p>在将磁盘或者磁盘分区用作物理卷（PV）之前，需要对其进行初始化工作，即进行磁盘分区操作；因磁盘分区需求大于2T，所以fdisk无法实现管理，需要使用parted命令来做磁盘分区管理</p><p>如果你不知道fdisk和parted的区别，那么请参考下面链接（包括但不限于）进行学习：</p><p><a href="https://unix.stackexchange.com/questions/104238/fdisk-vs-parted" target="_blank" rel="noopener">fdisk-vs-parted</a></p><ul><li>分区sda</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 新建&#x2F;dev&#x2F;sda的磁盘标签类型为GPT</span><br><span class="line">$ parted &#x2F;dev&#x2F;sda mklabel gpt </span><br><span class="line"># 将&#x2F;dev&#x2F;sda整个空间分给同一个分区</span><br><span class="line">$ parted &#x2F;dev&#x2F;sda mkpart primary 0 100%</span><br><span class="line">Warning: The resulting partition is not properly aligned for best performance.</span><br><span class="line">Ignore&#x2F;Cancel? I                                                          </span><br><span class="line">Information: You may need to update &#x2F;etc&#x2F;fstab.</span><br></pre></td></tr></table></figure><ul><li>分区sdb</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 新建&#x2F;dev&#x2F;sdb的磁盘标签类型为GPT</span><br><span class="line">$ parted &#x2F;dev&#x2F;sdb mklabel gpt </span><br><span class="line"># 将&#x2F;dev&#x2F;sda整个空间分给同一个分区</span><br><span class="line">$ parted &#x2F;dev&#x2F;sdb mkpart primary 0 100%</span><br><span class="line">Warning: The resulting partition is not properly aligned for best performance.</span><br><span class="line">Ignore&#x2F;Cancel? I                                                          </span><br><span class="line">Information: You may need to update &#x2F;etc&#x2F;fstab.</span><br></pre></td></tr></table></figure><h2 id="创建PV"><a href="#创建PV" class="headerlink" title="创建PV"></a>创建PV</h2><p>创建物理卷的命令为pvcreate；利用该命令将希望添加到卷组的所有分区或磁盘创建为物理卷；<br>将分区/dev/sdb1和/dev/sdc1分区创建为物理卷：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ pvcreate &#x2F;dev&#x2F;sda1</span><br><span class="line">Physical volume &quot;&#x2F;dev&#x2F;sda1&quot; successfully created.</span><br><span class="line">$ pvcreate &#x2F;dev&#x2F;sdb1</span><br><span class="line">Physical volume &quot;&#x2F;dev&#x2F;sdb1&quot; successfully created.</span><br></pre></td></tr></table></figure><h2 id="创建VG"><a href="#创建VG" class="headerlink" title="创建VG"></a>创建VG</h2><p>创建卷组的命令为vgcreate；用此命令将使用pvcreate建立的物理卷创建为一个完整的VG</p><p>将sda1的PV创建名为s3proxy的VG</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ vgcreate s3proxy &#x2F;dev&#x2F;sda1</span><br><span class="line"> Volume group &quot;s3proxy&quot; successfully created</span><br></pre></td></tr></table></figure><h2 id="添加新的PV到VG中"><a href="#添加新的PV到VG中" class="headerlink" title="添加新的PV到VG中"></a>添加新的PV到VG中</h2><p>使用vgextend命令将其他PV添加到VG中</p><p>将sdb1的PV添加到s3proxy的VG</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ vgextend s3proxy &#x2F;dev&#x2F;sdb1</span><br><span class="line">  Volume group &quot;s3proxy&quot; successfully extended</span><br></pre></td></tr></table></figure><h2 id="查看VG"><a href="#查看VG" class="headerlink" title="查看VG"></a>查看VG</h2><p>查看卷组用vgs</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ vgs</span><br><span class="line">  VG      #PV #LV #SN Attr   VSize  VFree</span><br><span class="line">  s3proxy   2   1   0 wz--n- 14.55t 14.55t</span><br></pre></td></tr></table></figure><p>即已经将2块磁盘容量合并了</p><h2 id="创建逻辑卷"><a href="#创建逻辑卷" class="headerlink" title="创建逻辑卷"></a>创建逻辑卷</h2><p>创建逻辑卷的命令为lvcreate；用此命令将在使用vgcreate建立的卷组上创建逻辑卷；<br>在卷组s3proxy上创建一个名为lvs3proxy的逻辑卷，大小为14.55t；</p><ul><li>-n：指定逻辑卷名</li><li>-L：指定逻辑卷大小</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$  lvcreate -L 14.55T -n lvs3proxy s3proxy</span><br><span class="line">  Rounding up size to full physical extent 14.55 TiB</span><br><span class="line">  Logical volume &quot;lvs3proxy&quot; created.</span><br></pre></td></tr></table></figure><h2 id="格式化逻辑卷"><a href="#格式化逻辑卷" class="headerlink" title="格式化逻辑卷"></a>格式化逻辑卷</h2><p>将创建的lvs3proxy逻辑卷格式化为xfs</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mkfs -t xfs &#x2F;dev&#x2F;s3proxy&#x2F;lvs3proxy</span><br></pre></td></tr></table></figure><h2 id="创建挂载目录并挂载"><a href="#创建挂载目录并挂载" class="headerlink" title="创建挂载目录并挂载"></a>创建挂载目录并挂载</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 创建s3proxy目录</span><br><span class="line">$ mkdir &#x2F;s3proxy</span><br><span class="line"># 挂载</span><br><span class="line">$ mount &#x2F;dev&#x2F;s3proxy&#x2F;lvs3proxy &#x2F;s3proxy&#x2F;</span><br><span class="line"># 开机自动挂载</span><br><span class="line">$ echo &#39;&#x2F;dev&#x2F;mapper&#x2F;s3proxy-lvs3proxy &#x2F;s3proxy xfs   defaults 0 0&#39; &gt;&#x2F;etc&#x2F;fstab</span><br></pre></td></tr></table></figure><h2 id="查看是否挂载成功"><a href="#查看是否挂载成功" class="headerlink" title="查看是否挂载成功"></a>查看是否挂载成功</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ df -h</span><br><span class="line">Filesystem                     Size  Used Avail Use% Mounted on</span><br><span class="line">udev                           126G     0  126G   0% &#x2F;dev</span><br><span class="line">tmpfs                           26G  267M   25G   2% &#x2F;run</span><br><span class="line">&#x2F;dev&#x2F;sdc2                      439G  232G  185G  56% &#x2F;</span><br><span class="line">tmpfs                          126G  192K  126G   1% &#x2F;dev&#x2F;shm</span><br><span class="line">tmpfs                          5.0M  4.0K  5.0M   1% &#x2F;run&#x2F;lock</span><br><span class="line">tmpfs                          126G     0  126G   0% &#x2F;sys&#x2F;fs&#x2F;cgroup</span><br><span class="line">&#x2F;dev&#x2F;sdc1                      511M  3.7M  508M   1% &#x2F;boot&#x2F;efi</span><br><span class="line">tmpfs                           26G   28K   26G   1% &#x2F;run&#x2F;user&#x2F;108</span><br><span class="line">tmpfs                           26G  4.0K   26G   1% &#x2F;run&#x2F;user&#x2F;1000</span><br><span class="line">&#x2F;dev&#x2F;mapper&#x2F;s3proxy-lvs3proxy   15T  515G   15T   4% &#x2F;s3proxy</span><br></pre></td></tr></table></figure><p>到这步就完成了</p><h1 id="报错总结"><a href="#报错总结" class="headerlink" title="报错总结"></a>报错总结</h1><h2 id="错误“-run-lvm-lvmetad-socket：连接失败：没有这样的文件或目录”"><a href="#错误“-run-lvm-lvmetad-socket：连接失败：没有这样的文件或目录”" class="headerlink" title="错误“ /run/lvm/lvmetad.socket：连接失败：没有这样的文件或目录”"></a>错误“ /run/lvm/lvmetad.socket：连接失败：没有这样的文件或目录”</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;run&#x2F;lvm&#x2F;lvmetad.socket: connect failed: No such file or directory</span><br></pre></td></tr></table></figure><p>解决方法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable lvm2-lvmetad.service</span><br><span class="line">systemctl enable lvm2-lvmetad.socket</span><br><span class="line">systemctl start lvm2-lvmetad.service</span><br><span class="line">systemctl start lvm2-lvmetad.socket</span><br></pre></td></tr></table></figure><h2 id="未安装xfs"><a href="#未安装xfs" class="headerlink" title="未安装xfs"></a>未安装xfs</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkfs xfs command not found ubuntu</span><br></pre></td></tr></table></figure><p>解决方法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install   xfsprogs</span><br><span class="line">modinfo xfs</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>LVM是现在默认的磁盘分区工具了，之前只是在安装操作系统的时候用过，没有深入了解其工作原理，后面会出一期关于LVM的运维文章</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://www.cnblogs.com/wholj/p/10961705.html" target="_blank" rel="noopener">LVM实现将2块磁盘总空间“合二为一”并挂载到同一目录</a></p>]]></content>
      
      
      <categories>
          
          <category> Storage </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Storage </tag>
            
            <tag> LVM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维手册——kubernetes容器不能解析内网部分DNS</title>
      <link href="2020/11/20/kubernetes/Kubernetes-pod-dns/"/>
      <url>2020/11/20/kubernetes/Kubernetes-pod-dns/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近把docker的服务迁移到k8s的过程发现一些问题，在滚动更新的时候一些容器不能解析部分DNS，导致了启动失败，但是多重启几次就又能正常解析了，一起来看看吧。</p><h1 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h1><p>公司的java程序启动前会连接mysql、redis、es、hadoop及几个业务接口，用的都是域名的方式。</p><p>从docker转到k8s上我突然发现一些域名会经常连不上</p><p>报错如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Exception during pool initialization., com.mysql.cj.jdbc.exceptions.CommunicationsException: Communications link failure||The last packet sent successfully to the server was 0 milliseconds ago. The driver has not received any packets from the server.|  at com.mysql.cj.jdbc.exceptions.SQLError.createCommunicationsException(SQLError.java:174)</span><br><span class="line"></span><br><span class="line">unable to connect to redis.test.com:6379</span><br></pre></td></tr></table></figure><p>奇怪的是容器多重启几次后又能解析到了，如下图所示</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Kubernetes/kubernetes-pod-bug-restart.jpg"  alt="kubernetes-pod-bug-restart.jpg"></p><p>这事让我百思不得其解</p><h1 id="分析问题"><a href="#分析问题" class="headerlink" title="分析问题"></a>分析问题</h1><h2 id="首次排查"><a href="#首次排查" class="headerlink" title="首次排查"></a>首次排查</h2><p>先来网络运维的经典分析方法</p><p>我进入一个已经正常运行的k8s pod里telnet 域名：PORT</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ telnet redis.test.com 6379</span><br><span class="line">telnet: could not resolve redis.test.com&#x2F;6379: Name or service not known</span><br><span class="line">$ telnet mysql.test.com 3306</span><br><span class="line">telnet: could not resolve mysql.test.com&#x2F;3306: Name or service not known</span><br><span class="line">$ telnet redis.test.com 6379</span><br><span class="line">Trying 192.168.20.4...</span><br><span class="line">Connected to redis.test.com.</span><br><span class="line">Escape character is &#39;^]&#39;.</span><br></pre></td></tr></table></figure><p>这个结论说明有时候成功有时候失败，太不正常了</p><p>但是我还不确定到底是什么原因，为了进一步加强我的判断，我用了经典的控制变量法做了以下操作</p><p>对于不太了解这几个命令的可以阅读我之前写过的一篇网络运维文章 </p><p><a href="https://rugod.cn/2020/11/07/linux/ubuntu-network-manager/" target="_blank" rel="noopener">Ubuntu网络基础运维</a></p><ul><li>k8s pod telnet ip:port</li><li>k8s pod telnet 域名:port</li><li>k8s pod traceroute 域名</li><li>docker  telnet ip:port</li><li>docker  telnet 域名:port</li><li>docker traceroute 域名</li><li>宿主机 telnet ip:port</li><li>宿主机 telnet 域名:port</li><li>宿主机 traceroute 域名</li></ul><p>域名及ip包括mysql、redis、es、hadoop、jenkins、harbor</p><table><thead><tr><th>是否能通信</th><th>k8s pod</th><th>docker</th><th>宿主机</th></tr></thead><tbody><tr><td>telnet  ip:port</td><td>一定</td><td>一定</td><td>一定</td></tr><tr><td>telnet 域名:port</td><td>不一定</td><td>一定</td><td>一定</td></tr><tr><td>traceroute 域名</td><td>不一定</td><td>一定</td><td>一定</td></tr></tbody></table><p>在不一定连通的类型里我又继续分类</p><table><thead><tr><th>是否能通信</th><th>域名</th></tr></thead><tbody><tr><td>mysql1(docker部署)</td><td>不一定</td></tr><tr><td>redis(docker部署)</td><td>不一定</td></tr><tr><td>es(docker部署)</td><td>不一定</td></tr><tr><td>hadoop(物理机部署)</td><td>不一定</td></tr><tr><td>mysql2(物理机部署)</td><td>一定</td></tr><tr><td>jenkins(docker部署)</td><td>一定</td></tr><tr><td>harbor(docker部署)</td><td>一定</td></tr></tbody></table><p>总结下来</p><p>k8s pod通过路由器的DNS服务有一定几率解析不到某2台机器的服务（包括docker启动和正常启动的服务）</p><p>说起来也奇怪，这2台机器都是公司最顶配的机器 32c 256g 2路2080TI </p><p>只不过由于历史原因，这台机器没有做虚拟化，还装的是ubuntu桌面版。。。</p><p>现在问题难就难在为什么k8s pod只不能DNS解析到这2台机器上来呢，可以正常解析到其他机器上</p><p>装k8s的时候和这2台机器没有任何关联，我真想不出来这两者之间的关联</p><p>也不是docker的原因</p><p>还是说有可能只是巧合，我试了至少100+次能正常解析到其他机器也只是巧合呢，如果失败一次我还真觉得就是巧合，可惜并没有</p><h2 id="进一步分析"><a href="#进一步分析" class="headerlink" title="进一步分析"></a>进一步分析</h2><p>仔细想想，这就是个dns的问题，因为pod通过ip是可以访问的，但是通过域名解析需要下面经过下面2个组件</p><ul><li>core-dns</li></ul><p>kubernetes V1.15用的dns组件是core-dns而不沿用kube-dns</p><p>如果你不知道core-dns是做什么的，那么请参考下面链接（包括但不限于）进行学习：</p><p><a href="https://coredns.io/" target="_blank" rel="noopener">core-dns</a></p><ul><li>路由器</li></ul><p>路由器是TP-LINK的TL-ER3220G，自带DNS服务</p><p>k8s pod的宿主机的首位DNS服务器就是路由器的IP</p><p>虽然现在路由器功能很多，但是这个DNS在TP-LINK的官网上就很简单的介绍</p><p>“支持DDNS及虚拟服务器功能，轻松搭建内网服务器及私有网站”</p><p>我觉得路由器的DNS出现问题的可能性不太大，因为宿主机之间的DNS解析都是正常的。只能从core-dns问题出发</p><p>网上说core-dns的负载可能顶不住这么多并发，我将默认的2个core-dns扩容到了6个，发现并不管用。</p><h1 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h1><p>正当我一筹莫展的时候，我突然想到了还有一个DNS服务器——Route53 可以作为k8s pod的第二层DNS服务</p><p>我尝试在Route53上添加这几条内网的DNS</p><p>然后再重启k8s pod发现可以解析了，测试了大概10多次，没有一个容器失败重启</p><p>不是很完美的方案（这样需要运维2个DNS服务器），但是还是解决了这个问题</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>其实我认为这个问题的根本原因还没有找出来，那就是K8s pod 为什么不能通过core-dns每次成功的解析到这2台机器上的服务，而是会断断续续地解析，并且只有这两台机器的域名才会解析出问题，我还是不能排除偶然情况。</p><p>这个问题可能若干年后我继续深入了解core-dns之后再做解答</p><p>如果你有幸看到这篇文章可以一起讨论下，在评论区给我留言即可</p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operation Manual </tag>
            
            <tag> Kubernetes </tag>
            
            <tag> Core-DNS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes调整nodePort端口范围</title>
      <link href="2020/11/17/kubernetes/Kubernetes-nodeport-range/"/>
      <url>2020/11/17/kubernetes/Kubernetes-nodeport-range/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>本周刚刚部署了K8S集群，准备把docker项目迁移到K8S上，但是发现某几个业务的grpc端口被设置成40000端口。</p><p>默认情况下，K8S 集群 nodePort 分配的端口范围为：30000-32767，如果我们指定的端口不在这个范围就会报类似下面这样的错误：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Error: Invalid value: 44444: provided port is not in the valid range. The range of valid ports is 30000-32767</span><br></pre></td></tr></table></figure><p>下面来看看怎么调整吧</p><h1 id="分析问题"><a href="#分析问题" class="headerlink" title="分析问题"></a>分析问题</h1><p>如果是用 kubeadm 安装的集群，那么 apiserver 是以静态 pod 的形式运行，pod 文件定义在 /etc/kubernetes/manifests/kube-apiserver.yaml。</p><p>/etc/kubernetes/manifests 目录下是所有静态 pod 文件的定义，kubelet 会监控该目录下文件的变动，只要发生变化，pod 就会重建，响应相应的改动。</p><p>所以我们修改 /etc/kubernetes/manifests/kube-apiserver.yaml 文件，添加 nodePort 范围参数后会自动生效，无需进行其他操作：</p><h1 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h1><p>vim /etc/kubernetes/manifests/kube-apiserver.yaml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  creationTimestamp: null</span><br><span class="line">  labels:</span><br><span class="line">    component: kube-apiserver</span><br><span class="line">    tier: control-plane</span><br><span class="line">  name: kube-apiserver</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - command:</span><br><span class="line">    - kube-apiserver</span><br><span class="line">    - --advertise-address&#x3D;192.168.20.151</span><br><span class="line">    - --allow-privileged&#x3D;true</span><br><span class="line">    - --apiserver-count&#x3D;1</span><br><span class="line">    - --authorization-mode&#x3D;Node,RBAC</span><br><span class="line">    - --client-ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt</span><br><span class="line">    - --enable-admission-plugins&#x3D;NodeRestriction</span><br><span class="line">    - --enable-bootstrap-token-auth&#x3D;true</span><br><span class="line">    - --encryption-provider-config&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;secrets-encryption.yaml</span><br><span class="line">    - --etcd-cafile&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;ca.crt</span><br><span class="line">    - --etcd-certfile&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;apiserver-etcd-client.crt</span><br><span class="line">    - --etcd-keyfile&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;apiserver-etcd-client.key</span><br><span class="line">    - --etcd-servers&#x3D;https:&#x2F;&#x2F;192.168.20.151:2379</span><br><span class="line">    - --insecure-port&#x3D;0</span><br><span class="line">    - --kubelet-certificate-authority&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt</span><br><span class="line">    - --kubelet-client-certificate&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;apiserver-kubelet-client.crt</span><br><span class="line">    - --kubelet-client-key&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;apiserver-kubelet-client.key</span><br><span class="line">    - --kubelet-https&#x3D;true</span><br><span class="line">    - --kubelet-preferred-address-types&#x3D;InternalIP,ExternalIP,Hostname</span><br><span class="line">    - --profiling&#x3D;false</span><br><span class="line">    - --proxy-client-cert-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-client.crt</span><br><span class="line">    - --proxy-client-key-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-client.key</span><br><span class="line">    - --requestheader-allowed-names&#x3D;front-proxy-client</span><br><span class="line">    - --requestheader-client-ca-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;front-proxy-ca.crt</span><br><span class="line">    - --requestheader-extra-headers-prefix&#x3D;X-Remote-Extra-</span><br><span class="line">    - --requestheader-group-headers&#x3D;X-Remote-Group</span><br><span class="line">    - --requestheader-username-headers&#x3D;X-Remote-User</span><br><span class="line">    - --secure-port&#x3D;6443</span><br><span class="line">    - --service-account-key-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;sa.pub</span><br><span class="line">    - --service-cluster-ip-range&#x3D;192.168.176.0&#x2F;20</span><br><span class="line">    - --service-node-port-range&#x3D;30000-32767</span><br><span class="line">    - --tls-cert-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;apiserver.crt</span><br><span class="line">    - --tls-private-key-file&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;apiserver.key</span><br></pre></td></tr></table></figure><p>将–service-node-port-range=30000-32767改为</p><p>–service-node-port-range=1-65535即可</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="http://www.thinkcode.se/blog/2019/02/20/kubernetes-service-node-port-range" target="_blank" rel="noopener">Kubernetes service node port range</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
            <tag> nodePort </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>个人总结(2020.10)</title>
      <link href="2020/11/12/summary/summary-2020-10/"/>
      <url>2020/11/12/summary/summary-2020-10/</url>
      
        <content type="html"><![CDATA[<h1 id="个人能力价值的体现"><a href="#个人能力价值的体现" class="headerlink" title="个人能力价值的体现"></a>个人能力价值的体现</h1><p>1个月的调整，给公司创造了如下价值</p><ul><li>将公司的服务器对比上月永久（注意是永久）减少接近200美金/月</li><li>部署一套深圳本地的系统（测试及生产环境）上云，且服务器费用还减少(又变相减少服务器的月支出)</li><li>设计新办公场地网络拓扑图、机房装修、设备购买方案，宽带、VPN业务办理并落地</li><li>搬家实操机房布线，有线无线网络划分管理</li><li>制作安全开关机脚本，开机自启服务，达到5分钟内安全关闭所有业务及服务器，10分钟内开机所有服务器并自启业务。</li><li>续费深信服VPN服务，将合同从9W/年砍到1w4/年，办理电信业务700/月 1000M宽带</li></ul><h1 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h1><p>学习底层网络下三层知识及七层应用配置，设计新办公场地网络拓扑图到机房布线实操的时候才发现这些知识有多么重要。</p><p>其中包括交换机、路由器、AP、DNS、NAT、VPN、DHCP等技术</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这个月主要就是搬家，因为在之前公司参与了一次搬家（当时跟着一个网络工程师，在后面坐着端茶倒水的小事，不过还是学习到了很多知识）现在终于到了我自己展现独挡一面的时候了。</p><p>因为旧网络拓扑图实属稀烂，而且不好改，一条专线办公服务器两用，还没有无线网。</p><p>现在改造成1000M宽带给办公网使用，并增加了无线WIFI，将电信专线给服务器网使用，充分利用带宽上限</p><p>设计新场地网络拓扑图花了快一个月，以及保证每台服务器的数据安全，备份，正常开关机脚本制作。</p><p>最后搬家2天内恢复所有服务</p><p>由于公司目前就我一个运维，能力有限，所以在时间上，我觉得还可以做的更好，毕竟一回生二回熟嘛，有了这次实战经验，我认为对我提升还是很大的。</p><h1 id="心态"><a href="#心态" class="headerlink" title="心态"></a>心态</h1><p>公司就我一个运维，不仅仅只做应用运维方面的事，网络、IT设备也需要我来管，其实我的压力还是相当大的。</p><p>能力越大，责任越大，这些工作任务的每一点都很关键，稍有不慎造成的结果可能不仅仅影响着我们的办公环境，还会影响着公司的业务、公司的命脉。</p><p>所以我对自己的要求相当之高，什么能做什么不能做，说到做到，不拖时间，尽自己最大的能力完成任务</p><p>因此我也非常感谢我的领导以及各位同事对我信任，放手让我干让我闯。</p><p>经过了3个月的努力</p><p>公司的同事对我说，“现在自动发布太舒服了，缺了你的自动化流水线，我不知道发布需要多久，这台服务器太重要了”</p><p>公司的领导对我说，“什么？你来了才3个月，感觉做了好多事啊，你不说我还以为你来了很久了”</p><p>其实做运维，有时候能让团队的成员说出这样的话实属对我技术的肯定。</p><p>不需要任何的华丽的辞藻，就一句，有你在，运维的事我们放心，足矣。</p><p>但其实我一直追求真正的SRE的境界：就是不需要运维，所有的服务自动化构建，无人值守，高可用，有我和没我没有区别才是最高境界</p><p>目前以为的能力还远远不够，加油努力达到这个目标吧。</p><h1 id="对自己说"><a href="#对自己说" class="headerlink" title="对自己说"></a>对自己说</h1><p>RUGOD，永不止步！现在搬家也搬完了，尘埃落定，接下来继续深入做运维开发的事情，我准备手动打造一套属于公司体系的K8S生态，所有服务上K8S，让我们拭目以待吧。</p><p>总结下本月学习的各种顶级理解</p><ul><li>努力最坏的结果就是大器晚成</li><li>努力的动力就是努力不一定成功</li><li>但行好事，莫问前程</li></ul>]]></content>
      
      
      <categories>
          
          <category> 个人总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 个人总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跟我学Devops之实践篇（Gitlab-Runner）</title>
      <link href="2020/11/08/devops/devops-gitlab-runner/"/>
      <url>2020/11/08/devops/devops-gitlab-runner/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="Gitlab-Runner简介"><a href="#Gitlab-Runner简介" class="headerlink" title="Gitlab Runner简介"></a>Gitlab Runner简介</h1><p>GitLab Runner是与GitLab CI / CD一起使用的应用程序，用于在管道中运行作业。</p><p>您可以选择在您拥有或管理的基础架构上安装GitLab Runner应用程序。如果这样做，则应在与托管GitLab实例的计算机不同的计算机上安装GitLab Runner。</p><p>GitLab Runner是开源的，用Go编写。它可以作为一个二进制文件运行。不需要特定于语言的要求。</p><p>您可以在多种支持的操作系统上安装GitLab Runner。其他操作系统也可以工作，只要您可以在它们上编译Go二进制文件即可。</p><p>GitLab Runner也可以在Docker容器中运行或部署到Kubernetes集群中。</p><h1 id="安装GitLab-Runner"><a href="#安装GitLab-Runner" class="headerlink" title="安装GitLab Runner"></a>安装GitLab Runner</h1><p>可以在GNU / Linux，macOS，FreeBSD和Windows上安装和使用GitLab Runner。有三种安装方法。使用Docker，手动下载二进制文件或使用rpm / deb软件包的存储库。</p><h2 id="添加GitLab的官方存储库"><a href="#添加GitLab的官方存储库" class="headerlink" title="添加GitLab的官方存储库"></a>添加GitLab的官方存储库</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># For Debian&#x2F;Ubuntu&#x2F;Mint</span><br><span class="line">curl -L https:&#x2F;&#x2F;packages.gitlab.com&#x2F;install&#x2F;repositories&#x2F;runner&#x2F;gitlab-runner&#x2F;script.deb.sh | sudo bash</span><br><span class="line"></span><br><span class="line"># For RHEL&#x2F;CentOS&#x2F;Fedora</span><br><span class="line">curl -L https:&#x2F;&#x2F;packages.gitlab.com&#x2F;install&#x2F;repositories&#x2F;runner&#x2F;gitlab-runner&#x2F;script.rpm.sh | sudo bash</span><br></pre></td></tr></table></figure><h2 id="安装最新版本的GitLab-Runner，或跳至下一步以安装特定版本"><a href="#安装最新版本的GitLab-Runner，或跳至下一步以安装特定版本" class="headerlink" title="安装最新版本的GitLab Runner，或跳至下一步以安装特定版本"></a>安装最新版本的GitLab Runner，或跳至下一步以安装特定版本</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># For Debian&#x2F;Ubuntu&#x2F;Mint</span><br><span class="line">export GITLAB_RUNNER_DISABLE_SKEL&#x3D;true; sudo -E apt-get install gitlab-runner</span><br><span class="line"></span><br><span class="line"># For RHEL&#x2F;CentOS&#x2F;Fedora</span><br><span class="line">export GITLAB_RUNNER_DISABLE_SKEL&#x3D;true; sudo -E yum install gitlab-runner</span><br></pre></td></tr></table></figure><h2 id="要安装特定版本的GitLab-Runner"><a href="#要安装特定版本的GitLab-Runner" class="headerlink" title="要安装特定版本的GitLab Runner"></a>要安装特定版本的GitLab Runner</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># for DEB based systems</span><br><span class="line">apt-cache madison gitlab-runner</span><br><span class="line">export GITLAB_RUNNER_DISABLE_SKEL&#x3D;true; sudo -E apt-get install gitlab-runner&#x3D;10.0.0</span><br><span class="line"></span><br><span class="line"># for RPM based systems</span><br><span class="line">yum list gitlab-runner --showduplicates | sort -r</span><br><span class="line">export GITLAB_RUNNER_DISABLE_SKEL&#x3D;true; sudo -E yum install gitlab-runner-10.0.0-1</span><br></pre></td></tr></table></figure><p>一般来说按照前2步安装即可</p><h1 id="注册runner"><a href="#注册runner" class="headerlink" title="注册runner"></a>注册runner</h1><p>获取令牌：</p><ul><li>对于共享runner，请管理员进入GitLab管理区域，然后单击概述&gt;runner。</li><li>对于团体runner，请转到“设置”&gt;“ CI / CD”，然后展开“跑步者”部分</li><li>对于特定于项目的runner，请转到“设置”&gt;“ CI / CD”，然后展开“runner”部分</li></ul><h2 id="查看gitlab-runner的注册说明"><a href="#查看gitlab-runner的注册说明" class="headerlink" title="查看gitlab-runner的注册说明"></a>查看gitlab-runner的注册说明</h2><ul><li>Install GitLab Runner</li><li>Specify the following URL during the Runner setup: <a href="https://gitlab.com/" target="_blank" rel="noopener">https://gitlab.com/</a> </li><li>Use the following registration token during setup: hbssCDnswfVeovqcEev- </li><li>Start the Runner!</li></ul><h2 id="进入服务器配置gitlab-runner"><a href="#进入服务器配置gitlab-runner" class="headerlink" title="进入服务器配置gitlab-runner"></a>进入服务器配置gitlab-runner</h2><p>首先进入到服务器，执行下面步骤</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">Runtime platform                                    arch&#x3D;amd64 os&#x3D;linux pid&#x3D;30883 revision&#x3D;ece86343 version&#x3D;13.5.0</span><br><span class="line">Running in system-mode.                            </span><br><span class="line">                                                   </span><br><span class="line">Please enter the gitlab-ci coordinator URL (e.g. https:&#x2F;&#x2F;gitlab.com&#x2F;):</span><br><span class="line"></span><br><span class="line">#填写gitlab的url</span><br><span class="line">https:&#x2F;&#x2F;gitlab.com&#x2F;</span><br><span class="line"></span><br><span class="line">Please enter the gitlab-ci token for this runner:</span><br><span class="line"></span><br><span class="line">#填写注册说明的密钥</span><br><span class="line">hbssCDnswfVeovqcEev-</span><br><span class="line"></span><br><span class="line">Please enter the gitlab-ci description for this runner:</span><br><span class="line"></span><br><span class="line">#对这个标签的描述，写个让自己知道是干什么的标记就行</span><br><span class="line">[nginx ]: </span><br><span class="line">Please enter the gitlab-ci tags for this runner (comma separated):</span><br><span class="line"></span><br><span class="line">#这个很重要，是需要你在gitlab-ci里pipline选择对应标签的runner</span><br><span class="line">test-runner</span><br><span class="line"></span><br><span class="line">Registering runner... succeeded                     runner&#x3D;hbssCDns</span><br><span class="line">Please enter the executor: docker, shell, docker+machine, docker-ssh+machine, kubernetes, custom, docker-ssh, parallels, ssh, virtualbox:</span><br><span class="line"></span><br><span class="line">#选择runner的运行环境，一般选择docker</span><br><span class="line">docker</span><br><span class="line"></span><br><span class="line">Please enter the default Docker image (e.g. ruby:2.6):</span><br><span class="line"></span><br><span class="line">#选择默认镜像，这个一般也无所谓，因为gitlab-ci里面要写的</span><br><span class="line">ruby:2.6</span><br><span class="line"></span><br><span class="line">Runner registered successfully. Feel free to start it, but if it&#39;s running already the config should be automatically reloaded!</span><br></pre></td></tr></table></figure><p>至此一个runner已经部署完成，可以在gitlab setting&gt;CICD/runner中查看</p><h2 id="gitlab-runner基本运维命令"><a href="#gitlab-runner基本运维命令" class="headerlink" title="gitlab-runner基本运维命令"></a>gitlab-runner基本运维命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"># 查看状态</span><br><span class="line">gitlab-runner status</span><br><span class="line"># 启动</span><br><span class="line">gitlab-runner start </span><br><span class="line"># 停止</span><br><span class="line">gitlab-runner stop</span><br><span class="line"># 重启</span><br><span class="line">gitlab-runner restart </span><br><span class="line"># 查看runner列表</span><br><span class="line">gitlab-runner list  </span><br><span class="line"># 注销名叫test-runner的runner服务</span><br><span class="line">gitlab-runner unregister --name test-runner </span><br><span class="line">#</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>至此，部署一个runner基本上就完成了，后续我会介绍如何依靠runner实现gitlab的cicd流程</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://docs.gitlab.com/runner/register/index.html" target="_blank" rel="noopener">Install Runner</a></p><p><a href="https://blog.csdn.net/londa/article/details/94165073" target="_blank" rel="noopener">Gitlab CI/CD 问题处理</a></p><p><a href="https://blog.csdn.net/qq_34206560/article/details/88827395" target="_blank" rel="noopener">gitlab runner命令</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> 跟我学Devops </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Gitlab </tag>
            
            <tag> CI/CD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ubuntu网络基础运维</title>
      <link href="2020/11/07/linux/ubuntu-network-manager/"/>
      <url>2020/11/07/linux/ubuntu-network-manager/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>公司由于历史原因，很多服务器和同事的服务器都是安装的Ubuntu，有16.04也有18.04，每个版本差异比较大，这期先总结下网络方面的运维技术</p><h1 id="安装网络运维软件包"><a href="#安装网络运维软件包" class="headerlink" title="安装网络运维软件包"></a>安装网络运维软件包</h1><p>如果你是最小化安装，你需要额外装一些软件包</p><ul><li>traceroute  链路追踪</li><li>net-tools   NET-3网络分发的基础包(包括 arp, hostname, ifconfig, netstat, rarp, route, plipconfig, slattach, mii-tool and iptunnel and ipmaddr)</li><li>telnet      测试IP：端口是否能访问</li></ul><p>安装命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install -y traceroute net-tools telnet</span><br></pre></td></tr></table></figure><p>如果出现nothing to do则需要更新apt源</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt update</span><br></pre></td></tr></table></figure><h1 id="查看网络信息"><a href="#查看网络信息" class="headerlink" title="查看网络信息"></a>查看网络信息</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ip add</span><br><span class="line">ifconfig</span><br><span class="line">nmcli device show</span><br></pre></td></tr></table></figure><h1 id="网络配置"><a href="#网络配置" class="headerlink" title="网络配置"></a>网络配置</h1><h2 id="16-04-server"><a href="#16-04-server" class="headerlink" title="16.04 server"></a>16.04 server</h2><p>配置文件   /etc/network/interfaces </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo vim &#x2F;etc&#x2F;network&#x2F;interfaces </span><br><span class="line">auto ens33 网卡名字</span><br><span class="line">#iface ens33 inet dhcp动态的获取IP地址</span><br><span class="line">iface ens33 inet static 静态的获取IP地址</span><br><span class="line">address 192.168.1.100 设置IP地址</span><br><span class="line">gateway 192.168.1.1 设置网关</span><br><span class="line">netmask 255.255.255.0 设置子网掩码</span><br><span class="line">dns-nameserver 8.8.8.8 设置DNS，域名解析</span><br></pre></td></tr></table></figure><hr><p>运维命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start networking 启动网卡服务</span><br><span class="line">sudo systemctl stop  networking 关闭网卡服务</span><br><span class="line">sudo systemctl restart networking 重启网卡服务</span><br></pre></td></tr></table></figure><h2 id="18-04-server"><a href="#18-04-server" class="headerlink" title="18.04 server"></a>18.04 server</h2><p>配置文件   /etc/netplan/下的一个yaml文件，名字可能各不相同</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">sudo vim &#x2F;etc&#x2F;netplan&#x2F;50-cloud-init.yaml</span><br><span class="line"># Let NetworkManager manage all devices on this system</span><br><span class="line">network:</span><br><span class="line">  version: 2</span><br><span class="line"> # renderer: NetworkManager</span><br><span class="line">  ethernets:</span><br><span class="line">     ens33: #配置的网卡名称,使用ifconfig  查看得到,且必须是空格缩进，netplan只认空格</span><br><span class="line">       dhcp4: no #no-dhcp4关闭 true-dhcp4开启</span><br><span class="line">       addresses: [192.168.1.100&#x2F;24, ] </span><br><span class="line">       gateway4: 192.168.1.1 #设置ipv4的默认网关</span><br><span class="line">       nameservers:  #设置DNS服务器</span><br><span class="line">         addresses: [114.114.114.114,8.8.8.8]  #多个DNS服务器之间用逗号隔开</span><br></pre></td></tr></table></figure><p>注意几个点</p><ul><li>修改权限必须为root</li><li>将/etc/netplan/01-network-manager-all.yaml文件中的renderer: NetworkManager注释，否则netplan命令无法生效</li><li>IP配置信息要按如上格式，使用yaml语法格式，每个配置项使用空格缩进表示层级</li><li>对应配置项后跟着冒号，之后要接个空格，否则netplan命令也会报错</li></ul><hr><p>运维命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo netplan apply 应用网卡服务</span><br></pre></td></tr></table></figure><h2 id="desktop"><a href="#desktop" class="headerlink" title="desktop"></a>desktop</h2><p>NetworkManager工具是Ubuntu桌面版的GUI设置工具。</p><p>这个工具推荐直接在GUI上操作，不建议用命令行进行管理，比如Wifi这些配置等。</p><p>当然，这个工具能带有命令行工具：nmcli，如果使用了NetworkManager进行配置网络，那么IP、网关、DNS都可以通过这个工具进行查询。</p><p>如果配置了命令行的网络设置，那么NetworkManager就会失效</p><p>你的所有连接信息都在/etc/NetworkManager/system-connections下</p><p>运维命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl start NetworkManager.service</span><br><span class="line">sudo systemctl sttop NetworkManager.service</span><br></pre></td></tr></table></figure><h1 id="DNS配置"><a href="#DNS配置" class="headerlink" title="DNS配置"></a>DNS配置</h1><h2 id="临时添加"><a href="#临时添加" class="headerlink" title="临时添加"></a>临时添加</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo vim &#x2F;etc&#x2F;resolv.conf</span><br><span class="line">添加 nameserver dns服务器的ip</span><br><span class="line">eg：nameserver 114.114.114.114</span><br></pre></td></tr></table></figure><h2 id="永久添加"><a href="#永久添加" class="headerlink" title="永久添加"></a>永久添加</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1.修改对应ubuntu版本的网络配置，上面已经说过，这里不在叙述</span><br><span class="line">2.sudo vim &#x2F;etc&#x2F;hosts</span><br><span class="line">直接加域名解析的地址，格式为： IP  域名</span><br><span class="line">eg：192.168.10.1    baidu.com</span><br><span class="line">保存后，你访问baidu.com就是访问192.168.10.1了</span><br></pre></td></tr></table></figure><h2 id="刷新dns"><a href="#刷新dns" class="headerlink" title="刷新dns"></a>刷新dns</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">16.04</span><br><span class="line">sudo systemd-resolve --statistics</span><br><span class="line"></span><br><span class="line">18.04 server</span><br><span class="line">sudo systemd-resolve --flush-caches</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">sudo &#x2F;etc&#x2F;init.d&#x2F;dns-clean start</span><br></pre></td></tr></table></figure><h2 id="查看域名解析"><a href="#查看域名解析" class="headerlink" title="查看域名解析"></a>查看域名解析</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install dnsutils</span><br><span class="line">dig -v</span><br><span class="line">dig www.baidu.com</span><br><span class="line">nslookup www.baidu.com</span><br></pre></td></tr></table></figure><h1 id="route-查看路由表"><a href="#route-查看路由表" class="headerlink" title="route 查看路由表"></a>route 查看路由表</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">route</span><br></pre></td></tr></table></figure><h1 id="ss-netstat-查看端口"><a href="#ss-netstat-查看端口" class="headerlink" title="ss/netstat 查看端口"></a>ss/netstat 查看端口</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ss -lnt</span><br><span class="line">netstat -nap</span><br></pre></td></tr></table></figure><h1 id="ping-测试主机通信"><a href="#ping-测试主机通信" class="headerlink" title="ping 测试主机通信"></a>ping 测试主机通信</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ping IP&#x2F;域名</span><br></pre></td></tr></table></figure><p>ICMP全称为 Internet 控制报文协议（Internet Control Message Protocol）。它是一种面向无连接的协议，属于TCP/IP协议中的网络层</p><p>ping 命令会发送一份ICMP回显请求报文给目标主机，并等待目标主机返回ICMP回显应答。因为ICMP协议会要求目标主机在收到消息之后，必须返回ICMP应答消息给源主机，如果源主机在一定时间内收到了目标主机的应答，则表明两台主机之间网络是可达的。</p><p>但是Ping不通并不一定代表网络不通。ping是基于ICMP协议的命令，就是你发出去一个数据包，对方收到后返给你一个！就好比声纳。这个协议是可以禁止的！禁止后，如果你ping对方，对方收到后就不回馈给你，这样你就显示无法ping通，但实际你们还是连着的！</p><h1 id="telnet-测试IP-域名-端口是否通信"><a href="#telnet-测试IP-域名-端口是否通信" class="headerlink" title="telnet 测试IP/域名:端口是否通信"></a>telnet 测试IP/域名:端口是否通信</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">telnet IP&#x2F;域名:端口</span><br><span class="line"></span><br><span class="line"># 测试192.168.20.150的443端口是否开放</span><br><span class="line">telnet 192.168.20.150 443</span><br><span class="line">Trying 192.168.20.150...</span><br><span class="line"></span><br><span class="line">一直trying则说明不行</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">telnet 192.168.20.150 80</span><br><span class="line">Trying 192.168.20.150...</span><br><span class="line">Connected to 192.168.20.150.</span><br><span class="line">Escape character is &#39;^]&#39;.</span><br><span class="line"></span><br><span class="line">成功</span><br></pre></td></tr></table></figure><p>telnet是OSI模型中基于TCP协议之上应用层的一种协议，是一个通过创建虚拟终端提供连接到远程主机终端仿真的TCP/IP协议。</p><p>现在telnet用于测试IP：端口的通信较多，本质上telnet是登陆服务器的！服务没禁止就能登陆，一般来说会比ping更容易测试主机之间的通信问题（端口通信）</p><h1 id="traceroute链路追踪"><a href="#traceroute链路追踪" class="headerlink" title="traceroute链路追踪"></a>traceroute链路追踪</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">traceroute ip</span><br></pre></td></tr></table></figure><h1 id="最原汁原味的配置网络信息"><a href="#最原汁原味的配置网络信息" class="headerlink" title="最原汁原味的配置网络信息"></a>最原汁原味的配置网络信息</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">#设置IP和子网掩码</span><br><span class="line">sudo ifconfig ens33 192.168.20.100 netmask 255.255.255.0</span><br><span class="line">#设置网关</span><br><span class="line">sudo route add default gw 192.168.20.1</span><br><span class="line">#设置DNS</span><br><span class="line">sudo echo &quot;nameserver 192.168.20.1&quot; &gt;&gt; &#x2F;etc&#x2F;resolv.conf</span><br></pre></td></tr></table></figure><h1 id="问题梳理"><a href="#问题梳理" class="headerlink" title="问题梳理"></a>问题梳理</h1><h2 id="关于desktop的网络配置"><a href="#关于desktop的网络配置" class="headerlink" title="关于desktop的网络配置"></a>关于desktop的网络配置</h2><p>在Desktop版本中，除了可以修改 /etc/network/interfaces 来进行配置以外；还可以直接在network-manager中配置。通过 interfaces修改的方法参照Server版本。network-manager的配置和直观，按照提示一步一步操作即可，有兴趣的朋友，可以自行Google或者Baidu。</p><p>但如果修改了interfaces，又配置了network-manager（以下简称nm），你就会发现出现了一些莫名其妙的问题：</p><p>1，interfaces和 nm中的网络设置不一样，系统实际的IP是哪个？</p><p>2，有时候莫名其妙的，界面右上角的网络连接图标就丢失了。</p><p>3，明明在nm中配置了正确的网络设置，为什么就上不了网呢？</p><p>其实，我们要知道 interfaces和 nm之间的关系，这些问题就不难解释了。</p><p>首先，当系统内没有第三方网络管理工具（比如nm）时，系统默认使用interfaces文件内的参数进行网络配置。（就像Server版本一样）</p><p>接着，当系统内安装了 nm之后，nm默认接管了系统的网络配置，使用nm 自己的网络配置参数来进行配置。</p><p>但是，如果用户在安装nm之后（Desktop版本默认安装了nm），自己手动修改了interfaces 文件，那nm 就自动停止对系统网络的管理，系统改使用interfaces 文件内的参数进行网络配置。</p><p>此时，再去修改nm 内的参数，不影响系统实际的网络配置。若要让nm 内的配置生效，必须重新启用nm 接管系统的网络配置。</p><p>现在知道了两者之间的工作关系，再看上面的三个问题：</p><p>1，要看nm是否接管，如果没有接管，系统实际的IP设置以interfaces 中的为准。反之，以nm 中的为准。</p><p>2，当nm 停止接管的时候，网络连接图标就丢失了。</p><p>3，同样是接管的问题。</p><p>如果用户希望在Desktop版本中，直接使用interfaces 进行网络配置，那可以关闭network-manager：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop network-manager</span><br></pre></td></tr></table></figure><p>vim /etc/network/interfaces修改之后</p><p>确保/etc/NetworkManager/Network-manager.conf内的managed=false(系统默认是false，但是你更改过的话需要改这里)</p><p>如果希望能继续使用nm 来进行网络配置，则需要进行如下操作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo systemctl stop network-manager # 停止 nm服务</span><br><span class="line">sudo rm &#x2F;var&#x2F;lib&#x2F;NetworkManager&#x2F;NetworkManager.state # 移除nm 的状态文件</span><br><span class="line">sudo vim &#x2F;etc&#x2F;NetworkManager&#x2F;Network-manager.conf # 打开nm 的配置文件(managed&#x3D;true)</span><br><span class="line">sudo systemctl start network-manager</span><br></pre></td></tr></table></figure><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://www.cnblogs.com/jins-note/p/10153374.html" target="_blank" rel="noopener">Ubuntu中网络配置interfaces与界面网络配置NetworkManager</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Ubuntu </tag>
            
            <tag> Network </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维手册——NVIDIA不能正常工作问题汇总</title>
      <link href="2020/10/31/bug/nvidia-reboot/"/>
      <url>2020/10/31/bug/nvidia-reboot/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>公司搬家需要关机所有服务器后再开机，其中遇到了不少问题，这期先分享下GPU服务器启动报错的问题</p><h1 id="问题归纳"><a href="#问题归纳" class="headerlink" title="问题归纳"></a>问题归纳</h1><h2 id="问题一-安装meshroom报错"><a href="#问题一-安装meshroom报错" class="headerlink" title="问题一 安装meshroom报错"></a>问题一 安装meshroom报错</h2><p>安装meshroom时报错了一个与cuda相关的问题，需要更新版本</p><p>解决办法</p><p>sudo apt remove(purge) nvidia-*<br>sudo reboot</p><h2 id="问题二-黑屏"><a href="#问题二-黑屏" class="headerlink" title="问题二 黑屏"></a>问题二 黑屏</h2><p>重启时无法进入登录页,黑屏</p><p>初步判断与显卡驱动有关</p><h3 id="解决办法"><a href="#解决办法" class="headerlink" title="解决办法"></a>解决办法</h3><p>在/etc/default/grub配置文件中添加nomodeset选项，意思是不加载视频驱动</p><p>sudo vim /etc/default/grub<br>在”quiet splash” 后添加 “nomodeset”参数，如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GRUB_DEFAULT&#x3D;&quot;Advanced options for Ubuntu&gt;Ubuntu, with Linux 4.15.0-20-generic&quot;</span><br><span class="line">GRUB_TIMEOUT_STYLE&#x3D;hidden</span><br><span class="line">GRUB_TIMEOUT&#x3D;10</span><br><span class="line">GRUB_DISTRIBUTOR&#x3D;&#96;lsb_release -i -s 2&gt; &#x2F;dev&#x2F;null || echo Debian&#96;</span><br><span class="line">GRUB_CMDLINE_LINUX_DEFAULT&#x3D;&quot;quiet splash nomodeset&quot;</span><br><span class="line">GRUB_CMDLINE_LINUX&#x3D;&quot;&quot;</span><br></pre></td></tr></table></figure><p>sudo update-grub<br>sudo reboot</p><h3 id="此时可以进入登页面，但是没有加载驱动的情况下，图形界面很卡"><a href="#此时可以进入登页面，但是没有加载驱动的情况下，图形界面很卡" class="headerlink" title="此时可以进入登页面，但是没有加载驱动的情况下，图形界面很卡"></a>此时可以进入登页面，但是没有加载驱动的情况下，图形界面很卡</h3><blockquote><p><a href="https://blog.mtkfan.com/post-431.html" target="_blank" rel="noopener">https://blog.mtkfan.com/post-431.html</a><br><a href="https://zhengdao.github.io/2018/10/09/switch-ubuntu-linux-kernel/" target="_blank" rel="noopener">https://zhengdao.github.io/2018/10/09/switch-ubuntu-linux-kernel/</a></p></blockquote><h3 id="调整内核的启动顺序"><a href="#调整内核的启动顺序" class="headerlink" title="调整内核的启动顺序"></a>调整内核的启动顺序</h3><p>因为ubuntu内核会自动更新，更新后nvidia-smi的驱动就失效了。需要降低linux内核版本。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1. 查看启动内核的菜单</span><br><span class="line">   grep menuentry &#x2F;boot&#x2F;grub&#x2F;grub.cfg</span><br><span class="line">2. 修改grub文件的启动配置</span><br><span class="line">   sudo vim &#x2F;etc&#x2F;default&#x2F;grub </span><br><span class="line">   修改GRUB_DEFAULT&#x3D;0的值为</span><br><span class="line">   GRUB_DEFAULT&#x3D;&quot;Advanced options for Ubuntu&gt;Ubuntu, with Linux 5.3.0-28-generic&quot;</span><br><span class="line">3. sudo update-grub</span><br><span class="line">4. sudo reboot</span><br></pre></td></tr></table></figure><h2 id="问题三-The-system-is-running-in-low-graphics-mode"><a href="#问题三-The-system-is-running-in-low-graphics-mode" class="headerlink" title="问题三 The system is running in low-graphics mode"></a>问题三 The system is running in low-graphics mode</h2><p>开机显示The system is running in low-graphics mode,但是不黑屏</p><p>这个是ubuntu系统可能存在的问题</p><p>解决方法</p><p>不用管提示，直接按 ctrl+alt+F1，强行进入命令输入的模式</p><p>输入用户名密码</p><p>输入以下命令:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;etc&#x2F;X11 </span><br><span class="line">sudo cp xorg.conf.failsafe xorg.conf </span><br><span class="line">sudo reboot</span><br></pre></td></tr></table></figure><p>如果这个方法也不行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get update</span><br><span class="line">sudo reboot</span><br></pre></td></tr></table></figure><h2 id="问题四-开机启动都正常，但是英伟达不工作"><a href="#问题四-开机启动都正常，但是英伟达不工作" class="headerlink" title="问题四 开机启动都正常，但是英伟达不工作"></a>问题四 开机启动都正常，但是英伟达不工作</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nvidia-smi</span><br><span class="line">NVIDIA-SMI has failed because it couldn&#39;t communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.</span><br></pre></td></tr></table></figure><p>google之后发现这个问题是因为为ubutnu内核升级了，新版本内核和显卡驱动不匹配出现了上面的问题</p><p>这个时候不需要回退内核，毕竟都更新了，直接让dkms(Dynamic Kernel ModuleSupport)重新生成对应nvidia的驱动模块</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install -y dkms</span><br><span class="line">whereis nvidia</span><br><span class="line">nvidia: &#x2F;usr&#x2F;lib&#x2F;nvidia &#x2F;usr&#x2F;share&#x2F;nvidia &#x2F;usr&#x2F;src&#x2F;nvidia-430.64&#x2F;nvidia</span><br><span class="line">sudo dkms install -m nvidia -v 430.64</span><br><span class="line">nvidia-smi</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 430.64       Driver Version: 430.64       CUDA Version: 10.1     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage&#x2F;Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|</span><br><span class="line">|   0  GeForce RTX 208...  Off  | 00000000:AF:00.0 Off |                  N&#x2F;A |</span><br><span class="line">| 43%   38C    P0    N&#x2F;A &#x2F;  N&#x2F;A |      0MiB &#x2F; 11016MiB |      0%      Default |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">                                                                               </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                       GPU Memory |</span><br><span class="line">|  GPU       PID   Type   Process name                             Usage      |</span><br><span class="line">|&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|</span><br><span class="line">|  No running processes found                                                 |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>以上问题均为解决各自报错的一种途径，没有绝对的方法，出现类似问题的处理方法仅供参考</p>]]></content>
      
      
      <categories>
          
          <category> NVIDIA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operation Manual </tag>
            
            <tag> NVIDIA </tag>
            
            <tag> Ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>配置企业级路由器VPN功能</title>
      <link href="2020/10/31/vpn/vpn/"/>
      <url>2020/10/31/vpn/vpn/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>公司的企业级路由器可以提供VPN功能，设备提供IPSEC、L2TP、PPTP协议，一起来学习下VPN的几个基础协议以及配置VPN方法吧</p><h1 id="VPN协议"><a href="#VPN协议" class="headerlink" title="VPN协议"></a>VPN协议</h1><p>VPN根据网络七层协议一般分为三种不同的协议</p><p>分别代表的协议</p><ul><li>数据链路层 PPTP、L2TP</li><li>网络层   IPSec、GRE VPN、VTP</li><li>应用层   SSL VPN、Open VPN </li></ul><p>我们主要了解下几种常见的协议</p><h2 id="PPTP"><a href="#PPTP" class="headerlink" title="PPTP"></a>PPTP</h2><p>点对点隧道协议 (PPTP) 是由包括微软和3Com等公司组成的PPTP论坛开发的一种点对点隧道协，基于拨号使用的PPP协议使用PAP或CHAP之类的加密算法，或者使用Microsoft的点对点加密算法MPPE。</p><p>其通过跨越基于 TCP/IP 的数据网络创建 VPN 实现了从远程客户端到专用企业服务器之间数据的安全传输。PPTP 支持通过公共网络(例如 Internet)建立按需的、多协议的、虚拟专用网络。PPTP 允许加密 IP 通讯，然后在要跨越公司 IP 网络或公共 IP 网络(如 Internet)发送的 IP 头中对其进行封装。</p><h2 id="L2TP"><a href="#L2TP" class="headerlink" title="L2TP"></a>L2TP</h2><p>第 2 层隧道协议 (L2TP) 是IETF基于L2F (Cisco的第二层转发协议)开发的PPTP的后续版本。是一种工业标准 Internet 隧道协议，其可以为跨越面向数据包的媒体发送点到点协议 (PPP) 框架提供封装。</p><p>PPTP和L2TP都使用PPP协议对数据进行封装，然后添加附加包头用于数据在互联网络上的传输。</p><ul><li>PPTP只能在两端点间建立单一隧道。</li><li>L2TP支持在两端点间使用多隧道，用户可以针对不同的服务质量创建不同的隧道。L2TP可以提供隧道验证，而PPTP则不支持隧道验证。</li></ul><p>但是当L2TP 或PPTP与IPSEC共同使用时，可以由IPSEC提供隧道验证，不需要在第2层协议上验证隧道使用L2TP。 PPTP要求互联网络为IP网络。L2TP只要求隧道媒介提供面向数据包的点对点的连接，L2TP可以在IP(使用UDP)，桢中继永久虚拟电路 (PVCs),X.25虚拟电路(VCs)或ATM VCs网络上使用。</p><h2 id="IPSEC"><a href="#IPSEC" class="headerlink" title="IPSEC"></a>IPSEC</h2><p>IPSec 的隧道是封装、路由与解封装的整个过程。隧道将原始数据包隐藏(或封装)在新的数据包内部。该新的数据包可能会有新的寻址与路由信息，从而使其能够通过网络传输。隧道与数据保密性结合使用时，在网络上窃听通讯的人将无法获取原始数据包数据(以及原始的源和目标)。封装的数据包到达目的地后，会删除封装，原始数据包头用于将数据包路由到最终目的地。</p><p>隧道本身是封装数据经过的逻辑数据路径，对原始的源和目的端，隧道是不可见的，而只能看到网络路径中的点对点连接。连接双方并不关心隧道起点和终点之间的任何路由器、交换机、代理服务器或其他安全网关。将隧道和数据保密性结合使用时，可用于提供VPN。</p><p>封装的数据包在网络中的隧道内部传输。</p><p>当以隧道模式使用 IPSec 时，其只为 IP 通讯提供封装。使用 IPSec 隧道模式主要是为了与其他不支持 IPSec 上的 L2TP 或 PPTP VPN 隧道技术的路由器、网关或终端系统之间的相互操作。</p><h2 id="SSLVPN"><a href="#SSLVPN" class="headerlink" title="SSLVPN"></a>SSLVPN</h2><p>SSL协议提供了数据私密性、端点验证、信息完整性等特性。SSL协议由许多子协议组成，其中两个主要的子协议是握手协议和记录协议。握手协议允许服务器 和客户端在应用协议传输第一个数据字节以前，彼此确认，协商一种加密算法和密码钥匙。在数据传输期间，记录协议利用握手协议生成的密钥加密和解密后来交换 的数据。</p><p>SSL独立于应用，因此任何一个应用程序都可以享受它的安全性而不必理会执行细节。SSL置身于网络结构体系的传输层和应用层之间。此外，SSL本身就被几乎所有的Web浏览器支持。这意味着客户端不需要为了支持SSL连接安装额外的软件。这两个特征就是SSL能 应用于VPN的关键点。</p><h2 id="VPN比较"><a href="#VPN比较" class="headerlink" title="VPN比较"></a>VPN比较</h2><ul><li>稳定性：SSLVPN &gt; L2TP &gt; PPTP</li><li>速度：PPTP &gt; SSLVPNUDP &gt; L2TP &gt; SSLVPNTCP</li><li>安全性：SSLnVPN &gt; L2TP &gt; PPTP</li><li>易用性：PPTP &gt; L2TP &gt; SSLVPN</li><li>网络适用性：SSLVPN &gt; PPTP &gt; L2TP</li></ul><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>一般来说，站点到站点的VPN打通用应该用IPSEC协议，而PC到站点用的协议既可以是2层协议也可以是7层协议</p><h1 id="配置路由器VPN"><a href="#配置路由器VPN" class="headerlink" title="配置路由器VPN"></a>配置路由器VPN</h1><p>下面以TP-LINK-ER3220G做例子配置企业级VPN</p><h2 id="第一步，创建IP池"><a href="#第一步，创建IP池" class="headerlink" title="第一步，创建IP池"></a>第一步，创建IP池</h2><p>进入路由器管理界面</p><p>点击 对象管理&gt;IP地址池</p><p>创建一个虚拟子网（不能是现有网络中的一段地址）</p><h2 id="第二步，添加协议"><a href="#第二步，添加协议" class="headerlink" title="第二步，添加协议"></a>第二步，添加协议</h2><p>进入路由器管理界面</p><p>点击 VPN&gt;L2TP或PPTP&gt;新增该协议的服务器</p><p>服务器接口选择路由器的一个WAN口</p><p>最好是能固定IP的WAN口，比如专线IP</p><p>然后选择IPSEC/MPPE加密</p><p>选择IPSEC加密需要设置一个预共享密钥</p><p>确定即可</p><h2 id="第三步，创建用户"><a href="#第三步，创建用户" class="headerlink" title="第三步，创建用户"></a>第三步，创建用户</h2><p>进入路由器管理界面</p><p>点击 VPN&gt;用户管理&gt;新增用户</p><p>填写账号密码，服务类型选择L2TP或PPTP</p><p>本地地址填写路由器的虚拟网关（自己配置）</p><p>比如路由器的真实网关是1.1</p><p>虚拟网关可以设为10.1</p><p>你拨号就是从10.1进入路由器，然后通过路由器1.1的LAN口访问内网</p><p>地址池选择第一步配好的子网</p><p>DNS选择114.114.114.114</p><p>组网模式为PC到站点</p><p>最大会话数为1-100（自己选择）</p><p>确定</p><h2 id="第四步，连接VPN"><a href="#第四步，连接VPN" class="headerlink" title="第四步，连接VPN"></a>第四步，连接VPN</h2><p>一般通过系统自带的VPN工具即可，目前我所知道的</p><p>win10自带的VPN支持PPTP、L2TP</p><p>mac新版本只支持L2TP</p><p>ubuntu16.04只支持PPTP</p><p>这样就需要给不同操作系统的用户添加不同协议的用户了</p><p>按照协议的配置项填好即可连接</p><h1 id="VPN协议各种问题"><a href="#VPN协议各种问题" class="headerlink" title="VPN协议各种问题"></a>VPN协议各种问题</h1><p>连接VPN还要根据操作系统自带的VPN客户端来配置，下面记录下配置时出现的问题</p><h2 id="Win10"><a href="#Win10" class="headerlink" title="Win10"></a>Win10</h2><h3 id="不能建立到远程计算机的连接"><a href="#不能建立到远程计算机的连接" class="headerlink" title="不能建立到远程计算机的连接"></a>不能建立到远程计算机的连接</h3><p>拨号过程中出现以下提示：“不能建立到远程计算机的连接。你可能需要更改此连接的网络设置”。检查过VPN的设置正确无误，但重新拨号的时候又会显示同样的错误提示。把公司的路由器（为VPN服务器）重启后，再重新拨号，问题依旧。</p><p>解决方法</p><ul><li>打开“设备管理器”（需要管理员权限）；</li><li>找到“网络适配器”——“WAN Miniport (IP)”，对该项点击鼠标右键，然后点击“卸载设备”</li><li>重启电脑，重新拨号即可</li></ul><h3 id="PPP链接控制协议终止，错误代码为734"><a href="#PPP链接控制协议终止，错误代码为734" class="headerlink" title="PPP链接控制协议终止，错误代码为734"></a>PPP链接控制协议终止，错误代码为734</h3><p>拨号L2TP出现的报错</p><p>原因引起的原因：</p><ul><li>宽带提供商ISP（也就是运营商）的BAS上面的地址池不够用了，用户无法及时的正确的获取到IP地址所造成的。（最主要原因）</li><li>拔号程序出现程序问题。</li><li>网络组件协议出现异常。</li><li>网卡驱动程序异常引起。</li></ul><p>解决方法：</p><ul><li>找到宽带连接PPP设置选项，勾选第三项“为单链路连接协商多重链接”，重新连接即可。</li><li>卸载原拔号程序，重新安装</li><li>在本地连接里面把micosoft客户端和tcp/ip协议卸载重启后再重新安装进行测试。</li><li>更新一下电脑上网卡的驱动程序。</li></ul><h2 id="Mac"><a href="#Mac" class="headerlink" title="Mac"></a>Mac</h2><p>大概在2015年后的某一版本，Mac安全性升级，直到现在。</p><p>PPTP协议的VPN不够安全原因不再支持了，Mac默认的VPN协议就是L2TP</p><p>但是用L2TP连接后发现并不能连到内网，只能ping通vpn的虚拟网关，但是访问不了路由器的真实网段</p><p>出现这种情况大概率是因为VPN没有作为默认网关</p><p>解决方案是进入网络设置-选择你配置的VPN-高级-通过VPN连接发送所有流量勾选然后确定</p><p>这一步相当于所有流量走VPN</p><p>也会有一些问题，比如你访问baidu，你是先经过VPN到公司内网，然后再去访问baidu，如果公司网络访问不了一些网站，你拨VPN也访问不了。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>至此，企业级路由器VPN的配置基本完成，但是L2TP和PPTP协议默认把所有流量全部请求到公司内网，可能导致你通过本地的网络可以访问的网站，拨了VPN后访问不了。</p><p>这个我咨询了下一个网络工程师，他说SSLVPN可以，但是需要新的SSLVPN设备，在访问控制里只做内网的部分请求控制</p><p>看来用企业级路由器并不能满足我们所有的需求啊，不过总的来说ER3220G做的事以及对得起这个价格了。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://linux.cn/article-3407-1.html" target="_blank" rel="noopener">VPN 隧道协议PPTP、L2TP、IPSec和SSLVPN的区别</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> VPN </category>
          
      </categories>
      
      
        <tags>
            
            <tag> VPN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跟我学Devops之工具篇(Gitlab-Pages)</title>
      <link href="2020/10/13/devops/devops-gitlab-pages/"/>
      <url>2020/10/13/devops/devops-gitlab-pages/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="Gitlab-Pages"><a href="#Gitlab-Pages" class="headerlink" title="Gitlab-Pages"></a>Gitlab-Pages</h1><p>GitLab页面允许托管静态站点。</p><p>GitLab Pages使用GitLab Pages守护程序，这是一个用Go编写的简单HTTP服务器，可以侦听外部IP地址并提供对自定义域和自定义证书的支持。</p><p>对于自定义域（而不是 通配符域），Pages守护程序需要在port 80和/或上侦听443。因此，设置方式具有一定的灵活性：</p><ul><li>在与GitLab相同的服务器上运行Pages守护程序，侦听辅助IP。</li><li>在单独的服务器上运行Pages守护程序。在这种情况下， Pages路径也必须存在于安装Pages守护程序的服务器中，因此您必须通过网络共享它。</li><li>在与GitLab相同的服务器上运行Pages守护程序，侦听相同的IP，但侦听不同的端口。在这种情况下，您将不得不使用负载平衡器代理流量。如果选择该路由，请注意，应该对HTTPS使用TCP负载平衡。如果您使用TLS终止（HTTPS负载平衡），则将无法使用用户提供的证书来提供页面。对于HTTP，可以使用HTTP或TCP负载平衡。</li></ul><h1 id="先决条件"><a href="#先决条件" class="headerlink" title="先决条件"></a>先决条件</h1><p>在进行页面配置之前，您需要：</p><ul><li>具有用于服务GitLab页面的专有根域。请注意，您不能使用GitLab实例域的子域。</li><li>配置通配符DNS记录。</li><li>（可选）如果您决定在HTTPS下提供Pages，则应具有该域的通配符证书。</li><li>（可选，但建议使用）启用共享运行器， 以便您的用户不必自己携带。</li><li>（仅用于自定义域）具有辅助IP。</li></ul><h2 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h2><p>GitLab页面希望在其自己的虚拟主机上运行。在您的DNS服务器/提供程序中，您需要添加通配符DNS A记录，该记录指向GitLab运行的主机。</p><p>例如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*.pages.gitlab.com. 1800 IN A    192.168.1.30</span><br></pre></td></tr></table></figure><h2 id="通配符域"><a href="#通配符域" class="headerlink" title="通配符域"></a>通配符域</h2><p>要求：配置DNS</p><p>网址示例：http://<namespace>.pages.gitlab.com/<project></p><p>这是可以与Pages一起使用的最低设置。如下所述，它是所有其他设置的基础。NGINX将把所有请求代理到守护程序。Pages守护程序不收听外界。</p><ul><li>设置GitLab页面的外部URL ：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim &#x2F;etc&#x2F;gitlab&#x2F;gitlab.rb</span><br><span class="line">添加一行</span><br><span class="line">pages_external_url &#39;http:&#x2F;&#x2F;pages.gitlab.com&#39;</span><br></pre></td></tr></table></figure><ul><li>重新配置gitlab</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gitlab-ctl reconfigure</span><br></pre></td></tr></table></figure><h2 id="具有TLS支持的通配域"><a href="#具有TLS支持的通配域" class="headerlink" title="具有TLS支持的通配域"></a>具有TLS支持的通配域</h2><p>要求：配置DNS、配置通配符SSL证书</p><p>网址示例：https://<namespace>.pages.gitlab.com/<project></p><p>NGINX将把所有请求代理到守护程序。Pages守护程序不收听外界。</p><ul><li>将证书和密钥放在 /etc/gitlab/ssl 目录下</li><li>在/etc/gitlab/gitlab.rb指定以下配置：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">vim &#x2F;etc&#x2F;gitlab&#x2F;gitlab.rb</span><br><span class="line"></span><br><span class="line">pages_external_url &#39;https:&#x2F;&#x2F;pages.gitlab.com&#39;</span><br><span class="line"></span><br><span class="line">pages_nginx[&#39;redirect_http_to_https&#39;] &#x3D; true</span><br><span class="line">pages_nginx[&#39;ssl_certificate&#39;] &#x3D; &quot;&#x2F;etc&#x2F;gitlab&#x2F;ssl&#x2F;pages-nginx.crt&quot;</span><br><span class="line">pages_nginx[&#39;ssl_certificate_key&#39;] &#x3D; &quot;&#x2F;etc&#x2F;gitlab&#x2F;ssl&#x2F;pages-nginx.key&quot;</span><br></pre></td></tr></table></figure><p>其中pages-nginx.crt和pages-nginx.key分别是SSL证书和密钥。</p><ul><li>重新配置gitlab</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gitlab-ctl reconfigure</span><br></pre></td></tr></table></figure><h1 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h1><p>不管配置http或https，下面的步骤都可以完成</p><h2 id="创建一个项目"><a href="#创建一个项目" class="headerlink" title="创建一个项目"></a>创建一个项目</h2><p>pages-test </p><p>添加3个文件<br>index.html 、LICENSE、<br>.gitlab-ci.yml </p><ul><li>index.html <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;&#x2F;head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h1&gt;hello world&lt;&#x2F;h1&gt;</span><br><span class="line">&lt;&#x2F;body&gt;</span><br><span class="line">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure></li><li>LICENSE</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">MIT License</span><br><span class="line"></span><br><span class="line">Copyright (c) 2020 chenyu</span><br><span class="line"></span><br><span class="line">Permission is hereby granted, free of charge, to any person obtaining a copy</span><br><span class="line">of this software and associated documentation files (the &quot;Software&quot;), to deal</span><br><span class="line">in the Software without restriction, including without limitation the rights</span><br><span class="line">to use, copy, modify, merge, publish, distribute, sublicense, and&#x2F;or sell</span><br><span class="line">copies of the Software, and to permit persons to whom the Software is</span><br><span class="line">furnished to do so, subject to the following conditions:</span><br><span class="line"></span><br><span class="line">The above copyright notice and this permission notice shall be included in all</span><br><span class="line">copies or substantial portions of the Software.</span><br><span class="line"></span><br><span class="line">THE SOFTWARE IS PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR</span><br><span class="line">IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,</span><br><span class="line">FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE</span><br><span class="line">AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER</span><br><span class="line">LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,</span><br><span class="line">OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE</span><br><span class="line">SOFTWARE.</span><br></pre></td></tr></table></figure><ul><li>.gitlab-ci.yml</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">pages:</span><br><span class="line">    stage: deploy</span><br><span class="line">    script:</span><br><span class="line">    - mkdir .public</span><br><span class="line">    - cp -r * .public</span><br><span class="line">    - mv .public public</span><br><span class="line">    artifacts:</span><br><span class="line">        paths:</span><br><span class="line">        - public</span><br><span class="line">    only:</span><br><span class="line">    - master</span><br></pre></td></tr></table></figure><h2 id="配置一个gitlab-runner"><a href="#配置一个gitlab-runner" class="headerlink" title="配置一个gitlab runner"></a>配置一个gitlab runner</h2><p>可以看之前一篇文章，这里不细讲</p><h2 id="合并代码触发gitlab-ci"><a href="#合并代码触发gitlab-ci" class="headerlink" title="合并代码触发gitlab-ci"></a>合并代码触发gitlab-ci</h2><p>ci跑完后，可以在gitlab的setting &gt; pages 看到页面</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Pages</span><br><span class="line">With GitLab Pages you can host your static websites on GitLab. Combined with the power of GitLab CI and the help of GitLab Runner you can deploy static pages for your individual projects, your user or your group.</span><br><span class="line"></span><br><span class="line">Access pages</span><br><span class="line">Your pages are served under:</span><br><span class="line"></span><br><span class="line">http:&#x2F;&#x2F;rugod.pages.gitlab.com&#x2F;pages-test</span><br></pre></td></tr></table></figure><p>本机测试</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">curl http:&#x2F;&#x2F;rugod.pages.gitlab.com&#x2F;pages-test&#x2F;</span><br><span class="line"></span><br><span class="line">&lt;html&gt;</span><br><span class="line">&lt;head&gt;</span><br><span class="line">&lt;&#x2F;head&gt;</span><br><span class="line">&lt;body&gt;</span><br><span class="line">&lt;h1&gt;hello world&lt;&#x2F;h1&gt;</span><br><span class="line">&lt;&#x2F;body&gt;</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>至此，Gitlab-Pages部署完成，也做了一个小测验完成。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://docs.gitlab.com/ee/administration/pages/" target="_blank" rel="noopener">GitLab页面管理</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> 跟我学Devops </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Gitlab </tag>
            
            <tag> CI/CD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维手册——解决Nginx504问题</title>
      <link href="2020/10/12/bug/nginx-504/"/>
      <url>2020/10/12/bug/nginx-504/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近开发反馈业务功能经常出现504 gateway。我问这个现象持续了多久，开发说从我进公司前就有了，只是最近特别不稳定，一起来看看问题吧。</p><p>先科普一下504出现的情况</p><h1 id="百度504错误解释"><a href="#百度504错误解释" class="headerlink" title="百度504错误解释"></a>百度504错误解释</h1><p>504错误代表网关超时 （Gateway timeout），是指服务器作为网关或代理，但是没有及时从上游服务器收到请求。</p><p>服务器（不一定是 Web 服务器）正在作为一个网关或代理来完成客户（如您的浏览器或我们的 CheckUpDown 机器人）访问所需网址的请求。 为了完成您的 HTTP 请求， 该服务器访问一个上游服务器， 但没得到及时的响应。</p><p>这通常意味着上游服务器已关闭（不响应网关 / 代理），而不是上游服务器和网关/代理在交换数据的协议上不一致。<br>正常情况下，是由于被请求服务器发送超时引起。504错误代表网关超时 （Gateway timeout），是指服务器作为网关或代理，但是没有及时从上游服务器收到请求。</p><p>服务器（不一定是 Web 服务器）正在作为一个网关或代理来完成客户（如您的浏览器或我们的 CheckUpDown 机器人）访问所需网址的请求。 为了完成您的 HTTP 请求， 该服务器访问一个上游服务器， 但没得到及时的响应。<br>这通常意味着上游服务器已关闭（不响应网关 / 代理），而不是上游服务器和网关/代理在交换数据的协议上不一致。</p><p>正常情况下，是由于被请求服务器发送超时引起。</p><h1 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h1><p>目前现状是业务的一个功能需要调用一个接口，经常http状态码返回504，不过也有成功的时候，大概看了一下，成功的返回时长都是在60s以内，超过60s就会返回504</p><h1 id="分析问题"><a href="#分析问题" class="headerlink" title="分析问题"></a>分析问题</h1><p>我google了一下这种情况，给出的信息就是</p><p>60s是nginx默认转发请求的等待超时时间</p><p>主要有以下3个参数</p><p>proxy_connect_timeout :后端服务器连接的超时时间_发起握手等候响应超时时间</p><p>proxy_read_timeout:连接成功后_等候后端服务器响应时间_其实已经进入后端的排队之中等候处理（也可以说是后端服务器处理请求的时间）</p><p>proxy_send_timeout :后端服务器数据回传时间_就是在规定时间之内后端服务器必须传完所有的数据</p><p>nginx使用proxy模块时，默认的读取超时时间是60s。</p><p>然后一看服务器的nginx，没有这几个参数</p><h1 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h1><p>原配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">location &#x2F; &#123;</span><br><span class="line">proxy_pass  http:&#x2F;&#x2F;a.com;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>改为</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">location &#x2F; &#123;</span><br><span class="line">proxy_pass  http:&#x2F;&#x2F;a.com;</span><br><span class="line">proxy_connect_timeout 300s;</span><br><span class="line">proxy_send_timeout 300s;</span><br><span class="line">proxy_read_timeout 300s;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>将时长设置为5分钟</p><p>重启nginx</p><p>再测试，5分钟内的请求没有出现之前的现象了</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这个问题改完后我总觉得哪里不对，后面又看了网上的一些评论我才明白我的感觉在哪里</p><p>摘自网上的一个评论</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1. 优化业务代码</span><br><span class="line"></span><br><span class="line">一个接口调用超过一分钟，一定有可以优化的地方，看看数据库或者接口的调用是否合理，是否可以合并请求。</span><br><span class="line"></span><br><span class="line">2. 修改Nginx的服务器配置</span><br><span class="line"></span><br><span class="line">如果实在是优化不了了，可以把Nginx的超时时间上调。</span><br></pre></td></tr></table></figure><p>一个接口调用超过一分钟，一定有可以优化的地方</p><p>确实，我点击主页的某个按钮调用这个功能的时候特别慢，大概1、2分钟的样子</p><p>问了开发，开发说这个接口是同步的，如果改成异步就不会有这个问题，而且这个接口是内部人员才会点，没时间改也没有必要改。</p><p>好吧，这开发优化不了的任务只能让运维来做，心累</p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> SLB </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operation Manual </tag>
            
            <tag> Nginx </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>个人总结(2020.9)</title>
      <link href="2020/10/12/summary/summary-2020-9/"/>
      <url>2020/10/12/summary/summary-2020-9/</url>
      
        <content type="html"><![CDATA[<h1 id="个人能力价值的体现"><a href="#个人能力价值的体现" class="headerlink" title="个人能力价值的体现"></a>个人能力价值的体现</h1><p>1个月的调整，给公司创造了如下价值</p><ul><li>将公司的服务器永久（注意是永久）减少接近3500美金/月</li><li>打造(一个按钮即可发布代码到生产环境)</li><li>Mysql/Redis迁云</li><li>梳理服务器/数据库/S3/route53/nginx/ssl证书相关信息</li><li>处理若干之前生产环境一直存在的重大问题</li><li>设计新办公场地网络拓扑图、机房装修、设备购买方案，宽带、VPN业务办理</li></ul><h1 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h1><p>恶补HTTPS/Docker/Harbor/SSL/TCP原理</p><p>学习AWS CLI及AWS EKS/ECS/ECR/VPC/RDS/等组件</p><h1 id="心态"><a href="#心态" class="headerlink" title="心态"></a>心态</h1><p>这个月出现了很多生产问题，我慢慢发现自己还有很多不足，特别在解决很多问题的时候，发现自己很多原理不会，经验也不够老道，走了太多弯路。</p><p>但是这个过程锻炼了我沉稳的心态。</p><p>让我在做任何一件事，执行任何一条命令时都会好好想想这个事情的后果，没有以前那么急躁。</p><p>有几次特别关键的事故我处理格外冷静，最后无一例外全部解决。</p><h1 id="对自己说"><a href="#对自己说" class="headerlink" title="对自己说"></a>对自己说</h1><p>RUGOD，你离成为一个合格的SRE又近了一大步</p><p>单人通关各个副本，查攻略，一步一步升级的过程真的特别充实</p><p>特别是当你进入城镇，那么多人对着你豪华的装备投来羡慕的眼光时，那种滋味真好</p><p>继续加油吧</p><p>争做团队的MVP</p>]]></content>
      
      
      <categories>
          
          <category> 个人总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 个人总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维手册——解决Harbor镜像传输TLS超时的问题</title>
      <link href="2020/10/11/bug/harbor-pull/"/>
      <url>2020/10/11/bug/harbor-pull/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>在设计自动化流水线我采取了经典的jenkins+harbor组合，但是在自动部署的流程中，服务器自动拉取镜像经常报错超时。</p><h1 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h1><p>目前有2段网络地址做了VPN对等连接(上行下行带宽均为25M)</p><p>AWS：172.31.0.0/16</p><p>内网：192.168.0.0/16</p><p>harbor在内网 </p><p>服务器在AWS上</p><p>目前服务器拉取镜像经常出现2种报错</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker login -u admin -p Harbor12345 https:&#x2F;&#x2F;harbor.com</span><br><span class="line">Error response from daemon: Get https:&#x2F;&#x2F;harbor.com&#x2F;v2&#x2F;: net&#x2F;http: request canceled (Client.Timeout exceeded while awaiting headers)</span><br><span class="line">docker pull  https:&#x2F;&#x2F;harbor.com&#x2F;jdk8&#x2F;demo:1.0.0</span><br><span class="line">Error response from daemon: Get https:&#x2F;&#x2F;harbor.com&#x2F;v2&#x2F;: net&#x2F;http: TLS handshake timeout</span><br></pre></td></tr></table></figure><p>更有甚者出现了如下情况</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">docker login -u admin -p Harbor12345 https:&#x2F;&#x2F;harbor.com</span><br><span class="line">WARNING! Using --password via the CLI is insecure. Use --password-stdin.</span><br><span class="line">WARNING! Your password will be stored unencrypted in &#x2F;root&#x2F;.docker&#x2F;config.json.</span><br><span class="line">Configure a credential helper to remove this warning. See</span><br><span class="line">https:&#x2F;&#x2F;docs.docker.com&#x2F;engine&#x2F;reference&#x2F;commandline&#x2F;login&#x2F;#credentials-store</span><br><span class="line"></span><br><span class="line">Login Succeeded</span><br><span class="line"></span><br><span class="line">docker pull  https:&#x2F;&#x2F;harbor.com&#x2F;jdk8&#x2F;demo:1.0.0</span><br><span class="line">Error response from daemon: Get https:&#x2F;&#x2F;harbor.com&#x2F;v2&#x2F;: net&#x2F;http: TLS handshake timeout</span><br><span class="line"></span><br><span class="line">docker pull  https:&#x2F;&#x2F;harbor.com&#x2F;jdk8&#x2F;demo:1.0.0</span><br><span class="line">1.0.0: Pulling from jdk8&#x2F;demo</span><br><span class="line">7595c8c21622: Already exists </span><br><span class="line">d13af8ca898f: Already exists </span><br><span class="line">70799171ddba: Already exists </span><br><span class="line">b6c12202c5ef: Already exists </span><br><span class="line">8374bff0d446: Already exists </span><br><span class="line">1514e412e368: Already exists </span><br><span class="line">d075d688d4bc: Already exists </span><br><span class="line">d3f2f6381e9b: Already exists </span><br><span class="line">61ef965b4675: Already exists </span><br><span class="line">c5307cd0b1a1: Already exists </span><br><span class="line">2e108958a480: Downloading [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;                            ]  97.76MB&#x2F;221.6MB</span><br><span class="line">2cb827909bfb: Download complete </span><br><span class="line">6f58b1e62713: Downloading [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;                                             ]  19.55MB&#x2F;179.2MB</span><br><span class="line">Error response from daemon: Get https:&#x2F;&#x2F;harbor.com&#x2F;v2&#x2F;: net&#x2F;http: TLS handshake timeout</span><br></pre></td></tr></table></figure><p>WTF，还能这样？</p><p>我在内网的其他服务器执行docker login docker pull 一点问题都没有</p><p>难道是只是因为网络原因吗</p><p>下面开始介绍我的排坑之旅</p><h1 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h1><p>google此类问题大多都是服务器直接拉取docker镜像默认从docker hub中拉取的，然后因为防火墙和网络原因，拉取速度慢造成超时，大多处理结果是换镜像源。</p><p>这种千篇一律治标不治本的答案对我这种场景没有什么帮助，我也不可能把镜像上传到公有源</p><p>还是继续查找这个原因吧。</p><h2 id="从网络入手"><a href="#从网络入手" class="headerlink" title="从网络入手"></a>从网络入手</h2><p>我试了很多次docker pull，终于有一次成功，在此期间我查看在整个镜像传输过程中的网络带宽监控图</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Harbor/network-up1.png"  alt="network-up1.png"></p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Harbor/network-up2.png"  alt="network-up2.png"></p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Harbor/network-up3.png"  alt="network-up3.png"></p><p>我发现在这个正常传输的过程中，镜像上传会将VPN上行带宽几乎占满了(上限是25M)</p><p>带宽协议类型ssl占用是那段时间最多的</p><p>传输镜像时间约为3分钟</p><p>我在想是不是因为网络堵塞的时候，连接中断了。。。</p><p>这个时候带宽立马降下去了，但是docker login 还是报错tls超时</p><p>我纳闷了，现在也没有人占用VPN的带宽啊，为什么还是这样</p><h2 id="从VPN入手"><a href="#从VPN入手" class="headerlink" title="从VPN入手"></a>从VPN入手</h2><p>我又想到了可不可能因为VPN的HTTPS的策略有问题</p><p>查了下深信服的VPN协议</p><p>AWS和内网的VPN协议叫做：丢包补偿TCP</p><p>并且协议中添加了HTTPS的加速功能</p><p>不太了解这种协议，google也找不到相关说明</p><h3 id="测试TCP协议"><a href="#测试TCP协议" class="headerlink" title="测试TCP协议"></a>测试TCP协议</h3><p>我找到了一个时间段，这个时候正好服务器docker login超时</p><p>我试了下mysql连接，我在内网的一台服务器给AWS的Mysql里写入一个循环插入的语句，在测试过程中一直尝试docker login均超时，但是数据能正常插入。</p><p>Mysql-client连接走的是tcp协议</p><p>https也是基于tcp协议</p><p>这个时候我让研发测试业务之间传输（rpc协议），也能正常发送请求</p><p>那说明就是这个SSL的问题了</p><p>至此我已经确定了在VPN正常、TCP协议正常的情况</p><p>SSL连接超时</p><h3 id="咨询VPN售后"><a href="#咨询VPN售后" class="headerlink" title="咨询VPN售后"></a>咨询VPN售后</h3><p>调试无果后我只能打电话咨询深信服技术支持</p><p>这时候说一句，深信服售后真的会推皮球。直接把这个问题推给电信，因为VPN实质也是用的电信专线加速的，经常丢包很正常</p><p>我就告诉他，在这段时间VPN是正常的，并且应用的服务之间调用(RPC)并没有中断，只有https协议是出现了若干次连接超时的问题</p><p>最后深信服就一直转移话题说是因为专线不稳定云云</p><p>把我气的</p><p>算了</p><p>还是自己解决</p><p>问了他关于丢包补偿TCP的问题也爱答不理</p><p>国内最牛的VPN厂商就这？</p><p>太牛了</p><h2 id="从Harbor出发"><a href="#从Harbor出发" class="headerlink" title="从Harbor出发"></a>从Harbor出发</h2><p>我这个时候开始怀疑是不是只是Harbor出了问题</p><p>重启Harbor后，还是会出现这种情况</p><p>于是重新看看Harbor的架构</p><p><a href="https://github.com/goharbor/harbor/wiki/Architecture-Overview-of-Harbor" target="_blank" rel="noopener">Architecture Overview of Harbor</a></p><p>由于过于复杂，我只截取其中docker login发生的过程</p><h3 id="docker-login过程"><a href="#docker-login过程" class="headerlink" title="docker login过程"></a>docker login过程</h3><p>假设将Harbor部署在IP为192.168.1.10的主机上。用户运行docker命令将登录请求发送到Harbor：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker login 192.168.1.10</span><br></pre></td></tr></table></figure><p>用户输入所需的凭证后，Docker客户端将HTTP GET请求发送到地址“ 192.168.1.10/v2/”。Harbor的不同容器将按照以下步骤进行处理：</p><ul><li>首先，代理容器在端口80上侦听此请求。该容器中的Nginx将请求转发到后端的Registry容器。</li><li>注册表容器已配置为基于令牌的身份验证，因此它返回错误代码401，通知Docker客户端从指定的URL获取有效的令牌。在Harbor中，此URL指向核心服务的令牌服务；</li><li>当Docker客户端收到此错误代码时，它将根据HTTP规范的基本身份验证将请求发送到令牌服务URL，并将用户名和密码嵌入请求标头中；</li><li>在此请求通过端口80发送到代理容器之后，Nginx根据预先配置的规则再次将请求转发到UI容器。UI容器中的令牌服务接收请求，将请求解码并获取用户名和密码；</li><li>获得用户名和密码后，令牌服务将检查数据库并通过MySql中的数据对用户进行身份验证。将令牌服务配置为进行LDAP / AD身份验证时，它将针对外部LDAP / AD服务器进行身份验证。成功认证之后，令牌服务将返回指示成功的HTTP代码。HTTP响应主体包含由私钥生成的令牌。</li></ul><p>如下图所示</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Harbor/harbor-the-process-of-docker-login.png"  alt="network-up3.png"></p><p>用通俗易懂的话来说，docker login harbor是一个二次请求的过程</p><ul><li>第一次请求：docker向registry发起请求，由于registry是基于token auth的，因此registry回复应答，告诉docker client去哪个URL去获取token；<br>docker client根据应答中的URL向token service(ui)发起请求，通过user和passwd获取token<br>如果user和passwd在db中通过了验证，那么token service将用自己的私钥(harbor/common/config/ui/private_key.pem)生成一个token，返回给docker client端；</li><li>第二次请求：docker client获得token后再向registry发起login请求，registry用自己的证书(harbor/common/config/registry/root.crt)对token进行校验。通过则返回成功，docker client 端接收到返回的200状态码并在控制台上打印Login Succeeded的信息，否则返回失败。</li></ul><h3 id="docker-push的过程"><a href="#docker-push的过程" class="headerlink" title="docker push的过程"></a>docker push的过程</h3><p>用户成功登录后，将通过Docker Push命令将Docker映像发送到Harbor</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker push 192.168.1.10&#x2F;library&#x2F;hello-world</span><br></pre></td></tr></table></figure><ul><li><p>首先，docker客户端通过将请求发送到注册表来重复类似于登录的过程，然后取回令牌服务的URL；</p></li><li><p>随后，在联系令牌服务时，Docker客户端会提供其他信息，以申请对映像进行推送操作的令牌（库/ hello-world）；</p></li><li><p>在收到Nginx转发的请求之后，令牌服务查询数据库以查找用户的角色和允许推送镜像的权限。如果用户拥有适当的权限，它将对推送操作的信息进行编码，并使用私钥对其进行签名，并为Docker客户端生成令牌；</p></li><li><p>Docker客户端获取令牌后，它将带有包含令牌的标头的推送请求发送到注册表。注册管理机构收到请求后，将使用公共密钥对令牌进行解码并验证其内容。公钥对应于令牌服务的私钥。如果注册表发现可用于推送镜像的令牌，则镜像传输过程开始。</p></li></ul><h3 id="Harbor的结论"><a href="#Harbor的结论" class="headerlink" title="Harbor的结论"></a>Harbor的结论</h3><p>虽然Harbor给出的例子是docker login 和docker push </p><p>但是我认为docker pull也会和push的流程类似（经过登陆，验证权限，最后镜像传输）</p><p>这里面会有一点</p><p>即使我先docker login了，但是后面的docker pull仍然会有docker login的请求</p><p>以及docker pull中镜像传输过程中可能出现的网络抖动或者harbor的token过期的可能</p><p>初步判断是这个方面的原因</p><h2 id="从https出发"><a href="#从https出发" class="headerlink" title="从https出发"></a>从https出发</h2><p>harbor默认安装后采用的是http方式，后面使用的时候可能会发现很多不方面。因为Docker客户端登录harbor进行镜像推送或拉取时默认是https方式！所以http方式下，需要在每一台harbor客户端机器上都要设置”insecure-registries”, 感觉很麻烦！所以最好还是将harbor默认的http方式改为https方式！另外，从安全角度考虑，容器的仓库在生产环境中往往也是需要被设定为https的方式</p><p>因为报错很明显是tls超时</p><p>其实我也不太懂https内部经过了什么，又要学习下https的知识</p><h3 id="https通信过程"><a href="#https通信过程" class="headerlink" title="https通信过程"></a>https通信过程</h3><p>HTTPS协议 = HTTP协议 + SSL/TLS协议，在HTTPS数据传输的过程中，需要用SSL/TLS对数据进行加密和解密，需要用HTTP对加密后的数据进行传输，由此可以看出HTTPS是由HTTP和SSL/TLS一起合作完成的。</p><p>SSL的全称是Secure Sockets Layer，即安全套接层协议，是为网络通信提供安全及数据完整性的一种安全协议。</p><p>TLS的全称是Transport Layer Security，即安全传输层协议，最新版本的TLS（Transport Layer Security，传输层安全协议）是IETF（Internet Engineering Task Force，Internet工程任务组）制定的一种新的协议，它建立在SSL 3.0协议规范之上，是SSL 3.0的后续版本。在TLS与SSL3.0之间存在着显著的差别，主要是它们所支持的加密算法不同，所以TLS与SSL3.0不能互操作。虽然TLS与SSL3.0在加密算法上不同，但是在我们理解HTTPS的过程中，我们可以把SSL和TLS看做是同一个协议。</p><p>HTTPS为了兼顾安全与效率，同时使用了对称加密和非对称加密。数据是被对称加密传输的，对称加密过程需要客户端的一个密钥，为了确保能把该密钥安全传输到服务器端，采用非对称加密对该密钥进行加密传输，总的来说，对数据进行对称加密，对称加密所要使用的密钥通过非对称加密传输。</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Harbor/https.png"  alt="network-up3.png"></p><p>HTTPS在传输的过程中会涉及到三个密钥：</p><p>服务器端的公钥和私钥，用来进行非对称加密</p><p>客户端生成的随机密钥，用来进行对称加密</p><p>一个HTTPS请求实际上包含了两次HTTP传输，可以细分为8步。</p><p>1.客户端向服务器发起HTTPS请求，连接到服务器的443端口</p><p>2.服务器端有一个密钥对，即公钥和私钥，是用来进行非对称加密使用的，服务器端保存着私钥，不能将其泄露，公钥可以发送给任何人。</p><p>3.服务器将自己的公钥发送给客户端。</p><p>4.客户端收到服务器端的证书之后，会对证书进行检查，验证其合法性，如果发现发现证书有问题，那么HTTPS传输就无法继续。严格的说，这里应该是验证服务器发送的数字证书的合法性，关于客户端如何验证数字证书的合法性，下文会进行说明。如果公钥合格，那么客户端会生成一个随机值，这个随机值就是用于进行对称加密的密钥，我们将该密钥称之为client key，即客户端密钥，这样在概念上和服务器端的密钥容易进行区分。然后用服务器的公钥对客户端密钥进行非对称加密，这样客户端密钥就变成密文了，至此，HTTPS中的第一次HTTP请求结束。</p><p>5.客户端会发起HTTPS中的第二个HTTP请求，将加密之后的客户端密钥发送给服务器。</p><p>6.服务器接收到客户端发来的密文之后，会用自己的私钥对其进行非对称解密，解密之后的明文就是客户端密钥，然后用客户端密钥对数据进行对称加密，这样数据就变成了密文。</p><p>7.然后服务器将加密后的密文发送给客户端。</p><p>8.客户端收到服务器发送来的密文，用客户端密钥对其进行对称解密，得到服务器发送的数据。这样HTTPS中的第二个HTTP请求结束，整个HTTPS传输完成。</p><h2 id="分析docker-pull-https-harbor-com"><a href="#分析docker-pull-https-harbor-com" class="headerlink" title="分析docker pull https:harbor.com"></a>分析docker pull https:harbor.com</h2><p>https的过程我也只是一知半解，后面会专门针对协议内容进行学习。</p><p>现在了解docker pull和https的基本原理后，我把这个过程分解成下面几步</p><ul><li>第一步获取URL</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">curl -v &quot;https:&#x2F;&#x2F;harbor.com&#x2F;v2&#x2F;&quot;</span><br><span class="line">&lt; HTTP&#x2F;2 401 </span><br><span class="line">&lt; content-type: application&#x2F;json; charset&#x3D;utf-8</span><br><span class="line">&lt; docker-distribution-api-version: registry&#x2F;2.0</span><br></pre></td></tr></table></figure><ul><li>第二步获取Token</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl -v &quot;https:&#x2F;&#x2F;harbor.com&#x2F;auth?service</span><br><span class="line"></span><br><span class="line">&#123;&quot;access_token&quot;:&quot;eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIs&#125;</span><br></pre></td></tr></table></figure><ul><li>第三步通过Token获取image下载配置</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">curl -v -H &quot;Accept: application&#x2F;vnd.docker.distribution.manifest.v2+json&quot; -H &quot;Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIs&quot; &quot;https:&#x2F;&#x2F;harbor.com&#x2F;v2&#x2F;acs-sample&#x2F;ubuntu&#x2F;manifests&#x2F;latest&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#123;</span><br><span class="line">   &quot;schemaVersion&quot;: 2,</span><br><span class="line">   &quot;mediaType&quot;: &quot;application&#x2F;vnd.docker.distribution.manifest.v2+json&quot;,</span><br><span class="line">   &quot;config&quot;: &#123;</span><br><span class="line">      &quot;mediaType&quot;: &quot;application&#x2F;octet-stream&quot;,</span><br><span class="line">      &quot;size&quot;: 3820,</span><br><span class="line">      &quot;digest&quot;: &quot;sha256:4791cda23dbc3d1c7a0491644ae1c819c7d24b516be95df79113119e0f073416&quot;</span><br><span class="line">   &#125;,</span><br><span class="line">   &quot;layers&quot;: [</span><br><span class="line">      &#123;</span><br><span class="line">         &quot;mediaType&quot;: &quot;application&#x2F;vnd.docker.image.rootfs.diff.tar.gzip&quot;,</span><br><span class="line">         &quot;size&quot;: 65699368,</span><br><span class="line">         &quot;digest&quot;: &quot;sha256:56eb14001cebec19f2255d95e125c9f5199c9e1d97dd708e1f3ebda3d32e5da7&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">         &quot;mediaType&quot;: &quot;application&#x2F;vnd.docker.image.rootfs.diff.tar.gzip&quot;,</span><br><span class="line">         &quot;size&quot;: 101415,</span><br><span class="line">         &quot;digest&quot;: &quot;sha256:7ff49c327d838cf14f7db33fa44f6057b7209298e9c03369257485a085e231df&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">         &quot;mediaType&quot;: &quot;application&#x2F;vnd.docker.image.rootfs.diff.tar.gzip&quot;,</span><br><span class="line">         &quot;size&quot;: 365,</span><br><span class="line">         &quot;digest&quot;: &quot;sha256:6e532f87f96dd5821006d02e65e7d4729a4e6957a34c3f4ec72046e221eb7c52&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">         &quot;mediaType&quot;: &quot;application&#x2F;vnd.docker.image.rootfs.diff.tar.gzip&quot;,</span><br><span class="line">         &quot;size&quot;: 681,</span><br><span class="line">         &quot;digest&quot;: &quot;sha256:3ce63537e70c2c250fbc41b5f04bfb31f445be4034effc4b4c513bf8899dfa0a&quot;</span><br><span class="line">      &#125;,</span><br><span class="line">      &#123;</span><br><span class="line">         &quot;mediaType&quot;: &quot;application&#x2F;vnd.docker.image.rootfs.diff.tar.gzip&quot;,</span><br><span class="line">         &quot;size&quot;: 686,</span><br><span class="line">         &quot;digest&quot;: &quot;sha256:a521f68c7946d409bc182c615aa77d7e89de0914f67b2c0ce9be9f4c8e27c949&quot;</span><br><span class="line">      &#125;</span><br><span class="line">   ]</span><br></pre></td></tr></table></figure><ul><li>第四步获取config开始传输</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -v -H &quot;Accept: application&#x2F;vnd.docker.distribution.manifest.v2+json&quot; -H &quot;Authorization: Bearer eyJ0eXAiOiJKV1QiLCJhbGciOiJSUzI1NiIs</span><br></pre></td></tr></table></figure><p>看harbor的registry和nginx的日志判断出在第三步重新请求的过程中出现了问题</p><p>那么问题来了，docker pull会发多次https请求，并且在建立镜像传输的时候是并发传输layers的</p><p>中途任何一个https超时的情况都会影响整个流程</p><h2 id="绝杀"><a href="#绝杀" class="headerlink" title="绝杀"></a>绝杀</h2><p>其实到这里我还是不能定位到底是哪个地方出了问题</p><p>这个时候我跟领导反馈了一下这个事</p><p>领导说可以看看证书是不是存在问题</p><p>继续google到了一些例子，和我这个很像</p><p>其中一个案例如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">项目部署上去之后之前HTTP访问正常，后来升级为https，刚升级的时候是正常访问的，之后就很频繁的出现不能访问，提示超时。</span><br><span class="line"></span><br><span class="line">证书是在百度SSL那边申请的免费证书，我司域名是http:&#x2F;&#x2F;xxx.com.cn这样的，当时给阿里提工单，发现SSL有问题，阿里给的建议是--如果真的想https访问，就购买他们的全球加速....不然可以开启ssl，建议不强制hppts，抓包结果说他们国际链路有问题，暂时无法解决。</span><br></pre></td></tr></table></figure><p>我发现我用的也是免费申请的证书，说不定也是这个链路有问题</p><h1 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h1><p>网上重新换了一个证书</p><p>替换证书</p><p>重启harbor</p><p>OK</p><p>观察近1个月，再也没有出现类似问题</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这个问题从发现到解决花了我3天左右，但是复盘这个问题花了我接近半个月，恶补了一下docker pull/harbor/https等知识，还是非常有收获的。</p><p>后面我会继续研究https的原理问题以及是如何抓包ssl的过程</p><p>感谢我的这个领导</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://tonybai.com/2017/06/15/fix-auth-fail-when-login-harbor-registry/" target="_blank" rel="noopener">解决登录Harbor Registry时鉴权失败的问题</a></p><p><a href="https://github.com/docker/for-win/issues/611" target="_blank" rel="noopener">Get https://registry-1.docker.io/v2/: net/http: request canceled while waiting for connection</a></p><p><a href="https://github.com/docker/for-win/issues/1534" target="_blank" rel="noopener">Client.Timeout exceeded while awaiting headers</a></p><p><a href="https://github.com/goharbor/harbor/issues/11243" target="_blank" rel="noopener">error authorizing context: authorization token required</a></p><p><a href="https://www.jianshu.com/p/14cd2c9d2cd2" target="_blank" rel="noopener">Https原理及流程</a></p>]]></content>
      
      
      <categories>
          
          <category> SSL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operation Manual </tag>
            
            <tag> Harbor </tag>
            
            <tag> Docker </tag>
            
            <tag> HTTPS </tag>
            
            <tag> SSL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跟我学Devops之工具篇（Jenkins）</title>
      <link href="2020/10/11/devops/devops-jenkins-1/"/>
      <url>2020/10/11/devops/devops-jenkins-1/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="jenkins简介"><a href="#jenkins简介" class="headerlink" title="jenkins简介"></a>jenkins简介</h1><p>Jenkins是一款开源 CI&amp;CD 软件，用于自动化各种任务，包括构建、测试和部署软件。</p><p>Jenkins 支持各种运行方式，可通过系统包、Docker 或者通过一个独立的 Java 程序。</p><p>Jenkins 是一个扩展性非常强的软件，其功能主要通过插件来扩展。</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><h2 id="系统要求"><a href="#系统要求" class="headerlink" title="系统要求"></a>系统要求</h2><h3 id="最低推荐配置"><a href="#最低推荐配置" class="headerlink" title="最低推荐配置:"></a>最低推荐配置:</h3><p>256MB可用内存</p><p>1GB可用磁盘空间(作为一个Docker容器运行jenkins的话推荐10GB)</p><p>为小团队推荐的硬件配置:</p><p>1GB+可用内存</p><p>50 GB+ 可用磁盘空间</p><h3 id="软件配置"><a href="#软件配置" class="headerlink" title="软件配置:"></a>软件配置:</h3><p>Java 8无论是Java运行时环境（JRE）还是Java开发工具包（JDK）都可以。</p><p>注意: 如果将Jenkins作为Docker 容器运行，这不是必需的</p><h2 id="物理机部署"><a href="#物理机部署" class="headerlink" title="物理机部署"></a>物理机部署</h2><h3 id="安装java"><a href="#安装java" class="headerlink" title="安装java"></a>安装java</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install -y java-1.8.0-openjdk</span><br><span class="line">yum install -y java-devel</span><br></pre></td></tr></table></figure><h3 id="安装jenkins"><a href="#安装jenkins" class="headerlink" title="安装jenkins"></a>安装jenkins</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">wget -O &#x2F;etc&#x2F;yum.repos.d&#x2F;jenkins.repo https:&#x2F;&#x2F;pkg.jenkins.io&#x2F;redhat-stable&#x2F;jenkins.repo</span><br><span class="line">rpm --import https:&#x2F;&#x2F;pkg.jenkins.io&#x2F;redhat-stable&#x2F;jenkins.io.key</span><br><span class="line">yum install jenkins -y</span><br><span class="line">systemctl start jenkins</span><br></pre></td></tr></table></figure><p>安装好后，jenkins的主目录位于/var/lib/jenkins，这也是jenkins用户的家目录。</p><ul><li>jenkins主程序：/usr/lib/jenkins/jenkins.war</li><li>jenkins配置文件：/etc/sysconfig/jenkins</li><li>jenkins启动脚本：/etc/init.d/jenkins</li><li>jenkins日志目录：/var/log/jenkins</li></ul><p>初始化见下面docker部署初始化过程</p><h2 id="docker部署"><a href="#docker部署" class="headerlink" title="docker部署"></a>docker部署</h2><h3 id="配置docker-hub镜像加速"><a href="#配置docker-hub镜像加速" class="headerlink" title="配置docker hub镜像加速"></a>配置docker hub镜像加速</h3><p>由于默认拉取的镜像是docker hub，下载速度比较慢，可以切换国内镜像源</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">vim &#x2F;etc&#x2F;docker&#x2F;daemon.json</span><br><span class="line">添加</span><br><span class="line">&#123;</span><br><span class="line">    &quot;registry-mirrors&quot;: [</span><br><span class="line">        &quot;https:&#x2F;&#x2F;1nj0zren.mirror.aliyuncs.com&quot;,</span><br><span class="line">        &quot;https:&#x2F;&#x2F;docker.mirrors.ustc.edu.cn&quot;,</span><br><span class="line">        &quot;http:&#x2F;&#x2F;f1361db2.m.daocloud.io&quot;,</span><br><span class="line">        &quot;https:&#x2F;&#x2F;registry.docker-cn.com&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure><table><thead><tr><th>镜像加速器</th><th>镜像加速器地址</th></tr></thead><tbody><tr><td>Docker 中国官方镜像</td><td><a href="https://registry.docker-cn.com" target="_blank" rel="noopener">https://registry.docker-cn.com</a></td></tr><tr><td>DaoCloud 镜像站</td><td><a href="http://f1361db2.m.daocloud.io" target="_blank" rel="noopener">http://f1361db2.m.daocloud.io</a></td></tr><tr><td>Azure 中国镜像</td><td><a href="https://dockerhub.azk8s.cn" target="_blank" rel="noopener">https://dockerhub.azk8s.cn</a></td></tr><tr><td>阿里云</td><td>https://<your_code>.mirror.aliyuncs.com 需要登陆</td></tr><tr><td>腾讯云</td><td>ttps://mirror.ccs.tencentyun.com</td></tr></tbody></table><h3 id="拉取最新最稳定的jenkins镜像"><a href="#拉取最新最稳定的jenkins镜像" class="headerlink" title="拉取最新最稳定的jenkins镜像"></a>拉取最新最稳定的jenkins镜像</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull jenkinsci&#x2F;blueocean</span><br></pre></td></tr></table></figure><h3 id="将jenkins数据挂载到存储卷"><a href="#将jenkins数据挂载到存储卷" class="headerlink" title="将jenkins数据挂载到存储卷"></a>将jenkins数据挂载到存储卷</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker volume create jenkins-data &#x2F;&#x2F; 创建一个自定义存储卷</span><br><span class="line">docker volume ls &#x2F;&#x2F; 查看所有存储卷</span><br><span class="line">docker volume inspect jenkins-data &#x2F;&#x2F; 查看指定存储卷详情信息</span><br></pre></td></tr></table></figure><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"> docker run -u root -d --name jenkins -p 8080:8080 -v &#x2F;data&#x2F;jenkins&#x2F;:&#x2F;var&#x2F;jenkins_home -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock    jenkinsci&#x2F;blueocean ;</span><br><span class="line"></span><br><span class="line">-p 容器的端口8080到主机上的端口8080</span><br><span class="line">-v 此目录映射到计算机本地文件系统上的目录</span><br><span class="line">&#x2F;var&#x2F;run&#x2F;docker.sock 表示Docker守护程序通过其监听的基于Unix的套接字。 该映射允许 jenkin容器与Docker守护进程通信， 如果 jenkins 容器需要实例化其他Docker容器，则该守护进程是必需的。</span><br></pre></td></tr></table></figure><h3 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h3><p>访问<a href="http://ip:8080" target="_blank" rel="noopener">http://ip:8080</a> 解锁密码</p><p>获取密码</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it jenkins bash</span><br><span class="line">cat &#x2F;var&#x2F;jenkins_home&#x2F;secrets&#x2F;initialAdminPassword</span><br></pre></td></tr></table></figure><p>如果自动安装Maven Integration失败可以手动下载</p><p><a href="http://updates.jenkins-ci.org/download/plugins/maven-plugin/2.14/maven-plugin.hpi" target="_blank" rel="noopener">maven-plugin.hpi</a></p><p>然后在插件管理-高级-上传插件 将下载好的文件添加</p><p>下面说几个常用的插件</p><ul><li>插件：只拉取仓库指定的目录</li></ul><p>插件名：Git Parameter Plug-In</p><p>在源码管理处，选中Git，填写远程仓库地址，授权凭证，拉取分支，然后再点击新增，选中：Sparse Checkout Paths，填写上要从仓库里拉取的目录名称即可</p><ul><li>插件：jenkins任务失败重新构建</li></ul><p>插件名：Naginator Plugin</p><p>安装Naginator+Plugin后，新建一个任务，在构建后操作 选择 “Retry build after failure”</p><p>勾中Rerun build for unstable builds as well as failures</p><p>Maximum number of successive failed builds填1次</p><ul><li>插件：dingtalk告警机器人</li></ul><p>插件名：DingTalk</p><p>安装DingTalk后在系统管理 &gt; 系统配置里配置钉钉机器人</p><p>在钉钉群里的智能群助手里添加一个自定义的机器人，把webhook填到jenkins里即可</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Devops/dingtalk.jpg"  alt="dingtalk.jpg"></p><p>最后在任务里引用这个机器人即可</p><ul><li>插件：远程进入服务器执行命令及文件传输</li></ul><p>插件名：Publish Over SSH</p><p>安装完成后可以在任务里的 构建或者构建后操作 选择send files or execute commands over ssh 这个步骤</p><p>然后输入你想执行的命令和传输的文件即可</p><h3 id="重启"><a href="#重启" class="headerlink" title="重启"></a>重启</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker restart &#123;CONTAINER ID&#125;</span><br></pre></td></tr></table></figure><h1 id="开始jenkins构建项目"><a href="#开始jenkins构建项目" class="headerlink" title="开始jenkins构建项目"></a>开始jenkins构建项目</h1><h2 id="java项目"><a href="#java项目" class="headerlink" title="java项目"></a>java项目</h2><p>通过jenkins帮助我们构建一个java项目，从代码到应用的过程</p><p>流水线设计</p><ul><li>拉gitlab分支代码  </li><li>maven构建打jar包 </li><li>dockerfile将jar包做成镜像  </li><li>推送到harbor仓库 </li><li>k8s拉取harbor仓库种的镜像 </li><li>helm部署到k8s上</li><li>钉钉通知相关人员发布正常/失败</li></ul><p>具体实际流程下期详细讲解</p><h2 id="npm项目"><a href="#npm项目" class="headerlink" title="npm项目"></a>npm项目</h2><p>流水线设计</p><ul><li>拉gitlab分支代码</li><li>npm打包</li><li>上传到s3/oss/具体服务器的路径</li><li>钉钉通知相关人员发布正常/失败</li></ul><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>至此，一个入门级的jenkins搭建完成，中途还是遇到了许多问题，在后面我会具体讲下实战的jenkins流水线部署过程。</p><h1 id="报错"><a href="#报错" class="headerlink" title="报错"></a>报错</h1><h2 id="脚本没权限执行"><a href="#脚本没权限执行" class="headerlink" title="脚本没权限执行"></a>脚本没权限执行</h2><p>这个是物理机安装jenkins需要注意的点，docker安装不需要注意这个问题</p><p>jenkins自动部署会用到shell命令，而物理机安装jenkins一般是jenkins用户启动的进程，使用root用户会避免遇到更多的问题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">$ vim &#x2F;etc&#x2F;sysconfig&#x2F;jenkins # 打开配置文件</span><br><span class="line">    $JENKINS_USER&#x3D;&quot;root&quot; # 修改$JENKINS_USER变量为root，并去掉当前行注释</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#修改Jenkins相关文件夹用户权限(必须修改)</span><br><span class="line">$ chown -R root:root &#x2F;var&#x2F;lib&#x2F;jenkins</span><br><span class="line">$ chown -R root:root &#x2F;var&#x2F;log&#x2F;jenkins</span><br><span class="line">$ chown -R root:root &#x2F;var&#x2F;cache&#x2F;jenkins</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#重启Jenkins服务并检查运行Jenkins的用户是否已经切换为root</span><br><span class="line">$ systemctl restart  jenkins</span><br></pre></td></tr></table></figure><h2 id="插件安装不了"><a href="#插件安装不了" class="headerlink" title="插件安装不了"></a>插件安装不了</h2><p>有些插件下载速度慢是因为在国外，或者是这个插件本身下载就慢</p><p>这个时候我们只需要在官网插件地址看并下载即可</p><ul><li>搜索：<a href="https://plugins.jenkins.io/" target="_blank" rel="noopener">https://plugins.jenkins.io/</a> </li><li>列表：<a href="https://updates.jenkins-ci.org/download/plugins/" target="_blank" rel="noopener">https://updates.jenkins-ci.org/download/plugins/</a></li></ul><p>在jenkins的插件管理 &gt; 高级 &gt; 上传.hpi来安装插件</p><h2 id="git报错"><a href="#git报错" class="headerlink" title="git报错"></a>git报错</h2><p>添加gitlab地址报错如下</p><p>Error performing git command: git ls-remote -h 请查看日志 请检查配置</p><p>如果Jenkins主服务器上未安装git，则可能会发生此错误。</p><p>在宿主机上执行yum install -y git即可</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://www.jenkins.io/zh/doc/book/installing/" target="_blank" rel="noopener">jenkins官方安装</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> 跟我学Devops </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Devops </tag>
            
            <tag> 自动化 </tag>
            
            <tag> CI/CD </tag>
            
            <tag> Jenkins </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>U盘安装Centos7</title>
      <link href="2020/10/11/linux/U-centos7-install/"/>
      <url>2020/10/11/linux/U-centos7-install/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="下载镜像并制作U盘启动盘"><a href="#下载镜像并制作U盘启动盘" class="headerlink" title="下载镜像并制作U盘启动盘"></a>下载镜像并制作U盘启动盘</h1><h2 id="下载centos镜像"><a href="#下载centos镜像" class="headerlink" title="下载centos镜像"></a>下载centos镜像</h2><p><a href="http://mirrors.aliyun.com/centos/7/isos/x86_64/CentOS-7-x86_64-DVD-2003.iso" target="_blank" rel="noopener">阿里源</a></p><h2 id="UItraISO（软碟通）制作"><a href="#UItraISO（软碟通）制作" class="headerlink" title="UItraISO（软碟通）制作"></a>UItraISO（软碟通）制作</h2><p>下载UItraISO</p><p><a href="https://cn.ultraiso.net/xiazai.html" target="_blank" rel="noopener">https://cn.ultraiso.net/xiazai.html</a></p><ul><li>安装完成后点击 试用</li><li>点击文件，选择打开centos的iso文件</li><li>插好U盘</li><li>点击顶部菜单中的 启动  选择 写入硬盘映像</li><li>硬盘驱动器选择你的U盘 ，写入方式 usb+hdd+</li><li>点击写入</li></ul><p>等待制作启动盘</p><h1 id="U盘引导"><a href="#U盘引导" class="headerlink" title="U盘引导"></a>U盘引导</h1><p>注意：如果直接在已经存在的系统上装盘可能会导致异常，建议用一块新的盘或者直接把现有的盘格式化，利用老毛桃或者其他PE系统先格式化磁盘</p><ul><li>把U盘插在电脑上</li><li>开机</li><li>一般按f12或者del进入bios界面设置U盘启动</li><li>进入以下画面请将光标选择install 然后按e进行编辑<br><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Centos/install.jpg"  alt="centos-install.jpg"></li></ul><ul><li>将“LABEL=Centos\x207\x20x\86_64 quiet”的”6_64”给删除 quiet前面加上nomodeset </li><li>操作后你的install信息如下： </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">inst.stage2&#x3D;hd:LABEL&#x3D;Centos\x207\x20x\8 nomodeset  quiet</span><br></pre></td></tr></table></figure><ul><li>按ctrl+x安装即可进入centos安装界面</li></ul><h1 id="安装centos"><a href="#安装centos" class="headerlink" title="安装centos"></a>安装centos</h1><ul><li>语言选择英文</li><li>时区选择中国上海</li><li>软件选择最小化安装</li><li>配置网络和主机名，固定一个ip并设置开机自动开启网络，根据你的实际场景来</li><li>磁盘分区 选择手动分区(I will configure partitioning)</li></ul><p>分区内容如下</p><table><thead><tr><th>目录</th><th>空间</th></tr></thead><tbody><tr><td>/boot</td><td>1024M</td></tr><tr><td>/boot/efi</td><td>200M</td></tr><tr><td>swap</td><td>2048M</td></tr><tr><td>/</td><td>剩余所有磁盘空间</td></tr></tbody></table><p>有的时候不需要分/boot/efi</p><ul><li>点击begin installation</li><li>配置root pswword</li></ul><p>等待</p><p>装好后重启即可进入centos了</p><h1 id="报错"><a href="#报错" class="headerlink" title="报错"></a>报错</h1><p>U盘启动时在install centos 7时报错</p><p>dracut-pre-udev[351]:modprobe :ERROR:could not insert ‘floppy’<br>dracut-pre-udev[351]:modprobe :ERROR:could not insert ‘edd’:No</p><p>网上找了很久</p><p>大部分说按e，修改inst.stage2=hd:LABEL=Centos\x207\x20x\86_64 quiet 为你真实U盘的设备名（/dev/sdc4或其他)</p><p>那怎么知道设备名呢</p><p>先将inst.stage2=hd:LABEL=Centos\x207\x20x\86_64 quiet改为</p><p>initrd=initrd.img linux dd quiet</p><p>按ctrl+x</p><p>可以进入主机设备界面，找到你现在的U盘的设备名</p><p>然后再重启，继续按e</p><p>修改inst.stage2=hd:LABEL=Centos\x207\x20x\86_64 quiet</p><p>为inst.stage2=hd:/dev/sdc4 quiet</p><p>按ctrl+x</p><p>即可进入centos安装页面</p><p>但是我这昨天按照这个方法试了很多次，都不行</p><p>网上还有说是centos7.6这个版本不行，我后来又做了个centos7.8的，还是不行</p><p>最后将inst.stage2=hd:LABEL=Centos\x207\x20x\86_64 quiet改成</p><p>inst.stage2=hd:LABEL=Centos\x207\x20x\8 nomodeset  quiet</p><p>按ctrl+x</p><p>才成功</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://www.jianshu.com/p/1e93011a78ec" target="_blank" rel="noopener">CentOS 7.6 1810版本无法进入安装界面</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Centos </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>SRE实战之独立解决生产级的业务调用链路问题</title>
      <link href="2020/10/11/sre/traceroute-bug/"/>
      <url>2020/10/11/sre/traceroute-bug/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近开发反馈公司服务器网络环境不稳定，服务器业务功能时好时坏。我问这个现象持续了多久，开发说从我进公司前就有了，只是最近特别不稳定，一起来看看问题吧。</p><h1 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h1><p>目前现象是前端页面点击某按钮的功能是卡时不卡</p><p>我先让开发定位有没有错误日志</p><p>开发看了业务日志后发现，后端代码调用hadoop后，hadoop的回调经常超时</p><p>那么很明显从hadoop开始找问题</p><h1 id="分析问题"><a href="#分析问题" class="headerlink" title="分析问题"></a>分析问题</h1><p>A调用B可以</p><p>B回调A不行</p><p>那么直接看看调用链的区别</p><p>我用链路追踪看了一下这个项目的调用链，如下图所示</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/DNS/traceroute_old.jpg"  alt="traceroute_old.jpg"></p><p>其实在之前的公司我遇到过这个问题，链路图画出来分析问题就一目了然</p><p>用户访问前端页面 &gt; 点击按钮 &gt; 请求后端接口https:a.com &gt; 这个地方用户的主机会做一次域名解析 &gt; 进入公司主路由器 &gt; Nginx &gt; 转发后端 &gt; 后端调用hadoop &gt; hadoop回调 </p><p>注意这个地方hadoop回调也是用的https:a.com</p><p>这个是公网的域名，回调一个内网的服务为什么还要从公网走一遭？</p><p>我当时问开发，开发说没有做内网dns，而且代码都是统一用一个接口</p><p>那么用公网的域名中间回让hadoop这台服务器再解析一次这个域名发送请求，而这台hadoop的网关正好是这个主路由器，那不就是相当于从主路由器出去，解析发现就是这个主路由器，然后又再请求进来，中间哪一步出现问题都会超时</p><p>然后我查看了nginx的日志，在超时的那段时间，nginx没有接收来自hadoop的回调请求，那么说明这个请求在中途因为某些原因不见了</p><h1 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h1><p>继续追究这个回调请求打不到nginx上的原因没有什么意义，直接开始解决问题吧</p><p>为此我提了3种实操方案</p><ul><li>直接改hadoop /etc/hosts文件强制指向后端（临时方法，目前也是用这个方法实现的）</li><li>建立一个内部的DNS服务器，在项目里分2种域名 前端调后端的还是走公网域名<a href="https://a.com" target="_blank" rel="noopener">https://a.com</a> 后端之间的内部调用都是用内网DNS解析的域名</li><li>加入服务注册中心，统一管理服务调用</li></ul><p>我认为终极方案肯定还是用注册中心，把服务之间的调用管理起来，但是由于历史原因，这个事情目前做不了，我只能通过改/etc/hosts强制指向后端</p><p>说到这个地方，当真是指向后端吗？其实应该指向nginx的服务器，因为后端调用的是<a href="https://a.com" target="_blank" rel="noopener">https://a.com</a> 还有证书呢</p><p>最后调用链切换至如下图所示</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/DNS/traceroute_new.png"  alt="traceroute_new.png"></p><p>后面我提建议让后端之间的调用采用rpc，都内网调用了还搞https干嘛呢</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>改进后持续跟踪半个月，再也没有出现超时的情况，并且后端处理速度大大提高</p><p>其实这个问题在我看来不应该出现，也许是因为团队当时写项目的时候没有考虑全面，导致了这种调用回路的事出现</p><p>但是时代变了</p><p>我加入了团队</p><p>这种问题我会逐渐处理掉。</p><p>争做团队的MVP！</p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Sre </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Sre </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维手册——Redis迁云问题总结</title>
      <link href="2020/09/23/bug/redis-migrate-rds/"/>
      <url>2020/09/23/bug/redis-migrate-rds/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>在自建Redis迁移到ElastiCache For Redis的过程中，发现一些问题，本文总结一下。</p><h1 id="加密传输"><a href="#加密传输" class="headerlink" title="加密传输"></a>加密传输</h1><p>创建ElastiCache For Redis需要开启密码验证</p><p>Redis刚刚建完，我用可视化工具连不上。</p><p>但是后来发现这个密码验证添加了传输中加密功能</p><h2 id="AWS官方解释"><a href="#AWS官方解释" class="headerlink" title="AWS官方解释"></a>AWS官方解释</h2><p>Redis 命令行界面 (redis-cli) 不支持启用 SSL 的客户端。</p><p>要使用 redis-cli 访问启用传输中加密功能的 ElastiCache for Redis 节点（已禁用集群模式），在您的基于 Linux 的客户端中使用 stunnel 包。stunnel 命令会创建一条 SSL 隧道，指向在 stunnel 配置中指定的 Redis 节点。在建立隧道以后，您可以使用 redis-cli 连接启用传输中加密功能的集群节点。</p><h2 id="AWS官方解决办法"><a href="#AWS官方解决办法" class="headerlink" title="AWS官方解决办法"></a>AWS官方解决办法</h2><h3 id="使用-SSH-连接到-Linux-客户端实例并安装-stunnel-包："><a href="#使用-SSH-连接到-Linux-客户端实例并安装-stunnel-包：" class="headerlink" title="使用 SSH 连接到 Linux 客户端实例并安装 stunnel 包："></a>使用 SSH 连接到 Linux 客户端实例并安装 stunnel 包：</h3><ul><li>在基于 CentOS 的系统上：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$sudo yum install stunnel</span><br></pre></td></tr></table></figure><ul><li>在基于 Debian 的系统上 (Ubuntu 16)：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$sudo apt-get install stunnel</span><br></pre></td></tr></table></figure><h3 id="在-redis-cli-conf-文件中，将-Redis-集群终端节点添加到一个或多个连接参数："><a href="#在-redis-cli-conf-文件中，将-Redis-集群终端节点添加到一个或多个连接参数：" class="headerlink" title="在 redis-cli.conf 文件中，将 Redis 集群终端节点添加到一个或多个连接参数："></a>在 redis-cli.conf 文件中，将 Redis 集群终端节点添加到一个或多个连接参数：</h3><p>vim  /etc/stunnel/redis-cli.conf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">fips &#x3D; no</span><br><span class="line">setuid &#x3D; root</span><br><span class="line">setgid &#x3D; root</span><br><span class="line">pid &#x3D; &#x2F;var&#x2F;run&#x2F;stunnel.pid</span><br><span class="line">debug &#x3D; 7</span><br><span class="line">options &#x3D; NO_SSLv2</span><br><span class="line">options &#x3D; NO_SSLv3</span><br><span class="line">[redis-cli]</span><br><span class="line">  client &#x3D; yes</span><br><span class="line">  accept &#x3D; 127.0.0.1:6379</span><br><span class="line">  connect &#x3D; master.ssltest.wif0lh.use1.cache.amazonaws.com:6379</span><br><span class="line">[redis-cli-replica]</span><br><span class="line">  client &#x3D; yes</span><br><span class="line">  accept &#x3D; 127.0.0.1:6380</span><br><span class="line">  connect &#x3D; ssltest-002.ssltest.wif0lh.use1.cache.amazonaws.com:6379</span><br></pre></td></tr></table></figure><p>在此示例中，配置文件有两个连接，redis-cli 和 redis-cli-replica。参数设置如下：</p><p>client 设置为 yes，以指定此 stunnel 实例是客户端。</p><p>accept 设置为客户端 IP。在此示例中，主连接设置为默认地址为 127.0.0.1，端口为 6379 的 Redis。副本必须调用不同端口，因而设置为 6380。您可以使用临时端口 1024 到 65535。</p><p>connect 设置为 Redis 服务器终端节点。有关更多信息，请参阅查找连接终端节点。</p><h3 id="开启stunnel。"><a href="#开启stunnel。" class="headerlink" title="开启stunnel。"></a>开启stunnel。</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ sudo stunnel &#x2F;etc&#x2F;stunnel&#x2F;redis-cli.conf</span><br><span class="line"></span><br><span class="line">使用 netstat 命令确认隧道已启动：</span><br><span class="line">$ netstat -tulnp | grep -i stunnel</span><br><span class="line">tcp    0      0 127.0.0.1:6379      0.0.0.0:*        LISTEN      3189&#x2F;stunnel</span><br><span class="line">tcp    0      0 127.0.0.1:6380      0.0.0.0:*        LISTEN      3189&#x2F;stunnel</span><br></pre></td></tr></table></figure><h3 id="redis-cli-通过隧道的本地终端节点连接到加密的-Redis-节点："><a href="#redis-cli-通过隧道的本地终端节点连接到加密的-Redis-节点：" class="headerlink" title="redis-cli 通过隧道的本地终端节点连接到加密的 Redis 节点："></a>redis-cli 通过隧道的本地终端节点连接到加密的 Redis 节点：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h localhost -p 6379 -a MySecretPassword</span><br><span class="line">localhost:6379&gt;set foo &quot;bar&quot;</span><br><span class="line">OK</span><br><span class="line">localhost:6379&gt;get foo</span><br><span class="line">&quot;bar&quot;</span><br></pre></td></tr></table></figure><p>此示例使用 telnet 连接到 Redis 服务器：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># telnet localhost 6379</span><br><span class="line">Trying 127.0.0.1...</span><br><span class="line">Connected to localhost.</span><br><span class="line">Escape character is &#39;^]&#39;.</span><br><span class="line">auth MySecretPassword</span><br><span class="line">+OKget foo</span><br><span class="line">$3</span><br><span class="line">bar</span><br></pre></td></tr></table></figure><h3 id="运行-pkill-命令以停止和关闭-SSL-隧道："><a href="#运行-pkill-命令以停止和关闭-SSL-隧道：" class="headerlink" title="运行 pkill 命令以停止和关闭 SSL 隧道："></a>运行 pkill 命令以停止和关闭 SSL 隧道：</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo pkill stunnel</span><br></pre></td></tr></table></figure><h1 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h1><h2 id="尝试按照官方的解决办法"><a href="#尝试按照官方的解决办法" class="headerlink" title="尝试按照官方的解决办法"></a>尝试按照官方的解决办法</h2><p>首先我在本机下了stunnel插件后，发现确实Redis-cli可以连接</p><p>但是项目还是连不了，报错</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">org.springframework.data.redis.connection.PoolException: Could not get a resource from the pool; nested exception is io.lettuce.core.RedisConnectionException: Unable to connect to master..cache.amazonaws.com:6379</span><br></pre></td></tr></table></figure><p>我想了下项目连接的原理，Spring-data-redis也是调Redis的API</p><p>抱着尝试的态度，在容器里下载了stunnel插件，然后java -jar重启发现可以连接了</p><p>太棒了，这样的话我就只用在Dockerfile里写好添加这个插件的步骤即可</p><p>等等，那么redis-cli.conf是不是应该跟着不同的环境更改不同的配置文件呢</p><p>想到这里我觉得制作Dockerfile也不能很好的解决这个问题</p><h2 id="AWS的SDK"><a href="#AWS的SDK" class="headerlink" title="AWS的SDK"></a>AWS的SDK</h2><p>看了下AWS的SDK介绍</p><p>可以用AWS的SDK去连接Redis</p><p>但是这样做有一个问题，万一我哪天不用AWS的Redis呢，那代码也要重新改。</p><h2 id="redisson和spring-data-redis"><a href="#redisson和spring-data-redis" class="headerlink" title="redisson和spring-data-redis"></a>redisson和spring-data-redis</h2><p>网上找了很久，突然看到一个人的问题和我很像。</p><p>但是他的项目用的软件包是Redisson</p><p>而我们用的是spring-data-Redis</p><p>Redisson的配置文件有个ssl：true</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  redis:</span><br><span class="line">    host: clustercfg.our-redis-instance-name.ssv2ov.use1.cache.amazonaws.com</span><br><span class="line">    port: 6379</span><br><span class="line">    password: ourRedisPassword</span><br><span class="line">    ssl: true</span><br><span class="line">    cluster:</span><br><span class="line">      nodes: node01.our-redis-instance-name.ssv2ov.use1.cache.amazonaws.com:6379,node02.our-redis-instance-name.ssv2ov.use1.cache.amazonaws.com:6379,node03.our-redis-instance-name.ssv2ov.use1.cache.amazonaws.com:6379</span><br></pre></td></tr></table></figure><p>同样找到了一个spring-data-redis的例子</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">JedisConnectionFactory conn &#x3D;  new JedisConnectionFactory();</span><br><span class="line">conn.setHostName(redisHost);</span><br><span class="line">conn.setPort(redisPort);</span><br><span class="line">conn.setUseSsl(true);</span><br></pre></td></tr></table></figure><h2 id="最简单的方法"><a href="#最简单的方法" class="headerlink" title="最简单的方法"></a>最简单的方法</h2><p>由于研发人员没时间看Redis-SDK的ssl功能，我又不太了解Java。导致最后我用运维层面的方法解决这个问题</p><p>就是不设密码</p><p>对，你没看错</p><p>就是不加密码</p><p>我把Redis连接的安全组控制到具体的内网IP即可</p><p>最后也是这样解决的</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>其实这个问题在后面我反思过，Redis应该还是要上密码的，即使Redis里没有存很敏感的信息，但是这不符合规范，后面只能让研发测试ssl加密的功能了。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://github.com/redisson/redisson/issues/2438" target="_blank" rel="noopener">Reddison AWS ElastiCache Redis群集连接问题 </a></p><p><a href="https://my.oschina.net/u/1249401/blog/820277" target="_blank" rel="noopener">MySql Host is blocked because of many connection errors; unblock with ‘mysqladmin flush-hosts’ </a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> Operation Manual </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维手册——服务器重启后加载不了文件系统</title>
      <link href="2020/09/17/bug/reboot-mount/"/>
      <url>2020/09/17/bug/reboot-mount/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>研发有需求跑3D程序，让我在一台服务器上装显卡驱动，结果重启的时候机器故障，加载不了文件系统</p><h1 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h1><p>装显卡驱动需要禁用Nouveau驱动、更新内核，然后重启</p><p>重启时，出现如下错误</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">GIVE root password for maintenance (or type control-D to continue)</span><br><span class="line">Login incorrct:</span><br><span class="line">Give root password for maintenance</span><br><span class="line">(or type Control-D to continue):</span><br></pre></td></tr></table></figure><p>google后发现 </p><p>当Linux系统被强行关闭或重新启动，电脑的档案系统便有可能受损，系统会自动检查并修复档案系统；但当档案系统未能自动修复，画面便会出现上述讯息。</p><h1 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h1><p>先输入root密码进入服务器</p><p>查看文件系统</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">df -hT</span><br><span class="line">Filesystem              Type      Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs                devtmpfs   16G     0   16G   0% &#x2F;dev</span><br><span class="line">tmpfs                   tmpfs      16G     0   16G   0% &#x2F;dev&#x2F;shm</span><br><span class="line">tmpfs                   tmpfs      16G  9.7M   16G   1% &#x2F;run</span><br><span class="line">tmpfs                   tmpfs      16G     0   16G   0% &#x2F;sys&#x2F;fs&#x2F;cgroup</span><br><span class="line">&#x2F;dev&#x2F;mapper&#x2F;centos-root xfs       1.8T  154G  1.7T   9% &#x2F;</span><br><span class="line">&#x2F;dev&#x2F;sda2               xfs      1014M  235M  780M  24% &#x2F;boot</span><br><span class="line">&#x2F;dev&#x2F;sda1               vfat      200M   12M  189M   6% &#x2F;boot&#x2F;efi</span><br></pre></td></tr></table></figure><p>查看硬盘设备及挂载配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[root@jenkins-harbor ~]# blkid </span><br><span class="line">&#x2F;dev&#x2F;mapper&#x2F;centos-root: UUID&#x3D;&quot;406eb28a-e11b-4361-b3eb-3244f895cbf9&quot; TYPE&#x3D;&quot;xfs&quot; </span><br><span class="line">&#x2F;dev&#x2F;sda3: UUID&#x3D;&quot;mULe6E-r4m5-3GYM-wgc2-VzxN-vomR-AP3neD&quot; TYPE&#x3D;&quot;LVM2_member&quot; PARTUUID&#x3D;&quot;fefb0fc6-b09b-4ea2-9f50-2601ce39fd62&quot; </span><br><span class="line">&#x2F;dev&#x2F;nvme0n1: PTTYPE&#x3D;&quot;gpt&quot; </span><br><span class="line">&#x2F;dev&#x2F;nvme0n1p1: UUID&#x3D;&quot;4292-32BD&quot; TYPE&#x3D;&quot;vfat&quot; PARTLABEL&#x3D;&quot;EFI System Partition&quot; PARTUUID&#x3D;&quot;b5ce22ae-35a1-4d6e-8e39-8e79c2bdf627&quot; </span><br><span class="line">&#x2F;dev&#x2F;nvme0n1p2: UUID&#x3D;&quot;d5993c22-3e0f-4cca-baca-8b41d65cf685&quot; TYPE&#x3D;&quot;ext4&quot; PARTUUID&#x3D;&quot;d0fb0bd8-f84a-44f8-b6cd-7eed306823d5&quot; </span><br><span class="line">&#x2F;dev&#x2F;nvme0n1p3: UUID&#x3D;&quot;2e9c7400-9214-4375-9818-ad5e94fbe3a6&quot; TYPE&#x3D;&quot;swap&quot; PARTUUID&#x3D;&quot;2980ef10-5cd2-4215-8e41-f6eff10d4c99&quot; </span><br><span class="line">&#x2F;dev&#x2F;sda1: SEC_TYPE&#x3D;&quot;msdos&quot; UUID&#x3D;&quot;54EC-FF86&quot; TYPE&#x3D;&quot;vfat&quot; PARTLABEL&#x3D;&quot;EFI System Partition&quot; PARTUUID&#x3D;&quot;fc41939c-89d6-4960-8cc7-d4895a06bf85&quot; </span><br><span class="line">&#x2F;dev&#x2F;sda2: UUID&#x3D;&quot;2a29efa6-1bfb-4299-bb75-fb4d2c769954&quot; TYPE&#x3D;&quot;xfs&quot; PARTUUID&#x3D;&quot;f78790e4-7d58-49d1-a714-05c0852449f4&quot; </span><br><span class="line">&#x2F;dev&#x2F;mapper&#x2F;centos-swap: UUID&#x3D;&quot;854cebfc-0956-4559-a20e-927580f29517&quot; TYPE&#x3D;&quot;swap&quot; </span><br><span class="line"></span><br><span class="line">[root@jenkins-harbor ~]# cat &#x2F;etc&#x2F;fstab</span><br><span class="line">#</span><br><span class="line"># &#x2F;etc&#x2F;fstab</span><br><span class="line"># Created by anaconda on Fri Aug 14 12:38:39 2020</span><br><span class="line">#</span><br><span class="line"># Accessible filesystems, by reference, are maintained under &#39;&#x2F;dev&#x2F;disk&#39;</span><br><span class="line"># See man pages fstab(5), findfs(8), mount(8) and&#x2F;or blkid(8) for more info</span><br><span class="line">#</span><br><span class="line">&#x2F;dev&#x2F;mapper&#x2F;centos-root &#x2F;                       xfs     defaults        0 0</span><br><span class="line">UUID&#x3D;2a29efa6-1bfb-4299-bb75-fb4d2c769954 &#x2F;boot                   xfs     defaults        0 0</span><br><span class="line">UUID&#x3D;54EC-FF86          &#x2F;boot&#x2F;efi               vfat    umask&#x3D;0077,shortname&#x3D;winnt 0 0</span><br><span class="line">UUID&#x3D;d276a0d4-c95f-4792-a222-6d1451899de2 &#x2F;home ext4    noatime,errors&#x3D;remount-ro 0 1</span><br><span class="line">&#x2F;dev&#x2F;mapper&#x2F;centos-swap swap                    swap    defaults        0 0</span><br></pre></td></tr></table></figure><p>起初我并没有发现有什么问题</p><p>然后查看开机时的系统日志</p><p>journalctl -xb</p><p>其中有这么一段报错</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">Sep 16 19:35:54 jenkins-harbor kernel: ACPI Error: [DSSP] Namespace lookup failure, AE_NOT_FOUND (20130517&#x2F;psargs-359)</span><br><span class="line">Sep 16 19:35:54 jenkins-harbor kernel: ACPI Error: Method parse&#x2F;execution failed [\_SB_.PCI0.SAT0.PRT4._GTF] (Node ffff900bf4b248d0), AE_NOT_</span><br><span class="line">Sep 16 19:35:54 jenkins-harbor kernel: ata5.00: ATA-10: WDC WD20EZAZ-00L9GB0, 80.00A80, max UDMA&#x2F;133</span><br><span class="line">Sep 16 19:35:54 jenkins-harbor kernel: ata5.00: 3907029168 sectors, multi 16: LBA48 NCQ (depth 31&#x2F;32), AA</span><br><span class="line">Sep 16 19:35:54 jenkins-harbor kernel: ACPI Error: [DSSP] Namespace lookup failure, AE_NOT_FOUND (20130517&#x2F;psargs-359)</span><br><span class="line">Sep 16 19:35:54 jenkins-harbor kernel: ACPI Error: Method parse&#x2F;execution failed [\_SB_.PCI0.SAT0.PRT4._GTF] (Node ffff900bf4b248d0), AE_NOT_</span><br><span class="line">Sep 16 19:35:54 jenkins-harbor kernel: ata5.00: configured for UDMA&#x2F;133</span><br><span class="line">Sep 16 19:35:54 jenkins-harbor kernel: scsi 4:0:0:0: Direct-Access     ATA      WDC WD20EZAZ-00L 0A80 PQ: 0 ANSI: 5</span><br><span class="line">Sep 16 19:35:54 jenkins-harbor kernel: sd 4:0:0:0: [sda] 3907029168 512-byte logical blocks: (2.00 TB&#x2F;1.81 TiB)</span><br><span class="line">Sep 16 19:35:54 jenkins-harbor kernel: sd 4:0:0:0: [sda] 4096-byte physical blocks</span><br><span class="line">Sep 16 19:35:54 jenkins-harbor kernel: sd 4:0:0:0: [sda] Write Protect is off</span><br><span class="line">Sep 16 19:35:54 jenkins-harbor kernel: sd 4:0:0:0: [sda] Mode Sense: 00 3a 00 00</span><br><span class="line">Sep 16 19:35:54 jenkins-harbor kernel: sd 4:0:0:0: [sda] Write cache: enabled, read cache: enabled, doesn&#39;t support DPO or FUA</span><br><span class="line">Sep 16 19:35:54 jenkins-harbor kernel:  sda: sda1 sda2 sda3</span><br><span class="line">Sep 16 19:35:54 jenkins-harbor kernel: sd 4:0:0:0: [sda] Attached SCSI disk</span><br><span class="line">Sep 16 19:35:54 jenkins-harbor kernel: random: fast init done</span><br></pre></td></tr></table></figure><p>后来仔细检查blkid 和/etc/fstab的区别发现</p><p>多了一条</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">UUID&#x3D;d276a0d4-c95f-4792-a222-6d1451899de2 &#x2F;home ext4    noatime,errors&#x3D;remount-ro 0 1</span><br></pre></td></tr></table></figure><p>不知道从哪里冒出来的</p><p>而且我没有这个设备挂载到/home目录下</p><p>最终删除这一行</p><p>reboot</p><p>成功</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这个事情发生的有些莫名其妙，因为网上说出现文件系统损坏是因为强行关闭或重新启动，我寻思reboot也不算强行重启吧。</p><p>这里不得不说，之前面试复习时经常被问到的一个问题（centos6和7的启动流程分别是什么 ）帮了我大忙，通过分析centos7的启动步骤我，找到了那块不能挂载的磁盘，并且清除挂载的配置项。</p><p>但是这个事故的后果在我看来相当严重</p><p>因为这台服务器部署了jenkins流水线+镜像仓库</p><p>导致一天的项目没法发布</p><p>我深深的感到自责</p><p>而且这台机器本身是有GPU的，在我未深入调查之前就将这台机器作为了Devops实施的服务器，实属浪费资源。</p><p>处理这个问题的心态我是非常不好的，因为马上要发布下项目了，但由于我临时为了帮助一个同事在这台机器上装显卡驱动，导致整个公司的业务更新中断一天。</p><ul><li>以后不能因为只帮同事解决问题而立即一些冒风险的事了（这里不是怪同事的意思，的确是自己疏忽了），至少得自己心里有杆秤，能不能完成，以及重要程度。</li><li>数据备份，其实如果这台服务器真的重启异常导致文件系统损坏的话，那么所有数据都丢失了，jenkins和harbor我都得花很久很久修复。这实在事太不应该了。</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://www.cnblogs.com/diantong/p/10745372.html" target="_blank" rel="noopener">CentOS7启动流程</a></p><p><a href="https://unix.stackexchange.com/questions/556819/systemd-time-out-waiting-for-device-dev-mapper-vg" target="_blank" rel="noopener">系统超时等待设备dev-mapper-vg</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operation Manual </tag>
            
            <tag> Centos </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>迁移自建Redis至AWS的ElastiCache For Redis</title>
      <link href="2020/09/16/aws/aws-redis-migrate/"/>
      <url>2020/09/16/aws/aws-redis-migrate/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>上期刚刚把Mysql迁云完成，紧接着我要把Redis迁云。AWS的服务组件ElastiCache For Redis</p><p>题外话：AWS是如何推销Redis产品的？</p><p>在“对于没有耐心的 Web 用户而言，一眨眼的功夫都显得太长”中，《纽约时报》报道用户会记下竞争网站之间的 250 毫秒（1/4 秒）的差异。用户将离开速度较慢的网站并转至速度较快的网站。网页加载时间与访客流失率的相关性中引用的 Amazon 所进行的测试表明，加载时间每增加 100 毫秒（1/10 秒），销售额就会减少 1%。</p><p>缓存组件对业务的体验感至关重要。</p><h1 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h1><p>目前公司自建了2个Redis实例（1个测试、1个生产）</p><h1 id="调研"><a href="#调研" class="headerlink" title="调研"></a>调研</h1><p>Redis的调研相比Mysql还麻烦这是我没想到的，从迁移时间来看确实是这样的，踩的坑也比Mysql多很多。</p><h2 id="资源调研"><a href="#资源调研" class="headerlink" title="资源调研"></a>资源调研</h2><h3 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h3><p>测试环境配置：2C 8G 500G磁盘 ec2类型t2.large</p><p>收费标准：</p><ul><li>服务器 一个月744个小时 一小时0.0928美元 一个月合计69美金</li><li>磁盘   一个月每G 0.1美元      一个月合计50美元</li></ul><p>由于没有Redis监控平台，只能实时看Redis使用率了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; info memory</span><br><span class="line">used_memory:20952496</span><br><span class="line">used_memory_human:19.98M</span><br><span class="line">used_memory_rss:21577728</span><br><span class="line">used_memory_peak:24330768</span><br><span class="line">used_memory_peak_human:23.20M</span><br><span class="line">used_memory_lua:36864</span><br><span class="line">mem_fragmentation_ratio:1.03</span><br><span class="line">mem_allocator:jemalloc-3.6.0</span><br></pre></td></tr></table></figure><h3 id="生产环境"><a href="#生产环境" class="headerlink" title="生产环境"></a>生产环境</h3><p>生产环境配置 2C 8G 500G磁盘 ec2类型t2.large</p><p>收费标准：</p><ul><li>服务器 一个月744个小时 一小时0.0928美元 一个月合计69美金</li><li>磁盘   一个月每G 0.1美元      一个月合计50美元</li></ul><p>实时看Redis使用率</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; info memory</span><br><span class="line">used_memory:21552008</span><br><span class="line">used_memory_human:20.55M</span><br><span class="line">used_memory_rss:34312192</span><br><span class="line">used_memory_peak:25640992</span><br><span class="line">used_memory_peak_human:24.45M</span><br><span class="line">used_memory_lua:36864</span><br><span class="line">mem_fragmentation_ratio:1.59</span><br><span class="line">mem_allocator:jemalloc-3.6.0</span><br></pre></td></tr></table></figure><h3 id="ElastiCache"><a href="#ElastiCache" class="headerlink" title="ElastiCache"></a>ElastiCache</h3><p>根据测试和生产实际Redis的使用大小</p><p>我选择了AWS 1c 0.5g 的redis实例 cache.t2micro</p><p>12.24美元/月</p><h3 id="对比结论"><a href="#对比结论" class="headerlink" title="对比结论"></a>对比结论</h3><p>ElastiCache好处有</p><ul><li>集群高可用 </li><li>备份 </li><li>弹性扩容 </li><li>监控</li></ul><p>降低运维成本</p><h2 id="迁移调研"><a href="#迁移调研" class="headerlink" title="迁移调研"></a>迁移调研</h2><p>经过调研发现AWS的迁移支持在线和离线迁移</p><h3 id="AWS的在线Redis迁移步骤说明"><a href="#AWS的在线Redis迁移步骤说明" class="headerlink" title="AWS的在线Redis迁移步骤说明"></a>AWS的在线Redis迁移步骤说明</h3><p>您必须确保已经满足了下面提到的所有四个先决条件，然后才能开始从 ElastiCache 控制台、API 或 AWS CLI 开始迁移。</p><h4 id="确定目标-ElastiCache-部署，并确保您可以将数据迁移到该部署。"><a href="#确定目标-ElastiCache-部署，并确保您可以将数据迁移到该部署。" class="headerlink" title="确定目标 ElastiCache 部署，并确保您可以将数据迁移到该部署。"></a>确定目标 ElastiCache 部署，并确保您可以将数据迁移到该部署。</h4><ul><li>使用Redis引擎5.0.5或更高版本禁用了集群模式。</li><li>它既没有启用传输中加密功能，也没有启用静态加密功能。</li><li>它启用了多可用区。</li><li>它有足够的内存来容纳来自EC2实例上Redis的数据。要配置正确的保留内存设置，请参阅管理分配内存。</li></ul><h4 id="确保-EC2-上的-Redis-与-ElastiCache-for-Redis-部署的配置兼容。"><a href="#确保-EC2-上的-Redis-与-ElastiCache-for-Redis-部署的配置兼容。" class="headerlink" title="确保 EC2 上的 Redis 与 ElastiCache for Redis 部署的配置兼容。"></a>确保 EC2 上的 Redis 与 ElastiCache for Redis 部署的配置兼容。</h4><p>至少，目标 ElastiCache 部署中的所有以下内容应与 Redis 配置兼容才能进行 Redis 复制：</p><ul><li>您的Redis应处于禁用群集模式的配置。</li><li>您在EC2实例上的Redis不应启用Redis AUTH。</li><li>Redis config protected-mode应该设置为no。</li><li>如果您bind的Redis配置中有配置，则应对其进行更新以允许来自ElastiCache节点的请求。</li><li>ElastiCache节点上的逻辑数据库数应与EC2实例上的Redis数相同。databases在Redis配置中使用设置此值。</li><li>执行数据修改的Redis命令不应重命名以使数据复制成功。</li><li>要将数据从Redis集群复制到ElastiCache，请确保有足够的CPU和内存来处理此额外的负载。此负载来自Redis群集创建的RDB文件，并通过网络传输到ElastiCache节点。</li></ul><h4 id="执行以下操作，以确保-EC2-实例可以连接到-ElastiCache："><a href="#执行以下操作，以确保-EC2-实例可以连接到-ElastiCache：" class="headerlink" title="执行以下操作，以确保 EC2 实例可以连接到 ElastiCache："></a>执行以下操作，以确保 EC2 实例可以连接到 ElastiCache：</h4><ul><li>确保您的EC2实例的IP地址是私有的。</li><li>在与EC2实例上的Redis相同的虚拟私有云（VPC）中分配或创建ElastiCache部署（推荐）。</li><li>如果VPC不同，则设置VPC对等以允许节点之间的访问。有关VPC对等的更多信息，请参阅用于访问Amazon VPC中的ElastiCache集群的访问模式。</li><li>附加到EC2实例上的Redis的安全组应允许来自ElastiCache节点的入站流量。</li></ul><h4 id="在数据迁移完成后，确保应用程序可以将流量传送到-ElastiCache-节点。"><a href="#在数据迁移完成后，确保应用程序可以将流量传送到-ElastiCache-节点。" class="headerlink" title="在数据迁移完成后，确保应用程序可以将流量传送到 ElastiCache 节点。"></a>在数据迁移完成后，确保应用程序可以将流量传送到 ElastiCache 节点。</h4><h3 id="离线迁移"><a href="#离线迁移" class="headerlink" title="离线迁移"></a>离线迁移</h3><p>离线迁移很简单，把RDB文件存在S3上，在创建Redis的时候填上这个路径即可</p><h3 id="迁移方案对比"><a href="#迁移方案对比" class="headerlink" title="迁移方案对比"></a>迁移方案对比</h3><p>在线迁移：无缝数据同步，不中断业务，但是需要原Redis不能开启集群、密码验证、配置文件更改等等。这些要求均不满足现业务阶段，而且要求属实多。</p><p>难道我还要先关闭线上Redis，改好这些配置再启动Redis，最后实行在线迁移吗，我服了。</p><p>直接选择离线迁移，不过问题就是在bgsave备份之后的数据会丢失，和研发沟通后认为这一会的数据丢失并不会影响什么，所以选择离线迁移方式。</p><h2 id="Redis版本调研"><a href="#Redis版本调研" class="headerlink" title="Redis版本调研"></a>Redis版本调研</h2><p>AWS建议使用Redis版本为5.0.6</p><p>而目前自建Redis版本为4.0</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;org.springframework.data&lt;&#x2F;groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;spring-data-redis&lt;&#x2F;artifactId&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;springboot.version&gt;2.1.6.RELEASE&lt;&#x2F;springboot.version&gt;</span><br></pre></td></tr></table></figure><p>和研发人员一起调研后发现可以使用Redis 5.0.6的版本</p><h1 id="迁移"><a href="#迁移" class="headerlink" title="迁移"></a>迁移</h1><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><h3 id="备份"><a href="#备份" class="headerlink" title="备份"></a>备份</h3><p>由于自建Redis没有开启RDB持久化，所以手动备份一下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">redis-cli -h xxx </span><br><span class="line">xxx &gt;  auth passwd</span><br><span class="line">Ok</span><br><span class="line">xxx &gt;  BGSAVE</span><br></pre></td></tr></table></figure><p>备份完成后将RDB文件上传到S3上</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws s3 cp dump.rdb s3:&#x2F;&#x2F;redis-dump&#x2F;dump.rdb</span><br></pre></td></tr></table></figure><p>具体操作完全参考 <a href="https://docs.aws.amazon.com/zh_cn/AmazonElastiCache/latest/red-ug/backups-seeding-redis.html#backups-seeding-redis-create-s3-bucket" target="_blank" rel="noopener">使用外部创建的备份为新群集播种</a></p><h3 id="创建Redis安全组及子网组"><a href="#创建Redis安全组及子网组" class="headerlink" title="创建Redis安全组及子网组"></a>创建Redis安全组及子网组</h3><p>先创建Redis子网组，范围是项目连接的IP池</p><p>创建完后将安全组入站设为Redis的子网组：6379端口</p><h2 id="创建-ElastiCache-For-Redis"><a href="#创建-ElastiCache-For-Redis" class="headerlink" title="创建 ElastiCache For Redis"></a>创建 ElastiCache For Redis</h2><p>点击ElastiCache控制台 &gt; 创建Redis &gt;  禁用集群模式 &gt; 引擎版本兼容性选择5.0.6 &gt; 端口6379 &gt; 参数组选择已经调优过的Redis5.0组 &gt; 节点类型选择 cache.t3.medium &gt; 副本数量为0，关闭多可用区 &gt; 选择子网组 &gt; 选择安全组 &gt; 选择传输中加密协议，并添加密码 &gt; 选择S3的RDB备份文件路径 &gt; 开启自动备份，备份保留7天</p><p>创建！</p><p>大约5分钟后可以使用</p><h2 id="redis-cli"><a href="#redis-cli" class="headerlink" title="redis-cli"></a>redis-cli</h2><p>redis-cli 连接测试数据一致性</p><p>验证完成</p><h2 id="路由切换"><a href="#路由切换" class="headerlink" title="路由切换"></a>路由切换</h2><p>将老路由映射关系更新到RDS的域名上</p><p>即在DNS CNAME里指向</p><p>比如现在的DNS是redis.xxx.com &gt;&gt; 192.168.1.1</p><p>我将它改为</p><p>redis.xxx.com &gt;&gt; Redis的域名</p><p>保存设置</p><p>过一段时间解析</p><p>ping redis.xxx.com 发现已经更新指向的地址为Redis</p><p>重启应用</p><p>因为应用的连接地址是redis.xxx.com</p><p>所以直接重启服务即可</p><h2 id="验证功能"><a href="#验证功能" class="headerlink" title="验证功能"></a>验证功能</h2><p>切换Redis后再验证一下业务的核心流程，成功。</p><h2 id="同理迁移生产环境Redis流程一致"><a href="#同理迁移生产环境Redis流程一致" class="headerlink" title="同理迁移生产环境Redis流程一致"></a>同理迁移生产环境Redis流程一致</h2><p>第二次迁移速度更快了</p><h1 id="至此，Redis迁移完成。"><a href="#至此，Redis迁移完成。" class="headerlink" title="至此，Redis迁移完成。"></a>至此，Redis迁移完成。</h1><p>迁移后，节省费用为</p><p>106.76美金/月*2 台=213.5美金/月</p><p>每个月固定减少213.5美金，而且不用担心数据丢失，备份等问题</p><p>合理利用资源，拥护明天————SRE</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://docs.aws.amazon.com/AmazonElastiCache/latest/red-ug/GettingStarted.html" target="_blank" rel="noopener">Amazon ElastiCache for Redis入门</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> AWS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> Redis </tag>
            
            <tag> ElastiCache </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维手册——Mysql迁云问题总结</title>
      <link href="2020/09/14/bug/mysql-migrate-rds/"/>
      <url>2020/09/14/bug/mysql-migrate-rds/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>在自建Mysql迁移到RDS的过程中，发现一些问题，本文总结一下。</p><h1 id="问题一：errorCode-1045-state-28000"><a href="#问题一：errorCode-1045-state-28000" class="headerlink" title="问题一：errorCode 1045,state 28000"></a>问题一：errorCode 1045,state 28000</h1><p>这个是在刚刚迁移完RDS后，项目连接报错。</p><p>springboot集成druid登陆mysql发生errorCode 1045, state 28000错误</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">java.log</span><br><span class="line"></span><br><span class="line">errorCode 1045,state 28000 java sql.SQLException:Access denied for user &#39;root&#39;@&#39;192.168.1.1&#39;</span><br></pre></td></tr></table></figure><p>找了大概2个小时，才发现Mysql的项目连接密码不对。</p><p>好吧，之前同事给我的文档测试环境和生产环境账号密码搞反了</p><p>google一下这种问题出现频率最高的2种原因</p><ul><li>mysql用户密码错误</li><li>mysql用户权限</li></ul><p>根本原因还是密码错误</p><p>下次再出现这个问题直接本机连账号密码，不行就改密码</p><h1 id="问题二：Host-is-blocked-because-of-many-connection-errors-unblock-with-‘mysqladmin-flush-hosts’"><a href="#问题二：Host-is-blocked-because-of-many-connection-errors-unblock-with-‘mysqladmin-flush-hosts’" class="headerlink" title="问题二：Host is blocked because of many connection errors; unblock with ‘mysqladmin flush-hosts’"></a>问题二：Host is blocked because of many connection errors; unblock with ‘mysqladmin flush-hosts’</h1><p>和上个问题有着紧密关系</p><p>由于一开始项目的密码错误导致这台服务器的IP重连很多次，最后被Mysql拒绝访问了</p><p>官方解释：<br>同一个ip在短时间内产生太多（超过mysql数据库max_connection_errors的最大值）中断的数据库连接而导致的阻塞；</p><p>解决问题</p><h2 id="提高允许的max-connection-errors数量（治标不治本）："><a href="#提高允许的max-connection-errors数量（治标不治本）：" class="headerlink" title="提高允许的max_connection_errors数量（治标不治本）："></a>提高允许的max_connection_errors数量（治标不治本）：</h2><ul><li>进入Mysql数据库查看max_connection_errors： </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show variables like &#39;%max_connection_errors%&#39;;</span><br></pre></td></tr></table></figure><ul><li>修改max_connection_errors的数量为1000：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set global max_connect_errors &#x3D; 1000;</span><br></pre></td></tr></table></figure></li></ul><ul><li>查看是否修改成功：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show variables like &#39;%max_connection_errors%&#39;;</span><br></pre></td></tr></table></figure></li></ul><h2 id="使用mysqladmin-flush-hosts"><a href="#使用mysqladmin-flush-hosts" class="headerlink" title="使用mysqladmin flush-hosts"></a>使用mysqladmin flush-hosts</h2><p>命令清理一下hosts文件（不知道mysqladmin在哪个目录下可以使用命令查找：whereis mysqladmin）；</p><p>在查找到的目录下使用命令修改：/usr/bin/mysqladmin flush-hosts -h192.168.1.1 -P3306 -uroot -p;</p><p>备注：</p><p>其中端口号，用户名，密码都可以根据需要来添加和修改；</p><p>配置有master/slave主从数据库的要把主库和从库都修改一遍的</p><p>第二步也可以在数据库中进行，命令如下：flush hosts;　　　　</p><p>我用的是flush hosts</p><h1 id="问题三：又是数据导入的问题"><a href="#问题三：又是数据导入的问题" class="headerlink" title="问题三：又是数据导入的问题"></a>问题三：又是数据导入的问题</h1><p>之前我有篇文章分析了导入大量数据的问题，这次又踩到上次没踩到的坑了。</p><h2 id="蜜汁操作：navicat"><a href="#蜜汁操作：navicat" class="headerlink" title="蜜汁操作：navicat"></a>蜜汁操作：navicat</h2><p>navicat的在线同步工具真的垃圾</p><p>导数据真的慢，再用砍手。</p><p>导了半个小时，大概260w条数据的时候，突然假死一下（我人直接气傻了）</p><p>而且导入的进程中断了还没用，还在继续执行。</p><p>没办法我只能删库跑路了，再建一个RDS</p><h2 id="mysqldump导出"><a href="#mysqldump导出" class="headerlink" title="mysqldump导出"></a>mysqldump导出</h2><p>导出时警告了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -uroot -p userdb &gt; userdb.sql</span><br><span class="line">Warning: A partial dump from a server that has GTIDs will by default include the GTIDs of all transactions, even those that changed suppressed parts of the database. If you don&#39;t want to restore GTIDs, pass --set-gtid-purged&#x3D;OFF. To make a complete dump, pass --all-databases --triggers --routines --events</span><br></pre></td></tr></table></figure><p>google查看原因</p><p>mysql提示: 当前数据库实例中开启了 GTID 功能, 在开启有 GTID 功能的数据库实例中, 导出其中任何一个库, 如果没有显示地指定–set-gtid-purged参数, 都会提示这一行信息. 意思是默认情况下, 导出的库中含有 GTID 信息。</p><p>导入的时候也分两种, 一种是导入带有 GTID 的信息的库, 一种是导入不带有 GTID 信息的库</p><ul><li>不带有 GTID 信息</li></ul><p>不带有 GTID 信息的 dump 文件, 不管目标数据库实例是否开启了 GTID 功能, 且不管数据库实例是否已有其他 GTID 信息, 都可以顺利导入</p><ul><li>带有 GTID 信息时</li></ul><p>带有 GTID 信息的 dump 文件, 要求目标数据库实例必须开启 GTID 功能, 且当前数据库中无其他 GTID 信息. 如果目标数据库中已经记录了一条或一条以上的 GTID 信息, 那么在导入数据库时会报出类似如下的错误❌</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql -uroot -p userdb &lt; userdb.sql</span><br><span class="line">Password:xxxxxxxx</span><br><span class="line">ERROR 1840 (HY000) at line 24: @@GLOBAL.GTID_PURGED can only be set when @@GLOBAL.GTID_EXECUTED is empty.</span><br></pre></td></tr></table></figure><p>解决方法</p><ul><li>重新 dump 数据库, 使用–set-gtid-purged=OFF的参数禁止🚫导出 GTID 信息,再 load 进目标数据库</li><li>在目标数据库中执行mysql&gt; reset slave all; mysql&gt; reset master; 清空所有 GTID 信息之后就可以导入了</li></ul><p>我是用的第一种方式</p><p>即 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -uroot -p --set-gtid-purged&#x3D;OFF  userdb &gt; userdb.sql</span><br></pre></td></tr></table></figure><h2 id="mysql导入"><a href="#mysql导入" class="headerlink" title="mysql导入"></a>mysql导入</h2><p>mysqldump确实快，不过中间遇到一个问题</p><p>在数据即将导完的时候报错</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ERROR 2006 (HY000): MySQL server has gone away</span><br><span class="line"></span><br><span class="line">ERROR 1231 (42000): Variable &#39;time_zone&#39; can&#39;t be set to the value of &#39;NULL&#39;</span><br><span class="line">ERROR 1231 (42000): Variable &#39;sql_mode&#39; can&#39;t be set to the value of &#39;NULL&#39;</span><br><span class="line">ERROR 1231 (42000): Variable &#39;foreign_key_checks&#39; can&#39;t be set to the value of &#39;NULL&#39;</span><br><span class="line">ERROR 1231 (42000): Variable &#39;unique_checks&#39; can&#39;t be set to the value of &#39;NULL&#39;</span><br><span class="line">ERROR 1231 (42000): Variable &#39;character_set_client&#39; can&#39;t be set to the value of &#39;NULL&#39;</span><br><span class="line">Query OK, 0 rows affected (0.00 sec)</span><br><span class="line">ERROR 1231 (42000): Variable &#39;collation_connection&#39; can&#39;t be set to the value of &#39;NULL&#39;</span><br><span class="line">ERROR 1231 (42000): Variable &#39;sql_notes&#39; can&#39;t be set to the value of &#39;NULL&#39;</span><br></pre></td></tr></table></figure><p>google了一下发现</p><p>Mysql的参数max_allowed_packet默认是4M</p><p>这个参数可以使client端到server端传递大数据时，系统能够分配更多的扩展内存来处理。</p><p>根据网上的处理建议我设置为了256M</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set global max_allowed_packet&#x3D;268435456;</span><br><span class="line"></span><br><span class="line">ERROR 1419 (HY000): You do not have the SUPER Privilege  and Binary  Logging is  Enabled</span><br></pre></td></tr></table></figure><p>我心态崩了，打开用户权限又发现AWS的RDS没有给你Super权限</p><p>这是个毛的主账号啊，系统的参数都不能改</p><p>没办法，我又只能在控制台改RDS的参数组</p><p>折腾了好久后</p><p>重新导入数据</p><p>没有报错，最后完成本次迁移工作</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>关于数据库方面的我只能说，即使这么麻烦，未来的主流趋势肯定还是上云，不然线下维护这些问题不请专业的DBA搞不定。</p><p>上云后，像我这样的小菜鸡也能轻松运维啦。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://stackoverflow.com/questions/43842396/mysql-error-variable-collation-connection-cant-be-set-to-the-value-of-null" target="_blank" rel="noopener">MySQL error : Variable ‘collation_connection’ can’t be set to the value of ‘NULL’ when dump .sql file</a></p><p><a href="https://my.oschina.net/u/1249401/blog/820277" target="_blank" rel="noopener">MySql Host is blocked because of many connection errors; unblock with ‘mysqladmin flush-hosts’ </a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> AWS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> RDS </tag>
            
            <tag> Mysql </tag>
            
            <tag> Operation Manual </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>迁移自建Mysql至AWS的RDS</title>
      <link href="2020/09/11/aws/aws-rds-migrate/"/>
      <url>2020/09/11/aws/aws-rds-migrate/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>随着公司业务的增大，自建Mysql风险越来越高，运维成本也越来越大（数据库监控、备份、迁移等）。服务上云是整个互联网企业的趋势，由于AWS和阿里云的RDS还是有一定区别的，下面开始记录我整个迁云计划及部署的实操过程。</p><h1 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h1><p>目前公司自建了2个数据库实例（1个测试、1个生产）</p><h2 id="资源调研"><a href="#资源调研" class="headerlink" title="资源调研"></a>资源调研</h2><p>首先调取一个月内数据库资源监控指标</p><h3 id="测试环境"><a href="#测试环境" class="headerlink" title="测试环境"></a>测试环境</h3><p>测试环境配置：2C 8G 500G磁盘 ec2类型t2.large</p><p>收费标准：</p><ul><li>服务器 一个月744个小时 一小时0.0928美元 一个月合计69美金</li><li>磁盘   一个月每G 0.1美元      一个月合计50美元</li></ul><p>平均一个月使用率</p><ul><li>内存 平均使用1.16G 峰值1.24G 使用率14.5%</li><li>CPU  平均使用0.012C 峰值0.74C 使用率0.07%</li><li>IOPS 平均使用2 iops 峰值57</li><li>统计数据库总空间1.46G</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select (sum(data_length) + sum(index_length))&#x2F;1024&#x2F;1024&#x2F;1024  db_gbsize</span><br><span class="line">from information_schema.tables;</span><br><span class="line"></span><br><span class="line">db_gbsize</span><br><span class="line">1.467038034461</span><br></pre></td></tr></table></figure><h3 id="生产环境"><a href="#生产环境" class="headerlink" title="生产环境"></a>生产环境</h3><p>生产环境配置 2C 8G 500G磁盘 ec2类型t2.large</p><p>收费标准：</p><ul><li>服务器 一个月744个小时 一小时0.0928美元 一个月合计69美金</li><li>磁盘   一个月每G 0.1美元      一个月合计50美元</li></ul><p>平均一个月使用率</p><ul><li>内存 平均使用1.7G 峰值1.9G 使用率14.5%</li><li>CPU  平均使用0.02C 峰值0.2C 使用率0.1%</li><li>IOPS 平均使用5 iops 峰值60</li><li>统计数据库总空间3.15G</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select (sum(data_length) + sum(index_length))&#x2F;1024&#x2F;1024&#x2F;1024  db_gbsize</span><br><span class="line">from information_schema.tables;</span><br><span class="line"></span><br><span class="line">db_gbsize</span><br><span class="line">3.152370004915</span><br></pre></td></tr></table></figure><p>很显然，自建的Mysql机器性能过于浪费，其中一个很重要的原因就是磁盘使用率率很低，都快赶上一台服务器的价格了。</p><p>我们再来对比一下RDS的价格</p><h2 id="RDS收费"><a href="#RDS收费" class="headerlink" title="RDS收费"></a>RDS收费</h2><p>2c 8g 500G SSD IOPS最大1000  机器型号 db.m4.large </p><p>数据库实例<br>127.75 USD/月</p><p>存储<br>57.50 USD/月</p><p>总计<br>185.25 USD/月</p><p>1c 2g 20G SSD IOPS 60 机器型号 db.t2.small</p><p>数据库实例<br>24.82 USD/月</p><p>存储<br>2.30 USD/月</p><p>总计<br>27.12 USD/月</p><h2 id="对比结论"><a href="#对比结论" class="headerlink" title="对比结论"></a>对比结论</h2><p>同类型ec2自建mysql的价格是比RDS便宜的，但是RDS的好处在于：</p><ul><li>自动扩容磁盘</li><li>Mysql调优</li><li>可突增CPU、IOPS临时大小</li><li>自动备份</li><li>多地部署</li><li>运维简单（只用控制台运维即可）</li><li>监控</li></ul><p>而这次我通过现在的Mysql资源使用率选型RDS为以下配置</p><p>1c 2g 20G SSD IOPS 60 机器型号 db.t2.small </p><h1 id="迁移"><a href="#迁移" class="headerlink" title="迁移"></a>迁移</h1><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><ul><li>梳理现有DB、用户、安全组</li><li>Mysqldump全库数据</li></ul><p>导出一个数据库的结构以及数据</p><p>mysqldump dbname -uroot -p &gt; dbname.sql</p><p>导出多个数据库的结构以及数据</p><p>mysqldump -B dbname1 dbname2 -uroot -p &gt; dbname.sql</p><h2 id="创建RDS"><a href="#创建RDS" class="headerlink" title="创建RDS"></a>创建RDS</h2><p>点击RDS控制台 &gt; 创建数据库 &gt; 选择mysql &gt; 版本选择5.7.28 &gt; 选择生产模板 &gt; 设置主用户(最高权限用户，谨慎保管) &gt; 选择实例类型(可突增型db.t2.small) &gt; 选择可用性与持久性(多区域部署) &gt; 选择子网和安全组 &gt; 选择密码身份验证</p><p>创建！</p><p>大概10分钟后可以使用</p><h2 id="同步数据"><a href="#同步数据" class="headerlink" title="同步数据"></a>同步数据</h2><p>又来到了我们的主角navicat，选择navicat的工具&gt;数据同步&gt;选择库表，开始同步</p><p>大约过了12分钟才同步好，不得不得说还是挺慢的。</p><p>当然我也用Mysqldump同步了，时间仅仅只要3分钟。</p><p>差距立刻拉开，哈哈</p><h2 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h2><p>给RDS创建项目连接的用户并授权</p><h2 id="测试自动化SQL工具正常"><a href="#测试自动化SQL工具正常" class="headerlink" title="测试自动化SQL工具正常"></a>测试自动化SQL工具正常</h2><p>dbmate  -s db/schema-prod.sql migrate</p><p>成功</p><h2 id="路由切换"><a href="#路由切换" class="headerlink" title="路由切换"></a>路由切换</h2><p>将老路由映射关系更新到RDS的域名上</p><p>即在DNS CNAME里指向</p><p>比如现在的DNS是<br>mysql.xxx.com &gt;&gt; 192.168.1.1</p><p>我将它改为</p><p>mysql.xxx.com &gt;&gt; RDS的域名</p><p>保存设置</p><p>过一段时间解析</p><p>ping mysql.xxx.com 发现已经更新指向的地址为RDS</p><h2 id="重启应用"><a href="#重启应用" class="headerlink" title="重启应用"></a>重启应用</h2><p>因为应用的连接地址是mysql.xxx.com</p><p>所以直接重启服务即可</p><h2 id="验证功能"><a href="#验证功能" class="headerlink" title="验证功能"></a>验证功能</h2><p>切换RDS后再验证一下业务的核心流程，成功。</p><h2 id="同理迁移生产环境RDS流程一致"><a href="#同理迁移生产环境RDS流程一致" class="headerlink" title="同理迁移生产环境RDS流程一致"></a>同理迁移生产环境RDS流程一致</h2><p>第二次迁移速度更快了</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>至此，RDS迁移完成。</p><p>迁移后，节省费用为</p><p>90美金/月*2 台=180美金/月</p><p>每个月固定减少180美金，而且不用担心数据丢失，备份等问题</p><p>合理利用资源，拥护明天————SRE</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_GettingStarted.html" target="_blank" rel="noopener">Amazon RDS入门</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> AWS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
            <tag> RDS </tag>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>个人总结(2020.8)</title>
      <link href="2020/09/11/summary/summary-2020-8/"/>
      <url>2020/09/11/summary/summary-2020-8/</url>
      
        <content type="html"><![CDATA[<h1 id="感慨"><a href="#感慨" class="headerlink" title="感慨"></a>感慨</h1><p>赚钱不易</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>进入公司的第一个月，我的心态思想又有了很大的变化</p><h2 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h2><p>进入公司的第一个星期，就有了想离开的打算，为什么？</p><p>公司人不多，运维就只有我一个人，架构比较旧，随便举几个例子，代码的配置文件没有拿出来，每次修改配置文件都得重新打包，本地没有DNS服务器，网络架构混乱，几乎没有Docker化的项目，全部物理机部署，各种中间件混合和项目共用，SSL证书乱七八糟，几乎每台服务器都存在一个Nginx服务器，密钥管理也不全，人人都可以直连生产服务器，没有开发环境，流程管理很乱等等等等</p><p>我感觉就是一个大烂摊子等着我收拾</p><p>但和前领导一番沟通后，他鼓励我，公司花更多钱是让你解决这些问题的，要是没有这么多问题，让你来干嘛？我想想也是。领导继续说，这正是一个机会，证明你确实有能力独当一面的机会，你应该珍惜。</p><p>确实，在几个offer面前我选择这家不仅仅是因为工资高，还有一点是创业型公司没有大公司那么多繁文缛节。</p><p>我希望保持技术的纯粹性，那么还担心这么多的问题没法解决么？</p><h2 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h2><p>我决定好好证明我的价值了，第一个星期我就提出了自动化流水线的构建，以及Docker化所有项目，至今为止，我已经做完了这2个内容。</p><p>熟悉AWS是一件很不容易的过程，毕竟AWS是面向世界的云平台，而阿里云仅仅只是国内的大哥，或者说太符合国人的操作风格了，用起来才得心应手。</p><p>一个月的时间差不多把AWS基础组件熟悉完了，可以在云上运维部分组件。</p><p>在此基础上，我基于公司的业务，大胆的砍了4台没有必要的服务器。我无法想象之前的运维是怎么管理云服务器的，4台完全已经搁浅的服务器，任由AWS收割费用，老板都不心疼。</p><p>缩减后，给公司省下的1000美金/月的永久支出</p><p>下个月准备往AWS的EKS（托管型K8S)发展，然后数据库上RDS，增加SLB，将自建的服务全都用公有云组件，云上只部署自己的业务代码即可。</p><h2 id="格局"><a href="#格局" class="headerlink" title="格局"></a>格局</h2><p>来深圳一个月，想的太多了，大城市真实诱惑无限。</p><p>30岁之前靠自己攒到100W然后回武汉买房结婚的想法简直太low了。确实，我在今年6月之前还有点不敢想把这个目标定为我的长期目标。</p><p>因为我现在已经23了，还有7年，一年攒14w多，你得一年收入多少？月薪起码得2w+吧，虽然你的工资会越来越高，但是攒钱真是一个难事。</p><p>然后又经过高人指点了现在中国的社会阶层，我才了解到，确实如他所说，在中国，要么成为被剥削者，要么就是在成为剥削者的路上。</p><p>真正的资本家只会把996当作福报来像洗脑一样告诉你，我突然在想为什么要拼命工作，不就是为了将来，活得有点尊严吗？不会再为了穷，而不能做这不能做那。</p><p>确实，穷就是原罪，可富人都会说，我对钱没有兴趣，钱就是王八蛋。确实到了那种阶层的人，钱对他们来说意义已经不大了，怎么实现自己的价值，留下一个很好的名声才是最重要的</p><p>综上所述，我的目标改变了</p><p>3年内，我竭尽所能为资本家赚钱</p><p>6年内，我能够转变成为自己赚钱</p><p>9年甚至更久后，我也要成为资本家，让别人为我赚钱</p><h1 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h1><p>8月是我入职的第一个月，我从开始的想离开转变为要大展拳脚证明自己。同事们都特别热情，我也觉得没有困难能阻挡一个热血的团队，为此我这个月就包夜3次，加班干，帮助团队解决一些运维上的困难，我很有成就感。</p><p>工作上我要发挥出自己最大的努力，做好每一件事情，改善，改善，再改善，永远不要让自己满意——SRE</p><p>除了技术我开始在想怎么实现我的新目标：如何成为资本家？这是一个好问题，目前并没有一个明确的方向。</p>]]></content>
      
      
      <categories>
          
          <category> 个人总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 个人总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维手册——Dockerfile的JDK版本更换</title>
      <link href="2020/09/05/bug/dockerfile-jdk-version/"/>
      <url>2020/09/05/bug/dockerfile-jdk-version/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近同事反馈项目报错，查看日志发现我给公司项目做的Dockerfile的jdk版本出现问题，导致FontConfiguration.getVersion报空指针异常</p><h1 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h1><p>原Dockefile</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">yum install -y java-1.8.0-openjdk</span><br><span class="line"></span><br><span class="line">进入容器后java -version的版本是1.8.0_265</span><br><span class="line"></span><br><span class="line">root@b9907f6d3a04:&#x2F;# java -version</span><br><span class="line">openjdk version &quot;1.8.0_265&quot;</span><br><span class="line">OpenJDK Runtime Environment (AdoptOpenJDK)(build 1.8.0_265-b01)</span><br><span class="line">OpenJDK 64-Bit Server VM (AdoptOpenJDK)(build 25.265-b01, mixed mode)</span><br></pre></td></tr></table></figure><h1 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h1><h2 id="临时解决"><a href="#临时解决" class="headerlink" title="临时解决"></a>临时解决</h2><p>看了下网上的问题分析，大部分是直接安装 fontconfig组件，即</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">centos系统使用  yum install fontconfig</span><br><span class="line"></span><br><span class="line">debian系统使用 apt-get install fontconfig</span><br></pre></td></tr></table></figure><p>未验证</p><h2 id="永久解决"><a href="#永久解决" class="headerlink" title="永久解决"></a>永久解决</h2><p>为了保证和开发JDK版本一致</p><p>我使用了开发人员的JDK安装包，而不采用yum或apt直接安装</p><p>重做Dockerfile</p><p>先自己下载jdk-8u201-linux-x64.tar.gz</p><p><a href="https://www.oracle.com/java/technologies/javase/javase8-archive-downloads.html#license-lightbox" target="_blank" rel="noopener">https://www.oracle.com/java/technologies/javase/javase8-archive-downloads.html#license-lightbox</a></p><p>选择jdk-8u201-linux-x64.tar.gz</p><p>下载后放到和Dockerfile同级目录</p><p>Dockerfile如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#</span><br><span class="line">FROM centos</span><br><span class="line">MAINTAINER rugod.cn</span><br><span class="line">RUN mkdir &#x2F;usr&#x2F;local&#x2F;java</span><br><span class="line">ADD jdk-8u201-linux-x64.tar.gz &#x2F;usr&#x2F;local&#x2F;java&#x2F;</span><br><span class="line">ENV JAVA_HOME &#x2F;usr&#x2F;local&#x2F;java&#x2F;jdk1.8.0_201</span><br><span class="line">ENV JRE_HOME $JAVA_HOME&#x2F;jre</span><br><span class="line">ENV PATH $JAVA_HOME&#x2F;bin:$PATH</span><br></pre></td></tr></table></figure><p>制作JDK8镜像</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">docker build -t&#x3D;&quot;jdk8&#x2F;jdk8:1.0.0&quot; .</span><br><span class="line"></span><br><span class="line">docker images -a</span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">jdk8&#x2F;jdk8           1.0.0               9c5f587a8384        27 hours ago        546MB</span><br><span class="line"></span><br><span class="line">docker run -it --rm jdk8&#x2F;jdk8:1.0.0 java -version</span><br><span class="line">java version &quot;1.8.0_201&quot;</span><br><span class="line">Java(TM) SE Runtime Environment (build 1.8.0_201-b09)</span><br><span class="line">Java HotSpot(TM) 64-Bit Server VM (build 25.201-b09, mixed mode)</span><br></pre></td></tr></table></figure><p>然后把这个jdk重新push到Harbor覆盖之前jdk的镜像即可</p>]]></content>
      
      
      <categories>
          
          <category> JDK </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operation Manual </tag>
            
            <tag> Dockerfile </tag>
            
            <tag> JDK </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维手册——Redis持久化占用磁盘过高</title>
      <link href="2020/09/05/bug/redis-aof/"/>
      <url>2020/09/05/bug/redis-aof/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>公司服务器ES写索引异常，查看原因，发现ES数据所在目录磁盘空间使用率超过百分之90后，ES将修改为只读状态，所以判断是磁盘空间满了。然后我上服务器看，Redis占用了300G+磁盘，且Redis做AOF和RDB混合持久化，AOF 137G RDB 123G</p><h1 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h1><h2 id="查阅Redis持久化机制"><a href="#查阅Redis持久化机制" class="headerlink" title="查阅Redis持久化机制"></a>查阅Redis持久化机制</h2><p>Redis提供了两种持久化方案：RDB持久化和AOF持久化，一个是快照的方式，一个是类似日志追加的方式</p><h3 id="RDB快照持久化"><a href="#RDB快照持久化" class="headerlink" title="RDB快照持久化"></a>RDB快照持久化</h3><p>RDB持久化是通过快照的方式，即在指定的时间间隔内将内存中的数据集快照写入磁盘。在创建快照之后，用户可以备份该快照，可以将快照复制到其他服务器以创建相同数据的服务器副本，或者在重启服务器后恢复数据。RDB是Redis默认的持久化方式</p><p>RDB持久化会生成RDB文件，该文件是一个压缩过的二进制文件，可以通过该文件还原快照时的数据库状态，即生成该RDB文件时的服务器数据。RDB文件默认为当前工作目录下的dump.rdb，可以根据配置文件中的dbfilename和dir设置RDB的文件名和文件位置</p><h4 id="触发RDB持久化的时机"><a href="#触发RDB持久化的时机" class="headerlink" title="触发RDB持久化的时机"></a>触发RDB持久化的时机</h4><ul><li>执行save和bgsave命令</li><li>配置文件设置save <seconds> <changes>规则，自动间隔性执行bgsave命令</li><li>主从复制时，从库全量复制同步主库数据，主库会执行bgsave</li><li>执行flushall命令清空服务器数据</li><li>执行shutdown命令关闭Redis时，会执行save命令</li></ul><h4 id="save和bgsave命令"><a href="#save和bgsave命令" class="headerlink" title="save和bgsave命令"></a>save和bgsave命令</h4><p>执行save和bgsave命令，可以手动触发快照，生成RDB文件，两者的区别如下</p><p>使用save命令会阻塞Redis服务器进程，服务器进程在RDB文件创建完成之前是不能处理任何的命令请求</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; save</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><p>复制代码而使用bgsave命令不同的是，basave命令会fork一个子进程，然后该子进程会负责创建RDB文件，而服务器进程会继续处理命令请求</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; bgsave</span><br><span class="line">Background saving started</span><br></pre></td></tr></table></figure><p>fork()是由操作系统提供的函数，作用是创建当前进程的一个副本作为子进程</p><p>fork一个子进程，子进程会把数据集先写入临时文件，写入成功之后，再替换之前的RDB文件，用二进制压缩存储，这样可以保证RDB文件始终存储的是完整的持久化内容。</p><p>如图所示</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Redis/rdb.png"  alt="rdb.png"></p><h4 id="自动间隔触发"><a href="#自动间隔触发" class="headerlink" title="自动间隔触发"></a>自动间隔触发</h4><p>在配置文件中设置save <seconds> <changes>规则，可以自动间隔性执行bgsave命令，且不会造成Redis堵塞。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">################################ SNAPSHOTTING  ################################</span><br><span class="line">#</span><br><span class="line"># Save the DB on disk:</span><br><span class="line">#</span><br><span class="line">#   save &lt;seconds&gt; &lt;changes&gt;</span><br><span class="line">#</span><br><span class="line">#   Will save the DB if both the given number of seconds and the given</span><br><span class="line">#   number of write operations against the DB occurred.</span><br><span class="line">#</span><br><span class="line">#   In the example below the behaviour will be to save:</span><br><span class="line">#   after 900 sec (15 min) if at least 1 key changed</span><br><span class="line">#   after 300 sec (5 min) if at least 10 keys changed</span><br><span class="line">#   after 60 sec if at least 10000 keys changed</span><br><span class="line">#</span><br><span class="line">#   Note: you can disable saving completely by commenting out all &quot;save&quot; lines.</span><br><span class="line">#</span><br><span class="line">#   It is also possible to remove all the previously configured save</span><br><span class="line">#   points by adding a save directive with a single empty string argument</span><br><span class="line">#   like in the following example:</span><br><span class="line">#</span><br><span class="line">#   save &quot;&quot;</span><br><span class="line"></span><br><span class="line">save 900 1</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000</span><br></pre></td></tr></table></figure><p>save <seconds> <changes>表示在seconds秒内，至少有changes次变化，就会自动触发gbsave命令</p><ul><li>save 900 1  当时间到900秒时，如果至少有1个key发生变化，就会自动触发bgsave命令创建快照</li><li>save 300 10  当时间到300秒时，如果至少有10个key发生变化，就会自动触发bgsave命令创建快照</li><li>save 60 10000    当时间到60秒时，如果至少有10000个key发生变化，就会自动触发bgsave命令创建快照</li></ul><h3 id="AOF持久化"><a href="#AOF持久化" class="headerlink" title="AOF持久化"></a>AOF持久化</h3><p>除了RDB持久化，Redis还提供了AOF（Append Only File）持久化功能，AOF持久化会把被执行的写命令写到AOF文件的末尾，记录数据的变化。默认情况下，Redis是没有开启AOF持久化的，开启后，每执行一条更改Redis数据的命令，都会把该命令追加到AOF文件中，这是会降低Redis的性能，但大部分情况下这个影响是能够接受的，另外使用较快的硬盘可以提高AOF的性能</p><h4 id="触发AOF持久化的时机"><a href="#触发AOF持久化的时机" class="headerlink" title="触发AOF持久化的时机"></a>触发AOF持久化的时机</h4><ul><li>配置文件开启AOF即可</li></ul><p>配置文件如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># appendonly参数开启AOF持久化</span><br><span class="line">appendonly yes</span><br><span class="line"></span><br><span class="line"># AOF持久化的文件名，默认是appendonly.aof</span><br><span class="line">appendfilename &quot;appendonly.aof&quot;</span><br><span class="line"></span><br><span class="line"># AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的</span><br><span class="line">dir .&#x2F;</span><br><span class="line"></span><br><span class="line"># 同步策略</span><br><span class="line"># appendfsync always</span><br><span class="line">appendfsync everysec</span><br><span class="line"># appendfsync no</span><br><span class="line"></span><br><span class="line"># aof重写期间是否同步</span><br><span class="line">no-appendfsync-on-rewrite no</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 加载aof出错如何处理</span><br><span class="line">aof-load-truncated yes</span><br><span class="line"></span><br><span class="line"># 文件重写策略</span><br><span class="line">aof-rewrite-incremental-fsync yes</span><br></pre></td></tr></table></figure><h4 id="AOF的实现"><a href="#AOF的实现" class="headerlink" title="AOF的实现"></a>AOF的实现</h4><p>AOF需要记录Redis的每个写命令，步骤为：命令追加（append）、文件写入（write）和文件同步（sync）</p><ul><li>命令追加(append)</li></ul><p>开启AOF持久化功能后，服务器每执行一个写命令，都会把该命令以协议格式先追加到aof_buf缓存区的末尾，而不是直接写入文件，避免每次有命令都直接写入硬盘，减少硬盘IO次数</p><ul><li>文件写入(write)和文件同步(sync)</li></ul><p>对于何时把aof_buf缓冲区的内容写入保存在AOF文件中，Redis提供了多种策略</p><p>appendfsync always：将aof_buf缓冲区的所有内容写入并同步到AOF文件，每个写命令同步写入磁盘</p><p>appendfsync everysec：将aof_buf缓存区的内容写入AOF文件，每秒同步一次，该操作由一个线程专门负责</p><p>appendfsync no：将aof_buf缓存区的内容写入AOF文件，什么时候同步由操作系统来决定</p><p>appendfsync选项的默认配置为everysec，即每秒执行一次同步</p><p>关于AOF的同步策略是涉及到操作系统的write函数和fsync函数的，在《Redis设计与实现》中是这样说明的</p><p>为了提高文件写入效率，在现代操作系统中，当用户调用write函数，将一些数据写入文件时，操作系统通常会将数据暂存到一个内存缓冲区里，当缓冲区的空间被填满或超过了指定时限后，才真正将缓冲区的数据写入到磁盘里。</p><p>这样的操作虽然提高了效率，但也为数据写入带来了安全问题：如果计算机停机，内存缓冲区中的数据会丢失。为此，系统提供了fsync、fdatasync同步函数，可以强制操作系统立刻将缓冲区中的数据写入到硬盘里，从而确保写入数据的安全性。</p><p>从上面的介绍我们知道，我们写入的数据，操作系统并不一定会马上同步到磁盘，所以Redis才提供了appendfsync的选项配置。当该选项时为always时，数据安全性是最高的，但是会对磁盘进行大量的写入，Redis处理命令的速度会受到磁盘性能的限制；appendfsync everysec选项则兼顾了数据安全和写入性能，以每秒一次的频率同步AOF文件，即便出现系统崩溃，最多只会丢失一秒内产生的数据；如果是appendfsync no选项，Redis不会对AOF文件执行同步操作，而是有操作系统决定何时同步，不会对Redis的性能带来影响，但假如系统崩溃，可能会丢失不定数量的数据</p><h4 id="AOF重写-rewrite"><a href="#AOF重写-rewrite" class="headerlink" title="AOF重写(rewrite)"></a>AOF重写(rewrite)</h4><p>由于AOF的机制，每条写命令都需要被记录，如果一对kv先被创建，然后被修改4次，最后被删除，那么AOF会存在6个此kv的记录。</p><p>如果此时Redis重启，读取AOF，那么最终还是不会存在这对kv，但是AOF的文件大小会增大（因为记录了这6条命令）</p><p>为了不让AOF一直增大至无限大，Redis应该让删除这些不必要的命令（冗余命令）。比如：过期数据的命令、无效的命令（重复设置、删除）、多个命令可合并为一个命令（批处理命令）</p><p>AOF重写的目的就是减小AOF文件的体积，不过值得注意的是：AOF文件重写并不需要对现有的AOF文件进行任何读取、分享和写入操作，而是通过读取服务器当前的数据库状态来实现的</p><p>文件重写可分为手动触发和自动触发，手动触发执行bgrewriteaof命令，该命令的执行跟bgsave触发快照时类似的，都是先fork一个子进程做具体的工作</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; bgrewriteaof</span><br><span class="line">Background append only file rewriting started</span><br></pre></td></tr></table></figure><p>自动触发会根据auto-aof-rewrite-percentage和auto-aof-rewrite-min-size 64mb配置来自动执行bgrewriteaof命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 重写触发配置</span><br><span class="line">auto-aof-rewrite-percentage 100</span><br><span class="line">auto-aof-rewrite-min-size 64mb</span><br></pre></td></tr></table></figure><p>这个配置表示当AOF文件的体积大于64MB，且AOF文件的体积比上一次重写后的体积大了一倍（100%）时，会执行<code>bgrewriteaof</code>命令</p><h4 id="bgrewriteaof"><a href="#bgrewriteaof" class="headerlink" title="bgrewriteaof"></a>bgrewriteaof</h4><p>重写会有大量的写入操作，所以服务器进程会fork一个子进程来创建一个新的AOF文件</p><p>在重写期间，服务器进程继续处理命令请求，如果有写入的命令，追加到aof_buf的同时，还会追加到aof_rewrite_buf AOF重写缓冲区</p><p>当子进程完成重写之后，会给父进程一个信号，然后父进程会把AOF重写缓冲区的内容写进新的AOF临时文件中，再对新的AOF文件改名完成替换，这样可以保证新的AOF文件与当前数据库数据的一致性</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Redis/aof.png"  alt="aof.png"></p><h3 id="AOF和RDB的优缺点"><a href="#AOF和RDB的优缺点" class="headerlink" title="AOF和RDB的优缺点"></a>AOF和RDB的优缺点</h3><h4 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h4><p>优点：</p><ul><li>RDB 是一个非常紧凑（compact）的文件，体积小，因此在传输速度上比较快，因此适合灾难恢复。 </li><li>RDB 可以最大化 Redis 的性能：父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进程，然后这个子进程就会处理接下来的所有保存工作，父进程无须执行任何磁盘 I/O 操作。</li><li>RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。</li></ul><p>缺点：</p><ul><li>RDB是一个快照过程，无法完整的保存所以数据，尤其在数据量比较大时候，一旦出现故障丢失的数据将更多。</li><li>当redis中数据集比较大时候，RDB由于RDB方式需要对数据进行完成拷贝并生成快照文件，fork的子进程会耗CPU，并且数据越大，RDB快照生成会越耗时。</li><li>RDB文件是特定的格式，阅读性差，由于格式固定，可能存在不兼容情况。</li></ul><h4 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h4><p>优点：</p><ul><li>数据更完整，秒级数据丢失(取决于设置fsync策略)。</li><li>兼容性较高，由于是基于redis通讯协议而形成的命令追加方式，无论何种版本的redis都兼容，再者aof文件是明文的，可阅读性较好。</li></ul><p>缺点：</p><ul><li>数据文件体积较大,即使有重写机制，但是在相同的数据集情况下，AOF文件通常比RDB文件大。</li><li>相对RDB方式，AOF速度慢于RDB，并且在数据量大时候，恢复速度AOF速度也是慢于RDB。</li><li>由于频繁地将命令同步到文件中，AOF持久化对性能的影响相对RDB较大，但是对于我们来说是可以接受的。</li></ul><h4 id="反思"><a href="#反思" class="headerlink" title="反思"></a>反思</h4><p>通过AOF和RDB的优缺点比较，其实我关注的重点就是数据恢复的可靠性。</p><p>一台服务器如果你能保证永久不关机、不中断服务。那么这台机器就不需要做任何备份（实际基本上不存在这种）</p><p>那么一旦出现中断服务、或关机、或硬盘损失。我们就应该关注如何让这个服务恢复到正常状态最佳。</p><p>这个最佳的定义，在学习SRE的思想后，我是这样看的</p><ul><li>数据尽量不丢失</li><li>恢复的时间尽快</li></ul><p>这样才能对生产影响最小。</p><p>基于这个原则，Redis的备份策略应该吸收RDB(恢复速度快)、AOF(数据不丢失)这2个最重要的优点。</p><p>仔细研究发现这个备份策略已经实现了，那就是Redis的混合持久化</p><h3 id="Redis混合持久化"><a href="#Redis混合持久化" class="headerlink" title="Redis混合持久化"></a>Redis混合持久化</h3><p>Redis4.0开始支持RDB和AOF的混合持久化（可以通过配置项 aof-use-rdb-preamble 开启）5.0之后默认开启混合持久化</p><p>混合持久化同样也是通过bgrewriteaof完成的，不同的是当开启混合持久化时，fork出的子进程先将共享的内存副本全量的以RDB方式写入aof文件，然后在将aof_rewrite_buf重写缓冲区的增量命令以AOF方式写入到文件，写入完成后通知主进程更新统计信息，并将新的含有RDB格式和AOF格式的AOF文件替换旧的的AOF文件。简单的说：新的AOF文件前半段是RDB格式的全量数据后半段是AOF格式的增量数据。</p><p>如下图所示：</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Redis/aof-use-rdb-preamble.png"  alt="aof-use-rdb-preamble.png"></p><p>那么重启时redis按照以下规则读取数据</p><ul><li>如果是redis进程挂掉，那么重启redis进程即可，直接基于AOF日志文件恢复数据</li><li>如果是redis进程所在机器挂掉，那么重启机器后，尝试重启redis进程，尝试直接基于AOF日志文件进行数据恢复，如果AOF文件破损，那么用redis-check-aof fix命令修复</li><li>如果没有AOF文件，会去加载RDB文件</li><li>如果redis当前最新的AOF和RDB文件出现了丢失/损坏，那么可以尝试基于该机器上当前的某个最新的RDB数据副本进行数据恢复</li></ul><p>通过这些规则我们可以知道即使是混合持久化，在不丢失/破坏AOF的情况下，再持久化一份RDB几乎没用。因为开启了混合模式后的aof文件里包含了rdb的头+aof的增量文件，而每次重启读取的都是aof文件。</p><h2 id="现状"><a href="#现状" class="headerlink" title="现状"></a>现状</h2><p>目前Redis服务器是做了AOF和RDB混合持久化。磁盘439G 内存256G</p><p>我们先查看服务器状态</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">$ free -h</span><br><span class="line">              total        used        free      shared  buff&#x2F;cache   available</span><br><span class="line">Mem:           251G        151G        858M        730M         99G         97G</span><br><span class="line">$ df -h</span><br><span class="line">Filesystem    Size  Used Avail Use% Mounted on</span><br><span class="line">udev          126G     0  126G   0% &#x2F;dev</span><br><span class="line">tmpfs         26G   1.7G   24G   7%  &#x2F;run</span><br><span class="line">&#x2F;dev&#x2F;sdc2     439G  400G  38G   91% &#x2F;</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; INFO Memory</span><br><span class="line"># Memory</span><br><span class="line">used_memory:144520234248</span><br><span class="line">used_memory_human:134.59G</span><br><span class="line">used_memory_rss:151639486464</span><br><span class="line">used_memory_rss_human:141.23G</span><br><span class="line">used_memory_peak:145837846640</span><br><span class="line">used_memory_peak_human:135.82G</span><br><span class="line">used_memory_peak_perc:99.10%</span><br><span class="line">used_memory_overhead:46702054</span><br><span class="line">used_memory_startup:786608</span><br><span class="line">used_memory_dataset:144473532194</span><br><span class="line">used_memory_dataset_perc:99.97%</span><br><span class="line">total_system_memory:270115205120</span><br><span class="line">total_system_memory_human:251.56G</span><br><span class="line">used_memory_lua:37888</span><br><span class="line">used_memory_lua_human:37.00K</span><br><span class="line">maxmemory:0</span><br><span class="line">maxmemory_human:0B</span><br><span class="line">maxmemory_policy:volatile-ttl</span><br><span class="line">mem_fragmentation_ratio:1.05</span><br><span class="line">mem_allocator:jemalloc-4.0.3</span><br><span class="line">active_defrag_running:0</span><br><span class="line">lazyfree_pending_objects:0</span><br></pre></td></tr></table></figure><p>好家伙，Redis实际使用了134.59G</p><p>那么我们看看Redis的备份文件大小吧。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ ll -rth</span><br><span class="line">total 383G</span><br><span class="line">drwxrwxr-x 2 ubuntu ubuntu 4.0K 6月  18 18:44 log&#x2F;</span><br><span class="line">-rw-rw-r-- 1 ubuntu ubuntu  41K 7月  11 13:25 redis.conf</span><br><span class="line">-rw-r--r-- 1 root   root   866M 9月   3 12:22 temp-1.rdb</span><br><span class="line">drwxr-xr-x 3 root   root   4.0K 9月   3 12:29 ..&#x2F;</span><br><span class="line">-rw-r--r-- 1 root   root   123G 9月   4 20:10 dump.rdb</span><br><span class="line">drwxrwxr-x 3 ubuntu ubuntu 4.0K 9月   4 20:15 .&#x2F;</span><br><span class="line">-rw-r--r-- 1 root   root   137G 9月   4 20:38 appendonly.aof</span><br><span class="line">-rw-r--r-- 1 root   root   123G 9月   4 20:39 temp-75.rdb</span><br></pre></td></tr></table></figure><p>真的很顶 383G</p><p>通过dump.rdb和temp-75.rdb我们可以看出，Redis确实是一直在备份的，且AOF的大小比RDB大</p><p>那我们继续看看这个redis的备份策略吧</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">save 300 10</span><br><span class="line">auto-aof-rewrite-percentage 30</span><br><span class="line">auto-aof-rewrite-min-size 64mb</span><br></pre></td></tr></table></figure><p>那么就说明了 每6分钟只要存在 10对kv发生了改变就会备份RDB文件</p><p>每当实时的AOF文件大小比上次重写的AOF文件大百分之30，就会重写AOF</p><p>对于一个经常发生更改的Redis来说</p><p>save 300 10的配置，每6分钟就要刷一次盘，这个配置真是让人窒息。</p><h1 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h1><h2 id="Redis-写磁盘出错-Cannot-allocate-memory"><a href="#Redis-写磁盘出错-Cannot-allocate-memory" class="headerlink" title="Redis 写磁盘出错 Cannot allocate memory"></a>Redis 写磁盘出错 Cannot allocate memory</h2><p>先查看Redis日志，发现存在大量报错</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1:M 03 Sep 02:55:23.877 # Can&#39;t rewrite append only file in background: fork: Cannot allocate memory</span><br><span class="line">1:M 03 Sep 02:55:23.978 * Starting automatic rewriting of AOF on 198% growth</span><br><span class="line">1:M 03 Sep 02:55:23.978 # Can&#39;t rewrite append only file in background: fork: Cannot allocate memory</span><br><span class="line">1:M 03 Sep 02:55:24.078 * 10 changes in 300 seconds. Saving...</span><br><span class="line">1:M 03 Sep 02:55:24.079 # Can&#39;t save in background: fork: Cannot allocate memory</span><br><span class="line">1:M 03 Sep 02:55:24.079 * Starting automatic rewriting of AOF on 198% growth</span><br><span class="line">1:M 03 Sep 02:55:24.079 # Can&#39;t rewrite append only file in background: fork: Cannot allocate memory</span><br><span class="line">1:M 03 Sep 02:55:24.179 * Starting automatic rewriting of AOF on 198% growth</span><br><span class="line">1:M 03 Sep 02:55:24.179 # Can&#39;t rewrite append only file in background: fork: Cannot allocate memory</span><br><span class="line">1:M 03 Sep 02:55:24.280 * Starting automatic rewriting of AOF on 198% growth</span><br></pre></td></tr></table></figure><p>google查看原因</p><p>异步回写(BGSAVE), 主进程fork后, 复制自身并通过这个新的进程回写磁盘, 回写结束后新进程自行关闭.</p><p>由于 BGSAVE 不需要主进程阻塞, 系统也不会假死, 一般会采用 BGSAVE 来实现数据回写.</p><h3 id="原因分析"><a href="#原因分析" class="headerlink" title="原因分析"></a>原因分析</h3><p>在离线作业运行过程中，随着list中数据量增加，Redis内存占用逐渐增加；</p><p>当系统剩余内存不足以fork子进程时，AOF重写子进程启动失败，此时错误log为“Can’t rewrite append only file in background: fork: Cannot allocate memory”，而用于父子进程通信的pipe不知什么原因没有关闭；</p><p>Redis不断尝试启动AOF重写子进程，终于在数小时后将允许的fd数耗尽，此时错误log为“Error opening /setting AOF rewrite IPC pipes: Numerical result out of range”；</p><p>与此同时，随着离线作业的完成，内存占用已经下降，但由于fd不足，AOF重写子进程还是不能启动；</p><h3 id="解决问题-1"><a href="#解决问题-1" class="headerlink" title="解决问题"></a>解决问题</h3><p>最后参考网上资料</p><p>不改代码的规避方案：</p><ul><li>设置linux系统的vm.overcommit_memory = 1（其意义可查阅man手册，本文不再展开），尽量减少子进程fork失败的情况；</li><li>设置Redis的maxmemory限制，当内存使用达到一定比例时不再接受新的数据；</li><li>使用主从备份，或bgsave持久化（RDB方式无此问题），关闭AOF持久化，等下一版本发布。</li></ul><p>首先Redis是maxmemory限制，同时说过领导要求不限制Redis的最大使用率，不考虑</p><p>目前Redis单机，改成主从或者集群不显示，不考虑</p><p>那么只有改vm.overcommit_memory了</p><p>这个涉及到了linux内核的知识</p><p>简单说下 vm.overcommit_memory这个参数</p><ul><li>vm.overcommit_memory = 1，直接放行</li><li>vm.overcommit_memory = 0：则比较 此次请求分配的虚拟内存大小和系统当前空闲的物理内存加上swap，决定是否放行。</li><li>vm.overcommit_memory = 2：则会比较进程所有已分配的虚拟内存加上此次请求分配的虚拟内存和系统当前的空闲物理内存加上swap，决定是否放行。</li></ul><p>那么查看服务器的配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sysctl -a|grep  vm.overcommit_memory</span><br><span class="line">vm.overcommit_memory &#x3D; 0</span><br></pre></td></tr></table></figure><p>将其改为1即可</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo echo &#39;vm.overcommit_memory &#x3D; 1&#39; &gt;&gt; &#x2F;etc&#x2F;sysctl.conf</span><br><span class="line">sudo sysctl -p</span><br></pre></td></tr></table></figure><h2 id="磁盘不够的问题"><a href="#磁盘不够的问题" class="headerlink" title="磁盘不够的问题"></a>磁盘不够的问题</h2><p>解决完上面一个问题，我发现Redis的日志开始重写了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">1:M 03 Sep 02:55:30.710 * Background append only file rewriting started by pid 3025</span><br><span class="line">1:M 03 Sep 03:19:51.718 * AOF rewrite child asks to stop sending diffs.</span><br><span class="line">3025:C 03 Sep 03:19:51.719 * Parent agreed to stop sending diffs. Finalizing AOF...</span><br><span class="line">3025:C 03 Sep 03:19:51.719 * Concatenating 18.88 MB of AOF diff received from parent.</span><br><span class="line">3025:C 03 Sep 03:19:51.871 * SYNC append only file rewrite performed</span><br><span class="line">3025:C 03 Sep 03:19:54.247 * AOF rewrite: 965 MB of memory used by copy-on-write</span><br><span class="line">1:M 03 Sep 03:19:57.266 * Background AOF rewrite terminated with success</span><br><span class="line">1:M 03 Sep 03:19:57.266 * Residual parent diff successfully flushed to the rewritten AOF (0.00 MB)</span><br><span class="line">1:M 03 Sep 03:19:57.266 * Background AOF rewrite finished successfully</span><br><span class="line">1:M 03 Sep 03:19:57.367 * 10 changes in 300 seconds. Saving...</span><br></pre></td></tr></table></figure><p>大概花了25分钟时间，才把100多G的文件备份下来</p><p>在第二次重写的时候我发现磁盘已经打满了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1:M 03 Sep 03:20:01.234 * Background saving started by pid 3032</span><br><span class="line">3032:C 03 Sep 03:40:25.708 * DB saved on disk</span><br><span class="line">3032:C 03 Sep 03:40:28.021 * RDB: 667 MB of memory used by copy-on-write</span><br><span class="line">1:M 03 Sep 03:40:30.921 * Background saving terminated with success</span><br><span class="line">1:M 03 Sep 03:45:31.094 * 10 changes in 300 seconds. Saving...</span><br><span class="line">1:M 03 Sep 03:45:35.168 * Background saving started by pid 3033</span><br><span class="line">3033:C 03 Sep 04:05:47.989 # Write error saving DB on disk: No space left on device</span><br></pre></td></tr></table></figure><p>因为RDB备份是在保存一份的情况，重写一个RDB文件，然后删除之前的文件。这就意味着在最高峰的时候你得存在2倍内存大小的磁盘文件，然后再加上一个AOF文件</p><p>也就是说如果内存中存了100G，你要保证磁盘空间大于130*3=390G 甚至更多。</p><h2 id="配置文件修改"><a href="#配置文件修改" class="headerlink" title="配置文件修改"></a>配置文件修改</h2><p>由于上面分析的混合存储的机制，不需要再单独备份RDB了，所以我们选择根本解决问题，关闭单独备份RDB策略。</p><p>将redis.conf文件save注释</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">save &quot;&quot;</span><br><span class="line"></span><br><span class="line">#save 900 1</span><br><span class="line">#save 300 10</span><br><span class="line">#save 60 10000</span><br></pre></td></tr></table></figure><p>但是没有重启redis（因为重启速度太慢了）</p><p>进入redis—cli</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; config set save &quot;&quot;</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><p>然后在redis存放文件的目录下删除已生成的文件 </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;data&#x2F;redis&#x2F;data$ rm -rf *.rdb</span><br></pre></td></tr></table></figure><p>tail -f redis-server.log</p><p>发现最后一次生成后，再不存在自动备份rdb的日志了</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>问题最终是解决了，ES已经可以正常工作了，复盘这个问题往往才是最让人成长的时刻。</p><p>关于这个案例，从定位到解决问题我分了3步</p><ul><li>开发人员反馈线上功能异常，查看代码文件发现ES不可用，分析原因是磁盘占用率超过百分之90导致</li><li>我收到这个异常反馈，进入服务器，查看服务器资源使用量，内存占用过高，磁盘占用快满了，简单查询资料，分析得出删除RDB文件并且关闭RDB持久化策略</li><li>通知同事，服务器会修复一段时间，可能造成停机的问题，完成异常修复</li></ul><h1 id="改进方案"><a href="#改进方案" class="headerlink" title="改进方案"></a>改进方案</h1><p>要成为一个SRE，这个问题的解决肯定不止于此。</p><p>运维站的角度越高，看的问题越清晰。</p><h2 id="第一层：增加硬盘"><a href="#第一层：增加硬盘" class="headerlink" title="第一层：增加硬盘"></a>第一层：增加硬盘</h2><p>由于Redis内存占用很高，备份文件磁盘也自然很大，所以我选择了加一块硬盘，然后将Redis的日志dir挂载到这块盘里。</p><p>步骤</p><ul><li>先添加一块硬盘并格式化</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">$ fdisk -l</span><br><span class="line">Disk &#x2F;dev&#x2F;sda: 7.3 TiB, 8001563222016 bytes, 15628053168 sectors</span><br><span class="line">Units: sectors of 1 * 512 &#x3D; 512 bytes</span><br><span class="line">Sector size (logical&#x2F;physical): 512 bytes &#x2F; 4096 bytes</span><br><span class="line">I&#x2F;O size (minimum&#x2F;optimal): 4096 bytes &#x2F; 4096 bytes</span><br><span class="line"></span><br><span class="line">$ fdisk &#x2F;dev&#x2F;sda </span><br><span class="line">$ mkfs.ext4 &#x2F;dev&#x2F;sda1</span><br><span class="line">$ mount &#x2F;dev&#x2F;sda1 &#x2F;data</span><br><span class="line"></span><br><span class="line">$ vim  &#x2F;etc&#x2F;fstab 添加一行开机自动挂载 </span><br><span class="line">&#x2F;dev&#x2F;sdb1 &#x2F;data ext4 defaults  0  2</span><br><span class="line"></span><br><span class="line">$ fdisk -l</span><br><span class="line">Disk &#x2F;dev&#x2F;sda: 7.3 TiB, 8001563222016 bytes, 15628053168 sectors</span><br><span class="line">Units: sectors of 1 * 512 &#x3D; 512 bytes</span><br><span class="line">Sector size (logical&#x2F;physical): 512 bytes &#x2F; 4096 bytes</span><br><span class="line">I&#x2F;O size (minimum&#x2F;optimal): 4096 bytes &#x2F; 4096 bytes</span><br><span class="line">Disklabel type: dos</span><br><span class="line">Disk identifier: 0xb95afa0a</span><br><span class="line"></span><br><span class="line">Device     Boot Start        End    Sectors Size Id Type</span><br><span class="line">&#x2F;dev&#x2F;sda1        2048 4294967294 4294965247   2T 83 Linux</span><br></pre></td></tr></table></figure><ul><li><p>将原来Redis存储文件放到新添加的硬盘里</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ mv &#x2F;opt&#x2F;redis&#x2F;data&#x2F; &#x2F;data&#x2F;redis&#x2F;</span><br><span class="line">$ df -h</span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">udev            126G     0  126G   0% &#x2F;dev</span><br><span class="line">tmpfs           26G   1.7G  24G    7% &#x2F;run</span><br><span class="line">&#x2F;dev&#x2F;sdc2       439G  104G  313G  25% &#x2F;</span><br><span class="line">&#x2F;dev&#x2F;sda1       2.0T  153G  1.8T   8% &#x2F;data</span><br></pre></td></tr></table></figure></li><li><p>重启redis，开启新生活吧~</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -ti -v &#x2F;data&#x2F;redis&#x2F;data:&#x2F;data&#x2F; -p 6379:6379 --name redis -d redis:4.0.14 &#x2F;usr&#x2F;local&#x2F;bin&#x2F;redis-server &#x2F;data&#x2F;redis.conf</span><br></pre></td></tr></table></figure><h2 id="第二层：单线程的Redis"><a href="#第二层：单线程的Redis" class="headerlink" title="第二层：单线程的Redis"></a>第二层：单线程的Redis</h2><p>我在观察redis.log时还发现一些异常，并且频率很高，抱着寻根问底的思想去查看这个问题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.</span><br></pre></td></tr></table></figure><p>google后发现<br>该错误可能会造成 redis server 上的处理延迟，而且客户端上也可能发生异常或连接超时。</p><p>这妥妥的是一个生产BUG啊</p><p>继续深入发现，这是因为启用了RDB SAVE 300 10</p><p>也就是每300秒出现10个kv更改就会刷盘的备份策略</p><p>造成的磁盘 I/O 负载高。</p><p>虽然这个问题已经被我解决了，但是我继续了解了Redis的内部机制后发现这其实是一个使用Redis不到位的缺陷。</p><p>大家往往使用Redis是因为Redis快——数据都是加载在内存中的，但是很少有人会深入了解Redis的实现逻辑。</p><p>Redis 是一个多路复用的单进程应用程序。多路，指的是多个网络地址，复用是指重复利用单个线程。</p><p>当打开持久化功能后， Redis 处理完每个事件后会调用 write(2) 将变化写入 kernel 的 buffer，如果此时 write(2) 被阻塞，Redis 就不能处理下一个事件。Linux 规定执行 write(2) 时，如果对同一个文件正在执行fdatasync(2)将 kernel buffer写入物理磁盘，或者有system wide sync在执行，write(2)会被Block住，整个Redis被Block住。</p><p>如果系统IO 繁忙，比如有别的应用在写盘，或者Redis自己在重写AOF 或备份RDB，就可能导致 fdatasync(2) 迟迟未能完成从而 Block 住 write(2)，Block 住整个 Redis。</p><p>为此Redis提供了一个自救的方式，当发现文件有在执行 fdatasync(2) 时，就先不调用 write(2)，只存在 cache 里，免得被 Block。但如果已经超过两秒都还是这个样子，则会硬着头皮执行 write(2)，即使 redis 会被 Block 住。此时那句要命的 log 会打印：”Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.”。之后用redis-cli INFO 可以看到 aof_delayed_fsync 的值被加1。因此，对于 fsync 设为 everysec 时丢失数据的可能性的最严谨说法是：如果有 fdatasync 在长时间的执行，此时 redis 意外关闭会造成文件里不多于两秒的数据丢失。如果 fdatasync 运行正常，redis 意外关闭没有影响，只有当操作系统 crash 时才会造成少于1秒的数据丢失。</p><p>这个问题还是比较难理解的，我总结下即使是AOF开启了everysec：秒级备份，仍然会丢数据的问题，是由于存在磁盘IO过高造成请求堵塞的情况。</p><p>而网上对这个问题给出的解决意见也很真实</p><p>参考文献<br><a href="https://segmentfault.com/a/1190000016096933" target="_blank" rel="noopener">关于Redis的aof持久化的二三事</a></p><ul><li>关闭 RDB 或 AOF 持久化</li></ul><p>而已经开启了混合持久化策略的Redis直接关闭RDB备份即可解决</p><ul><li>从操作系统层面优化：修改内核参数</li></ul><p>又到了学习linux内核参数的时候了，哈哈</p><p>AOF rewrite是一直埋头的调用 write(2)，由系统自己去触发 sync。</p><p>默认配置vm.dirty_background_ratio=10，也就是占用了 10% 的可用内存才会开始后台 flush，256*10%=25.6G</p><p>很明显一次flush太多数据会造成堵塞</p><p>看了下网上的建议都是将刷新大小写为32M</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ sysctl -a | grep dirty_background_ratio</span><br><span class="line">vm.dirty_background_ratio &#x3D; 10</span><br><span class="line"> </span><br><span class="line">$ sysctl -a | grep vm.dirty_bytes</span><br><span class="line">vm.dirty_bytes &#x3D; 0</span><br><span class="line"></span><br><span class="line">$ echo &quot;vm.dirty_bytes&#x3D;33554432&quot; &gt;&gt; &#x2F;etc&#x2F;sysctl.conf</span><br></pre></td></tr></table></figure><h2 id="第三层：从技术选型上思考"><a href="#第三层：从技术选型上思考" class="headerlink" title="第三层：从技术选型上思考"></a>第三层：从技术选型上思考</h2><p>这一层其实是最难的，我在思考为什么Redis会存上百G的文件，还是用的单机Docker安装的。同事告诉我Redis是存图片，我寻思存图片不是用文件存储服务器吗（比如阿里云的OSS、AWS的S3、或者本地自建的文件系统）？同事告诉我图片是存储在AWS的S3上的，但是应用程序在国内，直接访问图片速度很慢</p><p>后来了解到，由于架构需要，中美之间的网络传输速度慢、不稳定，导致应用服务不能直接从S3访问，而且AWS的CDN也没有开放国内的站点加速，一张图片20多M加载速度慢，确实很难处理。</p><p>而且程序传图片一般是在国内晚上，从S3上拉图片经过程序最终存到Redis里，然后在白天的时候，项目人员可以直接访问Redis里的图片，速度会比直接从S3访问快很多。</p><p>但是用Redis太浪费资源了，一台32c 256g的服务器就装了Redis，作为一个特别喜欢薅羊毛的运维工程师，我对此表示：真的有钱。</p><p>因此我查看了网上的资料，得出2个解决此问题的办法</p><ul><li>增加公司网络带宽，硬方法处理</li><li>本地自建文件存储系统，用图片缓存功能，保证用户每次请求同样的资源不用去Redis里读取，而应该直接读图片缓存服务器，最经典的例子就是Nginx做静态资源服务器。</li></ul><p>第三层的处理过程我们留在下期运维实践里细说吧</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://redis.io/topics/persistence" target="_blank" rel="noopener">Redis官网持久化说明</a></p><p><a href="https://www.cnblogs.com/wdliu/p/9377278.html" target="_blank" rel="noopener">Redis4.0深入持久化</a></p><p><a href="https://zhuanlan.zhihu.com/p/39412293" target="_blank" rel="noopener">Redis持久化方案该如何选型</a></p><p><a href="https://www.jianshu.com/p/d03216c0150b" target="_blank" rel="noopener">Redis 写磁盘出错 Cannot allocate memory</a></p><p><a href="https://segmentfault.com/a/1190000016096933" target="_blank" rel="noopener">关于Redis的aof持久化的二三事</a></p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operation Manual </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Centos7安装NVIDIA显卡驱动和CUDA以及Docker-GPU环境</title>
      <link href="2020/08/28/gpu/nvidia-install/"/>
      <url>2020/08/28/gpu/nvidia-install/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>领导有需求让在AWS上买一台GPU的服务器，进行安装部署3D建模项目的集成开发环境</p><h1 id="安装NVIDIA显卡驱动和CUDA"><a href="#安装NVIDIA显卡驱动和CUDA" class="headerlink" title="安装NVIDIA显卡驱动和CUDA"></a>安装NVIDIA显卡驱动和CUDA</h1><p>我购买了一台g3s.xlarge型号的ec2，选择centos7 配置好网络、磁盘、安全组和标签就准备开机安装了</p><h2 id="查看显卡型号"><a href="#查看显卡型号" class="headerlink" title="查看显卡型号"></a>查看显卡型号</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@loaclhost ~]# yum install pciutils -y</span><br><span class="line">[root@loaclhost ~]# lspci | grep -i NVIDIA</span><br><span class="line">00:1e.0 VGA compatible controller: NVIDIA Corporation GM204GL [Tesla M60] (rev a1)</span><br></pre></td></tr></table></figure><p>Google后发现</p><p>NVIDIA® Tesla® GPU是适用于服务器的 TESLA 数据中心的 GPU</p><p>它可以更快速地处理要求最严格的高性能计算 (HPC) 和超大规模数据中心工作负载。</p><h2 id="在Linux实例上安装NVIDIA-GRID驱动程序"><a href="#在Linux实例上安装NVIDIA-GRID驱动程序" class="headerlink" title="在Linux实例上安装NVIDIA GRID驱动程序"></a>在Linux实例上安装NVIDIA GRID驱动程序</h2><h3 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h3><p>安装NVIDIA GRID驱动程序的依赖以及AWS CLI</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">yum update -y</span><br><span class="line">yum install -y lrzsz vim wget ntpdate yum-utils zip unzip tree  gcc gcc-c++  epel-release telnet traceroute </span><br><span class="line">curl &quot;https:&#x2F;&#x2F;awscli.amazonaws.com&#x2F;awscli-exe-linux-x86_64.zip&quot; -o &quot;awscliv2.zip&quot;</span><br><span class="line">unzip awscliv2.zip</span><br><span class="line">sudo .&#x2F;aws&#x2F;install</span><br><span class="line">reboot</span><br></pre></td></tr></table></figure><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>配置AWS并确保IAM用户必须具有AmazonS3ReadOnlyAccess 策略授予的权限。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws configure</span><br></pre></td></tr></table></figure><p>为您当前正在运行的内核版本安装gcc编译器和内核头文件包。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y gcc kernel-devel-$(uname -r)</span><br></pre></td></tr></table></figure><p>禁用nouveauNVIDIA图形卡的开源驱动程序。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">添加nouveau到 &#x2F;etc&#x2F;modprobe.d&#x2F;blacklist.conf黑名单文件。</span><br><span class="line">cat &lt;&lt; EOF | sudo tee --append &#x2F;etc&#x2F;modprobe.d&#x2F;blacklist.conf</span><br><span class="line">blacklist vga16fb</span><br><span class="line">blacklist nouveau</span><br><span class="line">blacklist rivafb</span><br><span class="line">blacklist nvidiafb</span><br><span class="line">blacklist rivatv</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">编辑&#x2F;etc&#x2F;default&#x2F;grub文件并添加以下行：</span><br><span class="line">GRUB_CMDLINE_LINUX&#x3D;&quot;rdblacklist&#x3D;nouveau&quot;</span><br><span class="line"></span><br><span class="line">重建Grub配置</span><br><span class="line">grub2-mkconfig -o &#x2F;boot&#x2F;grub2&#x2F;grub.cfg</span><br></pre></td></tr></table></figure><h3 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">下载GRID驱动程序安装实用程序</span><br><span class="line">aws s3 cp --recursive s3:&#x2F;&#x2F;ec2-linux-nvidia-drivers&#x2F;latest&#x2F; .</span><br><span class="line">chmod +x NVIDIA-Linux-x86_64*.run</span><br><span class="line">sudo &#x2F;bin&#x2F;sh .&#x2F;NVIDIA-Linux-x86_64*.run</span><br><span class="line">reboot</span><br></pre></td></tr></table></figure><p>出现提示时，接受许可协议并根据需要指定安装选项</p><p>安装过程中一些选项</p><ul><li>The distribution-provided pre-install script failed! Are you sure you want to continue? </li></ul><p>选择 yes 继续。</p><ul><li>Would you like to register the kernel module souces with DKMS? This will allow DKMS to automatically build a new module, if you install a different kernel later? </li></ul><p>选择 No 继续。</p><ul><li>Nvidia’s 32-bit compatibility libraries?</li></ul><p>选择 No 继续。</p><ul><li>Would you like to run the nvidia-xconfigutility to automatically update your x configuration so that the NVIDIA x driver will be used when you restart x? Any pre-existing x confile will be backed up.</li></ul><p>选择 Yes 继续</p><p>部署完成后执行说明安装成功</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@ ~]# nvidia-smi </span><br><span class="line">Thu Aug 27 06:15:12 2020       </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 450.51.05    Driver Version: 450.51.05    CUDA Version: 11.0     |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage&#x2F;Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                               |                      |               MIG M. |</span><br><span class="line">|&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|</span><br><span class="line">|   0  Tesla M60           On   | 00000000:00:1E.0 Off |                    0 |</span><br><span class="line">| N&#x2F;A   33C    P8    15W &#x2F; 150W |      0MiB &#x2F;  7618MiB |      0%      Default |</span><br><span class="line">|                               |                      |                  N&#x2F;A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">                                                                               </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                  |</span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span><br><span class="line">|        ID   ID                                                   Usage      |</span><br><span class="line">|&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|</span><br><span class="line">|  No running processes found                                                 |</span><br></pre></td></tr></table></figure><h1 id="运行3D程序"><a href="#运行3D程序" class="headerlink" title="运行3D程序"></a>运行3D程序</h1><p>目前公司的3D项目可以已经用Docker部署，查阅docker官网发现docker在19版本后在docker run –gpus all 即可(表示使用所有的gpu，如果要使用2个gpu：–gpus 2，也可直接指定哪几个卡：–gpus ‘“device=1,2”’</p><p>在docker19之前需要单独下载nvidia-docker1或nvidia-docker2来启动容器</p><p>目前最新的docker版本是19.03.12，即不需要额外安装nvidia-docker</p><h2 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@ ~]# yum install -y yum-utils </span><br><span class="line">[root@ ~]# yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https:&#x2F;&#x2F;download.docker.com&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo</span><br><span class="line">[root@ ~]# yum install -y docker-ce docker-ce-cli containerd.io</span><br><span class="line">[root@ ~]# systemctl start docker</span><br><span class="line">[root@ ~]# docker -v</span><br><span class="line">Docker version 19.03.12, build 48a66213fe</span><br></pre></td></tr></table></figure><h2 id="安装GPU容器运行时"><a href="#安装GPU容器运行时" class="headerlink" title="安装GPU容器运行时"></a>安装GPU容器运行时</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">distribution&#x3D;$(. &#x2F;etc&#x2F;os-release;echo $ID$VERSION_ID)</span><br><span class="line">curl -s -L https:&#x2F;&#x2F;nvidia.github.io&#x2F;nvidia-docker&#x2F;$distribution&#x2F;nvidia-docker.repo | sudo tee &#x2F;etc&#x2F;yum.repos.d&#x2F;nvidia-docker.repo</span><br><span class="line"></span><br><span class="line">sudo yum install -y nvidia-container-toolkit</span><br><span class="line">sudo systemctl restart docker</span><br></pre></td></tr></table></figure><h2 id="验证docker可以使用GPU"><a href="#验证docker可以使用GPU" class="headerlink" title="验证docker可以使用GPU"></a>验证docker可以使用GPU</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">docker run --help | grep -i gpus</span><br><span class="line">      --gpus gpu-request               GPU devices to add to the container (&#39;all&#39; to pass all GPUs)</span><br><span class="line">      </span><br><span class="line">docker run -it --rm --gpus all ubuntu nvidia-smi</span><br><span class="line">Thu Aug 27 09:57:43 2020       </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| NVIDIA-SMI 450.51.05    Driver Version: 450.51.05    CUDA Version: N&#x2F;A      |</span><br><span class="line">|-------------------------------+----------------------+----------------------+</span><br><span class="line">| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |</span><br><span class="line">| Fan  Temp  Perf  Pwr:Usage&#x2F;Cap|         Memory-Usage | GPU-Util  Compute M. |</span><br><span class="line">|                               |                      |               MIG M. |</span><br><span class="line">|&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;+&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|</span><br><span class="line">|   0  Tesla M60           On   | 00000000:00:1E.0 Off |                    0 |</span><br><span class="line">| N&#x2F;A   32C    P8    15W &#x2F; 150W |      0MiB &#x2F;  7618MiB |      0%      Default |</span><br><span class="line">|                               |                      |                  N&#x2F;A |</span><br><span class="line">+-------------------------------+----------------------+----------------------+</span><br><span class="line">                                                                               </span><br><span class="line">+-----------------------------------------------------------------------------+</span><br><span class="line">| Processes:                                                                  |</span><br><span class="line">|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |</span><br><span class="line">|        ID   ID                                                   Usage      |</span><br><span class="line">|&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;|</span><br><span class="line">|  No running processes found                                                 |</span><br><span class="line">+-----------------------------------------------------------------------------+</span><br></pre></td></tr></table></figure><p>说明可以运行</p><h1 id="报错总结"><a href="#报错总结" class="headerlink" title="报错总结"></a>报错总结</h1><p>执行sudo /bin/sh ./NVIDIA-Linux-x86_64*.run时报错</p><h2 id="Nouveau-kernel-driver"><a href="#Nouveau-kernel-driver" class="headerlink" title="Nouveau kernel driver"></a>Nouveau kernel driver</h2><p>ERROR: The Nouveau kernel driver is currently in use by your system.  This driver is incompatible with the NVIDIA driver, and must be disabled before proceeding.  Please consult<br>         the NVIDIA driver README and your Linux distribution’s documentation for details on how to correctly disable the Nouveau kernel driver. </p><p>这个驱动正在被系统使用,这个驱动和Nvidia驱动冲突,要想继续安装,则必须禁用此驱动！因为centos 系统默认装的显卡驱动就是Nouveau .　Nouveau是一个由爱好者组织的针对NVIDIA显卡开发第三方开源3D驱动的共同项目，并且Nouveau是在完全没有得到NVIDIA任何支 持的情况下进行开发的，Nouveau算是X.Org基金会的一个项目.</p><p>解决办法如下：</p><p>即关闭Nouveau：         </p><p>检查nouveau driver确保没有被加载！</p><p>lsmod | grep nouveau</p><h2 id="安装完GPU容器运行时报错"><a href="#安装完GPU容器运行时报错" class="headerlink" title="安装完GPU容器运行时报错"></a>安装完GPU容器运行时报错</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@ ~]# docker run -it --rm --gpus all ubuntu nvidia-smi</span><br><span class="line">Unable to find image &#39;ubuntu:latest&#39; locally</span><br><span class="line">latest: Pulling from library&#x2F;ubuntu</span><br><span class="line">54ee1f796a1e: Pull complete </span><br><span class="line">f7bfea53ad12: Pull complete </span><br><span class="line">46d371e02073: Pull complete </span><br><span class="line">b66c17bbf772: Pull complete </span><br><span class="line">Digest: sha256:31dfb10d52ce76c5ca0aa19d10b3e6424b830729e32a89a7c6eee2cda2be67a5</span><br><span class="line">Status: Downloaded newer image for ubuntu:latest</span><br><span class="line">docker: Error response from daemon: could not select device driver &quot;&quot; with capabilities: [[gpu]].</span><br></pre></td></tr></table></figure><p>解决办法，重启docker</p><p>systemctl restart docker</p><p>如果还不行，说明你没有安装GPU容器运行时</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/install-nvidia-driver.html#nvidia-GRID-driver" target="_blank" rel="noopener">在Linux实例上安装NVIDIA驱动程序</a></p><p><a href="https://github.com/NVIDIA/nvidia-docker" target="_blank" rel="noopener">nvidia-docker</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> NVIDIA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> NVIDIA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维手册——Mysql索引字段长度太长报错</title>
      <link href="2020/08/22/bug/mysql-key-long/"/>
      <url>2020/08/22/bug/mysql-key-long/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>Mysql执行Create Table语句时报错</p><p>Specified key was too long; max key length is 1536 bytes</p><h1 id="问题分析"><a href="#问题分析" class="headerlink" title="问题分析"></a>问题分析</h1><p>之前遇到过报错信息“ERROR 1071 (42000): Specified key was too long; max key length is 767 bytes”，其实意思就是“索引字段长度太长，超过了767bytes”。</p><p>mysql的varchar主键只支持不超过767个字节或者768/2=384个双字节 或者767/3=255个三字节的字段 而GBK是双字节的，UTF8是三字节的。</p><p>可是这次居然超过了这个长度1536，仔细发现1536/2=768 为什么是768？</p><p>然后我仔细看了下DDL语句</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE &#96;QRTZ_BLOB_TRIGGERS&#96; (</span><br><span class="line">  &#96;SCHED_NAME&#96; varchar(120) COLLATE utf8mb4_unicode_ci NOT NULL,</span><br><span class="line">  &#96;TRIGGER_NAME&#96; varchar(190) COLLATE utf8mb4_unicode_ci NOT NULL,</span><br><span class="line">  &#96;TRIGGER_GROUP&#96; varchar(190) COLLATE utf8mb4_unicode_ci NOT NULL,</span><br><span class="line">  &#96;BLOB_DATA&#96; mediumblob,</span><br><span class="line">  PRIMARY KEY (&#96;SCHED_NAME&#96;,&#96;TRIGGER_NAME&#96;,&#96;TRIGGER_GROUP&#96;) USING BTREE,</span><br><span class="line">  KEY &#96;SCHED_NAME&#96; (&#96;SCHED_NAME&#96;,&#96;TRIGGER_NAME&#96;,&#96;TRIGGER_GROUP&#96;) USING BTREE,</span><br><span class="line">  CONSTRAINT &#96;QRTZ_BLOB_TRIGGERS_ibfk_1&#96; FOREIGN KEY (&#96;SCHED_NAME&#96;, &#96;TRIGGER_NAME&#96;, &#96;TRIGGER_GROUP&#96;) REFERENCES &#96;QRTZ_TRIGGERS&#96; (&#96;SCHED_NAME&#96;, &#96;TRIGGER_NAME&#96;, &#96;TRIGGER_GROUP&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8mb4 COLLATE&#x3D;utf8mb4_unicode_ci ROW_FORMAT&#x3D;DYNAMIC;</span><br></pre></td></tr></table></figure><p>我的天，这个联合索引居然长度一共是500个字符，为什么会这么表结构呢？感觉不伦不类，开发同事回复说是引用第三方表的DDL，好吧，为了保持这个表结构，我只能从数据库底层优化查起。</p><p>因为 InnoDB 表引擎的限制：</p><p>默认情况下，索引前缀长度限制为 767 字节，当开启了 innodb_large_prefix 选项时，索引前缀长度扩展到 3072 字节。</p><p>查询资料发现直接下面语句即可更改</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set global innodb_large_prefix&#x3D;1;</span><br><span class="line">set global innodb_file_format&#x3D;BARRACUDA;</span><br></pre></td></tr></table></figure><p>补充一个额外知识</p><p>如果表的字符集是 utf8mb4 时，一个字符将占用 4 个字节。这意味着这个表的索引需要占500*4=2000个字节 超过了1536，然后我们再来看看1536是怎么来的。</p><p>由于之前优化过my.cnf,其中有这么一个参数innodb_page_size<br>我设置的是8kb</p><p>innodb_page_size 选项默认是 16KB 的时候，最长索引前缀长度是 3072 字节，如果是 8KB 的时候，最长索引前缀长度是 1536 字节，4KB 的时候，是 768 字节。</p><h1 id="解决问题"><a href="#解决问题" class="headerlink" title="解决问题"></a>解决问题</h1><ul><li>修改DDL语句</li></ul><p>解决根本原因，即使用的是第三方提供的，明明有问题为啥不尝试改改呢？</p><ul><li><p>更改innodb_large_prefix，不需要重启数据库</p></li><li><p>更改innodb_page_size，需要重启数据库</p></li></ul><p>其中第三种方法又引出了另一个问题，重启Mysql报错</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Data file &#39;.&#x2F;ibdata1&#39; uses page size 8192, but the innodb_page_size start-up parameter is 16384</span><br></pre></td></tr></table></figure><p>查找网上资料发现原因</p><p>当innodb已经运行时，innodb_page_size为只读，因为必须在启动InnoDB之前设置该参数，并创建一个新的表空间系统。当InnoDB在数据目录中找不到ibdata1时，会发生这种情况。</p><p>解决办法：</p><p>备份原数据库，重建数据库，在启动命令的etc/my.cnf里添加innodb_page_size的值，启动，导入原数据库。（其实这种方法很蠢，但是当前数据库是测试环境的，所以这样操作没啥问题，要是生产出现这个问题，只能GG）</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://bugs.mysql.com/bug.php?id=88746" target="_blank" rel="noopener">错误＃88746    简化InnoDB页面大小的配置</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
            <tag> Operation Manual </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Centos7安装Nodejs-v12.6.0</title>
      <link href="2020/08/22/nodejs/nodejs-install/"/>
      <url>2020/08/22/nodejs/nodejs-install/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="安装Nodejs"><a href="#安装Nodejs" class="headerlink" title="安装Nodejs"></a>安装Nodejs</h1><p><a href="https://nodejs.org/en/" target="_blank" rel="noopener">Nodejs官网下载</a></p><p><a href="https://nodejs.org/dist/" target="_blank" rel="noopener">Nodejs列表</a></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt</span><br><span class="line">wget https:&#x2F;&#x2F;nodejs.org&#x2F;dist&#x2F;v12.6.0&#x2F;node-v12.6.0-linux-x64.tar.gz</span><br><span class="line">tar -zxvf node-v12.6.0-linux-x64.tar.gz</span><br><span class="line">mv node-v12.6.0-linux-x64 nodejs</span><br><span class="line">ln -s &#x2F;opt&#x2F;nodejs&#x2F;bin&#x2F;npm &#x2F;usr&#x2F;local&#x2F;bin&#x2F;</span><br><span class="line">ln -s &#x2F;opt&#x2F;nodejs&#x2F;bin&#x2F;node &#x2F;usr&#x2F;local&#x2F;bin&#x2F;</span><br><span class="line"></span><br><span class="line"># 查看安装的版本</span><br><span class="line">[root@localhost]# node -v</span><br><span class="line">v12.6.0</span><br><span class="line">[root@localhost]# npm -v </span><br><span class="line">6.9.0</span><br></pre></td></tr></table></figure><h1 id="nodejs-install报错"><a href="#nodejs-install报错" class="headerlink" title="nodejs install报错"></a>nodejs install报错</h1><h2 id="执行npm-istall-命令时，出现了npm-ERR-cb-never-called-错误"><a href="#执行npm-istall-命令时，出现了npm-ERR-cb-never-called-错误" class="headerlink" title="执行npm istall 命令时，出现了npm ERR! cb() never called!错误"></a>执行npm istall 命令时，出现了npm ERR! cb() never called!错误</h2><p>解决方案：清除npm缓存</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm ERR! cb() never called!</span><br></pre></td></tr></table></figure><h2 id="打包出现node-modules-node-sass-vendor文件夹permission-denied权限不足的问题"><a href="#打包出现node-modules-node-sass-vendor文件夹permission-denied权限不足的问题" class="headerlink" title="打包出现node_modules/node-sass/vendor文件夹permission denied权限不足的问题"></a>打包出现node_modules/node-sass/vendor文件夹permission denied权限不足的问题</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">node-sass@4.13.1 install &#x2F;starlab&#x2F;www&#x2F;cloudtest&#x2F;node_modules&#x2F;node-sass</span><br><span class="line">&gt; node scripts&#x2F;install.js</span><br><span class="line"></span><br><span class="line">Unable to save binary &#x2F;starlab&#x2F;www&#x2F;cloudtest&#x2F;node_modules&#x2F;node-sass&#x2F;vendor&#x2F;linux-x64-64 : &#123; Error: EACCES: permission denied, mkdir &#39;&#x2F;starlab&#x2F;www&#x2F;cloudtest&#x2F;node_modules&#x2F;node-sass&#x2F;vendor&#39;</span><br><span class="line">    at Object.mkdirSync (fs.js:757:3)</span><br><span class="line">    at sync (&#x2F;starlab&#x2F;www&#x2F;cloudtest&#x2F;node_modules&#x2F;mkdirp&#x2F;index.js:71:13)</span><br><span class="line">    at Function.sync (&#x2F;starlab&#x2F;www&#x2F;cloudtest&#x2F;node_modules&#x2F;mkdirp&#x2F;index.js:77:24)</span><br><span class="line">    at checkAndDownloadBinary (&#x2F;starlab&#x2F;www&#x2F;cloudtest&#x2F;node_modules&#x2F;node-sass&#x2F;scripts&#x2F;install.js:114:11)</span><br><span class="line">    at Object.&lt;anonymous&gt; (&#x2F;starlab&#x2F;www&#x2F;cloudtest&#x2F;node_modules&#x2F;node-sass&#x2F;scripts&#x2F;install.js:157:1)</span><br><span class="line">    at Module._compile (internal&#x2F;modules&#x2F;cjs&#x2F;loader.js:778:30)</span><br><span class="line">    at Object.Module._extensions..js (internal&#x2F;modules&#x2F;cjs&#x2F;loader.js:789:10)</span><br><span class="line">    at Module.load (internal&#x2F;modules&#x2F;cjs&#x2F;loader.js:653:32)</span><br><span class="line">    at tryModuleLoad (internal&#x2F;modules&#x2F;cjs&#x2F;loader.js:593:12)</span><br><span class="line">    at Function.Module._load (internal&#x2F;modules&#x2F;cjs&#x2F;loader.js:585:3)</span><br><span class="line">  errno: -13,</span><br><span class="line">  syscall: &#39;mkdir&#39;,</span><br><span class="line">  code: &#39;EACCES&#39;,</span><br><span class="line">  path: &#39;&#x2F;starlab&#x2F;www&#x2F;cloudtest&#x2F;node_modules&#x2F;node-sass&#x2F;vendor&#39; &#125;</span><br></pre></td></tr></table></figure><p>首先造成这个问题的原因是：<br>npm会有生命周期，某个包会有生命周期来执行一些东西，安全起见会自动降级导致没有权限执行一些操作，通过–unsafe-perm参数来解锁该限制。</p><p>npm lifecycle 命令在执行前，会判断配置unsafe-perm为true 时才继续，否则会提前退出。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; lib&#x2F;utils&#x2F;lifecycle.js</span><br><span class="line">   unsafe &#x3D; unsafe || npm.config.get(&#39;unsafe-perm&#39;)</span><br><span class="line">   if ((wd.indexOf(npm.dir) !&#x3D;&#x3D; 0 || _incorrectWorkingDirectory(wd, pkg)) &amp;&amp; !unsafe &amp;&amp; pkg.scripts[stage]) &#123;</span><br><span class="line">     log.warn(&#39;lifecycle&#39;, logid(pkg, stage), &#39;cannot run in wd&#39;,</span><br><span class="line">       &#39;%s %s (wd&#x3D;%s)&#39;, pkg._id, pkg.scripts[stage], wd</span><br><span class="line">     )</span><br><span class="line">     return cb()</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>配置的读取顺序大致参考：npm-config，即cli -&gt; env -&gt; npmrc -&gt; default。</p><p>default中关于unsafe-perm的初始化如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; lib&#x2F;config&#x2F;defaults.js</span><br><span class="line">    &#39;unsafe-perm&#39;: process.platform &#x3D;&#x3D;&#x3D; &#39;win32&#39; ||</span><br><span class="line">                     process.platform &#x3D;&#x3D;&#x3D; &#39;cygwin&#39; ||</span><br><span class="line">                     !(process.getuid &amp;&amp; process.setuid &amp;&amp;</span><br><span class="line">                       process.getgid &amp;&amp; process.setgid) ||</span><br><span class="line">                     process.getuid() !&#x3D;&#x3D; 0</span><br></pre></td></tr></table></figure><p>针对unix 平台，使用root 用户执行npm 命令时得到的默认值都会是false。</p><p>解决办法：</p><p>临时解决：npm install –unsafe-perm</p><p>永久解决：npm config set unsafe-perm true</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://www.cnblogs.com/chrissong/p/10961521.html" target="_blank" rel="noopener">node-sass安装失败的问题 stack Error: EACCES: permission denied, mkdir</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Nodejs </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nodejs </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>安装AWS CLI及配置</title>
      <link href="2020/08/21/aws/aws-install/"/>
      <url>2020/08/21/aws/aws-install/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第二家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>AWS Command Line Interface（AWS CLI）是一个开源工具，使您能够使用命令行外壳中的命令与AWS服务进行交互。通过最少的配置，AWS CLI使您能够从您喜欢的终端程序中的命令提示符处启动运行与基于浏览器的AWS管理控制台提供的功能等效的命令。</p><p>目前公司很多云平台组件的控制方法都是基于AWS CLI（写在自动化脚本里）完成的</p><h1 id="安装AWS-CLI版本2"><a href="#安装AWS-CLI版本2" class="headerlink" title="安装AWS CLI版本2"></a>安装AWS CLI版本2</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">curl &quot;https:&#x2F;&#x2F;awscli.amazonaws.com&#x2F;awscli-exe-linux-x86_64.zip&quot; -o &quot;awscliv2.zip&quot;</span><br><span class="line">unzip awscliv2.zip</span><br><span class="line">sudo .&#x2F;aws&#x2F;install</span><br></pre></td></tr></table></figure><h1 id="使用get-login-password将Docker认证到Amazon-ECR注册表"><a href="#使用get-login-password将Docker认证到Amazon-ECR注册表" class="headerlink" title="使用get-login-password将Docker认证到Amazon ECR注册表"></a>使用get-login-password将Docker认证到Amazon ECR注册表</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">aws ecr get-login-password --region region | docker login --username AWS --password-stdin aws_account_id.dkr.ecr.region.amazonaws.com</span><br></pre></td></tr></table></figure><h1 id="使用AWS-Configure快速配置"><a href="#使用AWS-Configure快速配置" class="headerlink" title="使用AWS Configure快速配置"></a>使用AWS Configure快速配置</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ aws configure</span><br><span class="line">AWS Access Key ID [None]: AKIAIOSFODNN7EXAMPLE</span><br><span class="line">AWS Secret Access Key [None]: wJalrXUtnFEMI&#x2F;K7MDENG&#x2F;bPxRfiCYEXAMPLEKEY</span><br><span class="line">Default region name [None]: us-west-2</span><br><span class="line">Default output format [None]: json</span><br></pre></td></tr></table></figure><p>访问密钥ID和秘密访问密钥<br>访问密钥由访问密钥ID和秘密访问密钥组成，用于签署您对AWS发出的编程请求。如果您没有访问密钥，则可以从AWS管理控制台中创建它们。最佳做法是，不要对不需要执行任何任务的任务使用AWS账户root用户访问密钥。而是 使用您自己的访问密钥创建一个新的管理员IAM用户。</p><p>创建密钥时，唯一可以查看或下载秘密访问密钥的时间。您以后将无法恢复它们。但是，您可以随时创建新的访问密钥。您还必须具有执行所需的IAM操作的权限。有关更多信息，请参阅 《IAM用户指南》中的访问IAM资源所需的权限。</p><h1 id="个人资料"><a href="#个人资料" class="headerlink" title="个人资料"></a>个人资料</h1><p>设置的集合称为配置文件。默认情况下，AWS CLI使用 default配置文件。您可以通过指定–profile选项并分配名称来创建和使用具有不同凭据和设置的其他命名配置文件。配置文件存放在$HOME/.aws/下</p><p>以下示例创建一个名为的配置文件produser。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ aws configure --profile produser</span><br><span class="line">AWS Access Key ID [None]: AKIAI44QH8DHBEXAMPLE</span><br><span class="line">AWS Secret Access Key [None]: je7MtGbClwBF&#x2F;2Zp9Utk&#x2F;h3yCo8nvbEXAMPLEKEY</span><br><span class="line">Default region name [None]: us-east-1</span><br><span class="line">Default output format [None]: text</span><br></pre></td></tr></table></figure><p>然后，您可以指定a 并使用以该名称存储的凭据和设置。 –profile profilename</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ aws s3 ls --profile produser</span><br></pre></td></tr></table></figure><p>要更新这些设置，请aws configure再次运行（有无 –profile参数，取决于您要更新的配置文件），然后根据需要输入新值。下一节包含有关aws configure创建的文件，其他设置和命名的配置文件的更多信息。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html" target="_blank" rel="noopener">配置AWS CLI</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> AWS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> AWS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>顶级理解之天下没有不散的筵席</title>
      <link href="2020/08/04/king/king-job-hopping/"/>
      <url>2020/08/04/king/king-job-hopping/</url>
      
        <content type="html"><![CDATA[<blockquote><p>踏出熟悉的公司大门，我回头，知道以后应该不会经常回来，抬手，拍照，朋友圈里，我留下了“莫愁前路无知己，天下谁人不识君”的文字。              -《  <a href="http://wuwenliang.net/" target="_blank" rel="noopener">精诚所至,我的跳槽之路</a>》</p></blockquote><p>这是一位前公司JAVA大牛在离职前的感概，我们虽然只一起处过短短两天，但是我一直以他为榜样。</p><p>再见了，老东家，再见了，武汉，我开启我的南漂之旅——深圳。</p><hr><p>2020年注定不平凡，疫情在武汉爆发，我周围有很多朋友因此失业了，也有不少朋友因新行业崛起而发财的，还有如我一般在家里浑浑噩噩度过了2个月的。</p><p>疫情之后复工的一个星期，我的导师离职，然后公司离职的人接连不断，我出于本能地慌了，突然在思考为什么会出现这种情况。</p><p>我的目标在哪？</p><p>我的希望在哪？</p><p>我的未来在哪？</p><p>我才发现我根本不知道</p><p>我也曾想着学这位大牛一样跑，但是一年的工作经验让我觉得看似会的东西很多，实际在没有总结和系统性复习的情况下，根本没有人会要我。</p><p>5月4日，我有幸看到了《后浪》</p><p>国家一级演员何冰登台演讲，认可、赞美与寄语年轻一代：“你们有幸遇见这样的时代，但时代更有幸遇见这样的你们。” </p><p>我才发现，原来，世界上有那么多美好的事情等着我们去做，世界上有那么多条路供我们选择，我们真的很幸运。</p><p>从那天起，我开始寻找财富密码。</p><p>那段时间我接受了很多新思想、新知识、新文化，但是我始终在犹豫，对公司依旧抱有涨薪幻想，最终，这个幻想被不断地打破，最终我确定了一个小目标，那就是一定要去找一个更能肯定我价值，能提供更高平台的公司。</p><p>为此我制定了一系列方案（包括城市、公司类型、公司技术选型、发展空间、个人价值的肯定等等）</p><p>我参考大佬的博客给自己制定了一个个模块复习</p><ul><li>容器编排：深入了解docker、kubernetes底层知识、常用运维命令以及实战的案例总结</li><li>网络协议：重点复习OSI、TCP/IP协议、路由交换、子网划分、容器网络</li><li>Linux：重点复习Linux常用命令、内核、防火墙</li><li>负载均衡、中间件：Nginx、LVS、MQ几乎是必考题</li><li>Mysql：重点看索引、锁、MVCC、优化、备份、监控</li><li>CI/CD：重点复习gitlab、jenkins、ansible</li><li>监控：复习prometheus（顺便说下，zabbix已过时，可以说拜拜了）</li><li>日志系统：简单了解ELK和各种云产品的日志服务安装配置即可</li><li>运维手册：积累运维排错思路分析及案例整理，积累自己的心得体会 </li><li>脚本语言：重点复习python的语法，简单复习下shell即可，毕竟Python的第三方库多，很多成熟的功能套件开箱即用</li><li>算法数据结构：运维和开发不一样，这个东西你说不了解吧也不行，花时间在算法上面太多又容易出现面试造火箭,入职拧螺丝的情况，因人而异吧。</li></ul><p>这些模块是我一步步复习总结出来的，也复习过很多不太有用的模块（比如算法和数据结构以及云平台管理等），相比之下浪费较多时间。</p><p>经过一个月的面试，我发现在运维方面，网络协议和Linux基础是重中之重，尤其是网络协议这块，一个TCP/IP就够你复习很久，最重要的是你复习的成果需要由一个一个案例输出才能体现出来。</p><p>很简单的例子：</p><p>在浏览器打开<a href="http://www.baidu.com经过了哪些步骤" target="_blank" rel="noopener">www.baidu.com经过了哪些步骤</a></p><p>一个网页打开很卡，排查这个原因并提出解决方案</p><p>服务器特别卡，但是TOP发现没有很多资源被占用，应该怎么解决</p><p>面对这类面试常考的问题，你不光带着问题去学习，更得深入地了解各个底层知识，集中起来，面对问题你才能快准狠地定位并解决问题。</p><p>最后再讲一下面试需要注意的东西，如何在面试中展示自己的亮点，让自己能够吸引面试官的注意呢？</p><p>那位大牛的博客已经写了很好答案了，我这里就不再复述相同的，只做补充：</p><p>简历篇</p><ul><li>一定要掌握自己的简历：达到熟练地自我介绍，项目、技术有条不紊的讲出来</li><li>实事求是：仅仅用过的技术就不要写熟练，仅仅是平常用的较多的技术就不要写精通，只有到达了深入理解并熟练运用技术的水平才能写精通（例如底层原理，扩展方案，实现场景），否则面试官会问的你漏洞百出</li></ul><p>发展篇</p><ul><li>职业规划，个人目标，不要太泛，太虚（例如我要成为某某领域最牛逼的人，我要给公司创造多大多大的价值，吹呢），一定要讲实际例子，比如某案例，我是怎么想的，做了什么，花了多少心血，最终收获了什么，帮助团队成长了什么，总结反思了什么。</li><li>离职原因想清楚怎么说，必答题，不要太肤浅（公司不给我涨钱），也不要太假（我要与公司共存亡，极度认同公司文化，但是公司把我开除了等等）</li></ul><p>同样，授之以鱼不如授之以渔。</p><p>我想告诉未来有幸能看到我这篇文章的朋友们，如果你们也不满现状，不满自己的价值不被承认，不满自己浑浑噩噩地过日子，那么你应该学会</p><ul><li>思考（自主思考，就跟机器学习一样，自己有意识地去思考）</li><li>珍惜时间，少玩游戏少放松，制作一套切实可行的时间管理表</li><li>多结交/关注牛逼的人（高学历，知名大厂的优秀员工）学学别人成功的经验</li><li>保持技术的纯粹，不要太早被世俗影响</li><li>每日三省吾身，每周自我小结，每月自我总结，不要把这个当作一句空话</li><li>先定一个小目标，1-5年完成，再定一个大目标，10年甚至一生</li><li>投资（理财、自己的身体、人脉）</li></ul><p>顺便给你们也给未来的自己时刻敲响警钟：不求效果不看效率的勤奋比懒惰更可怕。</p><p>要相信，付出一定会有收获，收获可能会迟到，但一定不会缺席。</p><p>写到这里我还是得说那句老生常谈的话：种一棵树最好的时间是十年前，其次是现在。如果有遗憾，那么现在一定要去挽留。</p><p>最后我还是需要感谢老东家，在这里我学习到了很多技术，认识了很多大佬，我的三观在这里逐渐地形成。</p><p>在这里，我拼搏过，我通宵过，我不服过，我被人利用过，我证明过，我爱过、恨过。</p><p>领导走之前嘱咐我”天下没有不散的筵席”、”做人要大大方方的来，大大方方的走”、”不能人走茶凉，关系是需要维护的”、”坚持自己的原则，哪怕你抗衡的是整个世界”</p><p>我衷心地感谢在老东家认识的每一个人。</p><p>我已经不知道应该这篇文章到底要表达什么中心思想，如果要说一句鼓励的话，那么，</p><p>奔涌吧，后浪！RuGod，现在才刚刚开始！</p><h1 id="复习资料"><a href="#复习资料" class="headerlink" title="复习资料"></a>复习资料</h1><h2 id="系统复习课"><a href="#系统复习课" class="headerlink" title="系统复习课"></a>系统复习课</h2><ul><li>MySQL实战45讲（极客时间）</li><li>趣谈网络协议（极客时间）</li><li>深入剖析Kubernetes（极客时间）</li></ul><h2 id="书籍类"><a href="#书籍类" class="headerlink" title="书籍类"></a>书籍类</h2><ul><li>SRE Google运维解密 </li><li>Kubernetes权威指南</li><li>鸟哥的Linux私房菜 基础学习篇 第四版</li><li>云原生服务网格Istio</li><li>高性能MySQL（第3版）</li><li>CCNA学习指南 640-802 第7版</li><li>深入浅出Prometheus</li></ul><h2 id="面试总结类"><a href="#面试总结类" class="headerlink" title="面试总结类"></a>面试总结类</h2><ul><li><a href="https://blog.csdn.net/ThinkWon/article/details/104588679###" target="_blank" rel="noopener">Linux面试题（2020最新版）</a></li><li><a href="https://www.nowcoder.com/discuss/431440?type=5" target="_blank" rel="noopener">计算机网络学习路线和常见面试题总结（字节跳动面试必备）</a></li><li><a href="https://www.cnblogs.com/wuwuyong/p/12198928.html" target="_blank" rel="noopener">计算机网络常见面试题</a></li><li><a href="https://developer.aliyun.com/article/715486?spm=a2c6h.12873639.0.0.792939dfi0wzR1&groupCode=interview" target="_blank" rel="noopener">7大板块，200+面试题，助你拿下offer | 运维工程师面试宝典</a></li><li><a href="https://www.cs.usfca.edu/~galles/visualization/Algorithms.html" target="_blank" rel="noopener">算法实践</a></li><li><a href="https://www.jianshu.com/p/346d3c30eb2c" target="_blank" rel="noopener">MySQL 加锁处理分析</a></li><li><a href="https://zhuanlan.zhihu.com/p/54430650" target="_blank" rel="noopener">110道Python面试题（真题）</a></li></ul><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> 顶级理解 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 顶级理解 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>个人总结(2020.7)</title>
      <link href="2020/08/04/summary/summary-2020-7/"/>
      <url>2020/08/04/summary/summary-2020-7/</url>
      
        <content type="html"><![CDATA[<h1 id="感慨"><a href="#感慨" class="headerlink" title="感慨"></a>感慨</h1><p>2020的7月可能是我的整个人生的转折点</p><p>7月我经历了公司部门的震动（直属领导离职、华科大佬离职、大数据大佬们离职），我反思了很多，包括他们为什么会离职，以及自己的处境和发展空间。</p><p>最终我认为我不能按照原计划执行了（9月开始投简历），我需要加快我的复习进度以及现在就开始训练自己的面试能力。</p><p>为此我制定了一系列方案（后续会专门写篇文章分享我的跳槽之旅）以及如何落实（这个很难）</p><p>最终我在这个月内面试了20几家公司（有武汉深圳杭州的）也拿了几个不错的offer，最终在月底锁下了一家深圳的创业型公司。8月6日飞深圳，开始南漂。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h2 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h2><h3 id="文章"><a href="#文章" class="headerlink" title="文章"></a>文章</h3><p>7月我一共发布了14篇文章.</p><p>主要关于K8S、SRE、Docker的文章。</p><h3 id="学习："><a href="#学习：" class="headerlink" title="学习："></a>学习：</h3><p>买了极客时间 张磊老师的深入剖析Kubernetes</p><p>虽然是2年前的课，但是看完+官方文档的学习，能对K8S整个技术架构有了更加深刻的了解</p><p>买了本SRE《Site Reliability Engineering 》，学习下谷歌的运维团队的思想</p><h2 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h2><h3 id="作息时间"><a href="#作息时间" class="headerlink" title="作息时间"></a>作息时间</h3><p>7月我的生活是很辛苦的，高频率的面试使得我每天都在反复地总结，复习，进步。这个月超过12点睡觉一共有22天，平均睡觉时长为6小时21分钟。我每天复习面试题、核心知识细节，甚至几次晚上抱着书进入梦乡。</p><h3 id="做饭"><a href="#做饭" class="headerlink" title="做饭"></a>做饭</h3><p>这个月没时间做饭，天天吃外卖，确实有点不太健康。</p><h3 id="锻炼"><a href="#锻炼" class="headerlink" title="锻炼"></a>锻炼</h3><p>这个月只锻炼了3天，和北京出差的朋友打过篮球，带北京的朋友去看了一次黄鹤楼。</p><h1 id="对自己说"><a href="#对自己说" class="headerlink" title="对自己说"></a>对自己说</h1><p>7月的宇神辛苦了，每天不断地准备面试以及回放面试的电话录音，整个7月我就做两件事。</p><p>复习——面试——再复习——再面试</p><p>最好皇天不负有心人，结果是我比较满意的</p><h1 id="向前看"><a href="#向前看" class="headerlink" title="向前看"></a>向前看</h1><p>8月我会在深圳南山区科技园工作，那里都是高科技产业公司。我一边会快速融入新的公司完成自己的本职工作，一边也会去深大附件走走看看，感受大城市的科技魅力。</p><h1 id="名言共勉"><a href="#名言共勉" class="headerlink" title="名言共勉"></a>名言共勉</h1><p>莫愁前路无知己、天下谁人不识君</p><p>天下没有不散的筵席</p>]]></content>
      
      
      <categories>
          
          <category> 个人总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 个人总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mongodb4.2副本集安装</title>
      <link href="2020/07/30/mongodb/mongodb4.2-install/"/>
      <url>2020/07/30/mongodb/mongodb4.2-install/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>公司需要安装mongdb副本集，保证和阿里云的生产环境一样，版本还是4.2，说实话我们根本用不到副本集事务和高可用的备份。还是乖乖听领导的话部署吧</p><h1 id="Monodb副本集介绍"><a href="#Monodb副本集介绍" class="headerlink" title="Monodb副本集介绍"></a>Monodb副本集介绍</h1><ul><li>副本集在mongodb中是是一组 mongod保持相同的数据集过程，副本集提供冗余和高可用性，并且是所有生产部署的基础。</li><li>复制提供冗余并增加数据可用性，在不用数据库服务器上具有多个数据副本是，复制可以提供一个级别的单一数据库服务器丢失的容错能力。</li><li>副本集可以支撑更高的读操作，因为客户端可以向不同的服务器发送读取操作，可以配置在不同的数据中心用作遭难恢复或者报告，备份。</li><li>副本集成员最多50个，只有7个成员可以参与选举投票，多中心容灾能力，自动恢复，滚动式升级服务</li></ul><h1 id="部署Mongodb"><a href="#部署Mongodb" class="headerlink" title="部署Mongodb"></a>部署Mongodb</h1><p>阿里云的生产环境Mongodb部署模式为一主一从一仲裁，线下保持一致。</p><h2 id="服务器信息"><a href="#服务器信息" class="headerlink" title="服务器信息"></a>服务器信息</h2><p>三台机器一样配置8核32G内存 存储盘500G</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&quot;host&quot; : &quot;172.31.28.23:27020&quot;   主</span><br><span class="line">&quot;host&quot; : &quot;172.31.28.24:27020&quot;   从</span><br><span class="line">&quot;host&quot; : &quot;172.31.28.25:27020&quot;   仲裁</span><br></pre></td></tr></table></figure><h2 id="安装Mongodb"><a href="#安装Mongodb" class="headerlink" title="安装Mongodb"></a>安装Mongodb</h2><p>进入主节点机器172.31.28.23</p><p>修改配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-28-23 ~]# wget https:&#x2F;&#x2F;fastdl.mongodb.org&#x2F;linux&#x2F;mongodb-linux-x86_64-rhel70-4.2.8.tgz</span><br><span class="line">[root@VM-28-23 ~]# tar -zxvf mongodb-linux-x86_64-rhel70-4.2.8.tgz -C &#x2F;data&#x2F;</span><br><span class="line">[root@VM-28-23 ~]# mkdir &#x2F;data&#x2F;mongodb&#x2F;&#123;data,logs,pid,conf&#125; -p</span><br><span class="line">[root@VM-28-23 ~]# vim &#x2F;data&#x2F;mongodb&#x2F;conf&#x2F;mongodb.conf</span><br><span class="line"></span><br><span class="line">systemLog:</span><br><span class="line">  destination: file</span><br><span class="line">  logAppend: true</span><br><span class="line">  path: &#x2F;data&#x2F;mongodb&#x2F;logs&#x2F;mongod.log</span><br><span class="line"></span><br><span class="line">storage:</span><br><span class="line">  dbPath: &#x2F;data&#x2F;mongodb&#x2F;data</span><br><span class="line">  journal:</span><br><span class="line">    enabled: true</span><br><span class="line">  directoryPerDB: true</span><br><span class="line">  wiredTiger:</span><br><span class="line">     engineConfig:</span><br><span class="line">        cacheSizeGB: 24   #如果一台机器启动一个实例这个可以注释选择默认，如果一台机器启动多个实例，需要设置内存大小，避免互相抢占内存</span><br><span class="line">        directoryForIndexes: true</span><br><span class="line"></span><br><span class="line">processManagement:</span><br><span class="line">  fork: true</span><br><span class="line">  pidFilePath: &#x2F;data&#x2F;mongodb&#x2F;pid&#x2F;mongod.pid</span><br><span class="line"></span><br><span class="line">net:</span><br><span class="line">  port: 27020</span><br><span class="line">  bindIp: 172.31.28.23     #修改为本机IP地址</span><br><span class="line">  maxIncomingConnections: 5000</span><br><span class="line"></span><br><span class="line">#security:</span><br><span class="line">  #keyFile: &#x2F;data&#x2F;mongodb&#x2F;conf&#x2F;keyfile</span><br><span class="line">  #authorization: enabled</span><br><span class="line">replication: #副本集用到的配置</span><br><span class="line">   oplogSizeMB: 1024   #复制操作日志的大小</span><br><span class="line">   replSetName: rs02  #副本集名称，同一个副本集的所有主机必须设置相同的名称</span><br></pre></td></tr></table></figure><h2 id="将配置复制到其他机器"><a href="#将配置复制到其他机器" class="headerlink" title="将配置复制到其他机器"></a>将配置复制到其他机器</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-28-23 ~]# scp -r &#x2F;data&#x2F; root@172.31.28.24:&#x2F;data&#x2F;</span><br><span class="line">[root@VM-28-23 ~]# scp -r &#x2F;data&#x2F; root@172.31.28.25:&#x2F;data&#x2F;</span><br></pre></td></tr></table></figure><p>将/data/mongodb/conf/mongodb.conf文件中的bindIp修改成各自机器的IP</p><h2 id="启动Mongodb"><a href="#启动Mongodb" class="headerlink" title="启动Mongodb"></a>启动Mongodb</h2><p>下面操作需要在每台机器上执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-28-23 ~]# groupadd mongod</span><br><span class="line">[root@VM-28-23 ~]# useradd -g mongod mongod</span><br><span class="line">[root@VM-28-23 ~]# yum install -y libcurl openssl glibc</span><br><span class="line">[root@VM-28-23 ~]# cd &#x2F;data</span><br><span class="line">[root@VM-28-23 ~]# ln -s mongodb-linux-x86_64-rhel70-4.2.8 mongodb-4.2</span><br><span class="line">[root@VM-28-23 ~]# chown -R mongod.mongod &#x2F;data</span><br><span class="line">[root@VM-28-23 ~]# sudo -u mongod &#x2F;data&#x2F;mongodb-4.2&#x2F;bin&#x2F;mongod -f &#x2F;data&#x2F;mongodb&#x2F;conf&#x2F;mongodb.conf</span><br></pre></td></tr></table></figure><h2 id="初始化集群"><a href="#初始化集群" class="headerlink" title="初始化集群"></a>初始化集群</h2><p>准备一个config</p><p>config = { _id:”rs02”, members:[<br>… …                      {_id:0,host:”172.31.28.23:27020”,priority:90},<br>… …                      {_id:1,host:”172.31.28.24:27020”,priority:90},<br>… …                      {_id:2,host:”172.31.28.25:27020”,arbiterOnly:true}<br>… …               ]<br>… … }</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-28-23 ~] #cd &#x2F;data&#x2F;mongodb-4.2&#x2F;bin</span><br><span class="line">[root@VM-28-23 bin]# .&#x2F;mongo 172.31.28.23:27020</span><br><span class="line">&gt; use admin</span><br><span class="line">switched to db admin</span><br><span class="line">&gt; config &#x3D; &#123; _id:&quot;rs02&quot;, members:[</span><br><span class="line">... ...                      &#123;_id:0,host:&quot;172.31.28.23:27020&quot;,priority:90&#125;,</span><br><span class="line">... ...                      &#123;_id:1,host:&quot;172.31.28.24:27020&quot;,priority:90&#125;,</span><br><span class="line">... ...                      &#123;_id:2,host:&quot;172.31.28.25:27020&quot;,arbiterOnly:true&#125;</span><br><span class="line">... ...               ]</span><br><span class="line">... ... &#125;</span><br><span class="line">&#123;</span><br><span class="line">&quot;_id&quot; : &quot;rs02&quot;,</span><br><span class="line">&quot;members&quot; : [</span><br><span class="line">&#123;</span><br><span class="line">&quot;_id&quot; : 0,</span><br><span class="line">&quot;host&quot; : &quot;172.31.28.23:27020&quot;,</span><br><span class="line">&quot;priority&quot; : 90</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line">&quot;_id&quot; : 1,</span><br><span class="line">&quot;host&quot; : &quot;172.31.28.24:27020&quot;,</span><br><span class="line">&quot;priority&quot; : 90</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line">&quot;_id&quot; : 2,</span><br><span class="line">&quot;host&quot; : &quot;172.31.28.25:27020&quot;,</span><br><span class="line">&quot;arbiterOnly&quot; : true</span><br><span class="line">&#125;</span><br><span class="line">]</span><br><span class="line">&#125;</span><br><span class="line">&gt; rs.initiate(config);</span><br><span class="line">&#123;</span><br><span class="line">&quot;ok&quot; : 1,</span><br><span class="line">&quot;$clusterTime&quot; : &#123;</span><br><span class="line">&quot;clusterTime&quot; : Timestamp(1595209506, 1),</span><br><span class="line">&quot;signature&quot; : &#123;</span><br><span class="line">&quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA&#x3D;&quot;),</span><br><span class="line">&quot;keyId&quot; : NumberLong(0)</span><br><span class="line">&#125;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;operationTime&quot; : Timestamp(1595209506, 1)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="查看节点状态"><a href="#查看节点状态" class="headerlink" title="查看节点状态"></a>查看节点状态</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br></pre></td><td class="code"><pre><span class="line">rs02:SECONDARY&gt; rs.status()</span><br><span class="line">&#123;</span><br><span class="line">&quot;set&quot; : &quot;rs02&quot;,</span><br><span class="line">&quot;date&quot; : ISODate(&quot;2020-07-20T01:45:29.117Z&quot;),</span><br><span class="line">&quot;myState&quot; : 1,</span><br><span class="line">&quot;term&quot; : NumberLong(1),</span><br><span class="line">&quot;syncingTo&quot; : &quot;&quot;,</span><br><span class="line">&quot;syncSourceHost&quot; : &quot;&quot;,</span><br><span class="line">&quot;syncSourceId&quot; : -1,</span><br><span class="line">&quot;heartbeatIntervalMillis&quot; : NumberLong(2000),</span><br><span class="line">&quot;majorityVoteCount&quot; : 2,</span><br><span class="line">&quot;writeMajorityCount&quot; : 2,</span><br><span class="line">&quot;optimes&quot; : &#123;</span><br><span class="line">&quot;lastCommittedOpTime&quot; : &#123;</span><br><span class="line">&quot;ts&quot; : Timestamp(1595209518, 1),</span><br><span class="line">&quot;t&quot; : NumberLong(1)</span><br><span class="line">&#125;,</span><br><span class="line">&quot;lastCommittedWallTime&quot; : ISODate(&quot;2020-07-20T01:45:18.603Z&quot;),</span><br><span class="line">&quot;readConcernMajorityOpTime&quot; : &#123;</span><br><span class="line">&quot;ts&quot; : Timestamp(1595209518, 1),</span><br><span class="line">&quot;t&quot; : NumberLong(1)</span><br><span class="line">&#125;,</span><br><span class="line">&quot;readConcernMajorityWallTime&quot; : ISODate(&quot;2020-07-20T01:45:18.603Z&quot;),</span><br><span class="line">&quot;appliedOpTime&quot; : &#123;</span><br><span class="line">&quot;ts&quot; : Timestamp(1595209518, 1),</span><br><span class="line">&quot;t&quot; : NumberLong(1)</span><br><span class="line">&#125;,</span><br><span class="line">&quot;durableOpTime&quot; : &#123;</span><br><span class="line">&quot;ts&quot; : Timestamp(1595209518, 1),</span><br><span class="line">&quot;t&quot; : NumberLong(1)</span><br><span class="line">&#125;,</span><br><span class="line">&quot;lastAppliedWallTime&quot; : ISODate(&quot;2020-07-20T01:45:18.603Z&quot;),</span><br><span class="line">&quot;lastDurableWallTime&quot; : ISODate(&quot;2020-07-20T01:45:18.603Z&quot;)</span><br><span class="line">&#125;,</span><br><span class="line">&quot;lastStableRecoveryTimestamp&quot; : Timestamp(1595209517, 3),</span><br><span class="line">&quot;lastStableCheckpointTimestamp&quot; : Timestamp(1595209517, 3),</span><br><span class="line">&quot;electionCandidateMetrics&quot; : &#123;</span><br><span class="line">&quot;lastElectionReason&quot; : &quot;electionTimeout&quot;,</span><br><span class="line">&quot;lastElectionDate&quot; : ISODate(&quot;2020-07-20T01:45:17.641Z&quot;),</span><br><span class="line">&quot;electionTerm&quot; : NumberLong(1),</span><br><span class="line">&quot;lastCommittedOpTimeAtElection&quot; : &#123;</span><br><span class="line">&quot;ts&quot; : Timestamp(0, 0),</span><br><span class="line">&quot;t&quot; : NumberLong(-1)</span><br><span class="line">&#125;,</span><br><span class="line">&quot;lastSeenOpTimeAtElection&quot; : &#123;</span><br><span class="line">&quot;ts&quot; : Timestamp(1595209506, 1),</span><br><span class="line">&quot;t&quot; : NumberLong(-1)</span><br><span class="line">&#125;,</span><br><span class="line">&quot;numVotesNeeded&quot; : 2,</span><br><span class="line">&quot;priorityAtElection&quot; : 90,</span><br><span class="line">&quot;electionTimeoutMillis&quot; : NumberLong(10000),</span><br><span class="line">&quot;numCatchUpOps&quot; : NumberLong(0),</span><br><span class="line">&quot;newTermStartDate&quot; : ISODate(&quot;2020-07-20T01:45:17.693Z&quot;),</span><br><span class="line">&quot;wMajorityWriteAvailabilityDate&quot; : ISODate(&quot;2020-07-20T01:45:18.590Z&quot;)</span><br><span class="line">&#125;,</span><br><span class="line">&quot;members&quot; : [</span><br><span class="line">&#123;</span><br><span class="line">&quot;_id&quot; : 0,</span><br><span class="line">&quot;name&quot; : &quot;172.31.28.23:27020&quot;,</span><br><span class="line">&quot;health&quot; : 1,</span><br><span class="line">&quot;state&quot; : 1,</span><br><span class="line">&quot;stateStr&quot; : &quot;PRIMARY&quot;,</span><br><span class="line">&quot;uptime&quot; : 246,</span><br><span class="line">&quot;optime&quot; : &#123;</span><br><span class="line">&quot;ts&quot; : Timestamp(1595209518, 1),</span><br><span class="line">&quot;t&quot; : NumberLong(1)</span><br><span class="line">&#125;,</span><br><span class="line">&quot;optimeDate&quot; : ISODate(&quot;2020-07-20T01:45:18Z&quot;),</span><br><span class="line">&quot;syncingTo&quot; : &quot;&quot;,</span><br><span class="line">&quot;syncSourceHost&quot; : &quot;&quot;,</span><br><span class="line">&quot;syncSourceId&quot; : -1,</span><br><span class="line">&quot;infoMessage&quot; : &quot;could not find member to sync from&quot;,</span><br><span class="line">&quot;electionTime&quot; : Timestamp(1595209517, 1),</span><br><span class="line">&quot;electionDate&quot; : ISODate(&quot;2020-07-20T01:45:17Z&quot;),</span><br><span class="line">&quot;configVersion&quot; : 1,</span><br><span class="line">&quot;self&quot; : true,</span><br><span class="line">&quot;lastHeartbeatMessage&quot; : &quot;&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line">&quot;_id&quot; : 1,</span><br><span class="line">&quot;name&quot; : &quot;172.31.28.24:27020&quot;,</span><br><span class="line">&quot;health&quot; : 1,</span><br><span class="line">&quot;state&quot; : 2,</span><br><span class="line">&quot;stateStr&quot; : &quot;SECONDARY&quot;,</span><br><span class="line">&quot;uptime&quot; : 22,</span><br><span class="line">&quot;optime&quot; : &#123;</span><br><span class="line">&quot;ts&quot; : Timestamp(1595209518, 1),</span><br><span class="line">&quot;t&quot; : NumberLong(1)</span><br><span class="line">&#125;,</span><br><span class="line">&quot;optimeDurable&quot; : &#123;</span><br><span class="line">&quot;ts&quot; : Timestamp(1595209518, 1),</span><br><span class="line">&quot;t&quot; : NumberLong(1)</span><br><span class="line">&#125;,</span><br><span class="line">&quot;optimeDate&quot; : ISODate(&quot;2020-07-20T01:45:18Z&quot;),</span><br><span class="line">&quot;optimeDurableDate&quot; : ISODate(&quot;2020-07-20T01:45:18Z&quot;),</span><br><span class="line">&quot;lastHeartbeat&quot; : ISODate(&quot;2020-07-20T01:45:27.655Z&quot;),</span><br><span class="line">&quot;lastHeartbeatRecv&quot; : ISODate(&quot;2020-07-20T01:45:28.551Z&quot;),</span><br><span class="line">&quot;pingMs&quot; : NumberLong(1),</span><br><span class="line">&quot;lastHeartbeatMessage&quot; : &quot;&quot;,</span><br><span class="line">&quot;syncingTo&quot; : &quot;172.31.28.23:27020&quot;,</span><br><span class="line">&quot;syncSourceHost&quot; : &quot;172.31.28.23:27020&quot;,</span><br><span class="line">&quot;syncSourceId&quot; : 0,</span><br><span class="line">&quot;infoMessage&quot; : &quot;&quot;,</span><br><span class="line">&quot;configVersion&quot; : 1</span><br><span class="line">&#125;,</span><br><span class="line">&#123;</span><br><span class="line">&quot;_id&quot; : 2,</span><br><span class="line">&quot;name&quot; : &quot;172.31.28.25:27020&quot;,</span><br><span class="line">&quot;health&quot; : 1,</span><br><span class="line">&quot;state&quot; : 7,</span><br><span class="line">&quot;stateStr&quot; : &quot;ARBITER&quot;,</span><br><span class="line">&quot;uptime&quot; : 22,</span><br><span class="line">&quot;lastHeartbeat&quot; : ISODate(&quot;2020-07-20T01:45:27.654Z&quot;),</span><br><span class="line">&quot;lastHeartbeatRecv&quot; : ISODate(&quot;2020-07-20T01:45:27.393Z&quot;),</span><br><span class="line">&quot;pingMs&quot; : NumberLong(0),</span><br><span class="line">&quot;lastHeartbeatMessage&quot; : &quot;&quot;,</span><br><span class="line">&quot;syncingTo&quot; : &quot;&quot;,</span><br><span class="line">&quot;syncSourceHost&quot; : &quot;&quot;,</span><br><span class="line">&quot;syncSourceId&quot; : -1,</span><br><span class="line">&quot;infoMessage&quot; : &quot;&quot;,</span><br><span class="line">&quot;configVersion&quot; : 1</span><br><span class="line">&#125;</span><br><span class="line">],</span><br><span class="line">&quot;ok&quot; : 1,</span><br><span class="line">&quot;$clusterTime&quot; : &#123;</span><br><span class="line">&quot;clusterTime&quot; : Timestamp(1595209518, 1),</span><br><span class="line">&quot;signature&quot; : &#123;</span><br><span class="line">&quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA&#x3D;&quot;),</span><br><span class="line">&quot;keyId&quot; : NumberLong(0)</span><br><span class="line">&#125;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;operationTime&quot; : Timestamp(1595209518, 1)</span><br><span class="line">&#125;</span><br><span class="line">rs02:PRIMARY&gt;</span><br></pre></td></tr></table></figure><h2 id="验证副本集数据复制功能"><a href="#验证副本集数据复制功能" class="headerlink" title="验证副本集数据复制功能"></a>验证副本集数据复制功能</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#主节点</span><br><span class="line">use test</span><br><span class="line">db.createCollection(&#39;user&#39;)</span><br><span class="line">db.user.insert(&#123;&#39;name&#39;:&#39;james&#39;&#125;)</span><br><span class="line"> </span><br><span class="line">#从节点</span><br><span class="line">use test</span><br><span class="line">show collections</span><br><span class="line">db.user.find()</span><br></pre></td></tr></table></figure><p>发现主节点的数据在从节点能读到。</p><p>至此Mongodb副本集算是安装完了，如果需要开权限认证，请往后看~</p><h1 id="Mongodb权限认证"><a href="#Mongodb权限认证" class="headerlink" title="Mongodb权限认证"></a>Mongodb权限认证</h1><h2 id="副本集配置用户和密码，登录主节点-添加admin-用户。"><a href="#副本集配置用户和密码，登录主节点-添加admin-用户。" class="headerlink" title="副本集配置用户和密码，登录主节点,添加admin 用户。"></a>副本集配置用户和密码，登录主节点,添加admin 用户。</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt; use admin</span><br><span class="line">switched to db admin</span><br><span class="line">&gt; db.createUser(&#123; user: &quot;admin&quot;, pwd: &quot;123456&quot;, roles: [&#123; role: &quot;root&quot;, db: &quot;admin&quot; &#125;] &#125;)</span><br><span class="line">Successfully added user: &#123;</span><br><span class="line">    &quot;user&quot; : &quot;admin&quot;,</span><br><span class="line">    &quot;roles&quot; : [</span><br><span class="line">        &#123;</span><br><span class="line">            &quot;role&quot; : &quot;root&quot;,</span><br><span class="line">            &quot;db&quot; : &quot;admin&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="在主节点生成-keyflie-并复制到其它两个节点"><a href="#在主节点生成-keyflie-并复制到其它两个节点" class="headerlink" title="在主节点生成 keyflie 并复制到其它两个节点"></a>在主节点生成 keyflie 并复制到其它两个节点</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 生成 keyFile</span><br><span class="line">openssl rand -base64 90 -out &#x2F;data&#x2F;mongodb-4.2&#x2F;keyfile</span><br><span class="line"></span><br><span class="line"># 复制到其它两个节点</span><br><span class="line">scp keyfile root@172.31.28.24:&#x2F;data&#x2F;mongodb-4.2&#x2F;</span><br><span class="line">scp keyfile root@172.31.28.25:&#x2F;data&#x2F;mongodb-4.2&#x2F;</span><br><span class="line"></span><br><span class="line"># 更改三个节点的 keyFile 文件权限和所有者</span><br><span class="line">chmod 600 &#x2F;data&#x2F;mongodb-4.2&#x2F;keyfile</span><br><span class="line">chown mongod:mongod &#x2F;data&#x2F;mongodb-4.2&#x2F;keyfile</span><br></pre></td></tr></table></figure><h2 id="更改三个节点的-mongodb-conf-配置文件"><a href="#更改三个节点的-mongodb-conf-配置文件" class="headerlink" title="更改三个节点的 mongodb.conf 配置文件"></a>更改三个节点的 mongodb.conf 配置文件</h2><p>将 security 的参数 authorization 设置为 enabled，并配置<br>keyFile 的路径。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">vim &#x2F;data&#x2F;mongodb&#x2F;conf&#x2F;mongodb.conf</span><br><span class="line"></span><br><span class="line">security:</span><br><span class="line">   authorization: &quot;enabled&quot;</span><br><span class="line">   keyFile: &#39;&#x2F;data&#x2F;mongodb-4.2&#x2F;keyfile&#39;</span><br><span class="line">   clusterAuthMode: &quot;keyFile&quot;</span><br><span class="line">   </span><br><span class="line">然后依次重启mongdb01、02、03</span><br><span class="line"></span><br><span class="line"># 关闭</span><br><span class="line">sudo -u mongod &#x2F;data&#x2F;mongodb-4.2&#x2F;bin&#x2F;mongod --shutdown   --dbpath &#x2F;data&#x2F;mongodb&#x2F;data</span><br><span class="line"></span><br><span class="line"># 启动</span><br><span class="line">sudo -u mongod &#x2F;data&#x2F;mongodb-4.2&#x2F;bin&#x2F;mongod -f &#x2F;data&#x2F;mongodb&#x2F;conf&#x2F;mongodb.conf</span><br></pre></td></tr></table></figure><h2 id="测试权限验证"><a href="#测试权限验证" class="headerlink" title="测试权限验证"></a>测试权限验证</h2><p>登陆主节点</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt; show dbs</span><br><span class="line">&gt; use admin</span><br><span class="line">switched to db admin</span><br><span class="line">&gt; db.auth(&#39;admin&#39;,&#39;123456&#39;)</span><br><span class="line">1</span><br><span class="line">&gt; show dbs</span><br><span class="line">admin   0.000GB</span><br><span class="line">config  0.000GB</span><br><span class="line">local   0.002GB</span><br><span class="line">test    0.000GB</span><br></pre></td></tr></table></figure><p>权限认证则验证完成</p><h1 id="Mongodb常用管理命令"><a href="#Mongodb常用管理命令" class="headerlink" title="Mongodb常用管理命令"></a>Mongodb常用管理命令</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"># 副本集初始化</span><br><span class="line">rs.initiate( &#123;</span><br><span class="line">   _id : &quot;rs0&quot;,</span><br><span class="line">   members: [</span><br><span class="line">      &#123; _id: 0, host: &quot;mongodb0.example.net:27017&quot; &#125;,</span><br><span class="line">      &#123; _id: 1, host: &quot;mongodb1.example.net:27017&quot; &#125;,</span><br><span class="line">      &#123; _id: 2, host: &quot;mongodb2.example.net:27017&quot; &#125;</span><br><span class="line">   ]</span><br><span class="line">&#125;)</span><br><span class="line"># 副本集添加成员</span><br><span class="line">rs.add(&#39;mongodb3.example.net:27017&#39;)</span><br><span class="line"># 副本集添加仲裁节点</span><br><span class="line">rs.addArb(&#39;mongodb4.example.net:27017&#39;)</span><br><span class="line"># 移除节点</span><br><span class="line">rs.remove(&#39;hostportstr&#39;)</span><br><span class="line"># 查看当前的配置</span><br><span class="line">rs.conf()</span><br><span class="line"># 查看各个节点状态和身份</span><br><span class="line">rs.status()</span><br><span class="line"># 设定某个节点多少秒不可成为主节点</span><br><span class="line">rs.freeze(secs)</span><br><span class="line"># 设置次节点从指定节点同步数据</span><br><span class="line">rs.syncFrom(hostportstr)</span><br><span class="line"># 降低主节点为次节点，只能在主节点上运行</span><br><span class="line">rs.stepDown([stepdownSecs, catchUpSecs])</span><br><span class="line"># 查看帮助</span><br><span class="line">rs.help()</span><br><span class="line"># 次节点执行，表示允许次节点读取数据</span><br><span class="line">rs.slaveOk()</span><br><span class="line"># 判断当前节点是否是主节点</span><br><span class="line">rs.isMaster()</span><br><span class="line"># 查看 Oplog 信息</span><br><span class="line">rs.printReplicationInfo()</span><br><span class="line">#  查看副本集的次节点与主节点延迟</span><br><span class="line">db.printSlaveReplicationInfo()</span><br><span class="line"># 移除原有副本集命令</span><br><span class="line">use local</span><br><span class="line">db.system.replset.remove(&#123;&#125;)</span><br><span class="line"># 关闭 mongodb进程服务</span><br><span class="line">use admin</span><br><span class="line">db.shutdownServer()</span><br></pre></td></tr></table></figure><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://blog.51cto.com/jiachen/2485887" target="_blank" rel="noopener">Mongodb 4.2版本副本集配置</a></p><p><a href="https://www.cnblogs.com/operationhome/p/10744712.html" target="_blank" rel="noopener">MongoDB-副本集搭建与管理</a></p>]]></content>
      
      
      <categories>
          
          <category> Mongodb </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mongodb </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>部署开源API网关——kong</title>
      <link href="2020/07/30/slb/kong-install/"/>
      <url>2020/07/30/slb/kong-install/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><h1 id="kong简介"><a href="#kong简介" class="headerlink" title="kong简介"></a>kong简介</h1><p>Kong是全球最受欢迎的开源API网关。专为多云和混合而建，针对微服务和分布式架构进行了优化。</p><hr><p>功能</p><ul><li>认证方式<br>通过身份验证层保护您的服务</li><li>交通管制<br>管理，限制和限制入站和出站API流量</li><li>分析工具<br>可视化，检查和监视API和微服务流量</li><li>转发<br>即时转发请求和响应</li><li>记录中<br>将请求和响应数据流式传输到日志记录解决方案</li><li>无服务器<br>通过API调用无服务器功能</li></ul><hr><p>优点</p><ul><li>无与伦比的性能：借助Kong的超高性能内核，可实现业界最佳的延迟性能。确保所有服务之间的无缝通信，无论它们在何处运行。</li><li>专为云规模设计：借助Kong的轻量级核心，可最大程度地提高资源效率并最小化占地面积。线性扩展Kong节点以处理数万亿次API调用，而性能或稳定性降低为零。</li><li>无与伦比的灵活性和可扩展性：在从裸机到云，从容器到Kubernetes的任何环境，平台和任何实施模式下均可运行Kong。使用自定义插件轻松扩展Kong以使其适合任何用例。</li></ul><p>个人理解：我理解的kong就是一个加强版的Nginx，有着比负载均衡器更为强大的功能(使用服务和路由对象公开服务、设置速率限制和代理缓存、通过密钥验证来保护服务、负载均衡流量)及可视化界面的配置</p><p>kong-admin<br>kong-proxy</p><p>konga-ui</p><h1 id="准备条件"><a href="#准备条件" class="headerlink" title="准备条件"></a>准备条件</h1><p>一台服务器装PGSQL数据库（非必须）</p><p>一个K8S集群</p><p>集群均可以连外网</p><p>helm包如下</p><p>链接: <a href="https://pan.baidu.com/s/12IcxKic_fpVFfQzohiVLkw" target="_blank" rel="noopener">https://pan.baidu.com/s/12IcxKic_fpVFfQzohiVLkw</a> 提取码: iqcz 复制这段内容后打开百度网盘手机App，操作更方便哦</p><h1 id="部署kong"><a href="#部署kong" class="headerlink" title="部署kong"></a>部署kong</h1><h2 id="安装kong-database"><a href="#安装kong-database" class="headerlink" title="安装kong-database"></a>安装kong-database</h2><p>选择一台服务器装PGSQL数据库</p><p>建议使用Docker安装postgres。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"># 创建docker网络</span><br><span class="line">docker network create kong-net</span><br><span class="line"></span><br><span class="line"># 创建数据库</span><br><span class="line">docker run -d --restart always  --name kong-database \</span><br><span class="line">               --network&#x3D;kong-net \</span><br><span class="line">               -v &#x2F;data&#x2F;pgsql:&#x2F;var&#x2F;lib&#x2F;postgresql&#x2F;data \</span><br><span class="line">               -p 5432:5432 \</span><br><span class="line">               -e &quot;POSTGRES_USER&#x3D;kong&quot; \</span><br><span class="line">               -e &quot;POSTGRES_DB&#x3D;kong&quot; \</span><br><span class="line">               -e &quot;POSTGRES_PASSWORD&#x3D;kong&quot; \</span><br><span class="line">               postgres:9.6</span><br><span class="line">注意修改参数： POSTGRES_USER，POSTGRES_PASSWORD。</span><br><span class="line"></span><br><span class="line"># 初始化Kong连接数据库的默认结构</span><br><span class="line">docker run --rm \</span><br><span class="line">     --network&#x3D;kong-net \</span><br><span class="line">     -e &quot;KONG_DATABASE&#x3D;postgres&quot; \</span><br><span class="line">     -e &quot;KONG_PG_HOST&#x3D;kong-database&quot; \</span><br><span class="line">     -e &quot;KONG_PG_USER&#x3D;kong&quot; \</span><br><span class="line">     -e &quot;KONG_PG_PASSWORD&#x3D;kong&quot; \</span><br><span class="line">     -e &quot;KONG_CASSANDRA_CONTACT_POINTS&#x3D;kong-database&quot; \</span><br><span class="line">     kong:latest kong migrations bootstrap</span><br><span class="line">注意修改参数：KONG_PG_HOST，KONG_PG_PASSWORD</span><br></pre></td></tr></table></figure><h2 id="修改kong项目配置文件"><a href="#修改kong项目配置文件" class="headerlink" title="修改kong项目配置文件"></a>修改kong项目配置文件</h2><p>修改kong项目 helm部署文件夹里的values.yaml文件</p><h3 id="Kong-配置文件"><a href="#Kong-配置文件" class="headerlink" title="Kong 配置文件"></a>Kong 配置文件</h3><p>采用k8s外的postgres数据库，因此关闭heml脚本中的自动创建数据库</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">env:</span><br><span class="line">  database: &quot;postgres&quot;</span><br><span class="line">  PG_HOST: &quot;172.31.21.32&quot;</span><br><span class="line">  PG_PASSWORD: &quot;kong&quot;</span><br><span class="line">  CASSANDRA_CONTACT_POINTS: &quot;kong-database&quot;</span><br><span class="line"></span><br><span class="line">runMigrations: false</span><br></pre></td></tr></table></figure><h3 id="Kong-admin-配置文件"><a href="#Kong-admin-配置文件" class="headerlink" title="Kong admin 配置文件"></a>Kong admin 配置文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">admin:</span><br><span class="line">  # 控制k8s 是否生成Service</span><br><span class="line">  enabled: true</span><br><span class="line"> </span><br><span class="line">  http:</span><br><span class="line">    # enabled 控制 deployment 是否生成相应 docker http containerPort，如使用nodeport </span><br><span class="line">    enabled: true</span><br><span class="line">    servicePort: 8001</span><br><span class="line">    containerPort: 8001</span><br><span class="line">    # 如使用阿里云SLB直接到nodeport 请设置nodePort端口,保证集群内唯一</span><br><span class="line">    nodePort: 30001</span><br><span class="line">  </span><br><span class="line">  tls:</span><br><span class="line">    enabled: true</span><br><span class="line">    servicePort: 8444</span><br><span class="line">    containerPort: 8444</span><br><span class="line"></span><br><span class="line">  # 生产环境 如借助阿里云SLB服务，设置NodePort模式，</span><br><span class="line">  type: NodePort</span><br><span class="line"></span><br><span class="line">  ingress:</span><br><span class="line">    # ingress 部分根据实际情况配置域名和端口，建议打开；如使用nodeport模式，使用阿里云slb服务，可以设置为False。</span><br><span class="line">    enabled: False</span><br></pre></td></tr></table></figure><h3 id="Kong-proxy-配置文件"><a href="#Kong-proxy-配置文件" class="headerlink" title="Kong proxy 配置文件"></a>Kong proxy 配置文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">proxy: </span><br><span class="line">  enabled: true</span><br><span class="line">  http:</span><br><span class="line">    enabled: true</span><br><span class="line">    servicePort: 80</span><br><span class="line">    containerPort: 8000   </span><br><span class="line">    # 如使用阿里云SLB直接到nodeport 请设置nodePort端口,保证集群内唯一</span><br><span class="line">    nodePort: 30000</span><br><span class="line"></span><br><span class="line">  tls:</span><br><span class="line">    enabled: true</span><br><span class="line">    servicePort: 443</span><br><span class="line">    containerPort: 8443</span><br><span class="line">  </span><br><span class="line">  # 生产环境 如借助阿里云SLB服务，设置NodePort模式，</span><br><span class="line">  type: NodePort</span><br><span class="line"></span><br><span class="line">  ingress:</span><br><span class="line">    # ingress 部分根据实际情况配置域名和端口，建议打开；如使用nodeport模式，使用阿里云slb服务，可以设置为False。</span><br><span class="line">    enabled: false</span><br></pre></td></tr></table></figure><h3 id="kong-ingressController"><a href="#kong-ingressController" class="headerlink" title="kong ingressController"></a>kong ingressController</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ingressController: true</span><br></pre></td></tr></table></figure><h2 id="helm部署命令"><a href="#helm部署命令" class="headerlink" title="helm部署命令"></a>helm部署命令</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">进入kong的文件夹</span><br><span class="line"></span><br><span class="line">[root@localhost kong]tree</span><br><span class="line">├── kong-k8s</span><br><span class="line">│   ├── Chart.yaml</span><br><span class="line">│   ├── FAQs.md</span><br><span class="line">│   ├── README.md</span><br><span class="line">│   ├── templates</span><br><span class="line">│   │   ├── admission-webhook.yaml</span><br><span class="line">│   │   ├── config-custom-server-blocks.yaml</span><br><span class="line">│   │   ├── config-dbless.yaml</span><br><span class="line">│   │   ├── controller-rbac-resources.yaml</span><br><span class="line">│   │   ├── controller-service-account.yaml</span><br><span class="line">│   │   ├── custom-resource-definitions.yaml</span><br><span class="line">│   │   ├── deployment.yaml</span><br><span class="line">│   │   ├── _helpers.tpl</span><br><span class="line">│   │   ├── ingress-admin.yaml</span><br><span class="line">│   │   ├── ingress-manager.yaml</span><br><span class="line">│   │   ├── ingress-portal-api.yaml</span><br><span class="line">│   │   ├── ingress-portal.yaml</span><br><span class="line">│   │   ├── ingress-proxy.yaml</span><br><span class="line">│   │   ├── migrations-post-upgrade.yaml</span><br><span class="line">│   │   ├── migrations-pre-upgrade.yaml</span><br><span class="line">│   │   ├── migrations.yaml</span><br><span class="line">│   │   ├── NOTES.txt</span><br><span class="line">│   │   ├── pdb.yaml</span><br><span class="line">│   │   ├── psp.yaml</span><br><span class="line">│   │   ├── service-kong-admin.yaml</span><br><span class="line">│   │   ├── service-kong-manager.yaml</span><br><span class="line">│   │   ├── service-kong-portal-api.yaml</span><br><span class="line">│   │   ├── service-kong-portal.yaml</span><br><span class="line">│   │   ├── service-kong-proxy.yaml</span><br><span class="line">│   │   └── servicemonitor.yaml</span><br><span class="line">│   └── values.yaml</span><br><span class="line"></span><br><span class="line"># 第一次部署</span><br><span class="line">helm install -n kong .&#x2F;kong-k8s --values .&#x2F;kong-k8s&#x2F;values.yaml --namespace kong</span><br><span class="line"></span><br><span class="line">如果你要将kong部署到一个单独的命名空间，请指定namespace</span><br><span class="line">可选参数 --namespace kong</span><br><span class="line"></span><br><span class="line"># 修改yaml文件，或者更新镜像</span><br><span class="line">helm upgrade kong .&#x2F;kong-k8s --values .&#x2F;kong-k8s&#x2F;values.yaml --namespace kong</span><br><span class="line"></span><br><span class="line">可选参数 --namespace kong</span><br></pre></td></tr></table></figure><h1 id="kong-ui"><a href="#kong-ui" class="headerlink" title="kong-ui"></a>kong-ui</h1><h2 id="初始化kong-ui的数据库"><a href="#初始化kong-ui的数据库" class="headerlink" title="初始化kong-ui的数据库"></a>初始化kong-ui的数据库</h2><ul><li>你需要准备一个用户，可以和kong的一样，账号密码为kong/kong</li><li>进入postgres数据库执行建库语句</li></ul><p>CREATE DATABASE “konga” WITH ENCODING=’UTF8’;</p><ul><li>初始化化数据库<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm pantsel&#x2F;konga:latest -c prepare -a &#123;&#123;adapter&#125;&#125; -u &#123;&#123;connection-uri&#125;&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">argumentdescriptiondefault</span><br><span class="line">-c        command-</span><br><span class="line">-a        adapter (can be postgres or mysql)-</span><br><span class="line">-u        full database connection url-</span><br><span class="line"></span><br><span class="line">例如我的示例命令：</span><br><span class="line"></span><br><span class="line">docker run --rm  --network&#x3D;kong-net  pantsel&#x2F;konga:latest -c prepare -a postgres -u postgresql:&#x2F;&#x2F;kong:kong@10.66.2.134:5432&#x2F;konga</span><br></pre></td></tr></table></figure></li></ul><h2 id="创建konga"><a href="#创建konga" class="headerlink" title="创建konga"></a>创建konga</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">helm install -n konga-ui .&#x2F;konga-ui-k8s --values .&#x2F;konga-ui-k8s&#x2F;values.yaml --namespace kong</span><br></pre></td></tr></table></figure><h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="目前已知可以PGSQL迁移的版本"><a href="#目前已知可以PGSQL迁移的版本" class="headerlink" title="目前已知可以PGSQL迁移的版本"></a>目前已知可以PGSQL迁移的版本</h2><p>PGSQL为9.6 10 的这2个版本可以执行 初始化Kong连接数据库的默认结构</p><p>PGSQL:12版本目前不支持，具体原因未知</p><p>现象如下：你数据库迁移命令成功</p><p>但是实际上表却没有创建</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">migrating rate-limiting on database &#39;kong&#39;...</span><br><span class="line">rate-limiting migrated up to: 000_base_rate_limiting (executed)</span><br><span class="line">rate-limiting migrated up to: 003_10_to_112 (executed)</span><br><span class="line">rate-limiting migrated up to: 004_200_to_210 (executed)</span><br><span class="line">migrating hmac-auth on database &#39;kong&#39;...</span><br><span class="line">hmac-auth migrated up to: 000_base_hmac_auth (executed)</span><br><span class="line">hmac-auth migrated up to: 002_130_to_140 (executed)</span><br><span class="line">hmac-auth migrated up to: 003_200_to_210 (executed)</span><br><span class="line">migrating oauth2 on database &#39;kong&#39;...</span><br><span class="line">oauth2 migrated up to: 000_base_oauth2 (executed)</span><br><span class="line">oauth2 migrated up to: 003_130_to_140 (executed)</span><br><span class="line">oauth2 migrated up to: 004_200_to_210 (executed)</span><br><span class="line">migrating ip-restriction on database &#39;kong&#39;...</span><br><span class="line">ip-restriction migrated up to: 001_200_to_210 (executed)</span><br><span class="line">migrating jwt on database &#39;kong&#39;...</span><br><span class="line">jwt migrated up to: 000_base_jwt (executed)</span><br><span class="line">jwt migrated up to: 002_130_to_140 (executed)</span><br><span class="line">jwt migrated up to: 003_200_to_210 (executed)</span><br><span class="line">migrating basic-auth on database &#39;kong&#39;...</span><br><span class="line">basic-auth migrated up to: 000_base_basic_auth (executed)</span><br><span class="line">basic-auth migrated up to: 002_130_to_140 (executed)</span><br><span class="line">basic-auth migrated up to: 003_200_to_210 (executed)</span><br><span class="line">migrating key-auth on database &#39;kong&#39;...</span><br><span class="line">key-auth migrated up to: 000_base_key_auth (executed)</span><br><span class="line">key-auth migrated up to: 002_130_to_140 (executed)</span><br><span class="line">key-auth migrated up to: 003_200_to_210 (executed)</span><br><span class="line">migrating session on database &#39;kong&#39;...</span><br><span class="line">session migrated up to: 000_base_session (executed)</span><br><span class="line">migrating acl on database &#39;kong&#39;...</span><br><span class="line">acl migrated up to: 000_base_acl (executed)</span><br><span class="line">acl migrated up to: 002_130_to_140 (executed)</span><br><span class="line">acl migrated up to: 003_200_to_210 (executed)</span><br><span class="line">migrating response-ratelimiting on database &#39;kong&#39;...</span><br><span class="line">response-ratelimiting migrated up to: 000_base_response_rate_limiting (executed)</span><br><span class="line">migrating bot-detection on database &#39;kong&#39;...</span><br><span class="line">bot-detection migrated up to: 001_200_to_210 (executed)</span><br><span class="line">migrating acme on database &#39;kong&#39;...</span><br><span class="line">acme migrated up to: 000_base_acme (executed)</span><br><span class="line">34 migrations processed</span><br><span class="line">34 executed</span><br><span class="line">Database is up-to-date</span><br></pre></td></tr></table></figure><h2 id="网络问题"><a href="#网络问题" class="headerlink" title="网络问题"></a>网络问题</h2><p>如果初始化的数据库不是以容器方式运行（例如购买rds的PGSQL）</p><p>那么你需要提前创建数据库和用户kong 然后直接执行docker初始化命令，并且参数需要去掉</p><p> –network=  </p><p> 并且修改KONG_PG_HOST的实际IP</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">docker run --rm \</span><br><span class="line">     -e &quot;KONG_DATABASE&#x3D;postgres&quot; \</span><br><span class="line">     -e &quot;KONG_PG_HOST&#x3D;数据库的实际ip&quot; \</span><br><span class="line">     -e &quot;KONG_PG_USER&#x3D;kong&quot; \</span><br><span class="line">     -e &quot;KONG_PG_PASSWORD&#x3D;kong&quot; \</span><br><span class="line">     -e &quot;KONG_CASSANDRA_CONTACT_POINTS&#x3D;kong-database&quot; \</span><br><span class="line">     kong:latest kong migrations bootstrap</span><br></pre></td></tr></table></figure><h2 id="PGSQL白名单问题"><a href="#PGSQL白名单问题" class="headerlink" title="PGSQL白名单问题"></a>PGSQL白名单问题</h2><p>部署kong的时候需要初始化一个容器 waiting for db</p><p>我用PGSQL10版本报错如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Run with --v (verbose) or --vv (debug) for more details</span><br><span class="line">waiting for db</span><br><span class="line">Error: [PostgreSQL error] failed to retrieve PostgreSQL server_version_num: timeout</span><br></pre></td></tr></table></figure><p>连接超时，然后我试了下ping pgsql的ip是可以的</p><p>突然灵机一动</p><p>RDS一般都要添加白名单的，我添加了试下，成功</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://konghq.com/get-started/#install" target="_blank" rel="noopener">kong-install</a></p><p><a href="https://github.com/Kong/kong" target="_blank" rel="noopener">kong-github</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> SLB </category>
          
      </categories>
      
      
        <tags>
            
            <tag> API </tag>
            
            <tag> SLB </tag>
            
            <tag> 负载均衡 </tag>
            
            <tag> Kong </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《SRE：Google运维解密》读书心得(二)——Google生产环境：SRE视角</title>
      <link href="2020/07/23/sre/google-sre-2/"/>
      <url>2020/07/23/sre/google-sre-2/</url>
      
        <content type="html"><![CDATA[<blockquote><p>好书不怕读的晚，就怕明知道读的晚仍然还不去读。   - 宇神之息 </p></blockquote><h1 id="硬件"><a href="#硬件" class="headerlink" title="硬件"></a>硬件</h1><ul><li>物理服务器：代表具体的硬件（有时候也代表一个VM虚拟机）</li><li>软甲你服务器：代表对外提供哦那个服务的软件系统</li></ul><p>通常对于一个软件业务来说，软件服务器和物理服务器是紧密相连、密不可分的。</p><p>但是Google认为：软件不应该也不会与硬件有着强逻辑联系</p><h1 id="管理物理服务器的系统管理软件"><a href="#管理物理服务器的系统管理软件" class="headerlink" title="管理物理服务器的系统管理软件"></a>管理物理服务器的系统管理软件</h1><p>Borg，采用一套分布式集群操作系统管理系统进行资源分配。</p><p>它的下一代产品：Kubernetes，开源容器化集群编排系统。</p><p>Borg可以创建若干个任务实例(容器)，这些任务实例和物理服务器没有一对一的固定对应关系。</p><p>在Borg之上，有一个抽象层。每当Borg启动一个任务实例的适合，它会给每个具体的任务实例分配一个名字和一个编号，这个系统称为Borg名称解析系统(BNS)。当其他任务实例连接到某个任务实例时，使用BNS名称建立连接。</p><p>一个BNS地址可能是这样一个字符串：/bns/&lt;集群名&gt;/&lt;用户名&gt;/&lt;任务名&gt;/&lt;实例名&gt;，这个BNS地址最终将会被解析成IP地址：端口。</p><p>Borg还负责将具体资源分配给某个任务。可能是CPU、内存等</p><h1 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h1><p>每个任务实例可以利用集群级别的存储系统存储文件。</p><p>Google的存储系统负责向用户提供一套简单易用、可靠的集群存储服务。</p><ul><li>最底层由D服务提供，D是一个文件服务器，几乎运行在整个集群的所有物理服务器上。</li><li>D服务之上被称为Colossus，Colossus建立了一个覆盖文件系统，包含了传统文件系统的操作接口，还支持复制与加密</li><li>在Colossus之上，是谷歌自主研发的几种数据库</li><li>A：Bigtable是一个Nosql数据库，它可以处理高达PB的数据。Bigtable是一个松散存储的、分布式的、有序的、持久化的多维映射表。</li><li>B.Spanner是可以提供SQL接口满足一致性要求的全球数据库</li><li>C.其他几种数据库系统</li></ul><h1 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h1><p>Google的网络硬件设备是由一个基于OpenFlow协议的软件定义网络（SDN）控制的。</p><p>Google没有使用高级智能路由器，而是采用普通的非智能交换组件结合集中化（有备份的）的控制器连接方式。</p><p>该控制器计算网络中的最佳路径。</p><p>这种系统可以将复杂的路由计算从具体硬件上分离出来，降低成本。</p><p>带宽控制器（Bandwidth Enforcer，BwE）负责管理所有可用带宽。利用中心化的路由计算，有解决以前在分布式路由模式下难以解决的流量问题。</p><p>Google的全球负载均衡器在三个层面上负责工作：</p><ul><li>利用地理位置信息进行负载均衡的DNS请求，例如解析（<a href="http://www.google.com" target="_blank" rel="noopener">www.google.com</a>)</li><li>在用户服务层面进行负载均衡，例如YouTube和Google Maps</li><li>在远程调用（RPC）层面进行负载均衡</li></ul><h1 id="其他软件系统"><a href="#其他软件系统" class="headerlink" title="其他软件系统"></a>其他软件系统</h1><h2 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h2><p>Chubby集群锁提供一个API来操作锁，它可以处理异地、跨机房级别锁的请求。</p><p>Chubby使用Paxos协议来提供分布式一致性。</p><p>适合放对一致性要求非常高的数据。例如BNS服务就使用的Chubby存放路径与IP地址：端口的对应关系。</p><h2 id="监控与报警系统"><a href="#监控与报警系统" class="headerlink" title="监控与报警系统"></a>监控与报警系统</h2><ul><li>对真实问题报警</li><li>对比更新应用前后，新版本是否让软件服务更快了</li><li>检查资源使用量，对制定升降配计划很有效</li></ul><h2 id="基础软件设施"><a href="#基础软件设施" class="headerlink" title="基础软件设施"></a>基础软件设施</h2><p>所有的Google服务用RPC通信，称为Stubby。目前公布了一个开源实现：gRPC。</p><p>Protocol Buffer是Google RPC的传输格式，相比XML有很多优势，简单易用，数据大小比XML小3-10倍，序列化和反序列化快100倍，并且协议明确。</p><h2 id="研发环境"><a href="#研发环境" class="headerlink" title="研发环境"></a>研发环境</h2><p>规则：更新即需审核，即使这个更新是自己的代码。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>取自《SRE：Google运维解密》前10-20页，总结归纳的心得。</p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Sre </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Sre </tag>
            
            <tag> Google </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维手册——Kubernetes容器时区不同步</title>
      <link href="2020/07/22/bug/dockerfile-time-zone/"/>
      <url>2020/07/22/bug/dockerfile-time-zone/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>Kubernetes容器时间不同步,最近开发反应说容器里的时间不对，差了8个小时，我寻思不是应该时区不对吗，开始了排错之旅</p><h1 id="现象"><a href="#现象" class="headerlink" title="现象"></a>现象</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# docker exec -it test date</span><br><span class="line">Tue Jul 21 09:32:03 Asia 2020</span><br><span class="line">[root@localhost ~]# date</span><br><span class="line">Tue Jul 21 17:32:05 CST 2020</span><br></pre></td></tr></table></figure><h1 id="从容器的启动命令查起"><a href="#从容器的启动命令查起" class="headerlink" title="从容器的启动命令查起"></a>从容器的启动命令查起</h1><p>我查看这个项目deployment.yaml文件,只展示容器部分配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">containers:</span><br><span class="line">      - args:</span><br><span class="line">        - -jar</span><br><span class="line">        - -Xms4096m</span><br><span class="line">        - -Xmx4096m</span><br><span class="line">        - -Xmn256m</span><br><span class="line">        - -Xss256k</span><br><span class="line">        - -Duser.timezone&#x3D;GMT+08</span><br><span class="line">        - -XX:+DisableExplicitGC</span><br><span class="line">        - -XX:+UseConcMarkSweepGC</span><br><span class="line">        - -XX:+UseParNewGC</span><br><span class="line">        - -XX:+CMSParallelRemarkEnabled</span><br><span class="line">        - -XX:+CMSClassUnloadingEnabled</span><br><span class="line">        - -XX:LargePageSizeInBytes&#x3D;128m</span><br><span class="line">        - -XX:+UseFastAccessorMethods</span><br><span class="line">        - -XX:+UseCMSInitiatingOccupancyOnly</span><br><span class="line">        - -XX:CMSInitiatingOccupancyFraction&#x3D;80</span><br><span class="line">        - -XX:SoftRefLRUPolicyMSPerMB&#x3D;0</span><br><span class="line">        - -XX:+PrintClassHistogram</span><br><span class="line">        - -Dfile.encoding&#x3D;UTF8</span><br><span class="line">        - -Dsun.jnu.encoding&#x3D;UTF8</span><br><span class="line">        - app.jar</span><br><span class="line">        - --spring.profiles.active&#x3D;dev</span><br><span class="line">        command:</span><br><span class="line">        - java</span><br><span class="line">        env:</span><br><span class="line">        - name: PATH</span><br><span class="line">          value: &#x2F;usr&#x2F;local&#x2F;maven&#x2F;bin:&#x2F;bin:&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;local&#x2F;bin:&#x2F;usr&#x2F;sbin:&#x2F;usr&#x2F;bin:&#x2F;sbin:&#x2F;bin</span><br><span class="line">        image: xxxx</span><br><span class="line">        imagePullPolicy: Always</span><br><span class="line">        name: cjbbasecore</span><br><span class="line">        resources: &#123;&#125;</span><br><span class="line">        securityContext:</span><br><span class="line">          privileged: false</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - mountPath: &#x2F;etc&#x2F;localtime</span><br><span class="line">          name: time</span><br><span class="line">          readOnly: true</span><br><span class="line">        workingDir: &#x2F;</span><br><span class="line">      dnsPolicy: ClusterFirst</span><br><span class="line">      restartPolicy: Always</span><br><span class="line">      securityContext: &#123;&#125;</span><br><span class="line">      serviceAccountName: &quot;&quot;</span><br><span class="line">      terminationGracePeriodSeconds: 30</span><br><span class="line">      volumes:</span><br><span class="line">      - hostPath:</span><br><span class="line">          path: &#x2F;etc&#x2F;localtime</span><br><span class="line">        name: time</span><br><span class="line">status: &#123;&#125;</span><br></pre></td></tr></table></figure><p>我发现写这个yaml文件的同事已经考虑到了时间同步的问题，已经把本机Locattime挂载进去了，难道有其他问题？        </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">    volumeMounts:</span><br><span class="line">    - mountPath: &#x2F;etc&#x2F;localtime</span><br><span class="line">      name: time</span><br><span class="line">      readOnly: true</span><br><span class="line">volumes:</span><br><span class="line">    - hostPath:</span><br><span class="line">      path: &#x2F;etc&#x2F;localtime</span><br><span class="line">    name: time</span><br></pre></td></tr></table></figure><h1 id="查Dockerfile"><a href="#查Dockerfile" class="headerlink" title="查Dockerfile"></a>查Dockerfile</h1><p>我们容器的基础镜像的是Ubuntu:18.04，</p><p>我找到了JDK镜像中的底层镜像，我发现了环境变量中的TZ=”Asia/Shanghai”设置的没有问题，试一下启动这个基础镜像吧</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">############################################</span><br><span class="line"># desc : 当前版本安装的ssh，wget，curl，supervisor </span><br><span class="line">############################################</span><br><span class="line"># 设置继承自ubuntu官方镜像18</span><br><span class="line">FROM ubuntu:bionic </span><br><span class="line"></span><br><span class="line">ENV LANG&#x3D;C.UTF-8 \</span><br><span class="line">    TZ&#x3D;&quot;Asia&#x2F;Shanghai&quot; \</span><br><span class="line">    TINI_VERSION&#x3D;&quot;v0.19.0&quot;</span><br><span class="line"></span><br><span class="line"># Add mirror source</span><br><span class="line">RUN cp &#x2F;etc&#x2F;apt&#x2F;sources.list &#x2F;etc&#x2F;apt&#x2F;sources.list.bak &amp;&amp; \</span><br><span class="line">    sed -i &#39;s http:&#x2F;&#x2F;.*.ubuntu.com http:&#x2F;&#x2F;mirrors.aliyun.com g&#39; &#x2F;etc&#x2F;apt&#x2F;sources.list</span><br><span class="line"></span><br><span class="line"># Fix base image</span><br><span class="line">RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \</span><br><span class="line">libidn2-0 \</span><br><span class="line">ca-certificates \</span><br><span class="line">tar \</span><br><span class="line">gzip \</span><br><span class="line">unzip \</span><br><span class="line">locales \</span><br><span class="line">wget \</span><br><span class="line">        curl \</span><br><span class="line">        vim \</span><br><span class="line">gnupg \</span><br><span class="line">&amp;&amp; rm -rf &#x2F;var&#x2F;lib&#x2F;apt&#x2F;lists&#x2F;*</span><br><span class="line"></span><br><span class="line"># grab gosu for easy step-down from root</span><br><span class="line">ENV GOSU_VERSION 1.7</span><br><span class="line">RUN set -x \</span><br><span class="line">&amp;&amp; wget -O &#x2F;usr&#x2F;local&#x2F;bin&#x2F;gosu &quot;https:&#x2F;&#x2F;gh.api.99988866.xyz&#x2F;https:&#x2F;&#x2F;github.com&#x2F;tianon&#x2F;gosu&#x2F;releases&#x2F;download&#x2F;$GOSU_VERSION&#x2F;gosu-$(dpkg --print-architecture)&quot; \</span><br><span class="line">&amp;&amp; wget -O &#x2F;usr&#x2F;local&#x2F;bin&#x2F;gosu.asc &quot;https:&#x2F;&#x2F;gh.api.99988866.xyz&#x2F;https:&#x2F;&#x2F;github.com&#x2F;tianon&#x2F;gosu&#x2F;releases&#x2F;download&#x2F;$GOSU_VERSION&#x2F;gosu-$(dpkg --print-architecture).asc&quot; \</span><br><span class="line">&amp;&amp; export GNUPGHOME&#x3D;&quot;$(mktemp -d)&quot; \</span><br><span class="line">&amp;&amp; gpg --keyserver ha.pool.sks-keyservers.net --recv-keys B42F6819007F00F88E364FD4036A9C25BF357DD4 \</span><br><span class="line">&amp;&amp; gpg --batch --verify &#x2F;usr&#x2F;local&#x2F;bin&#x2F;gosu.asc &#x2F;usr&#x2F;local&#x2F;bin&#x2F;gosu \</span><br><span class="line">&amp;&amp; rm -r &quot;$GNUPGHOME&quot; &#x2F;usr&#x2F;local&#x2F;bin&#x2F;gosu.asc \</span><br><span class="line">&amp;&amp; chmod +x &#x2F;usr&#x2F;local&#x2F;bin&#x2F;gosu \</span><br><span class="line">&amp;&amp; gosu nobody true</span><br><span class="line"></span><br><span class="line">## 安装tini</span><br><span class="line">RUN set -x \</span><br><span class="line">  &amp;&amp; wget -O &#x2F;usr&#x2F;local&#x2F;bin&#x2F;tini \</span><br><span class="line">         &quot;https:&#x2F;&#x2F;gh.api.99988866.xyz&#x2F;https:&#x2F;&#x2F;github.com&#x2F;krallin&#x2F;tini&#x2F;releases&#x2F;download&#x2F;$&#123;TINI_VERSION&#125;&#x2F;tini-static-amd64&quot; &amp;&amp; \</span><br><span class="line">      wget -O &#x2F;usr&#x2F;local&#x2F;bin&#x2F;tini.asc \</span><br><span class="line">         &quot;https:&#x2F;&#x2F;gh.api.99988866.xyz&#x2F;https:&#x2F;&#x2F;github.com&#x2F;krallin&#x2F;tini&#x2F;releases&#x2F;download&#x2F;$&#123;TINI_VERSION&#125;&#x2F;tini-static-amd64.asc&quot; &amp;&amp; \</span><br><span class="line">    gpg --batch --keyserver hkp:&#x2F;&#x2F;p80.pool.sks-keyservers.net:80 \</span><br><span class="line">          --recv-keys 595E85A6B1B4779EA4DAAEC70B588DFF0527A9B7 &amp;&amp; \</span><br><span class="line">      gpg --batch --verify &#x2F;usr&#x2F;local&#x2F;bin&#x2F;tini.asc &#x2F;usr&#x2F;local&#x2F;bin&#x2F;tini &amp;&amp; \</span><br><span class="line">      rm -r &#x2F;usr&#x2F;local&#x2F;bin&#x2F;tini.asc &amp;&amp; \</span><br><span class="line">      chmod +x &#x2F;usr&#x2F;local&#x2F;bin&#x2F;tini &amp;&amp; \</span><br><span class="line">      tini --version</span><br><span class="line"></span><br><span class="line">ENTRYPOINT [&quot;tini&quot;, &quot;--&quot;]</span><br></pre></td></tr></table></figure><h1 id="启动这个基础镜像"><a href="#启动这个基础镜像" class="headerlink" title="启动这个基础镜像"></a>启动这个基础镜像</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# docker run -itd xxx.com&#x2F;javabase:0.1.0 </span><br><span class="line">[root@localhost ~]# docker exec -it llible_jones date</span><br><span class="line">Tue Jul 21 09:32:03 Asia 2020</span><br><span class="line">[root@localhost ~]# date</span><br><span class="line">Tue Jul 21 17:32:05 CST 2020</span><br></pre></td></tr></table></figure><p>发现还是不行，然后选择网上建议的几种修改时区的方法</p><h2 id="tzselect命令执行"><a href="#tzselect命令执行" class="headerlink" title="tzselect命令执行"></a>tzselect命令执行</h2><p>执行tzselect命令 –&gt; 选择Asia –&gt; 选择China –&gt; 选择east China - Beijing, Guangdong, Shanghai, etc–&gt;然后输入1。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">root@12aa3e0a3573:&#x2F;# tzselect</span><br><span class="line">&#x2F;usr&#x2F;bin&#x2F;tzselect: line 180: &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;iso3166.tab: No such file or directory</span><br><span class="line">&#x2F;usr&#x2F;bin&#x2F;tzselect: time zone files are not set up correctly</span><br></pre></td></tr></table></figure><p>结果直接发现找不到这个依赖</p><h2 id="修改配置文件来修改时区"><a href="#修改配置文件来修改时区" class="headerlink" title="修改配置文件来修改时区"></a>修改配置文件来修改时区</h2><p>复制主机的localtime</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker cp &#x2F;usr&#x2F;share&#x2F;zoneinfo&#x2F;Asia&#x2F;Shanghai 12aa3e0a3573:&#x2F;etc&#x2F;localtime</span><br></pre></td></tr></table></figure><p>结果还是不行</p><h2 id="最终方法"><a href="#最终方法" class="headerlink" title="最终方法"></a>最终方法</h2><p>经过搜索各种文件修改时区的方法后，只有一种我试过是成功的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">apt update</span><br><span class="line">apt install -y tzdata</span><br><span class="line">echo &quot;Asia&#x2F;Shanghai&quot; &gt; &#x2F;etc&#x2F;timezone</span><br><span class="line">rm -f &#x2F;etc&#x2F;localtime</span><br><span class="line">dpkg-reconfigure -f noninteractive tzdata</span><br></pre></td></tr></table></figure><h1 id="重新制作镜像"><a href="#重新制作镜像" class="headerlink" title="重新制作镜像"></a>重新制作镜像</h1><p>再开启另外有一个窗口,提交这个容器的当前状态为一个新的版本镜像，推送这个镜像到镜像仓库里</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker commit test xxx.com&#x2F;javabase:0.1.1</span><br><span class="line">docker pull xxx.com&#x2F;javabase:0.1.1</span><br></pre></td></tr></table></figure><p>最后再更改原jdk Dockerfile里的from xxx.com/javabase:0.1.1</p><p>重新打包构建项目即可恢复正常的时区</p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Operation Manual </tag>
            
            <tag> Timezone </tag>
            
            <tag> Dockerfile </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入浅出Docker原理及实战(六)——重新认识Docker容器</title>
      <link href="2020/07/19/docker/docker-idea-6/"/>
      <url>2020/07/19/docker/docker-idea-6/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><p>深入浅出Docker原理及实战系列第六篇，我主要讲一下Docker容器的本质。</p><p>从进程说起。</p><h1 id="进程"><a href="#进程" class="headerlink" title="进程"></a>进程</h1><p>假如，现在你要写一个计算加法的小程序，这个程序需要的输入来自于一个文件，计算完成后的结果则输出到另一个文件中。</p><p>由于计算机只认识 0 和 1，所以无论用哪种语言编写这段代码，最后都需要通过某种方式翻译成二进制文件，才能在计算机操作系统中运行起来。</p><p>而为了能够让这些代码正常运行，我们往往还要给它提供数据，比如我们这个加法程序所需要的输入文件。这些数据加上代码本身的二进制文件，放在磁盘上，就是我们平常所说的一个“程序”，也叫代码的可执行镜像（executable image）。</p><p>然后，我们就可以在计算机上运行这个“程序”了。</p><p>首先，操作系统从“程序”中发现输入数据保存在一个文件中，所以这些数据就会被加载到内存中待命。同时，操作系统又读取到了计算加法的指令，这时，它就需要指示 CPU 完成加法操作。而 CPU 与内存协作进行加法计算，又会使用寄存器存放数值、内存堆栈保存执行的命令和变量。同时，计算机里还有被打开的文件，以及各种各样的 I/O 设备在不断地调用中修改自己的状态。</p><p>就这样，一旦“程序”被执行起来，它就从磁盘上的二进制文件，变成了计算机内存中的数据、寄存器里的值、堆栈中的指令、被打开的文件，以及各种设备的状态信息的一个集合。像这样一个程序运行起来后的计算机执行环境的总和，就是我们今天的主角：进程。</p><p>所以，对于进程来说，它的静态表现就是程序，平常都安安静静地待在磁盘上；而一旦运行起来，它就变成了计算机里的数据和状态的总和，这就是它的动态表现。</p><p>而容器技术的核心功能，就是通过约束和修改进程的动态表现，从而为其创造出一个“边界”。</p><h1 id="Docker的底层原理"><a href="#Docker的底层原理" class="headerlink" title="Docker的底层原理"></a>Docker的底层原理</h1><p>我们在前面讲过Docker的底层原理其实就是几个概念</p><ul><li>NameSpace 命名空间</li><li>Cgroups 控制组</li><li>Union file systems 联合文件系统</li><li>Container format 容器格式。</li></ul><p>对于 Docker 等大多数 Linux 容器来说，Cgroups 技术是用来制造约束的主要手段，而 Namespace 技术则是用来修改进程视图的主要方法，Union file systems 技术存放了项目(代码)启动的所有环境依赖。</p><h2 id="NameSpace"><a href="#NameSpace" class="headerlink" title="NameSpace"></a>NameSpace</h2><p>Linux namespaces 是对全局系统资源的一种封装隔离，使得处于不同 namespace 的进程拥有独立的全局系统资源，改变一个 namespace 中的系统资源只会影响当前 namespace 里的进程，对其他 namespace 中的进程没有影响。</p><p>我们首先创建一个容器来试试。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -it busybox &#x2F;bin&#x2F;sh&#x2F;</span><br></pre></td></tr></table></figure><p>这个命令是 Docker 项目最重要的一个操作，即大名鼎鼎的 docker run。</p><p>而 -it 参数告诉了 Docker 项目在启动容器后，需要给我们分配一个文本输入 / 输出环境，也就是 TTY，跟容器的标准输入相关联，这样我们就可以和这个 Docker 容器进行交互了。</p><p>而 /bin/sh 就是我们要在 Docker 容器里运行的程序。</p><p>所以，上面这条指令翻译成人类的语言就是：请帮我启动一个容器，在容器里执行 /bin/sh，并且给我分配一个命令行终端跟这个容器交互。</p><h3 id="容器的第一个进程"><a href="#容器的第一个进程" class="headerlink" title="容器的第一个进程"></a>容器的第一个进程</h3><p>我们在讲Dockerfile制作的时候提到过，一个Dockerfile只能一个CMD指令。如果出现多个CMD 则只有最后一个CMD才会生效。因为容器启动的时候第一条命令就是容器内部的第一号进程。</p><p>接着上文，如果我们在容器里执行一下 ps 指令，就会发现一些更有趣的事情：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F; # ps</span><br><span class="line">PID USER TIME COMMAND </span><br><span class="line">1 root 0:00 &#x2F;bin&#x2F;sh </span><br><span class="line">10 root 0:00 ps</span><br></pre></td></tr></table></figure><p>可以看到，我们在 Docker 里最开始执行的 /bin/sh，就是这个容器内部的第 1 号进程（PID=1），而这个容器里一共只有两个进程在运行。这就意味着，前面执行的 /bin/sh，以及我们刚刚执行的 ps，已经被 Docker 隔离在了一个跟宿主机完全不同的世界当中。</p><h3 id="NameSpace的障眼法"><a href="#NameSpace的障眼法" class="headerlink" title="NameSpace的障眼法"></a>NameSpace的障眼法</h3><p>本来，每当我们在宿主机上运行了一个 /bin/sh 程序，操作系统都会给它分配一个进程编号，比如 PID=100。这个编号是进程的唯一标识，就像员工的工牌一样。</p><p>所以 PID=100，可以粗略地理解为这个 /bin/sh 是我们公司里的第 100 号员工，而第 1 号员工就自然是比尔 · 盖茨这样统领全局的人物。</p><p>而现在，我们要通过 Docker 把这个 /bin/sh 程序运行在一个容器当中。这时候，Docker 就会在这个第 100 号员工入职时给他施一个“障眼法”，让他永远看不到前面的其他 99 个员工，更看不到比尔 · 盖茨。这样，他就会错误地以为自己就是公司里的第 1 号员工。</p><p>这种机制，其实就是对被隔离应用的进程空间做了手脚，使得这些进程只能看到重新计算过的进程编号，比如 PID=1。可实际上，他们在宿主机的操作系统里，还是原来的第 100 号进程。</p><p>这种技术，就是 Linux 里面的 Namespace 机制。而 Namespace 的使用方式也非常有意思：它其实只是 Linux 创建新进程的一个可选参数。我们知道，在 Linux 系统中创建线程的系统调用是 clone()，比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int pid &#x3D; clone(main_function, stack_size, SIGCHLD, NULL);</span><br></pre></td></tr></table></figure><p>这个系统调用就会为我们创建一个新的进程，并且返回它的进程号 pid。</p><p>而当我们用 clone() 系统调用创建一个新进程时，就可以在参数中指定 CLONE_NEWPID 参数，比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">int pid &#x3D; clone(main_function, stack_size, CLONE_NEWPID | SIGCHLD, NULL);</span><br></pre></td></tr></table></figure><p>这时，新创建的这个进程将会“看到”一个全新的进程空间，在这个进程空间里，它的 PID 是 1。之所以说“看到”，是因为这只是一个“障眼法”，在宿主机真实的进程空间里，这个进程的 PID 还是真实的数值，比如 100。</p><p>当然，我们还可以多次执行上面的 clone() 调用，这样就会创建多个 PID Namespace，而每个 Namespace 里的应用进程，都会认为自己是当前容器里的第 1 号进程，它们既看不到宿主机里真正的进程空间，也看不到其他 PID Namespace 里的具体情况。</p><h3 id="NameSpace小结"><a href="#NameSpace小结" class="headerlink" title="NameSpace小结"></a>NameSpace小结</h3><p>而除了我们刚刚用到的 PID Namespace，Linux 操作系统还提供了 Mount、UTS、IPC、Network 和 User 这些 Namespace，用来对各种不同的进程上下文进行“障眼法”操作。</p><p>这，就是 Linux 容器最基本的实现原理了。所以，Docker 容器这个听起来玄而又玄的概念，实际上是在创建容器进程时，指定了这个进程所需要启用的一组 Namespace 参数。这样，容器就只能“看”到当前 Namespace 所限定的资源、文件、设备、状态，或者配置。而对于宿主机以及其他不相关的程序，它就完全看不到了。</p><p>在理解了 Namespace 的工作方式之后，你就会明白，跟真实存在的虚拟机不同，在使用 Docker 的时候，并没有一个真正的“Docker 容器”运行在宿主机里面。Docker 项目帮助用户启动的，还是原来的应用进程，只不过在创建这些进程时，Docker 为它们加上了各种各样的 Namespace 参数。这时，这些进程就会觉得自己是各自 PID Namespace 里的第 1 号进程，只能看到各自 Mount Namespace 里挂载的目录和文件，只能访问到各自 Network Namespace 里的网络设备，就仿佛运行在一个个“容器”里面，与世隔绝。</p><h2 id="Cgroups"><a href="#Cgroups" class="headerlink" title="Cgroups"></a>Cgroups</h2><p>Linux Cgroups 的全称是 Linux Control Group。它最主要的作用，就是限制一个进程组能够使用的资源上限，包括 CPU、内存、磁盘、网络带宽等等。</p><p>此外，Cgroups 还能够对进程进行优先级设置、审计，以及将进程挂起和恢复等操作。</p><h3 id="操作Cgroups"><a href="#操作Cgroups" class="headerlink" title="操作Cgroups"></a>操作Cgroups</h3><p>在 Linux 中，Cgroups 给用户暴露出来的操作接口是文件系统，即它以文件和目录的方式组织在操作系统的 /sys/fs/cgroup 路径下。</p><p>指令把它们展示出来，这条命令是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-28-16 ~]# mount -t cgroup</span><br><span class="line">cgroup on &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;systemd type cgroup (rw,nosuid,nodev,noexec,relatime,xattr,release_agent&#x3D;&#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;systemd-cgroups-agent,name&#x3D;systemd)</span><br><span class="line">cgroup on &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;hugetlb type cgroup (rw,nosuid,nodev,noexec,relatime,hugetlb)</span><br><span class="line">cgroup on &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;devices type cgroup (rw,nosuid,nodev,noexec,relatime,devices)</span><br><span class="line">cgroup on &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu,cpuacct type cgroup (rw,nosuid,nodev,noexec,relatime,cpuacct,cpu)</span><br><span class="line">cgroup on &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;pids type cgroup (rw,nosuid,nodev,noexec,relatime,pids)</span><br><span class="line">cgroup on &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;perf_event type cgroup (rw,nosuid,nodev,noexec,relatime,perf_event)</span><br><span class="line">cgroup on &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;net_cls,net_prio type cgroup (rw,nosuid,nodev,noexec,relatime,net_prio,net_cls)</span><br><span class="line">cgroup on &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;blkio type cgroup (rw,nosuid,nodev,noexec,relatime,blkio)</span><br><span class="line">cgroup on &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpuset type cgroup (rw,nosuid,nodev,noexec,relatime,cpuset)</span><br><span class="line">cgroup on &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;memory type cgroup (rw,nosuid,nodev,noexec,relatime,memory)</span><br><span class="line">cgroup on &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;freezer type cgroup (rw,nosuid,nodev,noexec,relatime,freezer)</span><br></pre></td></tr></table></figure><p>可以看到，在 /sys/fs/cgroup 下面有很多诸如 cpuset、cpu、 memory 这样的子目录，也叫子系统。</p><p>这些都是我这台机器当前可以被 Cgroups 进行限制的资源种类。而在子系统对应的资源种类下，你就可以看到该类资源具体可以被限制的方法。比如，对 CPU 子系统来说，我们就可以看到如下几个配置文件，这个指令是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-28-16 ~]# ls &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu</span><br><span class="line">cgroup.clone_children  cpuacct.usage         cpu.rt_runtime_us  kubepods.slice     user.slice</span><br><span class="line">cgroup.event_control   cpuacct.usage_percpu  cpu.shares         notify_on_release</span><br><span class="line">cgroup.procs           cpu.cfs_period_us     cpu.stat           release_agent</span><br><span class="line">cgroup.sane_behavior   cpu.cfs_quota_us      docker             system.slice</span><br><span class="line">cpuacct.stat           cpu.rt_period_us      kubepods           tasks</span><br></pre></td></tr></table></figure><p>如果熟悉 Linux CPU 管理的话，你就会在它的输出里注意到 cfs_period 和 cfs_quota 这样的关键词。这两个参数需要组合使用，可以用来限制进程在长度为 cfs_period 的一段时间内，只能被分配到总量为 cfs_quota 的 CPU 时间。</p><p>而这样的配置文件又如何使用呢？</p><p>你需要在对应的子系统下面创建一个目录，比如，我们现在进入 /sys/fs/cgroup/cpu 目录下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-28-16 cpu]# mkdir test</span><br><span class="line">[root@VM-28-16 cpu]# cd test&#x2F;</span><br><span class="line">[root@VM-28-16 test]# ll</span><br><span class="line">total 0</span><br><span class="line">-rw-r--r-- 1 root root 0 Jul 18 17:31 cgroup.clone_children</span><br><span class="line">--w--w--w- 1 root root 0 Jul 18 17:31 cgroup.event_control</span><br><span class="line">-rw-r--r-- 1 root root 0 Jul 18 17:31 cgroup.procs</span><br><span class="line">-r--r--r-- 1 root root 0 Jul 18 17:31 cpuacct.stat</span><br><span class="line">-rw-r--r-- 1 root root 0 Jul 18 17:31 cpuacct.usage</span><br><span class="line">-r--r--r-- 1 root root 0 Jul 18 17:31 cpuacct.usage_percpu</span><br><span class="line">-rw-r--r-- 1 root root 0 Jul 18 17:31 cpu.cfs_period_us</span><br><span class="line">-rw-r--r-- 1 root root 0 Jul 18 17:31 cpu.cfs_quota_us</span><br><span class="line">-rw-r--r-- 1 root root 0 Jul 18 17:31 cpu.rt_period_us</span><br><span class="line">-rw-r--r-- 1 root root 0 Jul 18 17:31 cpu.rt_runtime_us</span><br><span class="line">-rw-r--r-- 1 root root 0 Jul 18 17:31 cpu.shares</span><br><span class="line">-r--r--r-- 1 root root 0 Jul 18 17:31 cpu.stat</span><br><span class="line">-rw-r--r-- 1 root root 0 Jul 18 17:31 notify_on_release</span><br><span class="line">-rw-r--r-- 1 root root 0 Jul 18 17:31 tasks</span><br></pre></td></tr></table></figure><p>这个目录就称为一个“控制组”。你会发现，操作系统会在你新创建的 test 目录下，自动生成该子系统对应的资源限制文件。</p><p>现在，我们在后台执行这样一条脚本：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-28-16 test]# while : ; do : ; done &amp;</span><br><span class="line">[1] 32705</span><br><span class="line">[root@VM-28-16 test]# top</span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                    </span><br><span class="line">32705 root      20   0  116496   1632    140 R 100.0  0.0   3:58.89 bash</span><br></pre></td></tr></table></figure><p>可以看到CPU的打满了（%Cpu0 :100.0 us）</p><p>而此时，我们可以通过查看 test 目录下的文件，看到 container 控制组里的 CPU quota 还没有任何限制（即：-1），CPU period 则是默认的 100 ms（100000 us）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-28-16 test]# cat cpu.cfs_quota_us </span><br><span class="line">-1</span><br><span class="line">[root@VM-28-16 test]# cat cpu.cfs_period_us </span><br><span class="line">100000</span><br></pre></td></tr></table></figure><p>接下来，我们可以通过修改这些文件的内容来设置限制。比如，向 test 组里的 cfs_quota 文件写入 20 ms（20000 us）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-28-16 test]# echo 20000 &gt; &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu&#x2F;test&#x2F;cpu.cfs_quota_us</span><br></pre></td></tr></table></figure><p>结合前面的介绍，你应该能明白这个操作的含义，它意味着在每 100 ms 的时间里，被该控制组限制的进程只能使用 20 ms 的 CPU 时间，也就是说这个进程只能使用到 20% 的 CPU 带宽。</p><p>接下来，我们把被限制的进程的 PID 写入 test 组里的 tasks 文件，上面的设置就会对该进程生效了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-28-16 test]# echo 32705 &gt; &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu&#x2F;test&#x2F;tasks</span><br><span class="line"></span><br><span class="line">[root@VM-28-16 test]# top</span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                    </span><br><span class="line">32705 root      20   0  116496   1632    140 R  20.1  0.0   8:01.77 bash</span><br></pre></td></tr></table></figure><p>计算机的 CPU 使用率立刻降到了 20%（%Cpu0 : 20.8 us）。</p><h3 id="Cgroups的设计"><a href="#Cgroups的设计" class="headerlink" title="Cgroups的设计"></a>Cgroups的设计</h3><p>除 CPU 子系统外，Cgroups 的每一个子系统都有其独有的资源限制能力，比如：</p><ul><li>blkio，为块设备设定I/O 限制，一般用于磁盘等设备</li><li>cpuset，为进程分配单独的 CPU 核和对应的内存节点</li><li>memory，为进程设定内存使用的限制。</li></ul><p>Linux Cgroups 的设计还是比较易用的，简单粗暴地理解呢，它就是一个子系统目录加上一组资源限制文件的组合。而对于 Docker 等 Linux 容器项目来说，它们只需要在每个子系统下面，为每个容器创建一个控制组（即创建一个新目录），然后在启动容器进程之后，把这个进程的 PID 填写到对应控制组的 tasks 文件中就可以了。</p><p>而至于在这些控制组下面的资源文件里填上什么值，就靠用户执行 docker run 时的参数指定了，比如这样一条命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -it --cpu-period&#x3D;100000 --cpu-quota&#x3D;20000 ubuntu &#x2F;bin&#x2F;bash</span><br></pre></td></tr></table></figure><p>在启动这个容器后，我们可以通过查看 Cgroups 文件系统下，CPU 子系统中，“docker”这个控制组里的资源限制文件的内容来确认：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ cat &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu&#x2F;docker&#x2F;5d5c9f67d&#x2F;cpu.cfs_period_us </span><br><span class="line">100000</span><br><span class="line">$ cat &#x2F;sys&#x2F;fs&#x2F;cgroup&#x2F;cpu&#x2F;docker&#x2F;5d5c9f67d&#x2F;cpu.cfs_quota_us </span><br><span class="line">20000</span><br></pre></td></tr></table></figure><p>这就意味着这个 Docker 容器，只能使用到 20% 的 CPU 带宽。</p><h3 id="Cgroups小结"><a href="#Cgroups小结" class="headerlink" title="Cgroups小结"></a>Cgroups小结</h3><p>一个正在运行的 Docker 容器，其实就是一个启用了多个 Linux Namespace 的应用进程，而这个进程能够使用的资源量，则受 Cgroups 配置的限制。</p><h2 id="Union-File-System"><a href="#Union-File-System" class="headerlink" title="Union File System"></a>Union File System</h2><p>作为一个普通用户，我们希望：每当创建一个新容器时，容器里的应用进程，理应看到一份完全独立的文件系统。这样，它就可以在自己的容器目录（比如 /tmp）下进行操作，而完全不会受宿主机以及其他容器的影响。怎么才能做到这一点呢？</p><p>上文提到了Namespace里存在一种Mount Namespace</p><p>它的存在使我们可以在容器进程启动之前重新挂载它的整个根目录“/”。<br>这个挂载对宿主机不可见，所以容器进程就可以在里面随便折腾了。</p><h3 id="chroot"><a href="#chroot" class="headerlink" title="chroot"></a>chroot</h3><p>在 Linux 操作系统里，有一个名为 chroot 的命令可以帮助你在 shell 中方便地完成这个工作。顾名思义，它的作用就是帮你“change root file system”，即改变进程的根目录到你指定的位置。它的用法也非常简单。</p><p>假设，我们现在有一个 $HOME/test 目录，想要把它作为一个 /bin/bash 进程的根目录。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">首先，创建一个 test 目录和几个 lib 文件夹：</span><br><span class="line"></span><br><span class="line">mkdir -p $HOME&#x2F;test</span><br><span class="line">mkdir -p $HOME&#x2F;test&#x2F;&#123;bin,lib64,lib&#125;</span><br><span class="line"></span><br><span class="line">然后，把 bash 命令拷贝到 test 目录对应的 bin 路径下</span><br><span class="line"></span><br><span class="line">cp -v &#x2F;bin&#x2F;&#123;bash,ls&#125; $HOME&#x2F;test&#x2F;bin</span><br><span class="line"></span><br><span class="line">接下来，把 bash 命令需要的所有 so 文件，也拷贝到 test 目录对应的 lib 路径下。找到 so 文件可以用 ldd 命令：</span><br><span class="line"></span><br><span class="line">T&#x3D;$HOME&#x2F;test</span><br><span class="line">list&#x3D;&quot;$(ldd &#x2F;bin&#x2F;ls | egrep -o &#39;&#x2F;lib.*\.[0-9]&#39;)&quot;</span><br><span class="line">for i in $list; do cp -v &quot;$i&quot; &quot;$&#123;T&#125;$&#123;i&#125;&quot;; done</span><br><span class="line"></span><br><span class="line">最后，执行 chroot 命令，告诉操作系统，我们将使用 $HOME&#x2F;test 目录作为 &#x2F;bin&#x2F;bash 进程的根目录：</span><br><span class="line"></span><br><span class="line">chroot $HOME&#x2F;test &#x2F;bin&#x2F;bash</span><br></pre></td></tr></table></figure><p>这时，你如果执行 “ls /“，就会看到，它返回的都是 $HOME/test 目录下面的内容，而不是宿主机的内容。</p><p>更重要的是，对于被 chroot 的进程来说，它并不会感受到自己的根目录已经被“修改”成 $HOME/test 了。</p><h3 id="rootfs"><a href="#rootfs" class="headerlink" title="rootfs"></a>rootfs</h3><p>实际上，Mount Namespace 正是基于对 chroot 的不断改良才被发明出来的，它也是 Linux 操作系统里的第一个 Namespace。</p><p>而这个挂载在容器根目录上、用来为容器进程提供隔离后执行环境的文件系统，就是所谓的“容器镜像”。它还有一个更为专业的名字，叫作：rootfs（根文件系统）。</p><p>所以，一个最常见的 rootfs，或者说容器镜像，会包括如下所示的一些目录和文件，比如 /bin，/etc，/proc 等等</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ ls &#x2F;</span><br><span class="line">bin dev etc home lib lib64 mnt opt proc root run sbin sys tmp usr var</span><br></pre></td></tr></table></figure><p>现在，你应该可以理解，对 Docker 项目来说，它最核心的原理实际上就是为待创建的用户进程：</p><ul><li>启用 Linux Namespace 配置；</li><li>设置指定的 Cgroups 参数</li><li>切换进程的根目录（Change Root）。</li></ul><p>另外，需要明确的是，rootfs 只是一个操作系统所包含的文件、配置和目录，并不包括操作系统内核。</p><p>在 Linux 操作系统中，这两部分是分开存放的，操作系统只有在开机启动时才会加载指定版本的内核镜像。</p><h3 id="容器的一致性"><a href="#容器的一致性" class="headerlink" title="容器的一致性"></a>容器的一致性</h3><p>正是由于 rootfs 的存在，容器才有了一个被反复宣传至今的重要特性：一致性。</p><p>什么是容器的“一致性”呢？</p><p>由于 rootfs 里打包的不只是应用，而是整个操作系统的文件和目录，也就意味着，应用以及它运行所需要的所有依赖，都被封装在了一起。</p><p>有了容器镜像“打包操作系统”的能力，这个最基础的依赖环境也终于变成了应用沙盒的一部分。这就赋予了容器所谓的一致性：无论在本地、云端，还是在一台任何地方的机器上，用户只需要解压打包好的容器镜像，那么这个应用运行所需要的完整的执行环境就被重现出来了。</p><p>这种深入到操作系统级别的运行环境一致性，打通了应用在本地开发和远端执行环境之间难以逾越的鸿沟。</p><h3 id="联合文件系统（Union-File-System）到底是怎么回事"><a href="#联合文件系统（Union-File-System）到底是怎么回事" class="headerlink" title="联合文件系统（Union File System）到底是怎么回事"></a>联合文件系统（Union File System）到底是怎么回事</h3><p>Docker 在镜像的设计中，引入了层（layer）的概念。也就是说，用户制作镜像的每一步操作，都会生成一个层，也就是一个增量 rootfs。</p><p>Union File System 也叫 UnionFS，最主要的功能是将多个不同位置的目录联合挂载（union mount）到同一个目录下。比如，我现在有两个目录 A 和 B，它们分别有两个文件：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost test1]# tree</span><br><span class="line">.</span><br><span class="line">├── A</span><br><span class="line">│   ├── a</span><br><span class="line">│   └── x</span><br><span class="line">└── B</span><br><span class="line">    ├── b</span><br><span class="line">    └── x</span><br><span class="line"></span><br><span class="line">然后，我使用联合挂载的方式，将这两个目录挂载到一个公共的目录 C 上：</span><br><span class="line"></span><br><span class="line">[root@localhost test1]# mkdir C</span><br><span class="line">[root@localhost test1]# mount -t aufs -o dirs&#x3D;.&#x2F;A:.&#x2F;B none .&#x2F;C</span><br><span class="line">[root@localhost test1]# tree .&#x2F;C</span><br><span class="line">.&#x2F;C</span><br><span class="line">├── a</span><br><span class="line">├── b</span><br><span class="line">└── x</span><br><span class="line"></span><br><span class="line">可以看到，在这个合并后的目录 C 里，有 a、b、x 三个文件，并且 x 文件只有一份。</span><br><span class="line"></span><br><span class="line">这，就是“合并”的含义。此外，如果你在目录 C 里对 a、b、x 文件做修改，这些修改也会在对应的目录 A、B 中生效。</span><br></pre></td></tr></table></figure><h3 id="Docker-Image的底层原理"><a href="#Docker-Image的底层原理" class="headerlink" title="Docker Image的底层原理"></a>Docker Image的底层原理</h3><p>现在，我们启动一个容器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# docker run -d ubuntu:latest sleep 3600</span><br><span class="line">693d8e17e996e08819c0504ce01f0b58c7e67918e8346255b3cf2fddfb8800af</span><br></pre></td></tr></table></figure><p>此时的Docker Image，实际上就是一个 Ubuntu 操作系统的 rootfs，它的内容是 Ubuntu 操作系统的所有文件和目录。</p><p>不过，与之前我们讲述的 rootfs 稍微不同的是，Docker 镜像使用的 rootfs，往往由多个“层”组成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost test1]# docker image inspect ubuntu:latest</span><br><span class="line">...</span><br><span class="line">        &quot;RootFS&quot;: &#123;</span><br><span class="line">            &quot;Type&quot;: &quot;layers&quot;,</span><br><span class="line">            &quot;Layers&quot;: [</span><br><span class="line">                &quot;sha256:e1c75a5e0bfa094c407e411eb6cc8a159ee8b060cbd0398f1693978b4af9af10&quot;,</span><br><span class="line">                &quot;sha256:9e97312b63ff63ad98bb1f3f688fdff0721ce5111e7475b02ab652f10a4ff97d&quot;,</span><br><span class="line">                &quot;sha256:ec1817c93e7c08d27bfee063f0f1349185a558b87b2d806768af0a8fbbf5bc11&quot;,</span><br><span class="line">                &quot;sha256:05f3b67ed530c5b55f6140dfcdfb9746cdae7b76600de13275197d009086bb3d&quot;</span><br><span class="line">            ]</span><br><span class="line">        &#125;,</span><br><span class="line">        &quot;Metadata&quot;: &#123;</span><br><span class="line">            &quot;LastTagTime&quot;: &quot;0001-01-01T00:00:00Z&quot;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><p>可以看到，这个 Ubuntu 镜像，实际上由四层组成。这四层就是四个增量 rootfs，每一层都是 Ubuntu 操作系统文件与目录的一部分；而在使用镜像时，Docker 会把这些增量联合挂载在一个统一的挂载点上（等价于前面例子里的“/C”目录）。</p><p>overlay2是最新的Docker CE版本18.06.0上的默认存储驱动。</p><p>这个挂载点就是/var/lib/docker/overlay2</p><p>比如：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">#下载Ubuntu后的图层</span><br><span class="line">[root@localhost overlay2]# ll</span><br><span class="line">total 0</span><br><span class="line">drwx------ 4 root root     72 Jul 19 19:22 02dccddd7184a977f6a105f849ecfa69753e62e3931628325249bf2fa013524f</span><br><span class="line">drwx------ 4 root root     55 Jul 19 19:22 930e827392a2b099d8b2d4c4431b1a6b8685bbfdca55b97c5522906170c78f72</span><br><span class="line">brw------- 1 root root 253, 0 Jun  1 15:10 backingFsBlockDev</span><br><span class="line">drwx------ 4 root root     72 Jul 19 19:22 cc3d690e853be0c422705cd4e449a30bdc4a121db5fc9d8e1c433f6071756111</span><br><span class="line">drwx------ 3 root root     47 Jul 19 19:22 fecbaa2f5e0fff06b09a6164443a50bad7829c484d5c5db732fd51abc4506beb</span><br><span class="line">drwx------ 2 root root    142 Jul 19 19:22 l</span><br><span class="line"></span><br><span class="line">#启动一个Ubuntu镜像的容器</span><br><span class="line">[root@localhost overlay2]# docker run -d ubuntu:latest sleep 3600</span><br><span class="line"></span><br><span class="line">#启动后的图层</span><br><span class="line">[root@localhost overlay2]# ll</span><br><span class="line">total 0</span><br><span class="line">drwx------ 4 root root     72 Jul 19 19:22 02dccddd7184a977f6a105f849ecfa69753e62e3931628325249bf2fa013524f</span><br><span class="line">drwx------ 4 root root     72 Jul 19 20:12 930e827392a2b099d8b2d4c4431b1a6b8685bbfdca55b97c5522906170c78f72</span><br><span class="line">brw------- 1 root root 253, 0 Jun  1 15:10 backingFsBlockDev</span><br><span class="line">drwx------ 4 root root     72 Jul 19 19:22 cc3d690e853be0c422705cd4e449a30bdc4a121db5fc9d8e1c433f6071756111</span><br><span class="line">drwx------ 5 root root     69 Jul 19 20:12 e9165a3fd83378e53b1dfe4c72c3c5003d4d165a4acfd80b265f8c455bb31bbc</span><br><span class="line">drwx------ 4 root root     72 Jul 19 20:12 e9165a3fd83378e53b1dfe4c72c3c5003d4d165a4acfd80b265f8c455bb31bbc-init</span><br><span class="line">drwx------ 3 root root     47 Jul 19 19:22 fecbaa2f5e0fff06b09a6164443a50bad7829c484d5c5db732fd51abc4506beb</span><br><span class="line">drwx------ 2 root root    210 Jul 19 20:12 l</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">你会发现新增了2个目录，即被联合挂载之后形成新的目录</span><br><span class="line">进入目录后可以看见，这个里面就是容器里的东西</span><br><span class="line"></span><br><span class="line">[root@localhost merged]# pwd</span><br><span class="line">&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;e9165a3fd83378e53b1dfe4c72c3c5003d4d165a4acfd80b265f8c455bb31bbc&#x2F;merged</span><br><span class="line">[root@localhost merged]# ll</span><br><span class="line">total 0</span><br><span class="line">lrwxrwxrwx 1 root root  7 Jul  3 09:56 bin -&gt; usr&#x2F;bin</span><br><span class="line">drwxr-xr-x 2 root root  6 Apr 15 19:09 boot</span><br><span class="line">drwxr-xr-x 1 root root 43 Jul 19 20:12 dev</span><br><span class="line">drwxr-xr-x 1 root root 66 Jul 19 20:12 etc</span><br><span class="line">drwxr-xr-x 2 root root  6 Apr 15 19:09 home</span><br><span class="line">lrwxrwxrwx 1 root root  7 Jul  3 09:56 lib -&gt; usr&#x2F;lib</span><br><span class="line">lrwxrwxrwx 1 root root  9 Jul  3 09:56 lib32 -&gt; usr&#x2F;lib32</span><br><span class="line">lrwxrwxrwx 1 root root  9 Jul  3 09:56 lib64 -&gt; usr&#x2F;lib64</span><br><span class="line">lrwxrwxrwx 1 root root 10 Jul  3 09:56 libx32 -&gt; usr&#x2F;libx32</span><br><span class="line">drwxr-xr-x 2 root root  6 Jul  3 09:57 media</span><br><span class="line">drwxr-xr-x 2 root root  6 Jul  3 09:57 mnt</span><br><span class="line">drwxr-xr-x 2 root root  6 Jul  3 09:57 opt</span><br><span class="line">drwxr-xr-x 2 root root  6 Apr 15 19:09 proc</span><br><span class="line">drwx------ 2 root root 37 Jul  3 10:00 root</span><br><span class="line">drwxr-xr-x 1 root root 21 Jul  7 05:56 run</span><br><span class="line">lrwxrwxrwx 1 root root  8 Jul  3 09:56 sbin -&gt; usr&#x2F;sbin</span><br><span class="line">drwxr-xr-x 2 root root  6 Jul  3 09:57 srv</span><br><span class="line">drwxr-xr-x 2 root root  6 Apr 15 19:09 sys</span><br><span class="line">drwxrwxrwt 2 root root  6 Jul  3 10:00 tmp</span><br><span class="line">drwxr-xr-x 1 root root 18 Jul  3 09:57 usr</span><br><span class="line">drwxr-xr-x 1 root root 17 Jul  3 10:00 var</span><br></pre></td></tr></table></figure><p>那么，前面提到的五个镜像层，又是如何被联合挂载成这样一个完整的 Ubuntu 文件系统的呢？</p><p>可以查询挂载的信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost merged]# cat &#x2F;proc&#x2F;mounts| grep overlay2</span><br><span class="line">overlay &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;e9165a3fd83378e53b1dfe4c72c3c5003d4d165a4acfd80b265f8c455bb31bbc&#x2F;merged </span><br><span class="line">overlay rw,relatime,</span><br><span class="line">lowerdir&#x3D;&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;l&#x2F;X644A6N6JAYX6FLP76U6HFD3HQ:&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;l&#x2F;K4OIX32VD6WIAQ7R6LLXJXRVLQ:&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;l&#x2F;IJGD7NOFAJBGJFMMOCZVG7OXNC:&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;l&#x2F;OR4MXA5Z63JQCCXOQRSCFYMY2U:&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;l&#x2F;CPSWVQCU3X4JZWB3XEXL7TULDW,</span><br><span class="line">upperdir&#x3D;&#x2F;var&#x2F;lib&#x2F;dockeroverlay2&#x2F;e9165a3fd83378e53b1dfe4c72c3c5003d4d165a4acfd80b265f8c455bb31bbc&#x2F;diff,</span><br><span class="line">workdir&#x3D;&#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;e9165a3fd83378e53b1dfe4c72c3c5003d4d165a4acfd80b265f8c455bb31bbc&#x2F;work 0 0</span><br><span class="line"></span><br><span class="line">[root@localhost overlay2]# df -h</span><br><span class="line">overlay                  200G  4.3G  196G   3% &#x2F;var&#x2F;lib&#x2F;docker&#x2F;overlay2&#x2F;e9165a3fd83378e53b1dfe4c72c3c5003d4d165a4acfd80b265f8c455bb31bbc&#x2F;merged</span><br></pre></td></tr></table></figure><h3 id="一个容器的组成部分"><a href="#一个容器的组成部分" class="headerlink" title="一个容器的组成部分"></a>一个容器的组成部分</h3><p>OverlayFS在单个Linux主机上分层两个目录，并将它们显示为单个目录。这些目录称为图层，统一过程称为联合安装。OverlayFS指的是下层lowerdir目录a和上层目录a upperdir。统一视图通过其自己的目录公开merged。</p><p>镜像层（只读）是lowerdir，容器层（读写）是upperdir</p><ul><li>lower文件指向镜像层，即Ove​​rlayFS lowerdir。</li><li>upper文件指向容器层，该层对应于OverlayFS upperdir。</li><li>merged目录是联合安装的lowerdir和upperdir的挂载点，该方法包括从正在运行的容器内的文件系统的镜像。</li><li>work目录在OverlayFS内部。用于实现copy_up操作。</li></ul><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Docker/overlay_constructs.jpg"  alt="overlay_constructs.jpg"></p><p>启动后的容器分为3层</p><ul><li>第一部分，只读层。</li></ul><p>它是这个容器的 rootfs 最下面的四层，对应的正是 ubuntu:latest 镜像的四层。它们的挂载方式都是只读的（ro+wh，即 readonly+whiteout，至于什么是 whiteout，我下面马上会讲到）。这些层，都以增量的方式分别包含了 Ubuntu 操作系统的一部分。</p><ul><li>第二部分，可读写层。</li></ul><p>它是这个容器的 rootfs 最上面的一层（6e3be5d2ecccae7cc），它的挂载方式为：rw，即 read write。</p><p>可是，你有没有想到这样一个问题：如果我现在要做的，是删除只读层里的一个文件呢？</p><p>为了实现这样的删除操作，AuFS 会在可读写层创建一个 whiteout 文件，把只读层里的文件“遮挡”起来。</p><p>比如，你要删除只读层里一个名叫 foo 的文件，那么这个删除操作实际上是在可读写层创建了一个名叫.wh.foo 的文件。这样，当这两个层被联合挂载之后，foo 文件就会被.wh.foo 文件“遮挡”起来，“消失”了。这个功能，就是“ro+wh”的挂载方式，即只读 +whiteout 的含义。我喜欢把 whiteout 形象地翻译为：“白障”。</p><p>在没有写入文件之前，这个目录是空的。而一旦在容器里做了写操作，你修改产生的内容就会以增量的方式出现在这个层中。最上面这个可读写层的作用，就是专门用来存放你修改 rootfs 后产生的增量，无论是增、删、改，都发生在这里。而当我们使用完了这个被修改过的容器之后，还可以使用 docker commit 和 push 指令，保存这个被修改过的可读写层，并上传到 Docker Hub 上，供其他人使用；而与此同时，原先的只读层里的内容则不会有任何变化。这，就是增量 rootfs 的好处。</p><ul><li>第三部分，Init 层。它是一个以“-init”结尾的层，夹在只读层和读写层之间。Init 层是 Docker 项目单独生成的一个内部层，专门用来存放 /etc/hosts、/etc/resolv.conf 等信息。需要这样一层的原因是，这些文件本来属于只读的 Ubuntu 镜像的一部分，但是用户往往需要在启动容器时写入一些指定的值比如 hostname，所以就需要在可读写层对它们进行修改。可是，这些修改往往只对当前的容器有效，我们并不希望执行 docker commit 时，把这些信息连同可读写层一起提交掉。所以，Docker 做法是，在修改了这些文件之后，以一个单独的层挂载了出来。而用户执行 docker commit 只会提交可读写层，所以是不包含这些内容的。最终，这 7 个层都被联合挂载到 /var/lib/docker/aufs/mnt 目录下，表现为一个完整的 Ubuntu 操作系统供容器使用。</li></ul><p>具体细节后面我会深入讲解，这里就不重点讲了</p><p>可以参考官方文档 <a href="https://docs.docker.com/storage/storagedriver/overlayfs-driver/" target="_blank" rel="noopener">使用OverlayFS存储驱动程序</a></p><p>所以搞清楚一点即可</p><p>镜像的层都放置在 /var/lib/docker/overlay2/分层ID/diff 目录下，然后启动容器后被联合挂载在  /var/lib/docker/overlay2/联合层ID/merge 里面。</p><h3 id="UFS小结"><a href="#UFS小结" class="headerlink" title="UFS小结"></a>UFS小结</h3><p>容器镜像，也叫作：ufs（有的人喜欢叫rootfs）。它只是一个操作系统的所有文件和目录，并不包含内核，最多也就几百兆。而相比之下，传统虚拟机的镜像大多是一个磁盘的“快照”，磁盘有多大，镜像就至少有多大。</p><p>通过结合使用 Mount Namespace 和 rootfs，容器就能够为进程构建出一个完善的文件系统隔离环境。当然，这个功能的实现还必须感谢 chroot 和 pivot_root 这两个系统调用切换进程根目录的能力。</p><p>而在 rootfs 的基础上，Docker 公司创新性地提出了使用多个增量 rootfs 联合挂载一个完整 rootfs 的方案，这就是容器镜像中“层”的概念。</p><p>通过“分层镜像”的设计，以 Docker 镜像为核心，来自不同公司、不同团队的技术人员被紧密地联系在了一起。而且，由于容器镜像的操作是增量式的，这样每次镜像拉取、推送的内容，比原本多个完整的操作系统的大小要小得多；而共享层的存在，可以使得所有这些容器镜像需要的总空间，也比每个镜像的总和要小。这样就使得基于容器镜像的团队协作，要比基于动则几个 GB 的虚拟机磁盘镜像的协作要敏捷得多。</p><p>更重要的是，一旦这个镜像被发布，那么你在全世界的任何一个地方下载这个镜像，得到的内容都完全一致，可以完全复现这个镜像制作者当初的完整环境。这，就是容器技术“强一致性”的重要体现。</p><h1 id="Docker存在的问题"><a href="#Docker存在的问题" class="headerlink" title="Docker存在的问题"></a>Docker存在的问题</h1><p>我们既然要重新了解Docker，它的一些缺点注定是我们绕不过去的，首先，容器不是万能的，不然要虚拟机干嘛。我也是通过容器的3个技术分析它们的劣势</p><h2 id="Namespace"><a href="#Namespace" class="headerlink" title="Namespace"></a>Namespace</h2><ul><li>Namespace隔离得不彻底，首先，既然容器只是运行在宿主机上的一种特殊的进程，那么多个容器之间使用的就还是同一个宿主机的操作系统内核。</li><li>在 Linux 内核中，有很多资源和对象是不能被 Namespace 化的，最典型的例子就是：时间。</li></ul><p>如果你的容器中的程序使用 settimeofday(2) 系统调用修改了时间，整个宿主机的时间都会被随之修改，这显然不符合用户的预期。相比于在虚拟机里面可以随便折腾的自由度，在容器里部署应用的时候，“什么能做，什么不能做”，就是用户必须考虑的一个问题。</p><p>由于一个容器的本质就是一个进程，用户的应用进程实际上就是容器里 PID=1 的进程，也是其他后续创建的所有进程的父进程。这就意味着，在一个容器中，你没办法同时运行两个不同的应用，除非你能事先找到一个公共的 PID=1 的程序来充当两个不同应用的父进程，这也是为什么很多人都会用 systemd 或者 supervisord 这样的软件来代替应用本身作为容器的启动进程。</p><p>但是，在后面分享容器设计模式时，我还会推荐其他更好的解决办法。这是因为容器本身的设计，就是希望容器和应用能够同生命周期，这个概念对后续的容器编排非常重要。否则，一旦出现类似于“容器是正常运行的，但是里面的应用早已经挂了”的情况，编排系统处理起来就非常麻烦了。</p><h2 id="Cgroups-1"><a href="#Cgroups-1" class="headerlink" title="Cgroups"></a>Cgroups</h2><p>Cgroups 对资源的限制能力也有很多不完善的地方，被提及最多的自然是 /proc 文件系统的问题。</p><p>众所周知，Linux 下的 /proc 目录存储的是记录当前内核运行状态的一系列特殊文件，用户可以通过访问这些文件，查看系统以及当前正在运行的进程的信息，比如 CPU 使用情况、内存占用率等，这些文件也是 top 指令查看系统信息的主要数据来源。</p><p>但是，你如果在容器里执行 top 指令，就会发现，它显示的信息居然是宿主机的 CPU 和内存数据，而不是当前容器的数据。造成这个问题的原因就是，/proc 文件系统并不知道用户通过 Cgroups 给这个容器做了什么样的资源限制，即：/proc 文件系统不了解 Cgroups 限制的存在。</p><p>在生产环境中，这个问题必须进行修正，否则应用程序在容器里读取到的 CPU 核数、可用内存等信息都是宿主机上的数据，这会给应用的运行带来非常大的困惑和风险。</p><h2 id="UFS"><a href="#UFS" class="headerlink" title="UFS"></a>UFS</h2><p>上面的读写层通常也称为容器层，下面的只读层称为镜像层，所有的增删查改操作都只会作用在容器层，相同的文件上层会覆盖掉下层。</p><p>知道这一点，就不难理解镜像文件的修改，比如修改一个文件的时候，首先会从上到下查找有没有这个文件，找到，就复制到容器层中，修改，修改的结果就会作用到下层的文件，这种方式也被称为copy-on-write。</p><p>但是如果你的底层镜像发生变化，可能牵一发而动全身。因为其他的镜像如果都按照一个基础镜像的制作，那么这个改变会影响很多现有镜像。</p><p>比如我们现在java项目的环境依赖jdk1.7，由于项目的升级及其他原因，导致了jdk1.7必须升级到1.8才能完成，但是并不是所有的项目都需要升级。</p><p>应对这种情况就必须要更加细致化的区分基础镜像。</p><p>比如制作一个centos7的镜像</p><p>基于这个镜像制作一个jdk1.7 和一个jdk1.8 2个不同的基础镜像</p><p>然后项目分别跑着不同的基础环境中。</p><p>而虚拟机可以随意切换环境，重新启动项目即可。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>容器，其实是一种特殊的进程而已。</p><p>Namespace 的作用是“隔离”，它让应用进程只能看到该 Namespace 内的“世界”</p><p>而 Cgroups 的作用是“限制”，它给这个“世界”围上了一圈看不见的墙。这么一折腾，进程就真的被“装”在了一个与世隔绝的房间里，而这些房间就是 PaaS 项目赖以生存的应用“沙盒”。</p><p>通过结合使用 Mount Namespace 和 rootfs，容器就能够为进程构建出一个完善的文件系统隔离环境。</p><p>通过这样的剖析，对于曾经“神秘莫测”的容器技术，你是不是感觉清晰了很多呢？</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://docs.docker.com/storage/storagedriver/overlayfs-driver/" target="_blank" rel="noopener">使用OverlayFS存储驱动程序</a></p><p><a href="https://time.geekbang.org/column/intro/116" target="_blank" rel="noopener">深入剖析Kubernetes</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> Linux </tag>
            
            <tag> 容器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Ansible一键部署高可用Kubernetes集群</title>
      <link href="2020/07/18/kubernetes/Kubernetes-install/"/>
      <url>2020/07/18/kubernetes/Kubernetes-install/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><h2 id="前置要求与约定"><a href="#前置要求与约定" class="headerlink" title="前置要求与约定"></a>前置要求与约定</h2><ul><li><p>集群会使用到的端口号。</p></li><li><p>各服务器时间与时区需一致，集群内服务器间时间差值不能大于1秒。</p></li><li><p>文档以 4 个 CentOS 7.4 系统服务器安装高可用 Kubernetes 集群进行讲解。</p></li><li><p>按照本文档安装 Kubernetes 集群时，Ansible 脚本会将服务器上防火墙关闭，请使用安全组进行网络权限控制。</p></li><li><p>Master(s) 服务器为 Kubernetes 控制服务器；Worker(s) 服务器为 Kubernetes 运算服务器；Etcd 服务器为组建Etcd 集群的服务器，Etcd 官方建议 Etcd 集群服务器个数为奇数个（比如1、3、5）以防止脑裂。</p></li><li><p>为安全考虑按本教程安装的 Kubernetes 集群只会在 Master(s) 服务器上配置 kubectl 命令所需 kubeconfig，故 Worker(s) 服务器默认是无法使用 kubectl 命令的。</p></li></ul><table><thead><tr><th>授权策略</th><th>协议类型</th><th>端口范围</th><th>授权类型</th><th>授权对象</th><th>描述</th></tr></thead><tbody><tr><td>允许</td><td>TCP    80⁄80</td><td>地址段访问</td><td>0.0.0.0/0</td><td>http</td><td>协议访问集群</td></tr><tr><td>允许</td><td>TCP</td><td>443⁄443</td><td>地址段访问</td><td>0.0.0.0/0</td><td>https</td></tr><tr><td>允许</td><td>TCP    30000⁄32767</td><td>地址段访问</td><td>0.0.0.0/0</td><td>NodePort</td><td>访问集群</td></tr><tr><td>允许</td><td>全部</td><td>-1/-1</td><td>地址段访问</td><td>10.244.0.0/18</td><td>跨节点 Pod 之间互相访问</td></tr></tbody></table><h2 id="准备配置文件"><a href="#准备配置文件" class="headerlink" title="准备配置文件"></a>准备配置文件</h2><p>链接：<a href="https://pan.baidu.com/s/1fMms1KR72mzZJ94sGm6NAg" target="_blank" rel="noopener">https://pan.baidu.com/s/1fMms1KR72mzZJ94sGm6NAg</a><br>提取码：1997<br>复制这段内容后打开百度网盘手机App，操作更方便哦</p><p>解压文件kubeadm-ha-master.tar.gz后有下面的文件</p><p>我已经打包好了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-28-16 kubeadm-ha-master]# ll</span><br><span class="line">total 132</span><br><span class="line">-rw-r--r--  1 root root    89 Jun  4 17:00 00-kernel.yml</span><br><span class="line">-rw-r--r--  1 root root   103 Jun  4 17:00 01-base.yml</span><br><span class="line">-rw-r--r--  1 root root    73 Jun  4 17:00 02-docker.yml</span><br><span class="line">-rw-r--r--  1 root root    88 Jun  4 17:00 03-kubernetes-component.yml</span><br><span class="line">-rw-r--r--  1 root root   115 Jun  4 17:00 04-load-balancer.yml</span><br><span class="line">-rw-r--r--  1 root root   160 Jun  4 17:00 05-etcd.yml</span><br><span class="line">-rw-r--r--  1 root root   133 Jun  4 17:00 06-kubernetes-certificates.yml</span><br><span class="line">-rw-r--r--  1 root root    89 Jun  4 17:00 07-kubernetes-master.yml</span><br><span class="line">-rw-r--r--  1 root root    89 Jun  4 17:00 08-kubernetes-worker.yml</span><br><span class="line">-rw-r--r--  1 root root   113 Jun  4 17:00 09-post.yml</span><br><span class="line">-rw-r--r--  1 root root    86 Jun  4 17:00 21-network-plugin.yml</span><br><span class="line">-rw-r--r--  1 root root    89 Jun  4 17:00 22-ingress-controller.yml</span><br><span class="line">-rw-r--r--  1 root root    91 Jun  4 17:00 23-kubernetes-dashboard.yml</span><br><span class="line">-rw-r--r--  1 root root    85 Jun  4 17:00 24-metrics-server.yml</span><br><span class="line">-rw-r--r--  1 root root    83 Jun  4 17:00 25-cert-manager.yml</span><br><span class="line">-rw-r--r--  1 root root  1084 Jun  4 17:00 90-init-cluster.yml</span><br><span class="line">-rw-r--r--  1 root root   698 Jun  4 17:00 91-add-master.yml</span><br><span class="line">-rw-r--r--  1 root root   557 Jun  4 17:00 92-add-worker.yml</span><br><span class="line">-rw-r--r--  1 root root   523 Jun  4 17:00 93-add-etcd.yml</span><br><span class="line">-rw-r--r--  1 root root   995 Jun  4 17:00 94-upgrade-cluster.yml</span><br><span class="line">-rw-r--r--  1 root root   115 Jun  4 17:00 95-certificates-renew.yml</span><br><span class="line">-rw-r--r--  1 root root   394 Jun  4 17:00 96-backup-cluster.yml</span><br><span class="line">-rw-r--r--  1 root root   730 Jun  4 17:00 97-restore-cluster.yml</span><br><span class="line">-rw-r--r--  1 root root   374 Jun  4 17:00 99-reset-cluster.yml</span><br><span class="line">-rw-r--r--  1 root root 10506 Jun  4 17:00 ansible.cfg</span><br><span class="line">drwxr-xr-x  2 root root   240 Jun  4 17:00 docs</span><br><span class="line">drwxr-xr-x  2 root root   220 Jun  4 17:00 example</span><br><span class="line">-rwxr-xr-x  1 root root   319 Jun  4 17:00 install-ansible.sh</span><br><span class="line">-rw-r--r--  1 root root  3286 Jul 17 17:00 inventory.ini</span><br><span class="line">-rw-r--r--  1 root root  2585 Jun  4 17:00 LICENSE</span><br><span class="line">drwxr-xr-x  2 root root    95 Jun  4 17:00 offline</span><br><span class="line">-rw-r--r--  1 root root  5700 Jun  4 17:00 README.md</span><br><span class="line">drwxr-xr-x 14 root root   201 Jun  4 17:00 roles</span><br><span class="line">-rw-r--r--  1 root root  3299 Jun  4 17:00 Vagrantfile</span><br></pre></td></tr></table></figure><p>你只需要关注一个配置文件inventory.ini</p><h2 id="inventory-ini"><a href="#inventory-ini" class="headerlink" title="inventory.ini"></a>inventory.ini</h2><h3 id="IP分配"><a href="#IP分配" class="headerlink" title="IP分配"></a>IP分配</h3><table><thead><tr><th>节点</th><th>IP</th></tr></thead><tbody><tr><td>master-1</td><td>172.31.28.16</td></tr><tr><td>master-2</td><td>172.31.28.17</td></tr><tr><td>master-3</td><td>172.31.28.18</td></tr><tr><td>node-1</td><td>172.31.28.19</td></tr><tr><td>node-2</td><td>172.31.28.21</td></tr><tr><td>node-3</td><td>172.31.28.22</td></tr><tr><td>VIP</td><td>172.31.28.10</td></tr></tbody></table><h3 id="网段划分"><a href="#网段划分" class="headerlink" title="网段划分"></a>网段划分</h3><p>注意：你必须保证你划分的子网的网段个数要超过你总节点数</p><p>比如你一共要部署3master-3node类型，你的子网划分就不能是172.32.192.0/23 因为这样最多只能划分172.32.192.0-255/24和172.32.193.0-255/24网段，而每个节点的默认虚拟网关都是独占一段的</p><p>如果从172.32.192.0/24开始算起 你至少要给他划分到172.32.198.255，里面包含了（172.32.192.0/24 172.32.193.0/24 172.32.194.0/24 172.32.195.0/24 172.32.196.0/24 172.32.197.0/24 172.32.198.0/24）为了方便扩容，我们设为172.32.192.0/20 可以划分16个网段，也就是最多容纳16个节点（包括master和node）</p><p>集群pod ip段</p><p>kube_pod_subnet=”172.32.192.0/20”</p><p>集群service ip段</p><p>kube_service_subnet=”172.31.208.0/20”</p><h3 id="配置填写"><a href="#配置填写" class="headerlink" title="配置填写"></a>配置填写</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line">; 将所有节点的信息在这里填写</span><br><span class="line">;    第一个字段                  为节点内网IP，部署完成后为 kubernetes 节点 nodeName</span><br><span class="line">;    第二个字段 ansible_user     为节点远程登录用户名</span><br><span class="line">;    第三个字段 ansible_ssh_pass 为节点远程登录用户密码</span><br><span class="line">[all]</span><br><span class="line">172.31.28.16 ansible_user&#x3D;root ansible_ssh_pass&#x3D;123456</span><br><span class="line">172.31.28.17 ansible_user&#x3D;root ansible_ssh_pass&#x3D;123456</span><br><span class="line">172.31.28.18 ansible_user&#x3D;root ansible_ssh_pass&#x3D;123456</span><br><span class="line">172.31.28.19 ansible_user&#x3D;root ansible_ssh_pass&#x3D;123456</span><br><span class="line">172.31.28.21 ansible_user&#x3D;root ansible_ssh_pass&#x3D;123456</span><br><span class="line">172.31.28.22 ansible_user&#x3D;root ansible_ssh_pass&#x3D;123456</span><br><span class="line"></span><br><span class="line">; 私有云：</span><br><span class="line">;    VIP 负载模式：</span><br><span class="line">;       也就是负载均衡器 + keepalived 模式，比如常用的 haproxy + keepalived。</span><br><span class="line">;       本脚本中负载均衡器有 nginx、haproxy、envoy 可供选择，设置 lb_mode 即可进行任意切换。</span><br><span class="line">;       设置 lb_kube_apiserver_ip 即表示启用 keepalived，请先与服务器提供部门协商保留一个IP作为 lb_kube_apiserver_ip，</span><br><span class="line">;       一般 lb 节点组中有两个节点就够了，lb节点组中第一个节点为 keepalived 的 master 节点，剩下的都为 backed 节点。</span><br><span class="line">;</span><br><span class="line">;    节点本地负载模式：</span><br><span class="line">;       只启动负载均衡器，不启用 keepalived（即不设置 lb_kube_apiserver_ip），</span><br><span class="line">;       此时 kubelet 链接 apiserver 地址为 127.0.0.1:lb_kube_apiserver_port。</span><br><span class="line">;       使用此模式时请将 lb 节点组置空。</span><br><span class="line">;</span><br><span class="line">; 公有云：</span><br><span class="line">;    不推荐使用 slb 模式，建议直接使用节点本地负载模式。</span><br><span class="line">;    若使用 slb 模式，请先使用节点本地负载模式进行部署，</span><br><span class="line">;    部署成功后再切换至 slb 模式：</span><br><span class="line">;       将 lb_mode 修改为 slb，将 lb_kube_apiserver_ip 设置为购买到的 slb 内网ip，</span><br><span class="line">;       修改 lb_kube_apiserver_port 为 slb 监听端口。</span><br><span class="line">;    再次运行初始化集群脚本即可切换至 slb 模式。</span><br><span class="line">[lb]</span><br><span class="line">172.31.28.16</span><br><span class="line">172.31.28.17</span><br><span class="line">172.31.28.18</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">; 注意etcd集群必须是1,3,5,7...奇数个节点</span><br><span class="line">[etcd]</span><br><span class="line">172.31.28.16</span><br><span class="line">172.31.28.17</span><br><span class="line">172.31.28.18</span><br><span class="line"></span><br><span class="line">[kube-master]</span><br><span class="line">172.31.28.16</span><br><span class="line">172.31.28.17</span><br><span class="line">172.31.28.18</span><br><span class="line"></span><br><span class="line">[kube-worker]</span><br><span class="line">172.31.28.19</span><br><span class="line">172.31.28.21</span><br><span class="line">172.31.28.22</span><br><span class="line"></span><br><span class="line">; 预留组，后续添加master节点使用</span><br><span class="line">[new-master]</span><br><span class="line"></span><br><span class="line">; 预留组，后续添加worker节点使用</span><br><span class="line">[new-worker]</span><br><span class="line"></span><br><span class="line">; 预留组，后续添加etcd节点使用</span><br><span class="line">[new-etcd]</span><br><span class="line"></span><br><span class="line">;-------------------------------------- 以下为基础信息配置 ------------------------------------;</span><br><span class="line">[all:vars]</span><br><span class="line">; 是否跳过节点物理资源校验，Master节点要求2c2g以上，Worker节点要求2c4g以上</span><br><span class="line">skip_verify_node&#x3D;false</span><br><span class="line">; kubernetes版本</span><br><span class="line">kube_version&#x3D;&quot;1.15.5&quot;</span><br><span class="line">; 负载均衡器</span><br><span class="line">;   有 nginx、haproxy、envoy 和 slb 四个选项，默认使用 nginx；</span><br><span class="line">lb_mode&#x3D;&quot;nginx&quot;</span><br><span class="line">; 使用负载均衡后集群 apiserver ip，设置 lb_kube_apiserver_ip 变量，则启用负载均衡器 + keepalived</span><br><span class="line">lb_kube_apiserver_ip&#x3D;&quot;172.31.28.10&quot;</span><br><span class="line">; 使用负载均衡后集群 apiserver port</span><br><span class="line">lb_kube_apiserver_port&#x3D;&quot;8443&quot;</span><br><span class="line">; 集群pod ip段</span><br><span class="line">kube_pod_subnet&#x3D;&quot;172.32.192.0&#x2F;20&quot;</span><br><span class="line">; 集群service ip段</span><br><span class="line">kube_service_subnet&#x3D;&quot;172.31.208.0&#x2F;20&quot;</span><br><span class="line">; 集群网络插件，目前支持flannel,calico,kube-ovn</span><br><span class="line">network_plugin&#x3D;&quot;flannel&quot;</span><br><span class="line">; Kubelet 根目录</span><br><span class="line">kubelet_root_dir&#x3D;&quot;&#x2F;var&#x2F;lib&#x2F;kubelet&quot;</span><br><span class="line">; docker容器存储目录</span><br><span class="line">docker_storage_dir&#x3D;&quot;&#x2F;var&#x2F;lib&#x2F;docker&quot;</span><br></pre></td></tr></table></figure><h1 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 进入部署文件夹，部署ansible环境</span><br><span class="line">[root@VM-28-16 kubeadm-ha-master]# .&#x2F;install-ansible.sh</span><br><span class="line"></span><br><span class="line"># 安装完ansible后部署k8s集群</span><br><span class="line">[root@VM-28-16 kubeadm-ha-master]# ansible-playbook -i inventory.ini 90-init-cluster.yml</span><br><span class="line"></span><br><span class="line"># 如果部署失败，想要重置集群，执行：</span><br><span class="line">[root@VM-28-16 kubeadm-ha-master]# ansible-playbook -i inventory.ini 99-reset-cluster.yml</span><br><span class="line"></span><br><span class="line"># 部署完成后测试一下集群</span><br><span class="line">[root@VM-28-16 ~]# kubectl get nodes</span><br><span class="line">NAME           STATUS   ROLES            AGE   VERSION</span><br><span class="line">172.31.28.16   Ready    etcd,lb,master   20h   v1.15.5</span><br><span class="line">172.31.28.17   Ready    etcd,lb,master   20h   v1.15.5</span><br><span class="line">172.31.28.18   Ready    etcd,lb,master   20h   v1.15.5</span><br><span class="line">172.31.28.19   Ready    worker           20h   v1.15.5</span><br><span class="line">172.31.28.21   Ready    worker           20h   v1.15.5</span><br><span class="line">172.31.28.22   Ready    worker           20h   v1.15.5</span><br><span class="line"></span><br><span class="line">即说明部署完成</span><br></pre></td></tr></table></figure><h1 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h1><p>一般来说部署完集群只是第一步，后续你需要补齐监控、Helm、服务网格等组件，在这章不细讲了。</p><p>部署helm请参考 <a href="https://rugod.cn/2020/06/21/helm/helm-install/" target="_blank" rel="noopener">Helm简介及阿里云安装部署</a></p><p>部署监控请参考  <a href="https://rugod.cn/2020/06/17/kubernetes/Kubernetes-dashboard/" target="_blank" rel="noopener">Kubernetes可视化界面及监控安装</a></p><p>部署服务网格暂时还没写<del>~</del></p><h1 id="扩容节点"><a href="#扩容节点" class="headerlink" title="扩容节点"></a>扩容节点</h1><p>还是改inventory.ini文件，执行ansible-playbook的命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 在all组里加入新节点ip </span><br><span class="line">[all]</span><br><span class="line">172.31.28.23 ansible_user&#x3D;root ansible_ssh_pass&#x3D;123456</span><br><span class="line"></span><br><span class="line"># 在new-worker组里加入新节点</span><br><span class="line">[new-worker]</span><br><span class="line">172.31.28.23</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 改好后保存文件，然后执行</span><br><span class="line"></span><br><span class="line">[root@vm-26-11 ~]# ansible-playbook -i inventory.ini 92-add-worker.yml</span><br></pre></td></tr></table></figure><h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="etcd报错起不来"><a href="#etcd报错起不来" class="headerlink" title="etcd报错起不来"></a>etcd报错起不来</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">fatal: [172.31.28.17]: failed! &#x3D;&gt; &#123;&quot;attempts&quot;: 12, &quot;changed&quot;: true, &quot;cmd&quot;: &quot;docker run --net host -e etcdctl_api&#x3D;3 -v &#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd:&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd --rm registry.aliyuncs.com&#x2F;k8sxio&#x2F;etcd:3.4.3-0 etcdctl endpoint health --endpoints&#x3D;https:&#x2F;&#x2F;[127.0.0.1]:2379 --cacert&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;ca.crt --key&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;healthcheck-client.key --cert&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;healthcheck-client.crt\n&quot;, &quot;delta&quot;: &quot;0:00:05.690875&quot;, &quot;end&quot;: &quot;2020-07-17 16:43:55.778524&quot;, &quot;msg&quot;: &quot;non-zero return code&quot;, &quot;rc&quot;: 1, &quot;start&quot;: &quot;2020-07-17 16:43:50.087649&quot;, &quot;stderr&quot;: &quot;&#123;\&quot;level\&quot;:\&quot;warn\&quot;,\&quot;ts\&quot;:\&quot;2020-07-17t08:43:55.557z\&quot;,\&quot;caller\&quot;:\&quot;clientv3&#x2F;retry_interceptor.go:61\&quot;,\&quot;msg\&quot;:\&quot;retrying of unary invoker failed\&quot;,\&quot;target\&quot;:\&quot;endpoint:&#x2F;&#x2F;client-2d241951-f3e1-4e5d-9cf3-47dbe4bf7797&#x2F;[127.0.0.1]:2379\&quot;,\&quot;attempt\&quot;:0,\&quot;error\&quot;:\&quot;rpc error: code &#x3D; deadlineexceeded desc &#x3D; context deadline exceeded\&quot;&#125;\nhttps:&#x2F;&#x2F;[127.0.0.1]:2379 is unhealthy: failed to commit proposal: context deadline exceeded\nerror: unhealthy cluster&quot;, &quot;stderr_lines&quot;: [&quot;&#123;\&quot;level\&quot;:\&quot;warn\&quot;,\&quot;ts\&quot;:\&quot;2020-07-17t08:43:55.557z\&quot;,\&quot;caller\&quot;:\&quot;clientv3&#x2F;retry_interceptor.go:61\&quot;,\&quot;msg\&quot;:\&quot;retrying of unary invoker failed\&quot;,\&quot;target\&quot;:\&quot;endpoint:&#x2F;&#x2F;client-2d241951-f3e1-4e5d-9cf3-47dbe4bf7797&#x2F;[127.0.0.1]:2379\&quot;,\&quot;attempt\&quot;:0,\&quot;error\&quot;:\&quot;rpc error: code &#x3D; deadlineexceeded desc &#x3D; context deadline exceeded\&quot;&#125;&quot;, &quot;https:&#x2F;&#x2F;[127.0.0.1]:2379 is unhealthy: failed to commit proposal: context deadline exceeded&quot;, &quot;error: unhealthy cluster&quot;], &quot;stdout&quot;: &quot;&quot;, &quot;stdout_lines&quot;: []&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">核心就是</span><br><span class="line">https:&#x2F;&#x2F;localhost:2379 is unhealthy: failed to commit proposal: context deadline exceeded #3546</span><br></pre></td></tr></table></figure><p>etcd初始化失败</p><p>分析原因，服务器时间未同步（没细查），但是同步各服务器的时间之后确实好。</p><p>猜想：etcd存储各个服务器的信息，包括时间，这个不同步可能后期会出问题</p><h2 id="扩容节点报错"><a href="#扩容节点报错" class="headerlink" title="扩容节点报错"></a>扩容节点报错</h2><p>扩容节点的脚本执行完后发现新节点并没有加入到集群里</p><p>然后进入新节点查看,没有运行的容器也没有镜像,查看进程发现kubelet起来了，查看网卡接口发现没有flannel.1的</p><p>判断这些镜像没有，是不是因为镜像没有拉取到的原因。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-26-23 ~]# docker images -a</span><br><span class="line">REPOSITORY                                TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">[root@vm-26-23 ~]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE                                  COMMAND                  CREATED             STATUS                  PORTS</span><br><span class="line">[root@vm-26-23 ~]# ps -aux|grep kube</span><br><span class="line">root      9612  2.9  0.2 1906264 91656 ?       Ssl  Aug04  26:06 &#x2F;usr&#x2F;bin&#x2F;kubelet --bootstrap-kubeconfig&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;bootstrap-kubelet.conf --kubeconfig&#x3D;&#x2F;etc&#x2F;kubernetes&#x2F;kubelet.conf --config&#x3D;&#x2F;var&#x2F;lib&#x2F;kubelet&#x2F;config.yaml --cgroup-driver&#x3D;cgroupfs --hostname-override&#x3D;172.31.26.23 --network-plugin&#x3D;cni --pod-infra-container-image&#x3D;gcr.azk8s.cn&#x2F;google_containers&#x2F;pause:3.1 --root-dir&#x3D;&#x2F;var&#x2F;libkubelet</span><br><span class="line">root     20955  0.2  0.0 1321452 32100 ?       Ssl  Aug04   2:18 </span><br><span class="line">root     28066  0.0  0.0 112708   976 pts&#x2F;0    S+   10:58   0:00 grep --color&#x3D;auto kube</span><br><span class="line">[root@VM-26-23 ~]# ip add</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link&#x2F;loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1&#x2F;8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1&#x2F;128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens192: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000</span><br><span class="line">    link&#x2F;ether 00:50:56:99:fb:23 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.31.22.17&#x2F;24 brd 172.31.22.255 scope global noprefixroute ens192</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::f6b6:1049:1ed5:1321&#x2F;64 scope link noprefixroute </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default </span><br><span class="line">    link&#x2F;ether 02:42:f3:fb:d1:c2 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.17.0.1&#x2F;16 brd 172.17.255.255 scope global docker0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><p>查看系统日志，发现报错果然拉不了这些Node节点的镜像</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-26-23 ~]# tail -f &#x2F;var&#x2F;log&#x2F;messages</span><br><span class="line">Aug  4 20:28:22 VM-26-23 dockerd: time&#x3D;&quot;2020-08-04T20:28:22.778469318+08:00&quot; level&#x3D;error msg&#x3D;&quot;Handler for POST &#x2F;images&#x2F;create returned error: error parsing HTTP 403 response body: invalid character &#39;&lt;&#39; looking for beginning of value: \&quot;&lt;html&gt;\\r\\n&lt;head&gt;&lt;title&gt;403 Forbidden&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;\\r\\n&lt;body bgcolor&#x3D;\\\&quot;white\\\&quot;&gt;\\r\\n&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;&#x2F;h1&gt;&lt;&#x2F;center&gt;\\r\\n&lt;hr&gt;&lt;center&gt;nginx&#x2F;1.14.0 (Ubuntu)&lt;&#x2F;center&gt;\\r\\n&lt;&#x2F;body&gt;\\r\\n&lt;&#x2F;html&gt;\\r\\n\&quot;&quot;</span><br><span class="line">Aug  4 20:28:22 VM-26-23 kubelet: E0804 20:28:22.780471    9612 remote_runtime.go:105] RunPodSandbox from runtime service failed: rpc error: code &#x3D; Unknown desc &#x3D; failed pulling image &quot;gcr.azk8s.cn&#x2F;google_containers&#x2F;pause:3.1&quot;: Error response from daemon: error parsing HTTP 403 response body: invalid character &#39;&lt;&#39; looking for beginning of value: &quot;&lt;html&gt;\r\n&lt;head&gt;&lt;title&gt;403 Forbidden&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;\r\n&lt;body bgcolor&#x3D;\&quot;white\&quot;&gt;\r\n&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;&#x2F;h1&gt;&lt;&#x2F;center&gt;\r\n&lt;hr&gt;&lt;center&gt;nginx&#x2F;1.14.0 (Ubuntu)&lt;&#x2F;center&gt;\r\n&lt;&#x2F;body&gt;\r\n&lt;&#x2F;html&gt;\r\n&quot;</span><br><span class="line">Aug  4 20:28:22 VM-26-23 kubelet: E0804 20:28:22.780581    9612 kuberuntime_sandbox.go:68] CreatePodSandbox for pod &quot;kube-proxy-75rvp_kube-system(646f319e-af39-4d97-a6ac-f5046dedda24)&quot; failed: rpc error: code &#x3D; Unknown desc &#x3D; failed pulling image &quot;gcr.azk8s.cn&#x2F;google_containers&#x2F;pause:3.1&quot;: Error response from daemon: error parsing HTTP 403 response body: invalid character &#39;&lt;&#39; looking for beginning of value: &quot;&lt;html&gt;\r\n&lt;head&gt;&lt;title&gt;403 Forbidden&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;\r\n&lt;body bgcolor&#x3D;\&quot;white\&quot;&gt;\r\n&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;&#x2F;h1&gt;&lt;&#x2F;center&gt;\r\n&lt;hr&gt;&lt;center&gt;nginx&#x2F;1.14.0 (Ubuntu)&lt;&#x2F;center&gt;\r\n&lt;&#x2F;body&gt;\r\n&lt;&#x2F;html&gt;\r\n&quot;</span><br><span class="line">Aug  4 20:28:22 VM-26-23 kubelet: E0804 20:28:22.780654    9612 kuberuntime_manager.go:692] createPodSandbox for pod &quot;kube-proxy-75rvp_kube-system(646f319e-af39-4d97-a6ac-f5046dedda24)&quot; failed: rpc error: code &#x3D; Unknown desc &#x3D; failed pulling image &quot;gcr.azk8s.cn&#x2F;google_containers&#x2F;pause:3.1&quot;: Error response from daemon: error parsing HTTP 403 response body: invalid character &#39;&lt;&#39; looking for beginning of value: &quot;&lt;html&gt;\r\n&lt;head&gt;&lt;title&gt;403 Forbidden&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;\r\n&lt;body bgcolor&#x3D;\&quot;white\&quot;&gt;\r\n&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;&#x2F;h1&gt;&lt;&#x2F;center&gt;\r\n&lt;hr&gt;&lt;center&gt;nginx&#x2F;1.14.0 (Ubuntu)&lt;&#x2F;center&gt;\r\n&lt;&#x2F;body&gt;\r\n&lt;&#x2F;html&gt;\r\n&quot;</span><br><span class="line">Aug  4 20:28:22 VM-26-23 kubelet: E0804 20:28:22.780777    9612 pod_workers.go:190] Error syncing pod 646f319e-af39-4d97-a6ac-f5046dedda24 (&quot;kube-proxy-75rvp_kube-system(646f319e-af39-4d97-a6ac-f5046dedda24)&quot;), skipping: failed to &quot;CreatePodSandbox&quot; for &quot;kube-proxy-75rvp_kube-system(646f319e-af39-4d97-a6ac-f5046dedda24)&quot; with CreatePodSandboxError: &quot;CreatePodSandbox for pod \&quot;kube-proxy-75rvp_kube-system(646f319e-af39-4d97-a6ac-f5046dedda24)\&quot; failed: rpc error: code &#x3D; Unknown desc &#x3D; failed pulling image \&quot;gcr.azk8s.cn&#x2F;google_containers&#x2F;pause:3.1\&quot;: Error response from daemon: error parsing HTTP 403 response body: invalid character &#39;&lt;&#39; looking for beginning of value: \&quot;&lt;html&gt;\\r\\n&lt;head&gt;&lt;title&gt;403 Forbidden&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;\\r\\n&lt;body bgcolor&#x3D;\\\&quot;white\\\&quot;&gt;\\r\\n&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;&#x2F;h1&gt;&lt;&#x2F;center&gt;\\r\\n&lt;hr&gt;&lt;center&gt;nginx&#x2F;1.14.0 (Ubuntu)&lt;&#x2F;center&gt;\\r\\n&lt;&#x2F;body&gt;\\r\\n&lt;&#x2F;html&gt;\\r\\n\&quot;&quot;</span><br><span class="line">Aug  4 20:28:25 VM-26-23 kubelet: E0804 20:28:25.338166    9612 kubelet.go:2173] Container runtime network not ready: NetworkReady&#x3D;false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized</span><br><span class="line">Aug  4 20:28:25 VM-26-23 kubelet: W0804 20:28:25.931418    9612 cni.go:213] Unable to update cni config: No networks found in &#x2F;etc&#x2F;cni&#x2F;net.d</span><br><span class="line">Aug  4 20:28:30 VM-26-23 kubelet: E0804 20:28:30.364407    9612 kubelet.go:2173] Container runtime network not ready: NetworkReady&#x3D;false reason:NetworkPluginNotReady message:docker: network plugin is not ready: cni config uninitialized</span><br><span class="line">Aug  4 20:28:30 VM-26-23 kubelet: W0804 20:28:30.932040    9612 cni.go:213] Unable to update cni config: No networks found in &#x2F;etc&#x2F;cni&#x2F;net.d</span><br><span class="line">Aug  4 20:28:32 VM-26-23 kubelet: E0804 20:28:32.649344    9612 aws_credentials.go:77] while getting AWS credentials NoCredentialProviders: no valid providers in chain. Deprecated.</span><br><span class="line">Aug  4 20:28:32 VM-26-23 kubelet: For verbose messaging see aws.Config.CredentialsChainVerboseErrors</span><br><span class="line">Aug  4 20:28:32 VM-26-23 dockerd: time&#x3D;&quot;2020-08-04T20:28:32.827430989+08:00&quot; level&#x3D;info msg&#x3D;&quot;Attempting next endpoint for pull after error: error parsing HTTP 403 response body: invalid character &#39;&lt;&#39; looking for beginning of value: \&quot;&lt;html&gt;\\r\\n&lt;head&gt;&lt;title&gt;403 Forbidden&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;\\r\\n&lt;body bgcolor&#x3D;\\\&quot;white\\\&quot;&gt;\\r\\n&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;&#x2F;h1&gt;&lt;&#x2F;center&gt;\\r\\n&lt;hr&gt;&lt;center&gt;nginx&#x2F;1.14.0 (Ubuntu)&lt;&#x2F;center&gt;\\r\\n&lt;&#x2F;body&gt;\\r\\n&lt;&#x2F;html&gt;\\r\\n\&quot;&quot;</span><br><span class="line">Aug  4 20:28:32 VM-26-23 kubelet: E0804 20:28:32.828824    9612 remote_runtime.go:105] RunPodSandbox from runtime service failed: rpc error: code &#x3D; Unknown desc &#x3D; failed pulling image &quot;gcr.azk8s.cn&#x2F;google_containers&#x2F;pause:3.1&quot;: Error response from daemon: error parsing HTTP 403 response body: invalid character &#39;&lt;&#39; looking for beginning of value: &quot;&lt;html&gt;\r\n&lt;head&gt;&lt;title&gt;403 Forbidden&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;\r\n&lt;body bgcolor&#x3D;\&quot;white\&quot;&gt;\r\n&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;&#x2F;h1&gt;&lt;&#x2F;center&gt;\r\n&lt;hr&gt;&lt;center&gt;nginx&#x2F;1.14.0 (Ubuntu)&lt;&#x2F;center&gt;\r\n&lt;&#x2F;body&gt;\r\n&lt;&#x2F;html&gt;\r\n&quot;</span><br><span class="line">Aug  4 20:28:32 VM-26-23 dockerd: time&#x3D;&quot;2020-08-04T20:28:32.827650596+08:00&quot; level&#x3D;error msg&#x3D;&quot;Handler for POST &#x2F;images&#x2F;create returned error: error parsing HTTP 403 response body: invalid character &#39;&lt;&#39; looking for beginning of value: \&quot;&lt;html&gt;\\r\\n&lt;head&gt;&lt;title&gt;403 Forbidden&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;\\r\\n&lt;body bgcolor&#x3D;\\\&quot;white\\\&quot;&gt;\\r\\n&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;&#x2F;h1&gt;&lt;&#x2F;center&gt;\\r\\n&lt;hr&gt;&lt;center&gt;nginx&#x2F;1.14.0 (Ubuntu)&lt;&#x2F;center&gt;\\r\\n&lt;&#x2F;body&gt;\\r\\n&lt;&#x2F;html&gt;\\r\\n\&quot;&quot;</span><br><span class="line">Aug  4 20:28:32 VM-26-23 kubelet: E0804 20:28:32.828990    9612 kuberuntime_sandbox.go:68] CreatePodSandbox for pod &quot;kube-flannel-ds-amd64-rtcnv_kube-system(e5ddc865-e0c2-4c9e-ad52-c854168ab26b)&quot; failed: rpc error: code &#x3D; Unknown desc &#x3D; failed pulling image &quot;gcr.azk8s.cn&#x2F;google_containers&#x2F;pause:3.1&quot;: Error response from daemon: error parsing HTTP 403 response body: invalid character &#39;&lt;&#39; looking for beginning of value: &quot;&lt;html&gt;\r\n&lt;head&gt;&lt;title&gt;403 Forbidden&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;\r\n&lt;body bgcolor&#x3D;\&quot;white\&quot;&gt;\r\n&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;&#x2F;h1&gt;&lt;&#x2F;center&gt;\r\n&lt;hr&gt;&lt;center&gt;nginx&#x2F;1.14.0 (Ubuntu)&lt;&#x2F;center&gt;\r\n&lt;&#x2F;body&gt;\r\n&lt;&#x2F;html&gt;\r\n&quot;</span><br><span class="line">Aug  4 20:28:32 VM-26-23 kubelet: E0804 20:28:32.829060    9612 kuberuntime_manager.go:692] createPodSandbox for pod &quot;kube-flannel-ds-amd64-rtcnv_kube-system(e5ddc865-e0c2-4c9e-ad52-c854168ab26b)&quot; failed: rpc error: code &#x3D; Unknown desc &#x3D; failed pulling image &quot;gcr.azk8s.cn&#x2F;google_containers&#x2F;pause:3.1&quot;: Error response from daemon: error parsing HTTP 403 response body: invalid character &#39;&lt;&#39; looking for beginning of value: &quot;&lt;html&gt;\r\n&lt;head&gt;&lt;title&gt;403 Forbidden&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;\r\n&lt;body bgcolor&#x3D;\&quot;white\&quot;&gt;\r\n&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;&#x2F;h1&gt;&lt;&#x2F;center&gt;\r\n&lt;hr&gt;&lt;center&gt;nginx&#x2F;1.14.0 (Ubuntu)&lt;&#x2F;center&gt;\r\n&lt;&#x2F;body&gt;\r\n&lt;&#x2F;html&gt;\r\n&quot;</span><br><span class="line">Aug  4 20:28:32 VM-26-23 kubelet: E0804 20:28:32.829218    9612 pod_workers.go:190] Error syncing pod e5ddc865-e0c2-4c9e-ad52-c854168ab26b (&quot;kube-flannel-ds-amd64-rtcnv_kube-system(e5ddc865-e0c2-4c9e-ad52-c854168ab26b)&quot;), skipping: failed to &quot;CreatePodSandbox&quot; for &quot;kube-flannel-ds-amd64-rtcnv_kube-system(e5ddc865-e0c2-4c9e-ad52-c854168ab26b)&quot; with CreatePodSandboxError: &quot;CreatePodSandbox for pod \&quot;kube-flannel-ds-amd64-rtcnv_kube-system(e5ddc865-e0c2-4c9e-ad52-c854168ab26b)\&quot; failed: rpc error: code &#x3D; Unknown desc &#x3D; failed pulling image \&quot;gcr.azk8s.cn&#x2F;google_containers&#x2F;pause:3.1\&quot;: Error response from daemon: error parsing HTTP 403 response body: invalid character &#39;&lt;&#39; looking for beginning of value: \&quot;&lt;html&gt;\\r\\n&lt;head&gt;&lt;title&gt;403 Forbidden&lt;&#x2F;title&gt;&lt;&#x2F;head&gt;\\r\\n&lt;body bgcolor&#x3D;\\\&quot;white\\\&quot;&gt;\\r\\n&lt;center&gt;&lt;h1&gt;403 Forbidden&lt;&#x2F;h1&gt;&lt;&#x2F;center&gt;\\r\\n&lt;hr&gt;&lt;center&gt;nginx&#x2F;1.14.0 (Ubuntu)&lt;&#x2F;center&gt;\\r\\n&lt;&#x2F;body&gt;\\r\\n&lt;&#x2F;html&gt;\\r\\n\&quot;&quot;</span><br></pre></td></tr></table></figure><p>解决方法</p><ul><li>直接从其他node节点已有的镜像导入到这台新的node节点上</li></ul><p>主要是这4个镜像，版本号根据实际的情况而变</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">gcr.azk8s.cn&#x2F;google_containers&#x2F;kube-proxy                              v1.15.5             cbd7f21fec99        9 months ago        82.4MB</span><br><span class="line">quay.azk8s.cn&#x2F;kubernetes-ingress-controller&#x2F;nginx-ingress-controller   0.26.1              29024c9c6e70        10 months ago       483MB</span><br><span class="line">quay.azk8s.cn&#x2F;coreos&#x2F;flannel                                           v0.11.0-amd64       ff281650a721        18 months ago       52.6MB</span><br><span class="line">gcr.azk8s.cn&#x2F;google_containers&#x2F;pause                                   3.1                 da86e6ba6ca1        2 years ago         742kB</span><br></pre></td></tr></table></figure><p>进入一台node节点，导出镜像，并scp到其他机器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-26-19 ~]# docker save -o flannel.tar.gz quay.azk8s.cn&#x2F;coreos&#x2F;flannel:v0.11.0-amd64</span><br><span class="line">[root@vm-26-19 ~]# docker save -o  pause.tar.gz gcr.azk8s.cn&#x2F;google_containers&#x2F;pause:3.1</span><br><span class="line">[root@vm-26-19 ~]# docker save -o  kube-proxy.tar gcr.azk8s.cn&#x2F;google_containers&#x2F;kube-proxy:v1.15.5</span><br><span class="line">[root@vm-26-19 ~]# docker save -o  nginx-ingress-controller.tar  quay.azk8s.cn&#x2F;kubernetes-ingress-controller&#x2F;nginx-ingress-controller:0.26.1</span><br><span class="line">[root@VM-26-19 ~]# ll</span><br><span class="line">total 613372</span><br><span class="line">-rw-------. 1 root root      1549 Nov 25  2019 anaconda-ks.cfg</span><br><span class="line">-rw-------  1 root root  55390720 Aug  4 20:33 flannel.tar.gz</span><br><span class="line">-rw-------  1 root root  84286464 Aug  4 20:39 kube-proxy.tar</span><br><span class="line">-rw-------  1 root root 487647744 Aug  4 20:41 nginx-ingress-controller.tar</span><br><span class="line">-rw-------  1 root root    754176 Aug  4 20:37 pause.tar.gz</span><br><span class="line"></span><br><span class="line">[root@vm-26-19 ~]# scp * 172.31.26.23:&#x2F;root&#x2F;</span><br></pre></td></tr></table></figure><p>再进入新节点，导入镜像</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-26-23 ~]# docker load &lt;  flannel.tar.gz</span><br><span class="line">[root@vm-26-23 ~]# docker load &lt;  kube-proxy.tar</span><br><span class="line">[root@vm-26-23 ~]# docker load &lt;  nginx-ingress-controller.tar</span><br><span class="line">[root@vm-26-23 ~]# docker load &lt;  pause.tar.gz</span><br></pre></td></tr></table></figure><p>由于系统在不断尝试去拉取镜像，所以导入成功后系统会直接run这些镜像，即可完成后续加入集群的命令。</p><ul><li>自己从网上下载（科学上网）拉镜像，然后上传到这台新的node节点上（这里不作说明）</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://choerodon.io/zh/docs/installation-configuration/steps/kubernetes/" target="_blank" rel="noopener">Kubernetes集群部署</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
            <tag> Ansible </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes入门篇(三)——Kubernetes的对象和API</title>
      <link href="2020/07/18/kubernetes/Kubernetes-introduction-3/"/>
      <url>2020/07/18/kubernetes/Kubernetes-introduction-3/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="Kubernetes-对象"><a href="#Kubernetes-对象" class="headerlink" title="Kubernetes 对象"></a>Kubernetes 对象</h1><p>在 Kubernetes 系统中，Kubernetes 对象 是持久化的实体。Kubernetes 使用这些实体去表示整个集群的状态。特别地，它们描述了如下信息：</p><p>哪些容器化应用在运行（以及在哪个 Node 上）<br>可以被应用使用的资源<br>关于应用运行时表现的策略，比如重启策略、升级策略，以及容错策略<br>Kubernetes 对象是 “目标性记录” —— 一旦创建对象，Kubernetes 系统将持续工作以确保对象存在。通过创建对象，本质上是在告知 Kubernetes 系统，所需要的集群工作负载看起来是什么样子的，这就是 Kubernetes 集群的 期望状态（Desired State）。</p><p>操作 Kubernetes 对象 —— 无论是创建、修改，或者删除 —— 需要使用 Kubernetes API。比如，当使用 kubectl 命令行接口时，CLI 会执行必要的 Kubernetes API 调用，也可以在程序中使用客户端库直接调用 Kubernetes API。</p><h2 id="对象规则约定（Spec）与状态（Status）"><a href="#对象规则约定（Spec）与状态（Status）" class="headerlink" title="对象规则约定（Spec）与状态（Status）"></a>对象规则约定（Spec）与状态（Status）</h2><p>每个 Kubernetes 对象包含两个嵌套的对象字段，它们负责管理对象的配置：对象 spec 和 对象 status 。 spec 是必需的，它描述了对象的期望状态（Desired State） —— 希望对象所具有的特征。 status 描述了对象的 实际状态（Actual State） ，它是由 Kubernetes 系统提供和更新的。在任何时刻，Kubernetes 控制面一直努力地管理着对象的实际状态以与期望状态相匹配。</p><p>例如，Kubernetes Deployment 对象能够表示运行在集群中的应用。 当创建 Deployment 时，可能需要设置 Deployment 的规约，以指定该应用需要有 3 个副本在运行。 Kubernetes 系统读取 Deployment 规约，并启动我们所期望的该应用的 3 个实例 —— 更新状态以与规约相匹配。 如果那些实例中有失败的（一种状态变更），Kubernetes 系统通过修正来响应规约和状态之间的不一致 —— 这种情况，会启动一个新的实例来替换。</p><h2 id="描述-Kubernetes-对象"><a href="#描述-Kubernetes-对象" class="headerlink" title="描述 Kubernetes 对象"></a>描述 Kubernetes 对象</h2><p>当创建 Kubernetes 对象时，必须提供对象的规约，用来描述该对象的期望状态，以及关于对象的一些基本信息（例如名称）。 当使用 Kubernetes API 创建对象时（或者直接创建，或者基于kubectl），API 请求必须在请求体中包含 JSON 格式的信息。 大多数情况下，需要在 .yaml 文件中为 kubectl 提供这些信息。 kubectl 在发起 API 请求时，将这些信息转换成 JSON 格式。</p><p>这里有一个 nginx.yaml 示例文件，展示了 Kubernetes Deployment 的必需字段和对象规约：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: apps&#x2F;v1 # for versions before 1.9.0 use apps&#x2F;v1beta2</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: nginx-deployment</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: nginx</span><br><span class="line">  replicas: 2 # tells deployment to run 2 pods matching the template</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: nginx</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: nginx</span><br><span class="line">        image: nginx:1.14.2</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 80</span><br></pre></td></tr></table></figure><p>使用类似于上面的 .yaml 文件来创建 Deployment，一种方式是使用 kubectl 命令行接口（CLI）中的 kubectl apply 命令， 将 .yaml 文件作为参数。下面是一个示例：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f nginx.yaml --record</span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">deployment.apps&#x2F;nginx-deployment created</span><br></pre></td></tr></table></figure><h2 id="必需字段"><a href="#必需字段" class="headerlink" title="必需字段"></a>必需字段</h2><p>在想要创建的 Kubernetes 对象对应的 .yaml 文件中，需要配置如下的字段：</p><ul><li>apiVersion - 创建该对象所使用的 Kubernetes API 的版本</li><li>kind - 想要创建的对象的类型</li><li>metadata - 帮助识别对象唯一性的数据，包括一个 name 字符串、UID 和可选的 namespace</li></ul><p>您也需要提供对象的 spec 字段。对象 spec 的精确格式对每个 Kubernetes 对象来说是不同的，包含了特定于该对象的嵌套字段。<a href="https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/" target="_blank" rel="noopener">Kubernetes API</a> 参考能够帮助我们找到任何我们想创建的对象的 spec 格式。 例如，可以从 这里 查看 Pod 的 spec 格式， 并且可以从 这里 查看 Deployment 的 spec 格式。</p><h1 id="Kubernetes-API"><a href="#Kubernetes-API" class="headerlink" title="Kubernetes API"></a>Kubernetes API</h1><p>REST API是Kubernetes的基础架构。组件之间的所有操作和通信，以及外部用户命令都是API Server处理的REST API调用。因此，Kubernetes平台中的所有内容都被视为API对象，并且在API中具有相应的条目 。</p><p>大多数操作可以通过 kubectl命令行界面或其他命令行工具（例如kubeadm）执行，而后者又使用API​​。但是，您也可以使用REST调用直接访问API。</p><p>如果要使用Kubernetes API编写应用程序，请考虑使用一种客户端库。</p><p>Kubernetes API是通过HTTP提供的基于资源的（RESTful）编程接口。它支持通过标准HTTP动词（POST，PUT，PATCH，DELETE，GET）检索，创建，更新和删除主要资源，包括许多对象的附加子资源，这些对象允许进行细粒度的授权（例如将Pod绑定到节点） ，并且可以方便或有效地接受并以不同的表示形式提供这些资源。它还支持通过“监视”和一致的列表对资源进行有效的更改通知，以允许其他组件有效地缓存和同步资源状态。</p><h1 id="标准API术语"><a href="#标准API术语" class="headerlink" title="标准API术语"></a>标准API术语</h1><p>大多数Kubernetes API资源类型都是对象：它们代表集群上某个概念的具体实例，例如pod或名称空间。API资源类型的一个较小数目是“虚拟” -它们通常代表操作，而不是物体，如权限检查（使用POST用的JSON编码体SubjectAccessReview到subjectaccessreviews资源）。所有对象都将具有唯一名称，以允许进行幂等的创建和检索，但是如果虚拟资源类型不可检索或不依赖幂等，则它们可能没有唯一的名称。</p><h2 id="资源类别"><a href="#资源类别" class="headerlink" title="资源类别"></a>资源类别</h2><p>这是Kubernetes API提供的基本资源类型及其主要功能的高级概述。</p><ul><li><p>工作负载是用于在集群上管理和运行容器的对象。</p></li><li><p>发现和LB资源是用于将工作负载“缝合”到外部可访问的负载平衡服务中的对象。</p></li><li><p>配置和存储资源是用于将初始化数据注入到应用程序中并持久化容器外部数据的对象。</p></li><li><p>群集资源对象定义了群集本身的配置方式。这些通常仅由集群运营商使用。</p></li><li><p>元数据资源是用于配置集群中其他资源行为（例如HorizontalPodAutoscaler扩展工作负载）的对象。</p></li></ul><h2 id="资源对象"><a href="#资源对象" class="headerlink" title="资源对象"></a>资源对象</h2><p>资源对象通常具有3个组成部分：</p><ul><li>Resource ObjectMeta：这是有关资源的元数据，例如其名称，类型，api版本，注释和标签。它包含最终用户和系统都可能更新的字段（例如，注释）。</li><li>ResourceSpec：由用户定义，并描述所需的系统状态。在创建或更新对象时填写。</li><li>ResourceStatus：这由服务器填充，并报告系统的当前状态。在大多数情况下，用户无需更改此设置。</li></ul><h2 id="资源运作"><a href="#资源运作" class="headerlink" title="资源运作"></a>资源运作</h2><p>大多数资源提供以下操作：</p><h3 id="Create（创建）"><a href="#Create（创建）" class="headerlink" title="Create（创建）"></a>Create（创建）</h3><p>创建操作将在存储后端中创建资源。创建资源后，系统将应用所需的状态。</p><h3 id="Update（更新）"><a href="#Update（更新）" class="headerlink" title="Update（更新）"></a>Update（更新）</h3><p>更新有2种形式：Replace（替换）和补丁</p><ul><li>Replace（替换）：替换资源对象将通过使用提供的规范替换现有规范来更新资源。对于先读后写操作，这是安全的，因为如果在读写之间修改了资源，则会发生乐观锁定失败。注意：ResourceStatus将被系统忽略，并且不会更新。要更新状态，必须调用特定的状态更新操作。</li></ul><p>注意：替换资源对象可能不会立即导致更改传播到下游对象。例如，替换a ConfigMap或Secretresource不会导致所有Pod都看到更改，除非Pod重新带外重启。</p><ul><li>Patch（补丁）：补丁会将更改应用于特定字段。每个字段定义了如何合并更改。列表可以被替换或合并。合并列表将不会保留顺序。<br>修补程序永远不会导致乐观的锁定失败，并且最后的写入将获胜。 如果在更新之前未读取完整状态，或者不希望出现乐观锁定失败，则建议使用修补程序。在修补复杂类型，数组和映射时，将按字段定义修补程序的应用方式，并且可以替换字段的当前值，也可以将内容合并为当前值。</li></ul><h3 id="Read（读）"><a href="#Read（读）" class="headerlink" title="Read（读）"></a>Read（读）</h3><p>读分为3种形式：Get、 List 、 Watch</p><ul><li>Get：Get将按名称检索特定的资源对象。</li><li>List：List将检索名称空间中特定类型的所有资源对象，并且结果可以限制为与选择器查询匹配的资源。<br>列出所有命名空间：与列表类似，但在所有命名空间中检索资源。</li><li>Watch：Watch将在更新对象时流式传输结果。类似于回调，Watch用于响应资源更改。</li></ul><h3 id="Delete（删除）"><a href="#Delete（删除）" class="headerlink" title="Delete（删除）"></a>Delete（删除）</h3><p>删除将删除资源。根据特定的资源，子对象可能会也可能不会被服务器垃圾回收。有关详细信息，请参见有关特定资源对象的注释。</p><h3 id="Additional-Operations（附加操作）"><a href="#Additional-Operations（附加操作）" class="headerlink" title="Additional Operations（附加操作）"></a>Additional Operations（附加操作）</h3><p>资源可以定义特定于该资源类型的其他操作。</p><ul><li>Rollback（回滚）：将PodTemplate回滚到以前的版本。仅适用于某些资源类型。</li><li>Read / Write Scale（读取/写入比例）：读取或更新给定资源的副本数。仅适用于某些资源类型。</li><li>Read / Write Status（读取/写入状态）：读取或更新资源对象的状态。只能通过这些更新操作来更改状态。</li></ul><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>Kubernetes API是系统描述性配置的基础。 Kubectl 命令行工具被用于创建、更新、删除、获取API对象。</p><p>Kubernetes 通过API资源存储自己序列化状态(现在存储在etcd)。</p><p>Kubernetes 被分成多个组件，各部分通过API相互交互。</p><p>Kubernetes 对象一般由3个部分组成（Resource ObjectMeta、ResourceSpec、ResourceStatus）</p><p>而操作 Kubernetes 对象 —— 无论是创建、修改，或者删除都要使用 Kubernetes API。</p><p>从下章开始，我具体讲解各个 Kubernetes 对象的实体化。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p> <a href="https://kubernetes.io/docs/reference/" target="_blank" rel="noopener">API参考</a></p><p> <a href="https://kubernetes.io/docs/reference/using-api/api-concepts/" target="_blank" rel="noopener">Kubernetes API概念</a></p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
            <tag> API </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>顺序、监控地发布项目脚本</title>
      <link href="2020/07/12/script/k8s-upgrade/"/>
      <url>2020/07/12/script/k8s-upgrade/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>此脚本解决多项目顺序批量发布并自带监控，项目之间存在依赖关系，如果存在项目发布失败则终止整个发布流程，反之则一条命令搞定整个K8S发布</p><p>由于本人python不是特别精通(自学一段时间就开始用了，没有啥高大上的算法逻辑等等，写的也不是特别规范，希望看到的多些指点，少些嘲笑)</p><p><a href="https://github.com/chenyu1st/Automation-script/tree/master/K8S%E8%87%AA%E5%8A%A8%E5%8F%91%E5%B8%83" target="_blank" rel="noopener">源码地址</a></p><h1 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h1><p>使用python2.7 即linux自带python版本</p><p>需要更改对应k8s部署文件的yaml路径(固定下来，一劳永逸)及新版本镜像号(每次都需要改)</p><h1 id="命令"><a href="#命令" class="headerlink" title="命令"></a>命令</h1><p>例如：</p><p>python k8s-deploy.py   nginx  mysql </p><p>就会先更新nginx、再更新mysql</p><p>如果ngixn更新失败，则不更新mysql</p><h1 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h1>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line">#!&#x2F;usr&#x2F;bin&#x2F;env python</span><br><span class="line">#coding:utf-8</span><br><span class="line"># @Author  : chenyu</span><br><span class="line"># @Time    : 2020&#x2F;5&#x2F;18 10:21</span><br><span class="line"># @Blog    : rugod.cn</span><br><span class="line">import  os</span><br><span class="line">import  sys</span><br><span class="line">from datetime import datetime</span><br><span class="line">import time</span><br><span class="line">from collections import Counter </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def pods_upgrade_success(project):</span><br><span class="line">     global kubectl_get_pods</span><br><span class="line">     kubectl_images&#x3D;[]</span><br><span class="line">     #查看所有pods-id</span><br><span class="line">     kubectl_get_pods&#x3D;os.popen(&quot;kubectl get pods |grep %s|awk &#39;&#123;print $1&#125;&#39;&quot;%project).read().split()</span><br><span class="line">     for a in kubectl_get_pods:</span><br><span class="line">           #查看每个容器的镜像号</span><br><span class="line">           kubectl_describe_cmd&#x3D;os.popen(&quot;kubectl describe pods %s |sed -n &#39;&#x2F;Image:&#x2F;p&#39; |awk &#39;&#123;print $2&#125;&#39;|cut -d &#39;:&#39; -f2&quot;%a).read().split()</span><br><span class="line">           if kubectl_describe_cmd:                  </span><br><span class="line">                    kubectl_images.append(kubectl_describe_cmd[0])</span><br><span class="line">     print Counter(kubectl_images)</span><br><span class="line">     time.sleep(10) </span><br><span class="line">     return len(set(kubectl_images))</span><br><span class="line">#查看滚动更新完成时间内日志</span><br><span class="line">def pods_health(time_process,id):</span><br><span class="line">     kubectl_log_cmd&#x3D;os.popen(&quot;kubectl logs --since&#x3D;%s   %s&quot;%(time_process,id)).read()</span><br><span class="line">     if &quot;JVM running&quot; in kubectl_log_cmd:</span><br><span class="line">         print(&quot;%s 容器启动正常&quot;%(id))</span><br><span class="line">         return &quot;yes&quot;</span><br><span class="line">     else:</span><br><span class="line">         print(&quot;%s 容器启动异常&quot;%(id))</span><br><span class="line">         return &quot;no&quot;</span><br><span class="line"></span><br><span class="line">def deploy(project):</span><br><span class="line">    while True:</span><br><span class="line">       if pods_upgrade_success(project)&#x3D;&#x3D;1:</span><br><span class="line">         #查看项目滚动更新是否完成</span><br><span class="line">          kubectl_rollout_status&#x3D;os.popen(&quot;kubectl rollout status deployment %s --watch&#x3D;false | grep -ic waiting1&quot;%project).read()</span><br><span class="line">          if kubectl_rollout_status.strip()&#x3D;&#x3D;&quot;0&quot;:</span><br><span class="line">              time_end&#x3D;datetime.now()# 获得当前时间戳</span><br><span class="line">              time_process&#x3D;str((time_end-time_begin).seconds)+&quot;s&quot;   #将时间戳转换成秒</span><br><span class="line">              num_error&#x3D;0</span><br><span class="line">              print(&quot;发布时间为%s,开始分析日志&quot;%(time_process))</span><br><span class="line">              for i in kubectl_get_pods:</span><br><span class="line">                   if  pods_health(time_process, i)&#x3D;&#x3D;&quot;no&quot;:</span><br><span class="line">                       num_error&#x3D;num_error+1</span><br><span class="line">          if num_error&#x3D;&#x3D;0:</span><br><span class="line">                  print(&quot;%s更新成功&quot;%(project))</span><br><span class="line">                  return 1</span><br><span class="line">          else:</span><br><span class="line">                  time_max_end&#x3D;datetime.now()</span><br><span class="line">                  time_max_begin_end&#x3D;(time_max_end-time_begin).seconds</span><br><span class="line">                  if time_max_begin_end&lt;&#x3D;600:</span><br><span class="line">                          print(&quot;%s更新异常,一共有%s个容器更新异常,开始重试------&quot;%(project,num_error))</span><br><span class="line">                  else:</span><br><span class="line">                          print(&quot;都10分钟了，还没发完，咋回事啊&quot;)</span><br><span class="line">                          break</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def upgrade(project):</span><br><span class="line">     os.system(&#39;kubectl apply -f &#x2F;opt&#x2F;service&#x2F;%s&#x2F;prod-deploy.yaml&#39; %project)</span><br><span class="line">     print &quot;开始滚动发布&quot;+project+&quot;项目&quot;</span><br><span class="line"></span><br><span class="line">if __name__ &#x3D;&#x3D; &quot;__main__&quot;:</span><br><span class="line">     if len(sys.argv)&#x3D;&#x3D;1:</span><br><span class="line">         sys.exit(0)</span><br><span class="line">     print(&quot;主函数开始执行&quot;)</span><br><span class="line">     print(&quot;当前时间为&quot;+time.strftime(&#39;%Y-%m-%d %H:%M:%S&#39;))</span><br><span class="line">     succ&#x3D;[]</span><br><span class="line">     for i in sys.argv:</span><br><span class="line">         if i !&#x3D;&#39;k8s-deploy.py&#39; :</span><br><span class="line">              time_begin &#x3D; datetime.now() #获得当前时间戳</span><br><span class="line">              upgrade(i) </span><br><span class="line">              time.sleep(5)</span><br><span class="line">              if deploy(i)&#x3D;&#x3D;1:</span><br><span class="line">                    print &quot;稍等片刻，休息一下&quot; </span><br><span class="line">                    time.sleep(5) </span><br><span class="line">                    succ.append(i)</span><br><span class="line">              else:</span><br><span class="line">                    print (&quot;%s项目发布失败，终止整个发布&quot;%(i))</span><br><span class="line">                    break</span><br><span class="line">     if len(succ)+1&#x3D;&#x3D;len(sys.argv):</span><br><span class="line">            print &quot;已经全部发布完成&quot;       </span><br><span class="line">     else:</span><br><span class="line">            print &quot;未完全发布,已经发布成功的项目为:&quot;</span><br><span class="line">            print succ</span><br></pre></td></tr></table></figure><h1 id="自动发布"><a href="#自动发布" class="headerlink" title="自动发布"></a>自动发布</h1><p>主要就是4个函数</p><ul><li>def pods_upgrade_success(project)<br>查看容器是否滚动更新成功，已镜像号唯一来判断</li></ul><p>比如当前镜像版本为1.0 滚动更新的版本为1.1</p><p>那么在k8s更新容器的时候就会存在多个镜像号，将镜像号的值添加到列表里，然后set()去重,如果只有一个镜像号说明滚动更新成功</p><p>为了方便观察引用了Counter() 一个计数器工具提供快速和方便的计数，你就可以轻松的看到打印出来的镜像号的个数了</p><p>比如4个容器都是1.0 你要更新到1.1</p><p>那么打印出来的效果就是</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;&#39;1.0&#39;:4,&#39;1.1&#39;:1&#125;</span><br><span class="line">&#123;&#39;1.0&#39;:3,&#39;1.1&#39;:2&#125;</span><br><span class="line">------逐渐到</span><br><span class="line">&#123;&#39;1.1&#39;:4,&#39;1.0&#39;:1&#125;</span><br><span class="line">&#123;&#39;1.1&#39;:4&#125;</span><br></pre></td></tr></table></figure><p>一般来说只要镜像号能增长，那就说明新代码能跑起来了</p><p>当然，这个函数可以后期继续改进，比如一段时间如果新镜像号的容器数量不上升则直接打印预警信息等等</p><ul><li>def pods_health(time_process,id) </li></ul><p>查看滚动更新完成时间内日志是否含报错或启动成功等关键字，(和开发人员沟通的效果就是只要jvm running了就行了，其他的报错属于业务上面报错，不在和运维有关，嘻嘻)</p><p>每个人的标准不一样，可以酌情修改</p><p>检查正常返回yes</p><ul><li>def deploy(project)</li></ul><p>计算 开始调用主函数到此函数的触发 的累计时间，拿到现有的容器id，循环执行pods_health(time_process,id) </p><p>查看每个容器是否都出现关键字(判断成功与否的标准)，通过pods_health返回值做判断</p><p>日志分析正常返回1</p><ul><li>def upgrade(project)</li></ul><p>执行kubectl apply命令  需要更改yaml文件地址</p><ul><li>if <strong>name</strong> == “<strong>main</strong>“<br>   循环调用以下函数并将成功的个数计数<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">upgrade(project)  </span><br><span class="line">if deploy(i)&#x3D;&#x3D;1:</span><br><span class="line">   print &quot;稍等片刻，休息一下&quot; </span><br><span class="line">   time.sleep(5) </span><br><span class="line">   succ.append(i)</span><br><span class="line">else:</span><br><span class="line">   print (&quot;%s项目发布失败，终止整个发布&quot;%(i))</span><br><span class="line">   break</span><br></pre></td></tr></table></figure>   判断成功的计数量是否等于输入时的项目的个数，等于则说明每个项目都依次发布完成</li></ul><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>逻辑还是较为简单的</p><ul><li><p>执行更新命令</p></li><li><p>检查是否更新成功(日志关键字摘取分析)</p></li><li><p>返回结果通过后继续更新</p></li><li><p>统计整个发布数量</p></li></ul><h1 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h1><p>由于微服务关系比较紧凑，一个应用服务的更新容易被调用方所依赖，则如果此项目发布失败不停止，发布后面的项目会出现链式雪崩反应。</p><ul><li>回退</li></ul><p>当然这个脚本没有写回退的功能是因为生产环境出问题，一般得开发人员先定位报错，然后分析，再投产。目前每次出问题都得让开发人员过来看报错。</p><p>定位报错这点我想了一下方法，可以直接将更新时间内所有容器的日志都拉取出来给开发人员看，然后先让项目回退</p><ul><li>修改镜像号</li></ul><p>目前更改镜像号需要人工去配置文件更改，由于生产环境和线下分离，只能通过线下去传送镜像到生产环境，无法做到在推送镜像的那一步就加入这个脚本，不知道有啥办法</p><ul><li>告警</li></ul><p>后期做到更自动化地程度，如果发布失败就发邮件告警，不需要人工去看日志是否更新成功等等</p><p>如果有什么建议希望可以留言<del>~</del></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Script </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 自动化 </tag>
            
            <tag> Python </tag>
            
            <tag> Script </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>《SRE：Google运维解密》读书心得(一)——SRE介绍及方法论</title>
      <link href="2020/07/12/sre/google-sre-1/"/>
      <url>2020/07/12/sre/google-sre-1/</url>
      
        <content type="html"><![CDATA[<blockquote><p>好书不怕读的晚，就怕明知道读的晚仍然还不去读。   - 宇神之息  </p></blockquote><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近收获了一本运维神书《SRE：Google运维解密》，简直神的不能再神，如果关注国外技术的应该能接触甚至体验到这种这本书的所讲思想。</p><p>话不多说，从本篇开始做笔记。</p><h1 id="SRE序言"><a href="#SRE序言" class="headerlink" title="SRE序言"></a>SRE序言</h1><p>如果软件工程师主要专注于设计和构建软件系统，那么应该有另外一种直接专注于整个软件系统的生命周期管理。从其设计一直到部署，历经不断更新，最后顺利退役。</p><p>这样一种职业必须具备非常广泛的技能，但是和其他职业的专注点都不同。</p><p>Google将这个职位成为站点可靠性工程师</p><p>SRE：Site Reliability Engineering </p><h1 id="SRE介绍"><a href="#SRE介绍" class="headerlink" title="SRE介绍"></a>SRE介绍</h1><p>不能将碰运气当成战略 是SRE的至理名言。</p><h2 id="系统管理员模式"><a href="#系统管理员模式" class="headerlink" title="系统管理员模式"></a>系统管理员模式</h2><p>系统管理员运维复杂的计算机系统，但是谷歌很早就看出了这种运维工程师的缺陷。</p><ul><li><p>直接成本：随着系统复杂度的增加，部署规模的扩大，团队的大小基本与系统负载成线性相关，共同增长</p></li><li><p>间接成本：研发团队和运维团队背景各异，技术能力与工具使用习惯差距巨大，工作目标也截然不同，对产品的可靠程度要求理解不同，具体执行种对某项操作的危险程度评估与可能技术防范措施也有截然不同的理解。</p></li></ul><p>这些细节分歧及工作量累计起来，最后可能演变成目标与方向上的分歧及形成内部沟通问题，甚至最后上升到部门之间的信任与尊重层面。</p><h2 id="Google的解决之道：SRE"><a href="#Google的解决之道：SRE" class="headerlink" title="Google的解决之道：SRE"></a>Google的解决之道：SRE</h2><p>SRE团队的组成：</p><ul><li>第一类，团队中50%-60%是标准的软件工程师</li><li>第二类，团队中40%-50%是基本满足软件工程师的标准(具备85%-99%所有要求的能力)，同时还有一定程度其他技术能力的工程师。目前来看Google最看重的就是UNIX系统内部细节和1-3层网络知识。</li></ul><p>SRE团队成员的特点：</p><ul><li>对重复性、手工性的操作有天然的排斥感</li><li>有足够的技术能力快速开发出软件系统以替代手工操作</li></ul><p>SRE模型的成功关键正在与对工程的关注。如果没有持续的、工程化的解决方案，运维压力就会不断增加，团队也就需要更多人来手工完成操作。</p><p>为了避免手工操作，SRE团队必须有足够时间编程，否则他们就会被运维工作所淹没。</p><p>Google的经验法则是，SRE团队必须将50%的经历花在真实的开发工作上，随着时间的推移，SRE团队应该倾向于将基本的运维工作全部消除掉，推动整个系统趋于无人化运行，而不仅仅是自动化某些人工流程。</p><h2 id="Devops还是SRE？"><a href="#Devops还是SRE？" class="headerlink" title="Devops还是SRE？"></a>Devops还是SRE？</h2><p>Devops是SRE核心理念的普适版，开源用于更广范围内的组织架构、管理结构和人员安排。同时SRE是Devops模型在Google的具体实践，带有一些特别的扩展。</p><h1 id="SRE方法论"><a href="#SRE方法论" class="headerlink" title="SRE方法论"></a>SRE方法论</h1><p>职责：</p><ul><li>可用性改进</li><li>延迟优化</li><li>性能优化</li><li>效率优化</li><li>变更管理</li><li>监控</li><li>紧急事务处理</li><li>容量规划与管理</li></ul><h2 id="确保长期关注研发工作"><a href="#确保长期关注研发工作" class="headerlink" title="确保长期关注研发工作"></a>确保长期关注研发工作</h2><p>50%日常运维 50%研发项目</p><p>每8-12个值班时间最多处理2个紧急问题，这个准测保证了SRE有足够时间跟进紧急事件，处理故障、恢复服务、撰写事故报告。</p><p>如果一个产品事故没有触发报警，那么事后总结的意义更大：它将揭露监控系统的漏洞。</p><p>事后总结包括：事故发生、发现、解决的全过程</p><p>事故的根本原因：预防或者优化的解决方案</p><h2 id="在保障服务的前提下最大化迭代速度"><a href="#在保障服务的前提下最大化迭代速度" class="headerlink" title="在保障服务的前提下最大化迭代速度"></a>在保障服务的前提下最大化迭代速度</h2><p>任何产品都不是，也不应该做到100%可靠，就素按我们花费巨大精力将系统变成100%可靠也不能给用户带来任何实质意义的好处。</p><p>如果100%不是一个正确的可靠性目标，那么多少才是呢？</p><p>这其实不是一个技术问题，而是一个产品问题：</p><ul><li>基于用户的使用习惯，服务可靠性达到什么程度才会满意？</li><li>如果这个服务可靠性不够，用户是否有其他的选择？</li><li>服务的可靠性是否会影响用户对这项服务的使用模式？</li></ul><p>SRE的目标不再是“零事故运行”，需要和产品研发团队目标一致，都是在保障业务服务可靠性需求的同时尽可能地加快功能的上线速度，说白就是满足即可原则。</p><h2 id="监控系统"><a href="#监控系统" class="headerlink" title="监控系统"></a>监控系统</h2><p>监控系统不应该依赖人来分析报警信息，而是由系统自动分析，仅当需要用户执行某种操作时才需要通知用户。</p><p>一个监控系统的输出只应该有三类：</p><ul><li>紧急警报：必须人工立刻执行，否则将会出事故</li><li>工单：系统不能自动执行，只要人工在几天内解决这个问题，系统就不会受到任何影响</li><li>日志：记录自动化执行的记录，并改进</li></ul><h2 id="应急事件处理"><a href="#应急事件处理" class="headerlink" title="应急事件处理"></a>应急事件处理</h2><p>可靠性是MTTF(平均失败时间)和MTTR(平均恢复时间)的函数。评价一个团队将系统恢复到正常情况的最有效的指标就是MTTR。</p><p>任何需要人工操作的事情都只会延长恢复时间。</p><p>为此，你只能将它趋向自动化处理才能更快响应应急事件，有以下两种提高响应的方法。</p><ul><li>记录处理过程及记录到运维手册中，方便下次出现问题时快速找到解决问题的思路</li><li>将解决问题的思路转变成自动化处理</li></ul><p>当然第二种方法更难，在没有达到第二种目的的情况下，记录到运维手册是你必须也是最快最简单地提高效率的方法。</p><h2 id="变更管理"><a href="#变更管理" class="headerlink" title="变更管理"></a>变更管理</h2><p>SRE的经验说明70%的生产事故由某种部署的变更而触发。而对变更管理的最佳实践是使用自动化完成以下几个目标：</p><ul><li>渐进式发布机制(滚动更新)</li><li>迅速而准确地检测问题的发生</li><li>出现问题时，能安全迅速地回退</li></ul><p>这三点可以有效奖励变更给SRE和最终用户带来的实践成本和服务质量的下降。</p><h2 id="需求预测和容量规划"><a href="#需求预测和容量规划" class="headerlink" title="需求预测和容量规划"></a>需求预测和容量规划</h2><p>需求预测和容量规划必须要以下几个步骤：</p><ul><li>预测模型：必须有一个准确的自然增长需求预测模型，需求预测的实践应该超过资源获取的时间。</li><li>实际数据：规划中必须有准确的非自然增长的需求来源统计。</li><li>压力测试：必须要有周期性的压力测试，以便准确地将系统的原始资源与业务容量对应起来。</li></ul><h2 id="效率与性能"><a href="#效率与性能" class="headerlink" title="效率与性能"></a>效率与性能</h2><p>如果能密切地关注一个服务器的容量配置策略，进而改进其资源利用率，这可以非常有效地降低系统的总成本。</p><p>一个业务的总体资源使用情况可以由以下几个因素驱动：</p><ul><li>用户需求(流量)</li><li>可用容量</li><li>资源使用效率</li></ul><p>SRE通过模型预测用户需求，合理部署和配置可用容量</p><p>SRE和产品研发团队应该共同监控和优化整个系统的性能，这就相当于给服务增加容量和提升效率了</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>取自《SRE：Google运维解密》前10页，总结归纳的心得。</p><p>一本好书，认真读完10页你就已经知道在和说明样的人打交道了。</p><p>好书不怕读的晚，就怕明知道读的晚仍然还不去读。</p><p>祝读者能早日找到心目中的好书！</p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Sre </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Sre </tag>
            
            <tag> Google </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes入门篇(二)——Kubernetes组件介绍</title>
      <link href="2020/07/08/kubernetes/Kubernetes-introduction-2/"/>
      <url>2020/07/08/kubernetes/Kubernetes-introduction-2/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="Kubernetes-组件"><a href="#Kubernetes-组件" class="headerlink" title="Kubernetes 组件"></a>Kubernetes 组件</h1><p>当你部署完 Kubernetes, 即拥有了一个完整的集群。</p><p>一个 Kubernetes 集群包含 集群由一组被称作节点的机器组成。这些节点上运行 Kubernetes 所管理的容器化应用。集群具有至少一个工作节点和至少一个主节点。</p><p>工作节点托管作为应用程序组件的 Pod 。主节点管理集群中的工作节点和 Pod 。多个主节点用于为集群提供故障转移和高可用性。</p><p>本文档概述了交付正常运行的 Kubernetes 集群所需的各种组件。</p><p>这张图表展示了包含所有相互关联组件的 Kubernetes 集群。</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Kubernetes/kubernetes-components.jpg"  alt="kubernetes-components.jpg"></p><h1 id="控制平面节点-又称Master节点"><a href="#控制平面节点-又称Master节点" class="headerlink" title="控制平面节点(又称Master节点)"></a>控制平面节点(又称Master节点)</h1><p>控制平面的组件对集群做出全局决策(比如调度)，以及检测和响应集群事件（例如，当不满足部署的 replicas 字段时，启动新的 pod）。</p><p>控制平面组件可以在集群中的任何节点上运行。然而，为了简单起见，设置脚本通常会在同一个计算机上启动所有控制平面组件，并且不会在此计算机上运行用户容器。</p><h2 id="kube-apiserver"><a href="#kube-apiserver" class="headerlink" title="kube-apiserver"></a>kube-apiserver</h2><p>主节点上负责提供 Kubernetes API 服务的组件；它是 Kubernetes 控制面的接口。</p><p>kube-apiserver 在设计上考虑了水平扩缩的需要。 换言之，通过部署多个实例可以实现扩缩。 </p><h2 id="etcd"><a href="#etcd" class="headerlink" title="etcd"></a>etcd</h2><p>etcd 是兼具一致性和高可用性的键值数据库，可以作为保存 Kubernetes 所有集群数据的后台数据库。</p><p>您的 Kubernetes 集群的 etcd 数据库通常需要有个备份计划。要了解 etcd 更深层次的信息，请参考 <a href="https://etcd.io/docs/" target="_blank" rel="noopener">etcd</a> 文档。</p><h2 id="kube-scheduler"><a href="#kube-scheduler" class="headerlink" title="kube-scheduler"></a>kube-scheduler</h2><p>主节点上的组件，该组件监视那些新创建的未指定运行节点的 Pod，并选择节点让 Pod 在上面运行。</p><p>调度决策考虑的因素包括单个 Pod 和 Pod 集合的资源需求、硬件/软件/策略约束、亲和性和反亲和性规范、数据位置、工作负载间的干扰和最后时限。</p><h2 id="kube-controller-manager"><a href="#kube-controller-manager" class="headerlink" title="kube-controller-manager"></a>kube-controller-manager</h2><p>在主节点上运行控制器的组件。</p><p>从逻辑上讲，每个控制器都是一个单独的进程，但是为了降低复杂性，它们都被编译到同一个可执行文件，并在一个进程中运行。</p><p>这些控制器包括:</p><ul><li>节点控制器（Node Controller）: 负责在节点出现故障时进行通知和响应。</li><li>副本控制器（Replication Controller）: 负责为系统中的每个副本控制器对象维护正确数量的 Pod。</li><li>端点控制器（Endpoints Controller）: 填充端点(Endpoints)对象(即加入 Service 与 Pod)。</li><li>服务帐户和令牌控制器（Service Account &amp; Token Controllers）: 为新的命名空间创建默认帐户和 API 访问令牌.</li></ul><h2 id="cloud-controller-manager"><a href="#cloud-controller-manager" class="headerlink" title="cloud-controller-manager"></a>cloud-controller-manager</h2><p>cloud-controller-manager 运行与基础云提供商交互的控制器。cloud-controller-manager 二进制文件是 Kubernetes 1.6 版本中引入的 alpha 功能。</p><p>cloud-controller-manager 仅运行云提供商特定的控制器循环。您必须在 kube-controller-manager 中禁用这些控制器循环，您可以通过在启动 kube-controller-manager 时将 –cloud-provider 参数设置为 external 来禁用控制器循环。</p><p>cloud-controller-manager 允许云供应商的代码和 Kubernetes 代码彼此独立地发展。在以前的版本中，核心的 Kubernetes 代码依赖于特定云提供商的代码来实现功能。在将来的版本中，云供应商专有的代码应由云供应商自己维护，并与运行 Kubernetes 的云控制器管理器相关联。</p><p>以下控制器具有云提供商依赖性:</p><ul><li>节点控制器（Node Controller）: 用于检查云提供商以确定节点是否在云中停止响应后被删除</li><li>路由控制器（Route Controller）: 用于在底层云基础架构中设置路由</li><li>服务控制器（Service Controller）: 用于创建、更新和删除云提供商负载均衡器</li><li>数据卷控制器（Volume Controller）: 用于创建、附加和装载卷、并与云提供商进行交互以编排卷</li></ul><h1 id="Node节点"><a href="#Node节点" class="headerlink" title="Node节点"></a>Node节点</h1><p>节点组件在每个节点上运行，维护运行的 Pod 并提供 Kubernetes 运行环境。</p><h2 id="kubelet"><a href="#kubelet" class="headerlink" title="kubelet"></a>kubelet</h2><p>一个在集群中每个节点上运行的代理。它保证容器都运行在 Pod 中。</p><p>kubelet 接收一组通过各类机制提供给它的 PodSpecs，确保这些 PodSpecs 中描述的容器处于运行状态且健康。kubelet 不会管理不是由 Kubernetes 创建的容器。</p><h2 id="kube-proxy"><a href="#kube-proxy" class="headerlink" title="kube-proxy"></a>kube-proxy</h2><p>kube-proxy 是集群中每个节点上运行的网络代理,实现 Kubernetes Service 概念的一部分。</p><p>kube-proxy 维护节点上的网络规则。这些网络规则允许从集群内部或外部的网络会话与 Pod 进行网络通信。</p><p>如果操作系统提供了数据包过滤层并可用的话，kube-proxy会通过它来实现网络规则。否则，kube-proxy 仅转发流量本身。</p><h2 id="容器运行环境-Container-Runtime"><a href="#容器运行环境-Container-Runtime" class="headerlink" title="容器运行环境(Container Runtime)"></a>容器运行环境(Container Runtime)</h2><p>容器运行环境是 Kubernetes v1.5 引入的容器运行时接口，它将 Kubelet 与容器运行时解耦，将原来完全面向 Pod 级别的内部接口拆分成面向 Sandbox 和 Container 的 gRPC 接口，并将镜像管理和容器管理分离到不同的服务。</p><p>Kubernetes 支持多个容器运行环境: Docker、 containerd、cri-o、 rktlet 以及任何实现 Kubernetes CRI (容器运行环境接口)。</p><h1 id="插件-Addons"><a href="#插件-Addons" class="headerlink" title="插件(Addons)"></a>插件(Addons)</h1><p>插件使用 Kubernetes 资源 (DaemonSet, Deployment等) 实现集群功能。因为这些提供集群级别的功能，所以插件的命名空间资源属于 kube-system 命名空间。</p><p>所选的插件如下所述：有关可用插件的扩展列表，请参见插件 (Addons)。</p><h2 id="DNS"><a href="#DNS" class="headerlink" title="DNS"></a>DNS</h2><p>尽管并非严格要求其他附加组件，但所有示例都依赖集群 DNS，因此所有 Kubernetes 集群都应具有 DNS。</p><p>除了您环境中的其他 DNS 服务器之外，集群 DNS 还是一个 DNS 服务器，它为 Kubernetes 服务提供 DNS 记录。</p><p>Cluster DNS 是一个 DNS 服务器，和您部署环境中的其他 DNS 服务器一起工作，为 Kubernetes 服务提供DNS记录。</p><p>Kubernetes 启动的容器自动将 DNS 服务器包含在 DNS 搜索中。</p><h2 id="用户界面-Dashboard"><a href="#用户界面-Dashboard" class="headerlink" title="用户界面(Dashboard)"></a>用户界面(Dashboard)</h2><p>Dashboard 是 Kubernetes 集群的通用基于 Web 的 UI。它使用户可以管理集群中运行的应用程序以及集群本身并进行故障排除。</p><h2 id="容器资源监控"><a href="#容器资源监控" class="headerlink" title="容器资源监控"></a>容器资源监控</h2><p>容器资源监控将关于容器的一些常见的时间序列度量值保存到一个集中的数据库中，并提供用于浏览这些数据的界面。</p><h2 id="集群层面日志"><a href="#集群层面日志" class="headerlink" title="集群层面日志"></a>集群层面日志</h2><p>集群层面日志 机制负责将容器的日志数据保存到一个集中的日志存储中，该存储能够提供搜索和浏览接口。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>总结一下Kubernetes组件</p><p>Master节点(至少一个)所含组件</p><table><thead><tr><th>组件</th><th>用途</th></tr></thead><tbody><tr><td>kube-apiserver</td><td>集群接口</td></tr><tr><td>etcd</td><td>k-v型数据库</td></tr><tr><td>kube-scheduler</td><td>整个集群的资源调度</td></tr><tr><td>kube-controller-manager</td><td>集群内部的管理控制中心</td></tr><tr><td>cloud-controller-manager</td><td>云管理控制器</td></tr></tbody></table><p>Node节点(至少一个)</p><table><thead><tr><th>组件</th><th>用途</th></tr></thead><tbody><tr><td>kube-apiserver</td><td>集群接口</td></tr><tr><td>etcd</td><td>k-v型数据库</td></tr><tr><td>kube-scheduler</td><td>整个集群的资源调度</td></tr><tr><td>kube-controller-manager</td><td>集群内部的管理控制中心</td></tr><tr><td>cloud-controller-manager</td><td>云管理控制器</td></tr></tbody></table><p> API Server是etcd访问的唯一入口，只有API Server才能访问和操作etcd集群；API Server对内和对外都提供了统一的REST API，其他组件都是通过API Server进行通信的</p><p>用户使用kubectl命令来请求API Server接口完成相应操作<br>Kubernetes内部组件都是通过一种监听机制去监控API Server中的资源变化，然后对其做一些相应的操作。</p><p>实现具体逻辑较为复杂，后期再进行深入讲解。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://kubernetes.io/zh/docs/concepts/overview/components/" target="_blank" rel="noopener">Kubernetes 组件</a></p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
            <tag> 容器编排 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes入门篇(一)——Kubernetes是什么</title>
      <link href="2020/07/07/kubernetes/Kubernetes-introduction-1/"/>
      <url>2020/07/07/kubernetes/Kubernetes-introduction-1/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="Kubernetes简介"><a href="#Kubernetes简介" class="headerlink" title="Kubernetes简介"></a>Kubernetes简介</h1><p>Kubernetes 是一个可移植的、可扩展的开源平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化。Kubernetes 拥有一个庞大且快速增长的生态系统。Kubernetes 的服务、支持和工具广泛可用。</p><p>名称 Kubernetes 源于希腊语，意为 “舵手” 或 “飞行员”。Google 在 2014 年开源了 Kubernetes 项目。Kubernetes 建立在 Google 在大规模运行生产工作负载方面拥有十几年的经验的基础上，结合了社区中最好的想法和实践。</p><p>通俗点讲，管理Docker的各个对象很麻烦(容器、镜像、网络、存储等等)，而Kubernetes解决的很多容器的编排问题，并且不限于容器编排。</p><h1 id="对比传统部署"><a href="#对比传统部署" class="headerlink" title="对比传统部署"></a>对比传统部署</h1><h2 id="传统部署时代"><a href="#传统部署时代" class="headerlink" title="传统部署时代"></a>传统部署时代</h2><p>早期，组织在物理服务器上运行应用程序。无法为物理服务器中的应用程序定义资源边界，这会导致资源分配问题。例如，如果在物理服务器上运行多个应用程序，则可能会出现一个应用程序占用大部分资源的情况，结果可能导致其他应用程序的性能下降。一种解决方案是在不同的物理服务器上运行每个应用程序，但是由于资源利用不足而无法扩展，并且组织维护许多物理服务器的成本很高。</p><h2 id="虚拟化部署时代："><a href="#虚拟化部署时代：" class="headerlink" title="虚拟化部署时代："></a>虚拟化部署时代：</h2><p>作为解决方案，引入了虚拟化功能，它允许您在单个物理服务器的 CPU 上运行多个虚拟机（VM）。虚拟化功能允许应用程序在 VM 之间隔离，并提供安全级别，因为一个应用程序的信息不能被另一应用程序自由地访问。</p><p>因为虚拟化可以轻松地添加或更新应用程序、降低硬件成本等等，所以虚拟化可以更好地利用物理服务器中的资源，并可以实现更好的可伸缩性。</p><p>每个 VM 是一台完整的计算机，在虚拟化硬件之上运行所有组件，包括其自己的操作系统。</p><h2 id="容器部署时代：-容器类似于"><a href="#容器部署时代：-容器类似于" class="headerlink" title="容器部署时代： 容器类似于"></a>容器部署时代： 容器类似于</h2><p>VM，但是它们具有轻量级的隔离属性，可以在应用程序之间共享操作系统（OS）。因此，容器被认为是轻量级的。容器与 VM 类似，具有自己的文件系统、CPU、内存、进程空间等。由于它们与基础架构分离，因此可以跨云和 OS 分发进行移植。</p><p>容器因具有许多优势而变得流行起来。下面列出了容器的一些好处：</p><ul><li>敏捷应用程序的创建和部署：与使用 VM 镜像相比，提高了容器镜像创建的简便性和效率。</li><li>持续开发、集成和部署：通过快速简单的回滚(由于镜像不可变性)，提供可靠且频繁的容器镜像构建和部署。</li><li>关注开发与运维的分离：在构建/发布时而不是在部署时创建应用程序容器镜像，从而将应用程序与基础架构分离。</li><li>可观察性不仅可以显示操作系统级别的信息和指标，还可以显示应用程序的运行状况和其他指标信号。</li><li>跨开发、测试和生产的环境一致性：在便携式计算机上与在云中相同地运行。</li><li>云和操作系统分发的可移植性：可在 Ubuntu、RHEL、CoreOS、本地、Google Kubernetes Engine 和其他任何地方运行。</li><li>以应用程序为中心的管理：提高抽象级别，从在虚拟硬件上运行 OS 到使用逻辑资源在 OS 上运行应用程序。</li><li>松散耦合、分布式、弹性、解放的微服务：应用程序被分解成较小的独立部分，并且可以动态部署和管理 - 而不是在一台大型单机上整体运行。</li><li>资源隔离：可预测的应用程序性能。</li><li>资源利用：高效率和高密度。</li></ul><h2 id="为什么需要-Kubernetes，它能做什么"><a href="#为什么需要-Kubernetes，它能做什么" class="headerlink" title="为什么需要 Kubernetes，它能做什么?"></a>为什么需要 Kubernetes，它能做什么?</h2><p>容器是打包和运行应用程序的好方式。在生产环境中，您需要管理运行应用程序的容器，并确保不会停机。例如，如果一个容器发生故障，则需要启动另一个容器。如果系统处理此行为，会不会更容易？</p><p>这就是 Kubernetes 的救援方法！Kubernetes 为您提供了一个可弹性运行分布式系统的框架。Kubernetes 会满足您的扩展要求、故障转移、部署模式等。例如，Kubernetes 可以轻松管理系统的部署。</p><p>Kubernetes 为您提供：</p><ul><li>服务发现和负载均衡</li></ul><p>Kubernetes 可以使用 DNS 名称或自己的 IP 地址公开容器，如果到容器的流量很大，Kubernetes 可以负载均衡并分配网络流量，从而使部署稳定。</p><ul><li>存储编排</li></ul><p>Kubernetes 允许您自动挂载您选择的存储系统，例如本地存储、公共云提供商等。</p><ul><li>自动部署和回滚</li></ul><p>您可以使用 Kubernetes 描述已部署容器的所需状态，它可以以受控的速率将实际状态更改为所需状态。例如，您可以自动化 Kubernetes 来为您的部署创建新容器，删除现有容器并将它们的所有资源用于新容器。</p><ul><li>自动二进制打包</li></ul><p>Kubernetes 允许您指定每个容器所需 CPU 和内存（RAM）。当容器指定了资源请求时，Kubernetes 可以做出更好的决策来管理容器的资源。</p><ul><li>自我修复</li></ul><p>Kubernetes 重新启动失败的容器、替换容器、杀死不响应用户定义的运行状况检查的容器，并且在准备好服务之前不将其通告给客户端。</p><ul><li>密钥与配置管理</li></ul><p>Kubernetes 允许您存储和管理敏感信息，例如密码、OAuth 令牌和 ssh 密钥。您可以在不重建容器镜像的情况下部署和更新密钥和应用程序配置，也无需在堆栈配置中暴露密钥。</p><h2 id="Kubernetes-不是什么"><a href="#Kubernetes-不是什么" class="headerlink" title="Kubernetes 不是什么"></a>Kubernetes 不是什么</h2><p>Kubernetes 不是传统的、包罗万象的 PaaS（平台即服务）系统。由于 Kubernetes 在容器级别而不是在硬件级别运行，因此它提供了 PaaS 产品共有的一些普遍适用的功能，例如部署、扩展、负载均衡、日志记录和监视。但是，Kubernetes 不是单一的，默认解决方案是可选和可插拔的。Kubernetes 提供了构建开发人员平台的基础，但是在重要的地方保留了用户的选择和灵活性。</p><ul><li>Kubernetes 不限制支持的应用程序类型(你可以在kubernetes之上运行c程序、java程序、python程序等等)。Kubernetes 旨在支持极其多种多样的工作负载，包括无状态、有状态和数据处理工作负载。如果应用程序可以在容器中运行，那么它应该可以在 Kubernetes 上很好地运行。</li><li>Kubernetes 不部署源代码，也不构建您的应用程序。持续集成(CI)、交付和部署（CI/CD）工作流取决于组织的文化和偏好以及技术要求。</li><li>Kubernetes 不提供应用程序级别的服务作为内置服务，例如中间件（例如，消息中间件）、数据处理框架（例如，Spark）、数据库（例如，mysql）、缓存、集群存储系统（例如，Ceph）。这样的组件可以在 Kubernetes 上运行，并且/或者可以由运行在 Kubernetes 上的应用程序通过可移植机制（例如，开放服务代理）来访问。</li><li>Kubernetes 不指定日志记录、监视或警报解决方案。它提供了一些集成作为概念证明，并提供了收集和导出指标的机制。</li><li>Kubernetes 不提供或不要求配置语言/系统（例如 jsonnet），它提供了声明性 API，该声明性 API 可以由任意形式的声明性规范所构成。</li><li>Kubernetes 不提供也不采用任何全面的机器配置、维护、管理或自我修复系统。</li><li>此外，Kubernetes 不仅仅是一个编排系统，实际上它消除了编排的需要。编排的技术定义是执行已定义的工作流程：首先执行 A，然后执行 B，再执行 C。相比之下，Kubernetes 包含一组独立的、可组合的控制过程，这些过程连续地将当前状态驱动到所提供的所需状态。从 A 到 C 的方式无关紧要，也不需要集中控制，这使得系统更易于使用且功能更强大、健壮、弹性和可扩展性。</li></ul><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>以上来自google官方文档的翻译，我觉得看书什么的都不如官方文档来的简单直接，推荐大家学习技术看官方文档，提高自己的思想理解能力。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://kubernetes.io/zh/docs/concepts/overview/what-is-kubernetes/" target="_blank" rel="noopener">Kubernetes是什么</a></p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
            <tag> 容器编排 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入浅出Docker原理及实战(五)——Docker网络介绍</title>
      <link href="2020/07/06/docker/docker-idea-5/"/>
      <url>2020/07/06/docker/docker-idea-5/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><p>深入浅出Docker原理及实战系列第五篇，我主要分享Docker的网络概念及如何合理的使用Docker网络。</p><h1 id="Docker网络介绍"><a href="#Docker网络介绍" class="headerlink" title="Docker网络介绍"></a>Docker网络介绍</h1><p>Docker容器和服务如此强大的原因之一是您可以将它们连接在一起，或将它们连接到非Docker环境中。</p><p>Docker容器和服务甚至不需要知道它们已部署在Docker上，也不必知道它们的对等对象是否也是Docker中运行。</p><p>无论您的Docker主机运行Linux，Windows还是两者结合，您都可以使用Docker以与平台无关的方式管理它们。</p><h1 id="网络模式简介"><a href="#网络模式简介" class="headerlink" title="网络模式简介"></a>网络模式简介</h1><p>Docker的网络子系统可使用驱动程序插入。默认情况下，存在几个驱动程序，它们提供核心联网功能：</p><h2 id="bridge-网桥"><a href="#bridge-网桥" class="headerlink" title="bridge(网桥)"></a>bridge(网桥)</h2><p>默认的网络驱动程序。如果未指定驱动程序，则这是您正在创建的网络类型。当您的应用程序在需要通信的独立容器中运行时，通常会使用网桥网络。</p><h2 id="host-主机网络"><a href="#host-主机网络" class="headerlink" title="host(主机网络)"></a>host(主机网络)</h2><p>对于独立容器，请删除容器与Docker主机之间的网络隔离，然后直接使用主机的网络。</p><h2 id="overlay-覆盖网络"><a href="#overlay-覆盖网络" class="headerlink" title="overlay(覆盖网络)"></a>overlay(覆盖网络)</h2><p>覆盖网络将多个Docker守护程序连接在一起，并使群集服务能够相互通信。您还可以使用覆盖网络来促进群集服务和独立容器之间或不同Docker守护程序上的两个独立容器之间的通信。这种策略消除了在这些容器之间进行操作系统级路由的需要。</p><h2 id="macvlan-物理地址网络"><a href="#macvlan-物理地址网络" class="headerlink" title="macvlan(物理地址网络)"></a>macvlan(物理地址网络)</h2><p>Macvlan网络允许您将MAC地址分配给容器，使其在网络上显示为物理设备。Docker守护程序通过其MAC地址将流量路由到容器。macvlan 在处理希望直接连接到物理网络而不是通过Docker主机的网络堆栈进行路由的旧应用程序时，使用驱动程序有时是最佳选择。</p><h2 id="none-禁用网络"><a href="#none-禁用网络" class="headerlink" title="none(禁用网络)"></a>none(禁用网络)</h2><p>对于此容器，请禁用所有联网。通常与自定义网络驱动程序一起使用。none不适用于群体服务。</p><h2 id="如何选型网络模式"><a href="#如何选型网络模式" class="headerlink" title="如何选型网络模式"></a>如何选型网络模式</h2><ul><li>当您需要多个容器在同一Docker主机上进行通信时，最好使用用户定义的网桥网络。</li><li>当容器的应用程序不能与Docker主机隔离时，但您希望容器的其他方面隔离时，主机网络是最佳选择。</li><li>当您需要不同Docker主机上运行的容器进行通信时，或者当多个应用程序使用集群服务一起工作时，覆盖网络是最佳的选择。</li><li>从VM设置迁移或需要容器看起来像网络上的物理主机（每个都有唯一的MAC地址）时，Macvlan网络是最好的。</li></ul><h1 id="4种网络模式"><a href="#4种网络模式" class="headerlink" title="4种网络模式"></a>4种网络模式</h1><h2 id="bridge-networks"><a href="#bridge-networks" class="headerlink" title="bridge networks"></a>bridge networks</h2><p>在网络方面，网桥是在网段之间转发流量的链路层设备。桥可以是在主机内核中运行的硬件设备或软件设备。</p><p>就Docker而言，网桥网络使用软件网桥，该软件网桥允许连接到同一网桥网络的容器进行通信，同时与未连接到该网桥网络的容器隔离。Docker网桥驱动程序会自动在主机中安装规则，以使不同网桥网络上的容器无法直接相互通信。</p><p>桥接网络适用于在同一 Docker守护程序主机上运行的容器。</p><p>启动Docker时，会自动创建一个默认的桥接网络（也称为bridge），并且除非另有说明，否则新启动的容器将连接到它。您还可以创建用户定义的自定义网桥网络。用户定义的网桥网络优于默认bridge 网络。</p><p>下面是一个默认网桥的例子</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# ip add</span><br><span class="line"></span><br><span class="line">3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN group default </span><br><span class="line">    link&#x2F;ether 02:42:ec:96:8d:3a brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.17.0.1&#x2F;16 brd 172.17.255.255 scope global docker0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 fe80::42:ecff:fe96:8d3a&#x2F;64 scope link </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">       </span><br><span class="line">[root@localhost ~]# docker network ls</span><br><span class="line">NETWORK ID          NAME                DRIVER              SCOPE</span><br><span class="line">45c686d33317        bridge              bridge              local</span><br></pre></td></tr></table></figure><h3 id="用户定义的网桥和默认网桥之间的区别"><a href="#用户定义的网桥和默认网桥之间的区别" class="headerlink" title="用户定义的网桥和默认网桥之间的区别"></a>用户定义的网桥和默认网桥之间的区别</h3><h4 id="用户定义的网桥可在容器之间提供自动DNS解析"><a href="#用户定义的网桥可在容器之间提供自动DNS解析" class="headerlink" title="用户定义的网桥可在容器之间提供自动DNS解析"></a>用户定义的网桥可在容器之间提供自动DNS解析</h4><p>默认网桥上的容器只能通过IP地址相互访问，除非您使用–link选项。在用户定义的网桥网络上，容器可以通过名称或别名相互解析。</p><p>如果在默认网桥上运行相同的应用程序，则需要在容器之间手动创建链接（使用–link）。这些链接需要双向创建，因此您可以看到，要进行通信的容器超过两个，这将变得很复杂。或者，您可以修改/etc/hosts容器中的文件，但这会导致难以调试的问题。</p><p>想象一个具有Web前端和db后端的应用程序同时放在一个用户定义好的网桥上。如果容器web调用db，则db无论应用程序在哪个Docker主机上运行，Web容器都可以通过连接到db容器。</p><h4 id="用户定义的网桥可提供更好的隔离"><a href="#用户定义的网桥可提供更好的隔离" class="headerlink" title="用户定义的网桥可提供更好的隔离"></a>用户定义的网桥可提供更好的隔离</h4><p>所有没有通过–network指定的容器都将连接到默认网桥网络。这可能是一种风险，因为不相关的应用/服务/容器随后能够进行通信。</p><p>自定义的网桥可提供局域网，其中只有连接到该网络的容器才能通信。</p><h4 id="容器可以随时随地从用户定义的网络连接和分离"><a href="#容器可以随时随地从用户定义的网络连接和分离" class="headerlink" title="容器可以随时随地从用户定义的网络连接和分离"></a>容器可以随时随地从用户定义的网络连接和分离</h4><p>在容器的生命周期内，您可以即时将其与自定义的网桥连接或断开连接。要从默认网桥网络中删除容器，您需要停止容器并使用其他网络选项重新创建它。</p><h4 id="每个用户定义的网络都会创建一个可配置的网桥"><a href="#每个用户定义的网络都会创建一个可配置的网桥" class="headerlink" title="每个用户定义的网络都会创建一个可配置的网桥"></a>每个用户定义的网络都会创建一个可配置的网桥</h4><p>如果您的容器使用默认的网桥，则可以对其进行配置，但是所有容器都使用相同的设置，例如MTU和iptables规则。此外，配置默认桥接网络发生在Docker本身之外，并且需要重新启动Docker。</p><p>自定义的网桥是通过 docker network create创建和配置的。如果不同的应用程序组具有不同的网络要求，则可以在创建时分别配置每个自定义的网桥。</p><h4 id="默认网桥网络上的链接容器共享环境变量"><a href="#默认网桥网络上的链接容器共享环境变量" class="headerlink" title="默认网桥网络上的链接容器共享环境变量"></a>默认网桥网络上的链接容器共享环境变量</h4><p>最初，在两个容器之间共享环境变量的唯一方法是使用–link链接它们。自定义网络无法进行这种类型的变量共享。但是，存在共享环境变量的高级方法。</p><ul><li>多个容器可以使用Docker卷挂载包含共享信息的文件或目录。</li><li>使用可以一起启动多个容器docker-compose，并且compose文件可以定义共享变量(推荐配置)。</li><li>您可以使用集群服务来代替独立容器，并利用共享配置(分布式共享)。</li></ul><p>连接到同一自定义网桥的容器可以有效地将所有端口彼此公开。为了使容器或不同网络上的非Docker主机可以访问该端口，必须使用-p或–publish来发布该端口。</p><h3 id="使用自定义网桥"><a href="#使用自定义网桥" class="headerlink" title="使用自定义网桥"></a>使用自定义网桥</h3><p>使用docker network create命令创建自定义网桥,在不选择任何配置的情况创建的就是网桥模式，您还可以指定子网，IP地址范围，网关和其他选项。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network create my-net</span><br></pre></td></tr></table></figure><p>使用docker network rm命令删除用户定义的网桥网络。如果容器当前已连接到网络，请先断开它们的连接。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network rm my-net</span><br></pre></td></tr></table></figure><h4 id="将容器连接到用户定义的网桥"><a href="#将容器连接到用户定义的网桥" class="headerlink" title="将容器连接到用户定义的网桥"></a>将容器连接到用户定义的网桥</h4><p>创建新容器时，可以指定一个或多个–network参数。此示例将Nginx容器连接到my-net网络。它还将容器中的端口80发布到Docker主机上的端口8080，</p><p>因此外部客户端可以访问该端口。连接到my-net网络的任何其他容器都可以访问my-nginx容器上的所有端口，反之亦然。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker create --name my-nginx \</span><br><span class="line">  --network my-net \</span><br><span class="line">  --publish 8080:80 \</span><br><span class="line">  nginx:latest</span><br></pre></td></tr></table></figure><p>要将运行中的容器连接到现有的用户定义的网桥，请使用docker network connect命令。以下命令将一个已经在运行的my-nginx容器连接到一个已经存在的my-net网络：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network connect my-net my-nginx</span><br></pre></td></tr></table></figure><h4 id="断开容器与用户定义的网桥的连接"><a href="#断开容器与用户定义的网桥的连接" class="headerlink" title="断开容器与用户定义的网桥的连接"></a>断开容器与用户定义的网桥的连接</h4><p>要将运行中的容器与用户定义的网桥断开连接，请使用docker network断开命令。以下命令将my-nginx容器与my-net网络断开连接。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network disconnect my-net my-nginx</span><br></pre></td></tr></table></figure><h3 id="使用默认网桥"><a href="#使用默认网桥" class="headerlink" title="使用默认网桥"></a>使用默认网桥</h3><p>默认网桥被认为是Docker的遗留细节，不建议用于生产环境。对其进行配置需要手动操作，存在技术缺陷。</p><h4 id="将容器连接到默认网桥"><a href="#将容器连接到默认网桥" class="headerlink" title="将容器连接到默认网桥"></a>将容器连接到默认网桥</h4><p>如果您未使用–network标志指定网络，而是指定了网络驱动程序，则默认情况下，您的容器将连接到默认网桥网络。除非使用旧版–link标志进行链接，否则连接到默认网桥网络的容器只能通过IP地址进行通信。</p><h4 id="配置默认网桥网络"><a href="#配置默认网桥网络" class="headerlink" title="配置默认网桥网络"></a>配置默认网桥网络</h4><p>要配置默认的桥接网络，请在daemon.json中指定选项。这是一个daemon.json示例，其中指定了多个选项。仅指定您需要自定义的设置。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;bip&quot;: &quot;192.168.1.5&#x2F;24&quot;,</span><br><span class="line">  &quot;fixed-cidr&quot;: &quot;192.168.1.5&#x2F;25&quot;,</span><br><span class="line">  &quot;fixed-cidr-v6&quot;: &quot;2001:db8::&#x2F;64&quot;,</span><br><span class="line">  &quot;mtu&quot;: 1500,</span><br><span class="line">  &quot;default-gateway&quot;: &quot;10.20.1.1&quot;,</span><br><span class="line">  &quot;default-gateway-v6&quot;: &quot;2001:db8:abcd::89&quot;,</span><br><span class="line">  &quot;dns&quot;: [&quot;10.20.1.2&quot;,&quot;10.20.1.3&quot;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>重新启动Docker以使更改生效。</p><h3 id="网桥底层原理"><a href="#网桥底层原理" class="headerlink" title="网桥底层原理"></a>网桥底层原理</h3><p>创建或删除用户定义的网桥或将容器与用户定义的网桥连接或断开连接时，docker使用指定操作系统的工具来管理基础网络基础结构（例如，在Linux上添加或删除桥接设备或配置iptables规则）。这些细节应视为实施细节。让Docker为您管理用户定义的网络。</p><h3 id="开启从Docker容器到外界的转发规则"><a href="#开启从Docker容器到外界的转发规则" class="headerlink" title="开启从Docker容器到外界的转发规则"></a>开启从Docker容器到外界的转发规则</h3><p>默认情况下，来自连接到默认网桥网络的容器的流量不会转发到外界。要启用转发，您需要更改两个设置。这些不是Docker命令，它们会影响Docker主机的内核。</p><ul><li>配置Linux内核以允许IP转发</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sysctl net.ipv4.conf.all.forwarding&#x3D;1</span><br></pre></td></tr></table></figure><ul><li>将iptables FORWARD策略的策略从DROP更改为ACCEPT<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -P FORWARD ACCEPT</span><br></pre></td></tr></table></figure></li></ul><p>这些设置不会在重新启动后持续存在，因此您可能需要将它们添加到启动脚本中。</p><h2 id="overlay-networks"><a href="#overlay-networks" class="headerlink" title="overlay networks"></a>overlay networks</h2><p>覆盖网络驱动程序会在多个Docker守护程序主机之间创建一个分布式网络。该网络位于特定于主机的网络之上（覆盖主机网络），启用加密后，允许与其连接的容器（包括群集服务容器）进行安全通信。</p><p>Docker透明地处理每个数据包与正确的Docker守护程序主机和正确的目标容器之间的路由。</p><p>初始化群集或将Docker主机加入现有群集时，将在该Docker主机上创建两个新网络：</p><ul><li>一个名为Ingress的覆盖网络，用于处理与集群服务相关的控制和数据流量。创建群集服务并且不将其连接到用户定义的覆盖网络时，默认情况下它将连接到Ingress。</li><li>一个名为docker_gwbridge的网桥网络，该网络将各个服务器Docker守护程序连接到该集群中的其他守护程序。</li></ul><h3 id="创建覆盖网络的先决条件"><a href="#创建覆盖网络的先决条件" class="headerlink" title="创建覆盖网络的先决条件"></a>创建覆盖网络的先决条件</h3><p>使用覆盖网络的Docker守护程序的防火墙规则<br>您需要打开以下端口，以往返于参与覆盖网络的每个Docker主机的流量：</p><ul><li>用于群集管理通信的TCP端口2377</li><li>TCP和UDP端口7946，用于节点之间的通信</li><li>UDP端口4789，用于覆盖网络流量</li></ul><p>在创建覆盖网络之前，您需要使用初始化Docker守护程序作为swarm管理器，docker swarm init或者使用将该Docker守护程序加入现有的swarm docker swarm join。这两个都将创建默认的ingress覆盖网络，默认情况下，群集服务会使用该 覆盖网络。即使您从未计划使用群体服务，也需要这样做。之后，您可以创建其他用户定义的覆盖网络。</p><h3 id="使用覆盖网络"><a href="#使用覆盖网络" class="headerlink" title="使用覆盖网络"></a>使用覆盖网络</h3><p>官方文档讲了一个通俗易懂的例子：</p><p>需要三台物理或虚拟Docker主机，它们可以相互通信，并且都运行Docker 17.03或更高版本的新安装。本教程假定这三台主机在同一网络上运行，并且不涉及防火墙。</p><p>这些主机将被称为manager，worker-1和worker-2。该 manager主机将作为既是经理和工人，这意味着它可以运行服务任务和管理群。worker-1并且worker-2将作为唯一的工人</p><p>然后通过一系列命令，创建集群，加入集群，创建服务，连接服务即可。</p><p>看到这，如果你了解过kubernetes，是不是会发现Docker的覆盖网络和Kubernetes有异曲同工之妙，(虽然我还没仔细了解kubernetes的网络，但是我已经明显感觉到kubernetes就是加强版这种覆盖网络的使用，后期继续深挖主机之间的网络通信原理)</p><p>具体实现可以查看<br><a href="https://docs.docker.com/network/network-tutorial-overlay/" target="_blank" rel="noopener">覆盖网络官方教程</a></p><h2 id="host-networks"><a href="#host-networks" class="headerlink" title="host networks"></a>host networks</h2><p>如果您对容器使用主机网络模式，则该容器的网络堆栈不会与Docker主机隔离（该容器共享主机的网络名称空间），并且该容器不会分配自己的IP地址。例如，如果您运行一个绑定到端口80 host 的容器并使用网络，则该容器的应用程序在主机IP地址上的端口80上可用。</p><p>注意！！！</p><p>由于使用时容器不拥有自己的IP地址 host模式的网络，端口映射不生效，并且-p，–publish，-P，和–publish-all选项都将被忽略，并且产生一个警告：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WARNING: Published ports are discarded when using host network mode</span><br></pre></td></tr></table></figure><p>主机模式网络对于优化性能以及在容器需要处理大量端口的情况下很有用，因为它不需要网络地址转换（NAT），并且不会为每个端口创建”userland-proxy”。</p><p>通过将–network host传递给docker service create命令，您还可以将主机网络用于群集服务。在这种情况下，控制流量（与管理群集和服务有关的流量）仍会通过覆盖网络发送，但是单个群集服务容器会使用Docker守护程序的主机网络和端口发送数据。这带来了一些额外的限制。例如，如果服务容器绑定到端口80，则在给定的群集节点上只能运行一个服务容器。</p><p><a href="https://docs.docker.com/network/host/" target="_blank" rel="noopener">主机网络官方教程</a></p><h2 id="macvlan-networks"><a href="#macvlan-networks" class="headerlink" title="macvlan networks"></a>macvlan networks</h2><p>某些应用程序，尤其是旧版应用程序或监视网络流量的应用程序，期望直接连接到物理网络。在这种情况下，可以使用macvlan网络驱动程序为每个容器的虚拟网络接口分配MAC地址，使其看起来像是直接连接到物理网络的物理网络接口。在这种情况下，您需要在Docker主机上指定用于macvlan的物理接口，以及的子网和网关。</p><p>您甚至可以macvlan使用不同的物理网络接口隔离网络。请记住以下几点：</p><ul><li><p>由于IP地址耗尽或“ VLAN扩散”，很容易无意间损坏您的网络，在这种情况下，您的网络中有大量不正确的唯一MAC地址。</p></li><li><p>您的网络设备需要能够处理“混杂模式”，在该模式下，可以为一个物理接口分配多个MAC地址。</p></li><li><p>如果您的应用程序可以使用网桥（在单个Docker主机上）或覆盖（跨多个Docker主机进行通信）工作，那么从长远来看，这些解决方案可能会更好。</p></li></ul><p>具体实现可以看<br><a href="https://docs.docker.com/network/macvlan/" target="_blank" rel="noopener">macvlan网络官方教程</a></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>对于Docker来说，掌握好网桥模式足够，覆盖网络会有更好的替代容器编排工具(k8s),mac网络和主机网络用的也较少。</p><h1 id="Docker-Network-CLI"><a href="#Docker-Network-CLI" class="headerlink" title="Docker Network CLI"></a>Docker Network CLI</h1><p>管理网络。您可以使用子命令来创建，检查，列出，删除，修剪，连接和断开网络连接。</p><p>用法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network COMMAND</span><br></pre></td></tr></table></figure><p>COMMAND子命令</p><table><thead><tr><th>COMMAND</th><th>描述</th></tr></thead><tbody><tr><td>docker network connect</td><td>将容器连接到网络</td></tr><tr><td>docker network create</td><td>建立网络</td></tr><tr><td>docker network disconnect</td><td>断开容器与网络的连接</td></tr><tr><td>docker network inspect</td><td>显示网络的详细信息</td></tr><tr><td>docker network ls</td><td>列出网络</td></tr><tr><td>docker network rm</td><td>删除网络</td></tr></tbody></table><h2 id="docker-network-connect"><a href="#docker-network-connect" class="headerlink" title="docker network connect"></a>docker network connect</h2><p>将容器连接到网络</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network connect [OPTIONS] NETWORK CONTAINER</span><br></pre></td></tr></table></figure><table><thead><tr><th>OPTIONS</th><th>描述</th></tr></thead><tbody><tr><td>–alias</td><td>为容器添加网络的别名</td></tr><tr><td>–driver-opt</td><td>网络的驱动程序选项</td></tr><tr><td>–ip</td><td>指定要分配给容器接口的IP地址</td></tr><tr><td>–link</td><td>将链接添加到另一个容器</td></tr></tbody></table><p>例子：</p><ul><li>将正在运行的容器连接到网络</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network connect redis-network redis</span><br></pre></td></tr></table></figure><ul><li>启动容器时将其连接到网络</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -itd --network&#x3D;redis-network redis</span><br></pre></td></tr></table></figure><ul><li>指定容器在给定网络上将使用的IP地址</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network connect --ip 172.18.1.2 redis-network redis</span><br></pre></td></tr></table></figure><ul><li>为容器创建一个网络别名</li></ul><p>–alias 选项可用于通过所连接网络中的另一个名称来解析容器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network connect --alias redis6379 redis-network redis</span><br></pre></td></tr></table></figure><p>处在redis-network这个网络中的容器可以通过redis6379去连接redis</p><ul><li>使用–link选项</li></ul><p>您可以使用–link链接另一个具有首选别名的容器<br>docker network connect –link redis:redis6379 redis-network test</p><h2 id="docker-network-create"><a href="#docker-network-create" class="headerlink" title="docker network create"></a>docker network create</h2><p>创建一个新的网络。在DRIVER默认的网络驱动程序是bridge或者overlay。如果您安装了第三方或自己的自定义网络驱动程序，则也可以DRIVER在此处指定。如果未指定该 –driver选项，该命令将自动为您创建一个网桥。当您安装Docker Engine时，它会自动创建一个网桥。该网络对应于Docker Engine传统上依赖的网桥。当您启动一个新容器时， docker run它会自动连接到该网桥网络。您不能删除此默认网桥，但可以使用以下network create命令创建新的网桥。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network create [OPTIONS] NETWORK</span><br></pre></td></tr></table></figure><table><thead><tr><th>OPTIONS</th><th>描述</th></tr></thead><tbody><tr><td>–aux-address</td><td>网络驱动程序使用的辅助IPv4或IPv6地址</td></tr><tr><td>–driver , -d 默认是bridge</td><td>网络的驱动程序选项</td></tr><tr><td>–gateway</td><td>主子网的IPv4或IPv6网关</td></tr><tr><td>–internal</td><td>限制外部访问网络</td></tr><tr><td>–ip-range</td><td>从子范围分配容器ip</td></tr><tr><td>–subnet</td><td>代表网段的CIDR格式的子网</td></tr></tbody></table><h3 id="高级选项"><a href="#高级选项" class="headerlink" title="高级选项"></a>高级选项</h3><p>网桥是单个引擎安装上的隔离网络。如果要创建一个跨越多个运行主机的Docker主机的overlay网络，则必须创建一个网络。与网桥不同，覆盖网络需要先存在一些先决条件才能创建一个。这些条件已经在上文讲过，不再重复，这里主要讲创建网桥的具体内容。</p><p>创建网络时，默认情况下，引擎会为该网络创建一个不重叠的子网。该子网不是现有网络的细分。它仅用于ip寻址目的。您可以覆盖此默认值，并使用该–subnet选项直接指定子网值。</p><h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><ul><li>在 bridge网络上，您只能创建一个子网：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network create --driver&#x3D;bridge --subnet&#x3D;192.168.0.0&#x2F;16 redis-network</span><br></pre></td></tr></table></figure><ul><li>此外，还可以指定–gateway –ip-range和–aux-address 选项。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker network create \</span><br><span class="line">  --driver&#x3D;bridge \</span><br><span class="line">  --subnet&#x3D;172.28.0.0&#x2F;16 \</span><br><span class="line">  --ip-range&#x3D;172.28.5.0&#x2F;24 \</span><br><span class="line">  --gateway&#x3D;172.28.5.254 \</span><br><span class="line">  redis-network</span><br></pre></td></tr></table></figure><h2 id="docker-network-disconnect"><a href="#docker-network-disconnect" class="headerlink" title="docker network disconnect"></a>docker network disconnect</h2><p>断开容器与网络的连接，断开容器与网络的连接。容器必须正在运行才能将其与网络断开连接。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker network disconnect [OPTIONS] NETWORK CONTAINER</span><br><span class="line"></span><br><span class="line">--force , -f 强制容器断开网络连接</span><br><span class="line"></span><br><span class="line">eg: docker network disconnect multi-host-network container1</span><br></pre></td></tr></table></figure><h2 id="docker-network-inspect"><a href="#docker-network-inspect" class="headerlink" title="docker network inspect"></a>docker network inspect</h2><p>显示一个或多个网络详细信息，默认情况下，此命令将所有结果呈现在JSON对象中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker network inspect [OPTIONS] NETWORK [NETWORK...]</span><br><span class="line"></span><br><span class="line">--format , -f  使用给定的Go模板格式化输出</span><br><span class="line">--verbose , -v 详细输出以进行诊断</span><br></pre></td></tr></table></figure><h2 id="docker-network-ls"><a href="#docker-network-ls" class="headerlink" title="docker network ls"></a>docker network ls</h2><p>列出daemon引擎知道的所有网络。这包括跨群集中多个主机的网络。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network ls [OPTIONS]</span><br></pre></td></tr></table></figure><table><thead><tr><th>OPTIONS</th><th>描述</th></tr></thead><tbody><tr><td>–filter , -f</td><td>提供过滤器值（例如“ driver = bridge”）</td></tr><tr><td>–format</td><td>使用Go模板的打印网络</td></tr><tr><td>–no-trunc</td><td>不要截断输出</td></tr><tr><td>–quiet , -q</td><td>仅显示网络ID</td></tr></tbody></table><p>例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">列出所有网络：</span><br><span class="line"></span><br><span class="line">docker network ls</span><br><span class="line">NETWORK ID          NAME                DRIVER          SCOPE</span><br><span class="line">7fca4eb8c647        bridge              bridge          local</span><br><span class="line">9f904ee27bf5        none                null            local</span><br><span class="line">cf03ee007fb4        host                host            local</span><br><span class="line">78b03ee04fc4        multi-host          overlay         swarm</span><br><span class="line"></span><br><span class="line">使用--no-trunc选项显示完整的网络ID：</span><br><span class="line"></span><br><span class="line">docker network ls --no-trunc</span><br><span class="line">NETWORK ID                                                         NAME                DRIVER           SCOPE</span><br><span class="line">18a2866682b85619a026c81b98a5e375bd33e1b0936a26cc497c283d27bae9b3   none                null             local</span><br><span class="line">c288470c46f6c8949c5f7e5099b5b7947b07eabe8d9a27d79a9cbf111adcbf47   host                host             local</span><br><span class="line">7b369448dccbf865d397c8d2be0cda7cf7edc6b0945f77d2529912ae917a0185   bridge              bridge           local</span><br><span class="line">95e74588f40db048e86320c6526440c504650a1ff3e9f7d60a497c4d2163e5bd   foo                 bridge           local</span><br><span class="line">63d1ff1f77b07ca51070a8c227e962238358bd310bde1529cf62e6c307ade161   dev                 bridge           local</span><br><span class="line"></span><br><span class="line">过滤器匹配基于其驱动程序的网络。</span><br><span class="line">docker network ls --filter driver&#x3D;bridge</span><br><span class="line">NETWORK ID          NAME                DRIVER            SCOPE</span><br><span class="line">db9db329f835        test1               bridge            local</span><br><span class="line">f6e212da9dfd        test2               bridge            local</span><br></pre></td></tr></table></figure><h2 id="docker-network-rm"><a href="#docker-network-rm" class="headerlink" title="docker network rm"></a>docker network rm</h2><p>按名称或标识符删除一个或多个网络。要删除网络，必须首先断开连接到它的所有容器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network rm NETWORK [NETWORK...]</span><br></pre></td></tr></table></figure><p>例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker network rm my-network</span><br></pre></td></tr></table></figure><h1 id="Docker和Iptables-重中之重"><a href="#Docker和Iptables-重中之重" class="headerlink" title="Docker和Iptables(重中之重)"></a>Docker和Iptables(重中之重)</h1><p>在Linux上，Docker操纵iptables规则以提供网络隔离。尽管这是实现的详细信息，并且您不应修改Docker在iptables策略中插入的规则，但是如果您想要拥有自己的策略（而不是由Docker管理的策略），它确实会对您需要执行的操作产生一些影响。</p><p>如果您在已暴露网络的主机上运行Docker，则可能需要采用iptables策略，以防止未经授权访问您主机上运行的容器或其他服务。下面主要描述如何实现此目标以及需要注意的注意事项。</p><h2 id="启动Docker之前添加iptables策略"><a href="#启动Docker之前添加iptables策略" class="headerlink" title="启动Docker之前添加iptables策略"></a>启动Docker之前添加iptables策略</h2><p>Docker安装了两个iptables链，名叫DOCKER-USER 和DOCKER，它确保传入的数据包始终首先由这两个链进行检查。</p><p>手动或通过其他基于iptables的防火墙添加到FORWARD链中的规则在这些链之后进行评估。这意味着，如果您通过Docker公开端口，则无论防火墙配置了什么规则，该端口都会公开。如果您希望即使在通过Docker公开端口时也要应用这些规则，则必须将这些规则添加到DOCKER-USER链中。</p><h2 id="限制与Docker主机的连接"><a href="#限制与Docker主机的连接" class="headerlink" title="限制与Docker主机的连接"></a>限制与Docker主机的连接</h2><p>默认情况，允许所有外部IP连接到Docker主机。</p><p>要仅允许特定的IP或网络访问容器，请在DOCKER-USER过滤器链的顶部插入一个否定的规则。例如，下面一个规则限制了除192.168.1.1之外的所有IP地址的外部访问，也就是说只能有192.168.1.1才能访问这个容器内部</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -I DOCKER-USER -i ext_if ! -s 192.168.1.1 -j DROP</span><br></pre></td></tr></table></figure><p>请注意，您将需要更改ext_if以与主机的实际外部接口相对应。您可以改为允许来源子网的连接。以下规则仅允许从子网192.168.1.0/24访问容器内部：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -I DOCKER-USER -i ext_if ! -s 192.168.1.0&#x2F;24 -j DROP</span><br></pre></td></tr></table></figure><p>iptables是复杂的，更复杂的规则不在此主题范围内。有关它的更多信息，请参见<a href="https://www.netfilter.org/documentation/HOWTO/NAT-HOWTO.html" target="_blank" rel="noopener">Netfilter.org HOWTO</a>。</p><p>还有几种策略具体请看 <a href="https://docs.docker.com/network/iptables/" target="_blank" rel="noopener">Docker和iptables</a></p><h2 id="问题回顾"><a href="#问题回顾" class="headerlink" title="问题回顾"></a>问题回顾</h2><p>正好前几天出现了一个Docker的网络问题，无法启动容器，现在来回顾一下</p><p>为了证明启动Docker之前添加iptables策略这点非常重要，我做了以下实验。</p><ul><li>这台主机在启动docker之前已经关闭了防火墙，并且已运行了几个容器，执行iptables 命令查看链路信息 发现存在各个容器暴露端口的链路规则</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# iptables -L</span><br><span class="line">Chain INPUT (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain FORWARD (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">DOCKER-USER  all  --  anywhere             anywhere            </span><br><span class="line">DOCKER-ISOLATION-STAGE-1  all  --  anywhere             anywhere            </span><br><span class="line">ACCEPT     all  --  anywhere             anywhere             ctstate RELATED,ESTABLISHED</span><br><span class="line">DOCKER     all  --  anywhere             anywhere            </span><br><span class="line">ACCEPT     all  --  anywhere             anywhere            </span><br><span class="line">ACCEPT     all  --  anywhere             anywhere            </span><br><span class="line">ACCEPT     all  --  anywhere             anywhere             ctstate RELATED,ESTABLISHED</span><br><span class="line">DOCKER     all  --  anywhere             anywhere            </span><br><span class="line">ACCEPT     all  --  anywhere             anywhere            </span><br><span class="line">ACCEPT     all  --  anywhere             anywhere            </span><br><span class="line"></span><br><span class="line">Chain OUTPUT (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain DOCKER (2 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">ACCEPT     tcp  --  anywhere             172.17.0.2           tcp dpt:6379</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.2           tcp dpt:17010</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.2           tcp dpt:ups-onlinet</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.3           tcp dpt:17011</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.3           tcp dpt:talon-disc</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.4           tcp dpt:17012</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.4           tcp dpt:talon-engine</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.5           tcp dpt:17013</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.5           tcp dpt:microtalon-dis</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.6           tcp dpt:17014</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.6           tcp dpt:microtalon-com</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.7           tcp dpt:17015</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.7           tcp dpt:talon-webserver</span><br><span class="line"></span><br><span class="line">Chain DOCKER-ISOLATION-STAGE-1 (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">DOCKER-ISOLATION-STAGE-2  all  --  anywhere             anywhere            </span><br><span class="line">DOCKER-ISOLATION-STAGE-2  all  --  anywhere             anywhere            </span><br><span class="line">RETURN     all  --  anywhere             anywhere            </span><br><span class="line"></span><br><span class="line">Chain DOCKER-ISOLATION-STAGE-2 (2 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">DROP       all  --  anywhere             anywhere            </span><br><span class="line">DROP       all  --  anywhere             anywhere            </span><br><span class="line">RETURN     all  --  anywhere             anywhere            </span><br><span class="line"></span><br><span class="line">Chain DOCKER-USER (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">RETURN     all  --  anywhere             anywhere</span><br></pre></td></tr></table></figure><ul><li>开启防火墙，执行iptables 命令查看链路信息 发现iptables好像恢复出厂默认了</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# systemctl start firewalld</span><br><span class="line">[root@localhost ~]# iptables -L</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Chain INPUT (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">ACCEPT     all  --  anywhere             anywhere             ctstate RELATED,ESTABLISHED</span><br><span class="line">ACCEPT     all  --  anywhere             anywhere            </span><br><span class="line">INPUT_direct  all  --  anywhere             anywhere            </span><br><span class="line">INPUT_ZONES_SOURCE  all  --  anywhere             anywhere            </span><br><span class="line">INPUT_ZONES  all  --  anywhere             anywhere            </span><br><span class="line">DROP       all  --  anywhere             anywhere             ctstate INVALID</span><br><span class="line">REJECT     all  --  anywhere             anywhere             reject-with icmp-host-prohibited</span><br><span class="line"></span><br><span class="line">Chain FORWARD (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">ACCEPT     all  --  anywhere             anywhere             ctstate RELATED,ESTABLISHED</span><br><span class="line">ACCEPT     all  --  anywhere             anywhere            </span><br><span class="line">FORWARD_direct  all  --  anywhere             anywhere            </span><br><span class="line">FORWARD_IN_ZONES_SOURCE  all  --  anywhere             anywhere            </span><br><span class="line">FORWARD_IN_ZONES  all  --  anywhere             anywhere            </span><br><span class="line">FORWARD_OUT_ZONES_SOURCE  all  --  anywhere             anywhere            </span><br><span class="line">FORWARD_OUT_ZONES  all  --  anywhere             anywhere            </span><br><span class="line">DROP       all  --  anywhere             anywhere             ctstate INVALID</span><br><span class="line">REJECT     all  --  anywhere             anywhere             reject-with icmp-host-prohibited</span><br><span class="line"></span><br><span class="line">Chain OUTPUT (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">OUTPUT_direct  all  --  anywhere             anywhere            </span><br><span class="line"></span><br><span class="line">Chain FORWARD_IN_ZONES (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">FWDI_public  all  --  anywhere             anywhere            [goto] </span><br><span class="line">FWDI_public  all  --  anywhere             anywhere            [goto] </span><br><span class="line"></span><br><span class="line">Chain FORWARD_IN_ZONES_SOURCE (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain FORWARD_OUT_ZONES (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">FWDO_public  all  --  anywhere             anywhere            [goto] </span><br><span class="line">FWDO_public  all  --  anywhere             anywhere            [goto] </span><br><span class="line"></span><br><span class="line">Chain FORWARD_OUT_ZONES_SOURCE (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain FORWARD_direct (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain FWDI_public (2 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">FWDI_public_log  all  --  anywhere             anywhere            </span><br><span class="line">FWDI_public_deny  all  --  anywhere             anywhere            </span><br><span class="line">FWDI_public_allow  all  --  anywhere             anywhere            </span><br><span class="line">ACCEPT     icmp --  anywhere             anywhere            </span><br><span class="line"></span><br><span class="line">Chain FWDI_public_allow (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain FWDI_public_deny (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain FWDI_public_log (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain FWDO_public (2 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">FWDO_public_log  all  --  anywhere             anywhere            </span><br><span class="line">FWDO_public_deny  all  --  anywhere             anywhere            </span><br><span class="line">FWDO_public_allow  all  --  anywhere             anywhere            </span><br><span class="line"></span><br><span class="line">Chain FWDO_public_allow (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain FWDO_public_deny (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain FWDO_public_log (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain INPUT_ZONES (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">IN_public  all  --  anywhere             anywhere            [goto] </span><br><span class="line">IN_public  all  --  anywhere             anywhere            [goto] </span><br><span class="line"></span><br><span class="line">Chain INPUT_ZONES_SOURCE (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain INPUT_direct (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain IN_public (2 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">IN_public_log  all  --  anywhere             anywhere            </span><br><span class="line">IN_public_deny  all  --  anywhere             anywhere            </span><br><span class="line">IN_public_allow  all  --  anywhere             anywhere            </span><br><span class="line">ACCEPT     icmp --  anywhere             anywhere            </span><br><span class="line"></span><br><span class="line">Chain IN_public_allow (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">ACCEPT     tcp  --  anywhere             anywhere             tcp dpt:ssh ctstate NEW</span><br><span class="line"></span><br><span class="line">Chain IN_public_deny (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain IN_public_log (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain OUTPUT_direct (1 references)</span><br><span class="line">target     prot opt source               destination</span><br></pre></td></tr></table></figure><ul><li>关闭防火墙，执行iptables 命令查看链路信息<br>发现iptables链路信息全部被清空</li><li>启动容器 暴露80端口，发现启动失败</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# systemctl stop firewalld</span><br><span class="line">[root@localhost ~]# iptables -L</span><br><span class="line">Chain INPUT (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain FORWARD (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain OUTPUT (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[root@localhost ~]# docker  run  -d -p 80:80 --volumes-from pmm-data --name pmm-server --restart always  percona&#x2F;pmm-server:latest</span><br><span class="line">f86d559846840468a45ec4b69b3cd4458854b2e9392e4e47b84430e420c59f7c</span><br><span class="line">docker: Error response from daemon: driver failed programming external connectivity on endpoint pmm-server (b5e49ead04279b9c1ab16609ed3fcb78d309fb2fcab001adda57a9bd45dc23d0):  (iptables failed: iptables --wait -t nat -A DOCKER -p tcp -d 0&#x2F;0 --dport 80 -j DNAT --to-destination 172.17.0.3:80 ! -i docker0: iptables: No chain&#x2F;target&#x2F;match by that name.</span><br><span class="line"> (exit status 1)).</span><br></pre></td></tr></table></figure><ul><li>重启docker服务端，执行iptables 命令查看链路信息，发现重新录入docker策略</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# systemctl restart docker</span><br><span class="line">[root@localhost ~]# iptables -L</span><br><span class="line">Chain INPUT (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain FORWARD (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">DOCKER-USER  all  --  anywhere             anywhere            </span><br><span class="line">DOCKER-ISOLATION-STAGE-1  all  --  anywhere             anywhere            </span><br><span class="line">ACCEPT     all  --  anywhere             anywhere             ctstate RELATED,ESTABLISHED</span><br><span class="line">DOCKER     all  --  anywhere             anywhere            </span><br><span class="line">ACCEPT     all  --  anywhere             anywhere            </span><br><span class="line">ACCEPT     all  --  anywhere             anywhere            </span><br><span class="line">ACCEPT     all  --  anywhere             anywhere             ctstate RELATED,ESTABLISHED</span><br><span class="line">DOCKER     all  --  anywhere             anywhere            </span><br><span class="line">ACCEPT     all  --  anywhere             anywhere            </span><br><span class="line">ACCEPT     all  --  anywhere             anywhere            </span><br><span class="line"></span><br><span class="line">Chain OUTPUT (policy ACCEPT)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line"></span><br><span class="line">Chain DOCKER (2 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.2           tcp dpt:17014</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.2           tcp dpt:microtalon-com</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.3           tcp dpt:17015</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.4           tcp dpt:17010</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.5           tcp dpt:17012</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.3           tcp dpt:talon-webserver</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.4           tcp dpt:ups-onlinet</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.5           tcp dpt:talon-engine</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.6           tcp dpt:17013</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.7           tcp dpt:17011</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.6           tcp dpt:microtalon-dis</span><br><span class="line">ACCEPT     tcp  --  anywhere             172.18.0.7           tcp dpt:talon-disc</span><br><span class="line"></span><br><span class="line">Chain DOCKER-ISOLATION-STAGE-1 (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">DOCKER-ISOLATION-STAGE-2  all  --  anywhere             anywhere            </span><br><span class="line">DOCKER-ISOLATION-STAGE-2  all  --  anywhere             anywhere            </span><br><span class="line">RETURN     all  --  anywhere             anywhere            </span><br><span class="line"></span><br><span class="line">Chain DOCKER-ISOLATION-STAGE-2 (2 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">DROP       all  --  anywhere             anywhere            </span><br><span class="line">DROP       all  --  anywhere             anywhere            </span><br><span class="line">RETURN     all  --  anywhere             anywhere            </span><br><span class="line"></span><br><span class="line">Chain DOCKER-USER (1 references)</span><br><span class="line">target     prot opt source               destination         </span><br><span class="line">RETURN     all  --  anywhere             anywhere</span><br></pre></td></tr></table></figure><h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p>你一定要在启动Docker之前关闭防火墙，否则重新启动防火墙再关闭也不会让iptables加入Docker链，唯一的解决办法就是重启Docker，这对于生产环境来说是极为危险的(你这台机器上的所有容器都得重启)</p><h1 id="总结归纳"><a href="#总结归纳" class="headerlink" title="总结归纳"></a>总结归纳</h1><h2 id="容器网络"><a href="#容器网络" class="headerlink" title="容器网络"></a>容器网络</h2><p>容器使用的网络类型，无论是网桥，主机网络， 覆盖网络，macvlan网络还是自定义网络插件，在容器内部都是透明的。从容器的角度来看，它具有一个带有IP地址，网关，路由表，DNS服务和其他网络详细信息的网络接口（假定容器未使用none网络驱动程序）。</p><h2 id="发布端口"><a href="#发布端口" class="headerlink" title="发布端口"></a>发布端口</h2><p>默认情况下，创建容器时，它不会将其任何端口发布到外界。要使端口可用于Docker外部的服务或未连接到容器网络的Docker容器，请使用 –publish或-p标志。这将创建一个防火墙规则，该规则将容器端口映射到Docker主机上的端口。这里有些例子。</p><table><thead><tr><th>标志值</th><th>描述</th></tr></thead><tbody><tr><td>-p 8080:80</td><td>将容器中的TCP端口80映射到Docker主机上的端口8080。</td></tr><tr><td>-p 192.168.1.100:8080:80</td><td>将容器中的TCP端口80映射到Docker主机上的端口8080，以连接到主机IP 192.168.1.100。</td></tr><tr><td>-p 8080:80/udp</td><td>将容器中的UDP端口80映射到Docker主机上的端口8080。</td></tr><tr><td>-p 8080:80/tcp -p 8080:80/udp</td><td>将容器中的TCP端口80映射到Docker主机上的TCP端口8080，并将容器中的UDP端口80映射到Docker主机上的UDP端口8080。</td></tr></tbody></table><h2 id="容器的IP地址和主机名"><a href="#容器的IP地址和主机名" class="headerlink" title="容器的IP地址和主机名"></a>容器的IP地址和主机名</h2><p>默认情况下，为容器连接到的每个Docker网络分配一个IP地址。IP地址是在网络池中分配的，因此Docker守护程序实际上充当了每个容器的DHCP服务器。每个网络还具有默认的子网掩码和网关。</p><p>容器启动时，只能使用将该容器连接到单个网络 –network。但是，您可以使用将运行中的容器连接到多个网络docker network connect。使用–network标志启动容器时 ，可以使用–ip或–ip6标志指定分配给该网络上的容器的IP地址。</p><p>使用将现有容器连接到其他网络时 docker network connect，可以在该命令上使用–ip或–ip6标志来指定其他网络上容器的IP地址。</p><p>同样，容器的主机名默认为Docker中容器的ID。您可以使用覆盖主机名–hostname。使用来连接到现有网络时docker network connect，可以使用该–alias 标志为该网络上的容器指定其他网络别名。</p><h2 id="DNS服务"><a href="#DNS服务" class="headerlink" title="DNS服务"></a>DNS服务</h2><p>默认情况下，容器会继承/etc/resolv.conf配置文件中定义的主机的DNS设置 。使用默认网桥的容器将获得此文件的副本，而使用自定义网桥的容器将使用 Docker的嵌入式DNS服务器，该服务器会将外部DNS查找转发到主机上配置的DNS服务器。</p><p>自定义主机中定义的/etc/hosts不会继承。要将其他主机传递到您的容器中，请参考<a href="https://docs.docker.com/engine/reference/commandline/run/#add-entries-to-container-hosts-file---add-host" target="_blank" rel="noopener">docker run</a> 的参数设置。</p><h2 id="Iptables"><a href="#Iptables" class="headerlink" title="Iptables"></a>Iptables</h2><p>重要的事情说三次，你一定要在启动Docker之前关闭防火墙，你一定要在启动Docker之前关闭防火墙，你一定要在启动Docker之前关闭防火墙。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://docs.docker.com/engine/reference/commandline/network/" target="_blank" rel="noopener">Docker Network CLI</a></p><p><a href="https://docs.docker.com/network/" target="_blank" rel="noopener">Docker Networking overview</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> Linux </tag>
            
            <tag> 容器 </tag>
            
            <tag> 网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>See-SQL审计平台介绍及部署</title>
      <link href="2020/07/01/mysql/mysql-see/"/>
      <url>2020/07/01/mysql/mysql-see/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>线下数据库，成天有人要求运维执行这sql那sql的，又苦逼又容易背锅，问了下公司的DBA大神，推荐了see审计平台，执行sql有审计记录，留痕留痕留痕，重要的事情说三遍，即使是线下环境，谨防有人删库跑路找不到人，可以解决运维一大痛点。</p><h1 id="审计平台介绍"><a href="#审计平台介绍" class="headerlink" title="审计平台介绍"></a>审计平台介绍</h1><p>数据库审计平台作用</p><ul><li>《对于开发人员》提交代码通过Inception审核，不符合规范代码会有提示，通过<br>Inception 审核后，开发人员可自行发起执行或定时执行，回滚等操作</li><li>《对于测试人员》提交代码需走工单流，通过Inception审核，流程自动到达部门经理，<br>部门经理审核，所有执行、回滚等操作由管理员操作</li><li>支持DDL，DML语句上线，回滚操作，方便统计已上线SQL，便于问题回溯</li><li>SQL优化，可提供SQL优化建议，打分、SQL改写建议，增加索引建议等</li></ul><h2 id="API集成"><a href="#API集成" class="headerlink" title="API集成"></a>API集成</h2><ul><li>Inception: 去哪儿网开源，提供SQL语句审核、执行、回滚功能</li><li>SQLAdvisor: 美团开源，提供分析SQL中的where条件、聚合条件、多表Join关系，输出索引优化建议</li><li>SOAR: 小米开源，提供SQL启发式算法的语句优化、多列索引优化等功能</li></ul><h2 id="功能简介"><a href="#功能简介" class="headerlink" title="功能简介"></a>功能简介</h2><h3 id="目标库管理"><a href="#目标库管理" class="headerlink" title="目标库管理"></a>目标库管理</h3><ul><li>支持多场地/数据中心的数据库管理，集群方式归纳目标数据库</li><li>支持目标数据库配置，库/表结构查询</li></ul><h3 id="SQL操作"><a href="#SQL操作" class="headerlink" title="SQL操作"></a>SQL操作</h3><ul><li>基于Inception</li><li>SQL语法检测</li><li>SQL语句执行</li><li>SQL回滚</li><li>定时工单</li><li>历史记录</li></ul><h3 id="SQL查询"><a href="#SQL查询" class="headerlink" title="SQL查询"></a>SQL查询</h3><ul><li>查询目标数据库的详细表结构</li><li>查询表数据，对结果可导出文件</li><li>SQL语句优化（基于美团SQLAdvisor）</li><li>多层次优化建议（基于小米SOAR）</li></ul><h3 id="用户管理"><a href="#用户管理" class="headerlink" title="用户管理"></a>用户管理</h3><ul><li>对用户/组的注册/注销/加组/授权等管理</li></ul><h3 id="个性化设置"><a href="#个性化设置" class="headerlink" title="个性化设置"></a>个性化设置</h3><ul><li>管理员可以做SQL关键字拦截，平台的审批功能开关等设置</li><li>用户可以订阅其常用的数据库，指定审批工单的经理，以简化审核时所需的操作</li></ul><h3 id="inception设置"><a href="#inception设置" class="headerlink" title="inception设置"></a>inception设置</h3><ul><li>inception服务连接信息</li><li>inception备份库连接信息</li><li>inception支持的参数释义及值</li></ul><h3 id="人工审批功能"><a href="#人工审批功能" class="headerlink" title="人工审批功能"></a>人工审批功能</h3><ul><li>流程开关</li><li>开启流程，工单至少需双人确认（流程：提交人 – inception自动审核 – 经理审批 – DBA上线）</li><li>关闭流程，工单可由经理上线（流程：提交人 – inception自动审核 – 经理上线）</li></ul><h3 id="用户权限"><a href="#用户权限" class="headerlink" title="用户权限"></a>用户权限</h3><ul><li>基于RBAC的表级，对象级权限控制体系</li><li>通过用户管理设置用户权限</li><li>根据用户身份（组员/经理/总监）鉴权用户对SQL的审核/取消/执行/回滚等操作</li></ul><h3 id="操作流程"><a href="#操作流程" class="headerlink" title="操作流程"></a>操作流程</h3><ul><li>用户需要输入SQL，指定环境，执行人，数据库</li><li>inception自动审核SQL语法</li><li>审批人做审批通过或驳回操作</li><li>执行人做执行/撤销/回滚等操作</li><li>SQL列表界面提供SQL查询，操作等相关功能</li></ul><h3 id="API文档"><a href="#API文档" class="headerlink" title="API文档"></a>API文档</h3><ul><li>各接口生成自动化的API文档，对接外部需求</li></ul><h3 id="登录"><a href="#登录" class="headerlink" title="登录"></a>登录</h3><ul><li>支持see系统登录</li><li>支持自定义公司统一认证中心(sso)登录</li></ul><h3 id="通知"><a href="#通知" class="headerlink" title="通知"></a>通知</h3><p>E-mail邮件推送</p><h3 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h3><p>DashBoard数据报表展示</p><h1 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h1><h2 id="Inception"><a href="#Inception" class="headerlink" title="Inception"></a>Inception</h2><p>SQL操作基于Inception</p><ul><li>SQL语法检测</li><li>SQL语句执行</li><li>SQL回滚</li><li>定时工单</li><li>历史记录</li></ul><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Mysql/see/Inception.jpg"  alt="Inception"></p><p>Inception提供的功能很丰富，首先，它可以对提交的所有语句的语法分析，如果语法有问题，都会将相应的错误信息返回给审核者。<br>还提供语义分析，当一个表，库，列等信息不正确或者不符合规范的时候报错，或者使用了一个不存在的对象时报错等等。 还提供<br>了很多针对SQL规范性约束的功能，这些DBA都是可以通过系统参数来配置的。 更高级的功能是，可以辅助DBA分析一条查询语句的<br>性能，如果没有使用索引或者某些原因导致查询很慢，都可以检查。<br>还提供SQL语句的执行功能，可执行的语句类型包括常用的DML及DDL语句及truncate table等操作。<br> Inception 在执行 DML 时还提供生成回滚语句的功能，对应的操作记录及回滚语句会被存储在备份机器上面，备份机器通过配置Inception参数来指定。</p><h2 id="SOAR"><a href="#SOAR" class="headerlink" title="SOAR"></a>SOAR</h2><p>SOAR(SQL Optimizer And Rewriter)是一个对SQL进行优化和改写的自动化工具。 由小米人工智能与云平台的数据库团队开发与维护。</p><p>功能特点</p><ul><li>跨平台支持（支持Linux, Mac环境，Windows环境理论上也支持，不过未全面测试）</li><li>目前只支持 MySQL 语法族协议的SQL优化</li><li>支持基于启发式算法的语句优化</li><li>支持复杂查询的多列索引优化（UPDATE, INSERT, DELETE, SELECT）</li><li>支持EXPLAIN信息丰富解读</li><li>支持SQL指纹、压缩和美化</li><li>支持同一张表多条ALTER请求合并</li><li>支持自定义规则的SQL改写</li></ul><h2 id="SQLAdvisor"><a href="#SQLAdvisor" class="headerlink" title="SQLAdvisor"></a>SQLAdvisor</h2><p>SQLAdvisor是由美团点评公司技术工程部DBA团队（北京）开发维护的一个分析SQL给出索引优化建议的工具。它基于MySQL原生态词法解析，结合分析SQL中的where条件、聚合条件、多表Join关系 给出索引优化建议。</p><p>目前SQLAdvisor在美团点评内部广泛应用，公司内部对SQLAdvisor的开发全面转到github上，开源和内部使用保持一致。</p><p>主要功能：输出SQL索引优化建议</p><h1 id="离线部署"><a href="#离线部署" class="headerlink" title="离线部署"></a>离线部署</h1><p>部署过于复杂，而且部分组件网上很难下载(要么找不到官方安装包，要么在国外下载极慢)</p><p>所以本次部署采用离线方式，首先下载百度云上所有安装包</p><p>链接：<a href="https://pan.baidu.com/s/1126UeNZOVjrdVvOnrWO-uQ" target="_blank" rel="noopener">https://pan.baidu.com/s/1126UeNZOVjrdVvOnrWO-uQ</a> </p><p>提取码：1997 </p><p>复制这段内容后打开百度网盘手机App，操作更方便哦</p><h2 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h2><p>操作系统支持(没列举并不代表不能安装,可以自行尝试)</p><ul><li>CentOS 6+</li><li>CentOS 7+</li></ul><p>安装包</p><ul><li>bison-2.5.1.tar.gz</li><li>inception-master.zip</li><li>percona-toolkit-3.1.0_i386.tar.gz</li><li>percona-release-0.1-3.noarch.rpm</li><li>Python-3.6.6.tgz</li><li>redis-4.0.6.tar.gz</li><li>see-master.zip</li><li>SQLAdvisor-master.zip</li><li>mysql-5.7.28-linux-glibc2.12-x86_64.tar.gz</li></ul><p>安装路径</p><ul><li>/opt/see/</li></ul><h2 id="安装Mysql"><a href="#安装Mysql" class="headerlink" title="安装Mysql"></a>安装Mysql</h2><p>安装包：</p><p>mysql-5.7.28-linux-glibc2.12-x86_64.tar.gz</p><p>安装过程参考<br><a href="https://rugod.cn/2020/05/01/mysql/mysql-install/" target="_blank" rel="noopener">离线安装Mysql5.7.28及调优</a></p><p>Mysql配置文件内容需包含以下配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">server-id &#x3D; 100  # 不限制具体数值</span><br><span class="line">log_bin &#x3D; mysql-bin</span><br><span class="line">binlog_format &#x3D; row  # 或 MIXED</span><br></pre></td></tr></table></figure><h2 id="安装pt-online-schema-change"><a href="#安装pt-online-schema-change" class="headerlink" title="安装pt-online-schema-change"></a>安装pt-online-schema-change</h2><p>安装包：</p><p>percona-toolkit-3.1.0_i386.tar.gz</p><p>bison-2.5.1.tar.gz</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">yum install -y perl-DBI perl-DBD-mysql perl-Time-HiRes perl-ExtUtils-MakeMaker</span><br><span class="line"></span><br><span class="line">cd &#x2F;opt&#x2F;see&#x2F;</span><br><span class="line">tar -zxvf percona-toolkit-3.1.0_i386.tar.gz</span><br><span class="line">cd percona-toolkit-3.0.13</span><br><span class="line">perl Makefile.PL</span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line">ln -s &#x2F;usr&#x2F;local&#x2F;bin&#x2F;pt-online-schema-change &#x2F;usr&#x2F;bin&#x2F;</span><br></pre></td></tr></table></figure><h2 id="Inception-1"><a href="#Inception-1" class="headerlink" title="Inception"></a>Inception</h2><p>安装包：</p><p>inception-master.zip </p><p>bison-2.5.1.tar.gz</p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">yum -y install cmake libncurses5-dev libssl-dev g++ bison gcc gcc-c++ openssl-devel ncurses-devel mysql MySQL-python</span><br><span class="line"></span><br><span class="line">cd &#x2F;opt&#x2F;see&#x2F;</span><br><span class="line">tar -zxvf bison-2.5.1.tar.gz</span><br><span class="line">cd bison-2.5.1</span><br><span class="line">.&#x2F;configure</span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line"></span><br><span class="line">cd &#x2F;usr&#x2F;local&#x2F;</span><br><span class="line">unzip inception-master.zip</span><br><span class="line">cd inception-master&#x2F;</span><br><span class="line">sh inception_build.sh builddir linux</span><br></pre></td></tr></table></figure><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>创建文件 /etc/inc.cnf ,内容如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[inception]</span><br><span class="line">general_log&#x3D;1</span><br><span class="line">general_log_file&#x3D;inc.log</span><br><span class="line">port&#x3D;6669</span><br><span class="line">socket&#x3D;&#x2F;tmp&#x2F;inc.socket </span><br><span class="line">character-set-client-handshake&#x3D;0 </span><br><span class="line">character-set-server&#x3D;utf8 </span><br><span class="line">inception_remote_system_password&#x3D;123456 </span><br><span class="line">inception_remote_system_user&#x3D;root </span><br><span class="line">inception_remote_backup_port&#x3D;3306 </span><br><span class="line">inception_remote_backup_host&#x3D;127.0.0.1 </span><br><span class="line">inception_support_charset&#x3D;utf8 </span><br><span class="line">inception_enable_nullable&#x3D;0 </span><br><span class="line">inception_check_primary_key&#x3D;1 </span><br><span class="line">inception_check_column_comment&#x3D;1 </span><br><span class="line">inception_check_table_comment&#x3D;1 </span><br><span class="line">inception_osc_min_table_size&#x3D;1 </span><br><span class="line">inception_osc_bin_dir&#x3D;&#x2F;usr&#x2F;bin </span><br><span class="line">inception_osc_chunk_time&#x3D;0.1 </span><br><span class="line">inception_ddl_support&#x3D;1</span><br><span class="line">inception_enable_blob_type&#x3D;1 </span><br><span class="line">inception_check_column_default_value&#x3D;1</span><br></pre></td></tr></table></figure><p>注意！如果你需要对其他数据库创建utf8mb4或其他字符集的库或表，需要在inception_support_charset 增加响应字符集，以,隔开，例如：</p><p>inception_support_charset=utf8,utf8mb4</p><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><p>nohup /usr/local/inception-master/builddir/mysql/bin/Inception –defaults-file=/etc/inc.cnf &amp;</p><h2 id="Sqladvisor"><a href="#Sqladvisor" class="headerlink" title="Sqladvisor"></a>Sqladvisor</h2><p>安装包</p><p>SQLAdvisor-master.zip </p><p>percona-release-0.1-3.noarch.rpm</p><h3 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;usr&#x2F;local&#x2F;src&#x2F;</span><br><span class="line">unzip inception-master.zip</span><br><span class="line">yum install -y cmake libaio-devel libffi-devel glib2 glib2-devel bison</span><br><span class="line"># 移除mysql-community库(无用途且和Percona-Server有冲突)</span><br><span class="line">yum remove -y mysql-community-client mysql-community-server mysql-community-common mysql-community-libs</span><br><span class="line">cd &#x2F;usr&#x2F;lib64&#x2F; </span><br><span class="line">ln -s libperconaserverclient_r.so.18 libperconaserverclient_r.so </span><br><span class="line">rpm -ivh &#x2F;opt&#x2F;see&#x2F;percona-release-0.1-3.noarch.rpm</span><br><span class="line">yum install -y Percona-Server-shared-56</span><br><span class="line">cd &#x2F;usr&#x2F;local&#x2F;src&#x2F;SQLAdvisor&#x2F;</span><br><span class="line">cmake -DBUILD_CONFIG&#x3D;mysql_release -DCMAKE_BUILD_TYPE&#x3D;debug -DCMAKE_INSTALL_PREFIX&#x3D;&#x2F;usr&#x2F;local&#x2F;sqlparser .&#x2F;</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><h3 id="编译sqladvisor-源码目录"><a href="#编译sqladvisor-源码目录" class="headerlink" title="编译sqladvisor(源码目录)"></a>编译sqladvisor(源码目录)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd .&#x2F;sqladvisor&#x2F;</span><br><span class="line">cmake -DCMAKE_BUILD_TYPE&#x3D;debug .&#x2F;</span><br><span class="line">make</span><br></pre></td></tr></table></figure><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp &#x2F;usr&#x2F;local&#x2F;src&#x2F;SQLAdvisor&#x2F;sqladvisor&#x2F;sqladvisor &#x2F;usr&#x2F;bin&#x2F;sqladvisor</span><br><span class="line">sqladvisor -h 127.0.0.1  -P 3306  -u root -p &#39;123456&#39; -d test -q &quot;sql语句&quot; -v 1</span><br></pre></td></tr></table></figure><h2 id="Redis"><a href="#Redis" class="headerlink" title="Redis"></a>Redis</h2><p>安装包 </p><p>redis-4.0.6.tar.gz</p><h3 id="安装-2"><a href="#安装-2" class="headerlink" title="安装"></a>安装</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">yum install -y gcc</span><br><span class="line">cd &#x2F;opt&#x2F;see&#x2F;</span><br><span class="line">tar -zxvf redis-4.0.6.tar.gz</span><br><span class="line">cd redis-4.0.6</span><br><span class="line">make MALLOC&#x3D;libc　　</span><br><span class="line">cd src &amp;&amp; make install</span><br><span class="line">.&#x2F;redis-server &#x2F;opt&#x2F;see&#x2F;redis-4.0.6&#x2F;redis.conf</span><br></pre></td></tr></table></figure><h3 id="配置-opt-see-redis-4-0-6-redis-conf"><a href="#配置-opt-see-redis-4-0-6-redis-conf" class="headerlink" title="配置 /opt/see/redis-4.0.6/redis.conf"></a>配置 /opt/see/redis-4.0.6/redis.conf</h3><p>daemonize yes<br>bind 0.0.0.0</p><h2 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h2><p>yum install  -y  epel-release nginx</p><p>修改Nginx配置文件 nginx.conf, 使server部分的内容如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">server</span><br><span class="line">  &#123;</span><br><span class="line">    listen 81;  # 用户访问端口</span><br><span class="line">    access_log    &#x2F;var&#x2F;log&#x2F;access.log;</span><br><span class="line">    error_log    &#x2F;var&#x2F;log&#x2F;error.log;</span><br><span class="line"></span><br><span class="line">    location &#x2F; &#123; </span><br><span class="line">        root &#x2F;usr&#x2F;local&#x2F;seevenv&#x2F;see-master&#x2F;frontend&#x2F;dist&#x2F;;  # 前端项目文件</span><br><span class="line">        try_files $uri $uri&#x2F; &#x2F;index.html &#x3D;404; </span><br><span class="line">        index  index.html; </span><br><span class="line">    &#125; </span><br><span class="line"></span><br><span class="line">    location &#x2F;static&#x2F;rest_framework_swagger &#123;  #  前端API静态文件</span><br><span class="line">        root &#x2F;usr&#x2F;local&#x2F;seevenv&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;rest_framework_swagger&#x2F;; </span><br><span class="line">    &#125; </span><br><span class="line"></span><br><span class="line">    location &#x2F;static&#x2F;rest_framework &#123;  #  前端rest_framework静态文件</span><br><span class="line">        root &#x2F;usr&#x2F;local&#x2F;seevenv&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;rest_framework&#x2F;;</span><br><span class="line">    &#125; </span><br><span class="line"></span><br><span class="line">    location &#x2F;api &#123;</span><br><span class="line">        proxy_pass http:&#x2F;&#x2F;127.0.0.1:8090;  # 后端端口此处一定得是127.0.0.1</span><br><span class="line">        add_header Access-Control-Allow-Origin *; </span><br><span class="line">        add_header Access-Control-Allow-Headers Content-Type;</span><br><span class="line">        add_header Access-Control-Allow-Headers &quot;Origin, X-Requested-With, Content-Type, Accept&quot;;</span><br><span class="line">        add_header Access-Control-Allow-Methods &quot;GET, POST, OPTIONS, PUT, DELETE, PATCH&quot;;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h2 id="See"><a href="#See" class="headerlink" title="See"></a>See</h2><p>终于到了see平台本身了</p><h3 id="安装依赖"><a href="#安装依赖" class="headerlink" title="安装依赖"></a>安装依赖</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y readline readline-devel gcc gcc-c++ zlib zlib-devel openssl openssl-devel sqlite-devel python-devel openldap-clients openldap-devel openssl-devel</span><br></pre></td></tr></table></figure><h3 id="安装python3-6-6"><a href="#安装python3-6-6" class="headerlink" title="安装python3.6.6"></a>安装python3.6.6</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;opt&#x2F;see&#x2F;</span><br><span class="line">tar -xzf Python-3.6.6.tgz </span><br><span class="line">cd Python-3.6.6</span><br><span class="line">.&#x2F;configure --prefix&#x3D;&#x2F;usr&#x2F;local&#x2F;python3.6 --enable-shared</span><br><span class="line">make &amp;&amp; make install</span><br><span class="line">ln -s &#x2F;usr&#x2F;local&#x2F;python3.6&#x2F;bin&#x2F;python3.6 &#x2F;usr&#x2F;bin&#x2F;python3</span><br><span class="line">ln -s &#x2F;usr&#x2F;local&#x2F;python3.6&#x2F;bin&#x2F;pip3 &#x2F;usr&#x2F;bin&#x2F;pip3</span><br><span class="line">ln -s &#x2F;usr&#x2F;local&#x2F;python3.6&#x2F;bin&#x2F;pyvenv &#x2F;usr&#x2F;bin&#x2F;pyvenv</span><br><span class="line"></span><br><span class="line"># 链接库文件</span><br><span class="line">cp &#x2F;usr&#x2F;local&#x2F;python3.6&#x2F;lib&#x2F;libpython3.6m.so.1.0 &#x2F;usr&#x2F;local&#x2F;lib</span><br><span class="line">cd &#x2F;usr&#x2F;local&#x2F;lib</span><br><span class="line">ln -s libpython3.6m.so.1.0 libpython3.6m.so</span><br><span class="line">echo &#39;&#x2F;usr&#x2F;local&#x2F;lib&#39; &gt;&gt; &#x2F;etc&#x2F;ld.so.conf</span><br><span class="line">&#x2F;sbin&#x2F;ldconfig</span><br></pre></td></tr></table></figure><h3 id="安装Django及See后端"><a href="#安装Django及See后端" class="headerlink" title="安装Django及See后端"></a>安装Django及See后端</h3><p>安装包</p><p>see-master.zip</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;usr&#x2F;local&#x2F;</span><br><span class="line">&#x2F;usr&#x2F;local&#x2F;python3.6&#x2F;bin&#x2F;pyvenv seevenv</span><br><span class="line">cd seevenv</span><br><span class="line">source bin&#x2F;activate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">unzip master.zip</span><br><span class="line">cd see-master&#x2F;backend&#x2F;</span><br><span class="line">pip install -r requirements.txt --trusted-host mirrors.aliyun.com -i https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;pypi&#x2F;simple&#x2F;</span><br></pre></td></tr></table></figure><h3 id="创建数据库"><a href="#创建数据库" class="headerlink" title="创建数据库"></a>创建数据库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">确保mysql的root密码为 123456</span><br><span class="line">mysql -uroot -p123456 -e &quot;create database sqlweb CHARACTER SET utf8;&quot;</span><br><span class="line">python manage.py makemigrations</span><br><span class="line">python manage.py migrate</span><br><span class="line"># 再执行一次migrate</span><br><span class="line">python manage.py migrate</span><br></pre></td></tr></table></figure><h3 id="创建管理员用户-可用于页面的用户登录"><a href="#创建管理员用户-可用于页面的用户登录" class="headerlink" title="创建管理员用户 (可用于页面的用户登录)"></a>创建管理员用户 (可用于页面的用户登录)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python manage.py createsuperuser --username admin --email admin@domain.com</span><br></pre></td></tr></table></figure><h3 id="安装SOAR"><a href="#安装SOAR" class="headerlink" title="安装SOAR"></a>安装SOAR</h3><p>mkdir -p /usr/local/SOAR/bin/<br>cp /usr/local/seevenv/see-master/frontend/src/files/soar /usr/local/SOAR/bin<br>chmod +x /usr/local/SOAR/bin/soar</p><h2 id="设置（非必需操作）"><a href="#设置（非必需操作）" class="headerlink" title="设置（非必需操作）"></a>设置（非必需操作）</h2><p>打开文件 /usr/local/seevenv/see-master/backend/sqlweb/settings.py,找到以下设置并修改</p><h3 id="MySQL"><a href="#MySQL" class="headerlink" title="MySQL"></a>MySQL</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">DATABASES &#x3D; &#123;</span><br><span class="line">&#39;default&#39;: &#123;</span><br><span class="line">        &#39;ENGINE&#39;: &#39;django.db.backends.mysql&#39;,</span><br><span class="line">        &#39;NAME&#39;: &#39;sqlweb&#39;,</span><br><span class="line">        &#39;USER&#39;: &#39;root&#39;,</span><br><span class="line">        &#39;PASSWORD&#39;: &#39;123456&#39;,</span><br><span class="line">        &#39;HOST&#39;:&#39;127.0.0.1&#39;,</span><br><span class="line">        &#39;PORT&#39;:&#39;3306&#39;,</span><br><span class="line">        &#39;OPTIONS&#39;: &#123;&#39;charset&#39;:&#39;utf8mb4&#39;&#125;,</span><br><span class="line">&#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Redis-1"><a href="#Redis-1" class="headerlink" title="Redis"></a>Redis</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">REDIS_HOST &#x3D; &#39;127.0.0.1&#39;  # redis地址</span><br><span class="line">REDIS_PORT &#x3D; 6379  # redis端口</span><br><span class="line">REDIS_PASSWORD &#x3D; &#39;&#39;  # redis密码</span><br></pre></td></tr></table></figure><h3 id="Inception配置文件"><a href="#Inception配置文件" class="headerlink" title="Inception配置文件"></a>Inception配置文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">INCEPTION_SETTINGS &#x3D; &#123;</span><br><span class="line">    &#39;file_path&#39;: &#39;&#x2F;etc&#x2F;inc.cnf&#39;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="SQLAdvisor和SOAR的路径"><a href="#SQLAdvisor和SOAR的路径" class="headerlink" title="SQLAdvisor和SOAR的路径"></a>SQLAdvisor和SOAR的路径</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">OPTIMIZE_SETTINGS &#x3D; &#123;</span><br><span class="line">    &#39;sqladvisor_cli&#39;: &#39;&#x2F;usr&#x2F;bin&#x2F;sqladvisor&#39;,</span><br><span class="line">    &#39;soar_cli&#39;: &#39;&#x2F;usr&#x2F;local&#x2F;SOAR&#x2F;bin&#x2F;soar&#39;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="邮件"><a href="#邮件" class="headerlink" title="邮件"></a>邮件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">MAIL &#x3D; &#123;</span><br><span class="line">    &#39;smtp_host&#39;: &#39;smtp.163.com&#39;,  # 邮件服务器</span><br><span class="line">    &#39;smtp_port&#39;: 25,  # SMTP协议默认端口是25</span><br><span class="line">    &#39;mail_user&#39;: &#39;sql_see@163.com&#39;,  # 邮件用户名</span><br><span class="line">    &#39;mail_pass&#39;: &#39;see123&#39;,  # 授权码</span><br><span class="line">    &#39;see_addr&#39;: &#39;http:&#x2F;&#x2F;xxx.xxx.xxx.xxx:81&#39;,  # see项目访问地址</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="启动所有服务"><a href="#启动所有服务" class="headerlink" title="启动所有服务"></a>启动所有服务</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># mysql  3306端口</span><br><span class="line">&#x2F;etc&#x2F;init.d&#x2F;mysqld start</span><br><span class="line"></span><br><span class="line"># inception  6669端口</span><br><span class="line">nohup &#x2F;usr&#x2F;local&#x2F;inception-master&#x2F;builddir&#x2F;mysql&#x2F;bin&#x2F;Inception --defaults-file&#x3D;&#x2F;etc&#x2F;inc.cnf &amp;</span><br><span class="line"></span><br><span class="line"># redis  6379端口</span><br><span class="line">redis-server &#x2F;etc&#x2F;redis.conf</span><br><span class="line"></span><br><span class="line"># nginx  81端口</span><br><span class="line">&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;sbin&#x2F;nginx</span><br><span class="line"></span><br><span class="line"># see  8090端口</span><br><span class="line">source &#x2F;usr&#x2F;local&#x2F;seevenv&#x2F;bin&#x2F;activate</span><br><span class="line">cd &#x2F;usr&#x2F;local&#x2F;seevenv&#x2F;see-master&#x2F;backend</span><br><span class="line">nohup python manage.py celery worker -c 10 -B --loglevel&#x3D;info &amp;</span><br><span class="line">gunicorn -c sqlweb&#x2F;gunicorn_config.py sqlweb.wsgi</span><br></pre></td></tr></table></figure><p>启动都OK！可以使用啦：</p><p><a href="http://xxx.xxx.xxx.xxx:81/" target="_blank" rel="noopener">http://xxx.xxx.xxx.xxx:81/</a> # see 项目</p><p><a href="http://xxx.xxx.xxx.xxx:81/api/docs/" target="_blank" rel="noopener">http://xxx.xxx.xxx.xxx:81/api/docs/</a> # see api 文档</p><p>推荐用Chrome浏览器访问</p><h2 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h2><h3 id="yum-install-y-Percona-Server-shared-56-失败"><a href="#yum-install-y-Percona-Server-shared-56-失败" class="headerlink" title="yum install -y Percona-Server-shared-56 失败"></a>yum install -y Percona-Server-shared-56 失败</h3><p>yum 安装Percona MySQL时，提示错误：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">The GPG keys listed for the &quot;Percona-Release YUM repository - x86_64&quot; repository are already installed but they are not correct for this package.</span><br><span class="line">Check that the correct key URLs are configured for this repository.</span><br><span class="line"> Failing package is: Percona-Server-client-56-5.6.43-rel84.3.el7.x86_64</span><br><span class="line"> GPG Keys are configured as: file:&#x2F;&#x2F;&#x2F;etc&#x2F;pki&#x2F;rpm-gpg&#x2F;RPM-GPG-KEY-Percona</span><br></pre></td></tr></table></figure><p>解决方法：yum update percona-release</p><h3 id="重启see平台"><a href="#重启see平台" class="headerlink" title="重启see平台"></a>重启see平台</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ps aux|grep python|grep -v grep|cut -c 9-15|xargs kill -15</span><br><span class="line">nohup python manage.py celery worker -c 10 -B --loglevel&#x3D;info &amp;</span><br><span class="line">gunicorn -c sqlweb&#x2F;gunicorn_config.py sqlweb.wsgi</span><br></pre></td></tr></table></figure><h3 id="解决python3下pymysql对inception支持的问题"><a href="#解决python3下pymysql对inception支持的问题" class="headerlink" title="解决python3下pymysql对inception支持的问题"></a>解决python3下pymysql对inception支持的问题</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">ValueError: invalid literal for int() with base 10: &#39;Inception2&#39;</span><br><span class="line"># 查找pymysql源码修改connections.py文件，&#x2F;usr&#x2F;local&#x2F;seevenv&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;pymysql&#x2F;connections.py</span><br><span class="line"></span><br><span class="line">    # 找到此处</span><br><span class="line">    def _request_authentication(self):</span><br><span class="line">        # https:&#x2F;&#x2F;dev.mysql.com&#x2F;doc&#x2F;internals&#x2F;en&#x2F;connection-phase-packets.html#packet-Protocol::HandshakeResponse</span><br><span class="line">        if int(self.server_version.split(&#39;.&#39;, 1)[0]) &gt;&#x3D; 5:</span><br><span class="line">            self.client_flag |&#x3D; CLIENT.MULTI_RESULTS</span><br><span class="line"></span><br><span class="line">    # 修改为</span><br><span class="line">    def _request_authentication(self):</span><br><span class="line">        # https:&#x2F;&#x2F;dev.mysql.com&#x2F;doc&#x2F;internals&#x2F;en&#x2F;connection-phase-packets.html#packet-Protocol::HandshakeResponse</span><br><span class="line">        if self.server_version.split(&#39;.&#39;, 1)[0] &#x3D;&#x3D; &#39;Inception2&#39;:</span><br><span class="line">            self.client_flag |&#x3D; CLIENT.MULTI_RESULTS</span><br><span class="line">        elif int(self.server_version.split(&#39;.&#39;, 1)[0]) &gt;&#x3D; 5:</span><br><span class="line">            self.client_flag |&#x3D; CLIENT.MULTI_RESULTS</span><br></pre></td></tr></table></figure><h3 id="解决-Inception"><a href="#解决-Inception" class="headerlink" title="解决 Inception"></a>解决 Inception</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">始终反馈”Must start as begin statement”的语法错误</span><br><span class="line"># 查找pymysql源码修改cursors.py文件，&#x2F;usr&#x2F;local&#x2F;seevenv&#x2F;lib&#x2F;python3.6&#x2F;site-packages&#x2F;pymysql&#x2F;cursors.py</span><br><span class="line"></span><br><span class="line">    # 找到此处</span><br><span class="line">    if not self._defer_warnings:</span><br><span class="line">        self._show_warnings()    </span><br><span class="line"></span><br><span class="line">    # 修改为</span><br><span class="line">    if not self._defer_warnings:</span><br><span class="line">        pass</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>安装还是比较麻烦的，安装完成后基本上就可以省心很多了，当然你还得给开发测试人员开通账号，然后把一些公共的账号回收(这并不简单)，一劳永逸的事哪有那么多呢，不过趁机学习了一波还是挺值的。</p><p>see平台不仅是托管审计的功能，sql优化是它的亮点，你可以通过Sqladvisor和SOAR来优化sql，减轻DBA压力(但是好像也没人会记得用这个，就自信呗，就秀)。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://github.com/myide/see/blob/master/frontend/src/files/install.md" target="_blank" rel="noopener">See项目搭建</a></p><p><a href="https://github.com/XiaoMi/soar" target="_blank" rel="noopener">SOAR </a> </p><p><a href="https://github.com/Meituan-Dianping/SQLAdvisor" target="_blank" rel="noopener">SQLAdvisor</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
            <tag> 审计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>个人总结(毕业一年)</title>
      <link href="2020/07/01/summary/summary-2019.7-2020.7/"/>
      <url>2020/07/01/summary/summary-2019.7-2020.7/</url>
      
        <content type="html"><![CDATA[<p>今天是2020年7月1日，距离我大学毕业过去了一年，是时候回顾一下每个月的成长经历、总结及展望。</p><h1 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h1><h2 id="2019-7"><a href="#2019-7" class="headerlink" title="2019.7"></a>2019.7</h2><p>经历了公司岗前拓展培训及几天的业务培训后，我开始上岗——桌面运维。熟悉日常办公设施及认识更多地人(和公司所有人都打交道了一遍)</p><h2 id="2019-8"><a href="#2019-8" class="headerlink" title="2019.8"></a>2019.8</h2><p>我学完第一本书运维实战宝典，开始系统学习Linux——鸟哥私房菜</p><p>动手实操各种应用运维的技术，将公司主流技术都了解过一遍并且全部部署完成一次。</p><h2 id="2019-9"><a href="#2019-9" class="headerlink" title="2019.9"></a>2019.9</h2><p>公司大牛带我开始上手公司老项目生产环境的更新、维护工作。</p><p>主要方面在于实际的项目应用、调优、高可用、容器化的架构上，多参与进开发项目里。</p><h2 id="2019-10"><a href="#2019-10" class="headerlink" title="2019.10"></a>2019.10</h2><p>更加熟悉已经交付给我的4个大型项目运维工作流程，在独立承接原有的项目上线工作之外还要能承接新的项目上线工作，并且对公司未来开发、测试的环境构建参与方案设计。</p><h2 id="2019-11"><a href="#2019-11" class="headerlink" title="2019.11"></a>2019.11</h2><p>公司大牛带我部署新项目线下环境部署及参与运维分析方案规划</p><p>配置大数据服务器、部署及配置项目中间件、第一次独立迁移旧业务数据到服务器里(血泪史)</p><p>参与生产环境阿里云服务器规划，部署阿里云服务器中间件及K8S，测试稳定性、监控报警、巡检、备份</p><p>打通CI/CD部署上线流水线</p><p>通宵加班3次，新项目从头一天下午4点部署到第二天早上9点(芜湖~)</p><h2 id="2019-12"><a href="#2019-12" class="headerlink" title="2019.12"></a>2019.12</h2><p>新项目上线不是很顺利，问题较多，经常加班更新，整个人疲倦了许多，开始混了</p><h2 id="2020-1"><a href="#2020-1" class="headerlink" title="2020.1"></a>2020.1</h2><p>把线下环境规范起来，做好线下数据备份、权限隔离(公司有狠人直接进服务器rm -rf /* 这是我没想到的)</p><h2 id="2020-2-2020-4"><a href="#2020-2-2020-4" class="headerlink" title="2020.2-2020.4"></a>2020.2-2020.4</h2><p>远程办公，效率较低，没学到太多的东西，在家休息了3个月。</p><h2 id="2020-5"><a href="#2020-5" class="headerlink" title="2020.5"></a>2020.5</h2><p>5月是很关键的一个月，许多大牛对我的指点让我对未来充满了期待，一个月让人改变的东西太多了，努力，沉稳，思考，格局，最重要的是知道自己究竟想做什么了，并且有为之奋斗的理由和坚持到底的决心。</p><h2 id="2020-6"><a href="#2020-6" class="headerlink" title="2020.6"></a>2020.6</h2><p>技术的沉淀的第一个月，与大牛之间的交谈、分享，让我收获了不少知识，独立承担新的项目的从0-1的部署过程，制作一个让自己满意度较高的投产+监控的自动化脚本，设计一条CI/CD的流水线，让自己在独当一面的经验上弥补不足。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h2 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h2><p>运维技术学了不少，在此感谢公司的各个大牛，带我成长，也感谢这一年的自己，没有白白浪费时间，努力学习更多地知识并能灵活应用。</p><h2 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h2><p>很长一段时间，我的思想和刚刚毕业没啥区别，是个莫得感情的工具人，让我做什么就做什么。</p><p>又是一年的54青年节，几位大佬的指点再加上B站的《后浪》，新思想的传播与发展，让我学会了思考，思考自己的处境；学习的方向、方法；未来的规划与发展，彻彻底底的思考了一遍</p><p>我想做什么，我追求的什么，在我心里已经有了一个大概，我从未如此清晰地能看到一个人的未来会是什么样子，仿佛能直抵终章。</p><h2 id="格局"><a href="#格局" class="headerlink" title="格局"></a>格局</h2><p>即使到现在我也不是很清楚互联网的格局是怎样的，自己格局太小，这种东西不是一时半会就能领悟到地，按照形势不断地调整自己的理解才是王道。</p><h1 id="展望"><a href="#展望" class="headerlink" title="展望"></a>展望</h1><p>一个人的展望至关重要，还好我领导及时灌输了我一些思想，不要只顾及眼下，未来是属于我们这代人的，怎么才能成功扛起一个家庭的重任，扛起一个国家的(别了，有心无力)</p><p>我深知这是迟早面对的事实，买房结婚，很多人现在都在逃避这个现实，与其逃避，不如勇敢的接下。这既是不可逃避的事实也事一种责任，曾经一段时间我被这种责任压得喘不过去了，为了承担这个责任我定了一系列目标，有条不紊的朝着目标努力，就像打怪升级一样，让自己更优秀。</p><p>我深知我是一个不甘平凡的人，多少人甘心自己的付出与收获不成正比，多少人甘心自己的价值被人嗤之以鼻，多少人甘心自己平淡地过完一辈子。我不想成为这样的人，舍我其谁，成为团队的MVP是我一直奉行的标准。</p><p>我深知种一棵树最好的时间是十年前，其次是现在。那些过去的，就让它们过去吧，毕竟你已经浪费了好几年的时间痛快的畅玩了，畅玩之后你得付出一些代价，我不后悔，因为那些我想放纵自己的时光我都体验过了，未来我可能不会在浪费时间在玩上了，时刻提醒自己的野心和责任，我没有理由再浪费一分一秒了。</p><p>如果能给周围人带来一点点影响，我希望有幸看到我这篇文章的朋友能够好好思考自己的目标，定一些切实可行的计划，与大佬交流沟通(学习别人的成功经验)，沉淀自己的内心，至少等到自己老的那天不会因此而后悔白过了一生，你为此奋斗过，追求过，成功过，那是一种多么美好的体验。</p><p>共勉</p>]]></content>
      
      
      <categories>
          
          <category> 个人总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 个人总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跟我学Mysql之索引篇</title>
      <link href="2020/06/30/mysql/mysql-index/"/>
      <url>2020/06/30/mysql/mysql-index/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="索引是什么"><a href="#索引是什么" class="headerlink" title="索引是什么"></a>索引是什么</h1><p>索引用于快速查找具有特定列值的行。没有索引，MySQL必须从第一行开始，然后通读整个表以找到相关的行。表越大，花费越多。如果表中有相关列的索引，MySQL可以快速确定要在数据文件中间查找的位置，而不必查看所有数据。这比顺序读取每一行要快得多。</p><p>如果上面的描述还不足够让你理解，我可以先给大家讲一个例子，假如你需要在一本字典里查找一个生僻字（首先你不知道它的发音，你就不会去找字母目录，而是会去找偏旁目录）如果你不找目录，你就必须要把字典全部翻一遍一个一个对比这个字（我的天，有这么麻烦吗）前提是你确实不知道这个字的发音，而且你也不想找偏旁索引，那你只能这样麻烦地做了，然后你找到偏旁所在的页数后，你就会去那一页找到相关的字，最终找到你想查找的生僻字的全部信息。</p><p>数据库索引也是如此，查询一张表的某一行的信息（不是查全表数据）。</p><p>select * from test where a=”1”</p><p>如果你不用索引，那么查询过程是这样的：先获取这张表的所有数据，然后依次遍历，将a=1的行筛选出来，最后返回</p><p>如果你使用索引，那么查询过程是这样的：直接去索引里找到a=1的所有行，返回。</p><p>当然我这么说不太准确，只是为了帮助大家更好的理解索引，因为索引也分几种，具体实现的底层逻辑也不太一样，下面我就讲讲索引的分类。</p><h1 id="索引分类"><a href="#索引分类" class="headerlink" title="索引分类"></a>索引分类</h1><p>由于在Mysql5.7中，InnoDB是默认的MySQL存储引擎。所以下面我讲到的索引都是基于InnoDB下的。</p><h2 id="聚簇索引"><a href="#聚簇索引" class="headerlink" title="聚簇索引"></a>聚簇索引</h2><p>每个InnoDB表都有一个特殊的索引，称为聚簇索引（也叫主键索引、一级索引） ，用于存储行数据。通常，聚簇索引与主键同义，也就是说主键的字段默认给它上了聚簇索引 。使用InnoDB聚簇索引为每个表优化最常见的查找和DML操作。</p><p>官方解释：</p><ul><li>在PRIMARY KEY表上定义a 时，InnoDB将其用作聚簇索引。为创建的每个表定义一个主键。如果没有逻辑唯一且非空的列或列集，请添加一个新的 自动递增列，其值将自动填充。</li><li>如果没有PRIMARY KEY为表定义，MySQL找到所有列都不为空且唯一的第一个UNIQUE索引，InnoDB将其用作聚集索引。</li><li>如果表没有索引PRIMARY KEY或没有合适的 UNIQUE索引，则在InnoDB 内部生成一个隐藏的聚集索引GEN_CLUST_INDEX，该索引在包含行ID值的合成列上命名 。这些行由InnoDB分配给该表中各行的ID排序 。行ID是一个6字节的字段，随着插入新行而单调增加。因此，按行ID排序的行实际上在插入顺序上。</li></ul><p>下面有几点需要注意：</p><ul><li>聚簇索引必须是唯一索引，也就是该字段的值必须唯一且非空。</li><li>如果一个表有主键，那么该主键也作聚簇索引。</li><li>如果一个表无主键，但是有很多索引，那么第一个非空且唯一的索引会被转化成聚簇索引。</li><li>如果一个表无主键（实战基本不可能），且整个表的所有索引都不满足（既不为空，而且唯一），则InnoDB为了保证表的完整性，会给隐藏字段中6字节的DB_ROW_ID上主键和聚簇索引，只不过不能被外部调用。</li></ul><p>在实战中，一般来说主键最好设为自增id，而且尽量避免用业务id作为主键，这样会减少索引的存储空间以及提高搜索效率，具体原因我会我后面进行讲解。</p><h2 id="二级索引"><a href="#二级索引" class="headerlink" title="二级索引"></a>二级索引</h2><p>除聚簇索引之外的所有索引都称为二级索引（也叫辅助索引、非聚簇索引）。在中InnoDB，二级索引中的每个记录都包含该行的主键列以及为辅助索引指定的列。InnoDB使用此主键值在聚簇索引中搜索行。</p><p>也就是说如果你需要通过一个二级索引去查找一行的值，那么你得先通过二级索引去找到二级索引所存储的聚簇索引的值，然后再通过聚簇索引去找到该行的值，这个过程叫做回表。</p><p>如果主键较长，则辅助索引将使用更多空间，因此具有短的主键是有利的。这也是上文说的主键最好设为自增id，且与业务无关。</p><h2 id="联合索引"><a href="#联合索引" class="headerlink" title="联合索引"></a>联合索引</h2><p>由于二级索引的回表操作会再次查询聚簇索引的值，这是一件比较耗时的操作，如果你需要高频率地查找某些字段，这时候就可以用联合索引（覆盖索引），将你基于查询的字段和最终想查询到的字段组合一起。一个联合索引最多可以包含16列，可以被认为是排序数组，其行包含通过串联索引列的值而创建的值。</p><p>比如一张用户信息表的结构如下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE &#96;user&#96; (</span><br><span class="line">  &#96;id&#96; int(11) NOT NULL,</span><br><span class="line">  &#96;id_card&#96; varchar(32) DEFAULT NULL,</span><br><span class="line">  &#96;name&#96; varchar(32) DEFAULT NULL,</span><br><span class="line">  &#96;age&#96; int(11) DEFAULT NULL,</span><br><span class="line">  &#96;ismale&#96; tinyint(1) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (&#96;id&#96;),</span><br><span class="line">  KEY &#96;id_card&#96; (&#96;id_card&#96;),</span><br><span class="line">  KEY &#96;name_age&#96; (&#96;name&#96;,&#96;age&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB</span><br></pre></td></tr></table></figure><p>id是主键，idcard是唯一信息，但是长度是varchar类型且长度很大不适合做聚簇索引，所以设为二级索引，这个时候你可以通过idcard去查询每个用户的所有信息。</p><p>此时你有需要通过名字去查年龄的需求，这个时候可以把名字和年龄上一个联合索引，名字在前，年龄在后（顺序很重要，后面在讲索引的结构会讲到为什么要这样排序）。你每次通过年龄索引查询的值为主键id和age，这个时候可以直接取到age的值，这样就不用重新通过主键id再去查询age一次了（回表操作）。</p><p>但是联合索引是比较占资源，如果你不需要高频请求，建议不要随便使用联合索引，索引的维护总是有代价的。</p><h2 id="索引前缀"><a href="#索引前缀" class="headerlink" title="索引前缀"></a>索引前缀</h2><p>使用字符串列的索引规范中的语法，您可以创建仅使用列首字符的索引 。以这种方式仅索引列值的前缀可以使索引文件小得多。</p><p>例如给一个字符串的字段上索引，一般定义这个字段的前N位字符串来建立索引。<br>CREATE TABLE test (blob_col BLOB, INDEX(blob_col(10)));</p><p>前缀最长可以为1000个字节（InnoDB表中为767个字节 ，除非已 innodb_large_prefix设置）。</p><p>如果搜索词超过索引前缀长度，则使用索引排除不匹配的行，然后检查其余行是否可能匹配。</p><p>例如在刚刚的那张表，执行<br>select * from test where blob_col=’abcdefghijklmn’</p><p>索引会去匹配字段前10位为’abcdefghij’的所有行，然后依次比较剩下的匹配’klmn’的值，返回。</p><h1 id="索引的数据结构"><a href="#索引的数据结构" class="headerlink" title="索引的数据结构"></a>索引的数据结构</h1><p>索引的数据结构是怎么都逃不走的一块，我比较难理解，所以也不在讲索引分类的时候讲了。</p><h2 id="常见的几种索引数据结构"><a href="#常见的几种索引数据结构" class="headerlink" title="常见的几种索引数据结构"></a>常见的几种索引数据结构</h2><p>我先介绍常见的几种索引的数据结构</p><ul><li>key-value：这种数据结构应该比较常见，键值对也叫哈希表，实现也比较简单，用一个哈希函数把key换算成一个确定的value，然后把value放在数组这个位置，对于可能出现不同的key换算成了一个相同的value这种情况，可以在value处加上一个链表，保存相同value值的key信息。如果没有出现这种情况（不同的key换算成了相同的value），查询、插入速度是很快的。但是一旦出现上述情况，哈希索引在做链表区间查询是很慢的，因为你通过键值对查询后需要遍历后面链表的所有用户。</li></ul><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Mysql/index/hash.png"  alt="hash.png"></p><ul><li>有序数组： 假设索引没有重复，那么数组会按着这个索引字段的值递增顺序保存。如果你需要查询某个字段的值，通过二分法可以快速找到，时间复杂度为O(log(N)。<br>只看查询速度，有序数组是接近完美的，但是更新数据的时候比较麻烦，如果你在中间插入一条数据需要将后面所有数据的下标往后挪一位，这个成本是很高的。</li></ul><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Mysql/index/list.png"  alt="list.png"></p><ul><li>二叉树：二叉树的规则是，每个节点的左儿子小于父节点，父节点又小于右儿子，这种数据结构的查询时间复杂度是O(log(N))，并且为了维持O(log(N))的查询速度，你还得保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是O(log(N))。单看查询和插入二叉树接近完美了，但是二叉树有一个坏处，就是占空间，因为索引不只是存在内存，还要写到磁盘上。假如你存储100w条数据，那么用平衡二叉树的话，树高就是20。一次查询你最多需要访问20个数据块，也就是最多读20次磁盘，为了让一个查询最少地读磁盘，我们就应该使用N叉树，这里的N取决于数据块的大小。这也是大多数数据库的存储选择的基础数据结构N叉树，并在基础上进行改造。</li></ul><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Mysql/index/tree.png"  alt="tree.png"></p><p>总结：</p><p>哈希表结构适合等值查询的场景，比如非关系型数据库</p><p>有序数组适合静态存储的场景，比如你保存某年某个城市所有人口信息，并且不会修改数据了。</p><p>N叉树适合大部分数据库引擎，有着良好的读写性能优点以及适配磁盘的访问模式。</p><h2 id="InnoDB的索引模型"><a href="#InnoDB的索引模型" class="headerlink" title="InnoDB的索引模型"></a>InnoDB的索引模型</h2><p>在InnoDB中，表都是根据主键顺序以索引的形式存放的，InnoDB使用了B+树索引模型，所以数据都是存在B+树的。</p><p>每一个索引都对应一颗B+树,对于B+树这种数据结构,我简单的介绍一下它的特征和优势。参考资料里有详细介绍B+树的链接，有兴趣的可以学下具体是如何实现的。</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Mysql/index/B+tree.png"  alt="B+tree.png"></p><p>B+树的特征：</p><p>1.有k个子树的中间节点包含有k个元素，每个元素不保存数据，只用来索引，所有数据都保存在叶子节点。</p><p>2.所有的叶子结点中包含了全部元素的信息，及指向含这些元素记录的指针，且叶子结点本身依关键字的大小自小而大顺序链接。</p><p>3.所有的中间节点元素都同时存在于子节点，在子节点元素中是最大（或最小）元素。</p><p>B+树的优势：</p><p>1.单一节点存储更多的元素，使得查询的IO次数更少。</p><p>2.所有查询都要查找到叶子节点，查询性能稳定。</p><p>3.所有叶子节点形成有序链表，便于范围查询。</p><p>总结：InnoDB的索引结构始终保持排序，从而可以快速查找精确匹配（等于运算符）和范围（例如，大于，小于和BETWEEN 运算符）</p><h3 id="多个索引模型"><a href="#多个索引模型" class="headerlink" title="多个索引模型"></a>多个索引模型</h3><p>前面我讲过索引的分类，一般实战中最常见的一张表结构都含有聚簇索引（主键）配合一个二级索引组成的，那么通过了解InnoDB的索引模型，我们应该能很清晰的看到二级索引的实现过程了。</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Mysql/index/two_index.jpg"  alt="two_index.jpg"></p><p>如图所示，有这么一个表，ID是聚簇索引（主键），K是二级索引（唯一）。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">select * from table where ID&#x3D;100</span><br><span class="line">mysql会用聚簇索引进行查找，通过B+树迅速查询到ID&#x3D;100的叶子节点，拿到这一行的全部数据，返回。</span><br><span class="line"></span><br><span class="line">select * from table where k&#x3D;1</span><br><span class="line">mysql会用二级索引进行查找，通过B+树迅速查询到k&#x3D;1的叶子节点，拿到当k&#x3D;1时，主键的ID的值&#x3D;100，然后通过ID&#x3D;100再去另外一颗B+树去查询到ID&#x3D;100的叶子节点，拿到这一行的全部数据，返回。</span><br></pre></td></tr></table></figure><p>所以基于聚簇索引查询只需要搜索一棵树，而基于二级索引需要多扫描一棵树。因此我们应该在应用中尽量使用主键查询。不过问题来了，为什么上文我说主键最好使用与业务无关的自增id，如果无关的话，你怎么知道你想查询数据的主键ID是什么呢？因为我们还需要考虑到维护索引的代价。</p><h3 id="索引维护"><a href="#索引维护" class="headerlink" title="索引维护"></a>索引维护</h3><p>B+树为了维护索引的有序性，在插入数据的时候会做必要的维护。比如上图，你要插入主键ID为700的行数据，你只需要在600后面插入一个新数据即可。但是你要是插入的主键ID为400，那么就需要逻辑上移动后面的数据，把这个数据空出来让ID=400的数据插入。</p><p>更麻烦的是如果600是数据页最后一个数据，即该数据页满了，为了插入ID=400 ，你必须重新创建一个新数据页，将ID=600的数据放过去，然后才能将ID=400的数据插入到原数据页。这个过程叫做页分裂，在这种情况，查询就会多扫一张数据页，而且空间利用率会降低百分之50，因为本来只用存放在一页的数据，现在分到2页了。</p><p>不过有分裂页有合并，相邻的两页由于删除了数据，利用率变低后，会将数据页做合并。</p><p>所以回到上一个问题，为什么虽然通过聚簇索引查询很快，但我们仍然使用二级索引查询，因为主键索引如果不是自增的话，很难保证你的插入是有序的，如果你插入不是有序，那么就可能触发页分裂，影响性能和存储空间。所以得使用自增主键，这样的话主键也就是无业务意义的，我们也不能通过一个无意义的字段去做查询吧。</p><h3 id="最左前缀原则"><a href="#最左前缀原则" class="headerlink" title="最左前缀原则"></a>最左前缀原则</h3><p>上文我讲过对于联合索引的创建，顺序很重要，因为联合索引需要遵循最左前缀原则，具体看下面例子。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE test (</span><br><span class="line">    id         INT NOT NULL,</span><br><span class="line">    last_name  CHAR(30) NOT NULL,</span><br><span class="line">    first_name CHAR(30) NOT NULL,</span><br><span class="line">    PRIMARY KEY (id),</span><br><span class="line">    INDEX name (last_name,first_name)</span><br><span class="line">);</span><br></pre></td></tr></table></figure><p>这个表，name为联合索引，它可用于查询指定在已知范围内的last_name和first_name 值组合的值。它也可以用于仅指定last_name值的查询， 因为该列是索引的最左前缀。</p><p>下面的sql是可以通过name索引进行查找的</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM test WHERE last_name&#x3D;&#39;Jones&#39;;</span><br><span class="line"></span><br><span class="line">SELECT * FROM test</span><br><span class="line">  WHERE last_name&#x3D;&#39;Jones&#39; AND first_name&#x3D;&#39;John&#39;;</span><br><span class="line"></span><br><span class="line">SELECT * FROM test</span><br><span class="line">  WHERE last_name&#x3D;&#39;Jones&#39;</span><br><span class="line">  AND (first_name&#x3D;&#39;John&#39; OR first_name&#x3D;&#39;Jon&#39;);</span><br><span class="line"></span><br><span class="line">SELECT * FROM test</span><br><span class="line">  WHERE last_name&#x3D;&#39;Jones&#39;</span><br><span class="line">  AND first_name &gt;&#x3D;&#39;M&#39; AND first_name &lt; &#39;N&#39;;</span><br></pre></td></tr></table></figure><p>但是，在以下查询中不能用name索引进行查找：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM test WHERE first_name&#x3D;&#39;John&#39;;</span><br><span class="line"></span><br><span class="line">SELECT * FROM test</span><br><span class="line">  WHERE last_name&#x3D;&#39;Jones&#39; OR first_name&#x3D;&#39;John&#39;;</span><br></pre></td></tr></table></figure><p>为什么必须通过联合索引的最左字段查询呢？因为索引的实质是B+树，对于非聚簇索引（联合索引属于非聚簇索引）叶子节点存储的是主键的值(如果是联合索引，还会存联合索引的非最左字段)</p><p>结论：如果表具有联合索引，则优化器可以使用索引的任何最左前缀来查找行。举例来说，如果你有一个三列的索引(col1, col2, col3)，你有索引的搜索功能 (col1)，(col1, col2)以及 (col1, col2, col3)。</p><h2 id="检查索引是否被使用"><a href="#检查索引是否被使用" class="headerlink" title="检查索引是否被使用"></a>检查索引是否被使用</h2><p>始终检查所有查询是否真的使用您在表中创建的索引。可以使用 EXPLAIN语句</p><p>EXPLAIN可以为 SELECT， DELETE， INSERT， REPLACE，和 UPDATE语句工作。</p><p>当EXPLAIN与可解释的语句一起使用时，MySQL将显示来自优化器的有关语句执行计划的信息。也就是说，MySQL解释了它将如何处理该语句，包括有关如何连接表以及以何种顺序连接表的信息。</p><p>在EXPLAIN的帮助下，您可以看到应该在表中添加索引的位置，以便通过使用索引查找行来使语句更快地执行。</p><p>具体由EXPLAIN输出字段的详细意义请查看  <a href="https://dev.mysql.com/doc/refman/5.7/en/explain-output.html" target="_blank" rel="noopener">EXPLAIN Output Columns</a></p><h1 id="浅谈索引的构建过程"><a href="#浅谈索引的构建过程" class="headerlink" title="浅谈索引的构建过程"></a>浅谈索引的构建过程</h1><h2 id="排序索引构建"><a href="#排序索引构建" class="headerlink" title="排序索引构建"></a>排序索引构建</h2><p>在创建或重建索引时，InnoDB执行批量加载，而不是一次插入一个索引记录。这种索引创建方法也称为排序索引构建。排序索引构建不支持空间索引(Spatial Indexes)。</p><p>索引构建分为三个阶段</p><ul><li>扫描聚簇索引，并生成索引条目并将其添加到排序缓冲区，当排序缓冲区已满时，将对条目进行排序并将其写到临时中间文件中。此过程也称为”RUN”</li><li>将一个或多个”RUN”写入临时中间文件后，将对文件中的所有条目执行合并排序。</li><li>排序后的条目将插入到B+树中。</li></ul><h2 id="修改数据"><a href="#修改数据" class="headerlink" title="修改数据"></a>修改数据</h2><p>由于InnoDB多版本并发控制（MVCC）的存在，增删改的操作对二级索引的处理方式不同于对聚簇索引的处理方式。如果忘了MVCC请复习一下 <a href="https://rugod.cn/2020/06/08/mysql/mysql-trx/" target="_blank" rel="noopener">跟我学Mysql之事务篇</a></p><ul><li>聚簇索引</li></ul><p>聚簇索引中的记录将就地更新，其隐藏的系统列指向撤消日志条目，可以从中重建记录的早期版本。</p><p>在聚簇索引中，DB_TRX_ID检查记录的记录，如果在启动读取事务后修改了记录，则从撤消日志中检索记录的正确版本。</p><ul><li>二级索引</li></ul><p>二级索引记录不包含隐藏的系统列，也不会就地更新。</p><p>更新二级索引列时，将对旧的二级索引记录进行删除标记，将新记录插入，并最终清除带有删除标记的记录。当二级索引记录被删除标记或二级索引页被较新的事务更新时，InnoDB在聚簇索引中查找数据库记录。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本篇讲解了索引的基本数据结构与分类，和INNODB模型和底层实现基本原理，后期会更加详细的介绍INNODB索引的具体实现过程。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://blog.csdn.net/qq_26222859/article/details/80631121" target="_blank" rel="noopener">B+树图文详解</a></p><p><a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-index-types.html" target="_blank" rel="noopener">INNODB索引-官方文档</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
            <tag> 索引 </tag>
            
            <tag> INNODB </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入浅出Docker原理及实战(四)——构建镜像</title>
      <link href="2020/06/29/docker/docker-idea-4/"/>
      <url>2020/06/29/docker/docker-idea-4/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><p>深入浅出Docker原理及实战系列第四篇，我主要分享制作镜像的两种方法以及如何高效构建镜像的注意点，最后展示一个构建项目级镜像的实践过程</p><h1 id="创建镜像的方式"><a href="#创建镜像的方式" class="headerlink" title="创建镜像的方式"></a>创建镜像的方式</h1><p>创建一个指定的镜像有两种方式</p><ul><li>基于一个现有的镜像来修改  docker commit </li><li>基于Dockerfile来创建      docker build </li></ul><h1 id="基于一个现有的镜像来修改"><a href="#基于一个现有的镜像来修改" class="headerlink" title="基于一个现有的镜像来修改"></a>基于一个现有的镜像来修改</h1><p>命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]</span><br><span class="line"></span><br><span class="line">--author , -a作者（例如“ rugod.cn ”）</span><br><span class="line">--change , -c将Dockerfile创建的镜像进行更新</span><br><span class="line">--message , -m提交讯息</span><br><span class="line">--pause , -ptrue提交期间暂停容器</span><br></pre></td></tr></table></figure><p>你可以理解成快照，不过不是你在容器里所有的操作都会快照上，支持更改命令有 CMD| ENTRYPOINT| ENV| EXPOSE| LABEL| ONBUILD| USER| VOLUME|WORKDIR</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ docker ps</span><br><span class="line"></span><br><span class="line">CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS              PORTS              NAMES</span><br><span class="line">c3f279d17e0a        ubuntu:12.04        &#x2F;bin&#x2F;bash           7 days ago          Up 25 hours                            desperate_dubinsky</span><br><span class="line">197387f1b436        ubuntu:12.04        &#x2F;bin&#x2F;bash           7 days ago          Up 25 hours                            focused_hamilton</span><br><span class="line"></span><br><span class="line">$ docker commit --change&#x3D;&#39;CMD [&quot;apachectl&quot;, &quot;-DFOREGROUND&quot;]&#39; -c &quot;EXPOSE 80&quot; c3f279d17e0a  svendowideit&#x2F;testimage:version4</span><br><span class="line"></span><br><span class="line">f5283438590d</span><br><span class="line"></span><br><span class="line">$ docker run -d svendowideit&#x2F;testimage:version4</span><br><span class="line"></span><br><span class="line">89373736e2e7f00bc149bd783073ac43d0507da250e999f3f1036e0db60817c0</span><br><span class="line"></span><br><span class="line">$ docker ps</span><br><span class="line"></span><br><span class="line">CONTAINER ID        IMAGE               COMMAND                 CREATED             STATUS              PORTS              NAMES</span><br><span class="line">89373736e2e7        testimage:version4  &quot;apachectl -DFOREGROU&quot;  3 seconds ago       Up 2 seconds        80&#x2F;tcp             distracted_fermat</span><br><span class="line">c3f279d17e0a        ubuntu:12.04        &#x2F;bin&#x2F;bash               7 days ago          Up 25 hours                            desperate_dubinsky</span><br><span class="line">197387f1b436        ubuntu:12.04        &#x2F;bin&#x2F;bash               7 days ago          Up 25 hours</span><br></pre></td></tr></table></figure><p>总结：一般来说这种修改的方式镜像都是用于测试构建，不适合生产环境的构建。</p><p>注意！！！提交操作将不包含容器内挂载卷中的任何数据。</p><h1 id="基于Dockerfile来创建"><a href="#基于Dockerfile来创建" class="headerlink" title="基于Dockerfile来创建"></a>基于Dockerfile来创建</h1><p>常规来讲，镜像都是需要有一个dockerfile来构建的，但是我们在制作前需要理解一下底层的构建原理，这很重要</p><h2 id="底层构建原理"><a href="#底层构建原理" class="headerlink" title="底层构建原理"></a>底层构建原理</h2><p>先回顾一下Docker的架构=Docker客户端(CLI)+Docker服务端(docker的守护进程)。</p><p>Docker 客户端通过 REST API 和服务端进行交互，docker 客户端每发送一条指令，底层都会转化成 REST API 调用的形式发送给服务端，服务端处理客户端发送的请求并给出响应。</p><p>Docker 镜像的构建、容器创建、容器运行等工作都是 Docker 服务端来完成的，Docker 客户端只是承担发送指令的角色。</p><p>所以构建一个镜像是由Docker守护程序(Docker的服务端)而不是CLI运行的。构建过程要做的第一件事是将整个上下文（递归）发送到守护程序。在大多数情况下，最好以空目录作为上下文，并将Dockerfile保留在该目录中。仅添加构建Dockerfile所需的文件。</p><p>无论Dockerfile实际位于何处，当前目录中文件和目录的所有递归内容都将作为构建上下文发送到Docker守护程序。</p><p>docker build 构建镜像的流程大概如下：</p><ul><li>执行 docker build -t <a href="imageName:imageTag">imageName:imageTag</a> . ;</li><li>Docker 客户端会将构建命令后面指定的路径(.)下的所有文件打包成一个 tar 包，发送给 Docker 服务端;</li><li>Docker 服务端收到客户端发送的 tar 包，然后解压，根据 Dockerfile 里面的指令进行镜像的分层构建；</li></ul><h2 id="上下文"><a href="#上下文" class="headerlink" title="上下文"></a>上下文</h2><p>这里好好理解一下上下文的意思，官方给出上下文的解释：位于指定位置PATH或URL的文件集。</p><p>context翻译为语境，前后关系</p><p>什么意思呢，Docker 构建上下文就是 Docker 客户端上传给服务端的 tar 文件解压后的内容，也即 docker build 命令行后面指定路径下的文件。</p><p>Docker 镜像的构建是在远程服务端进行的，所以客户端需要把构建所需要的文件传输给服务端。服务端以客户端发送的文件为上下文，也就是说 Dockerfile 中指令的工作目录就是服务端解压客户端传输的 tar 包的路径。</p><p>上下文特别关键，因为在构建的时候构建文件中也是应用的是上下文的相对路径，简单来说<br>COPY 和 ADD 命令不能拷贝上下文之外的本地文件</p><p>比如你的目录结构是这样</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# tree</span><br><span class="line">.</span><br><span class="line">├── test</span><br><span class="line">│   └── Dockerfile</span><br><span class="line">└── test.conf</span><br><span class="line"></span><br><span class="line">你如果在构建的时候在~&#x2F;test&#x2F;目录下执行的docker build . 则Dockerfile里不能copy或add 上一级目录的test.conf</span><br><span class="line"></span><br><span class="line">即使你可以在~&#x2F;目录下执行docker build -f test&#x2F;Dockerfile .</span><br><span class="line">但也不要这么做，保持所有文件在当前docker build 的执行目录下是一件良好也有很必要的习惯。</span><br></pre></td></tr></table></figure><hr><p>注意！！！<br>请勿将root目录或/目录用作PATH，因为它会导致构建将硬盘驱动器的全部内容传输到Docker守护程序。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build [OPTIONS] PATH | URL | -</span><br></pre></td></tr></table></figure><p>docker build命令从Dockerfile和上下文构建镜像。 PATH是本地文件系统上的目录。该URL是一个Git存储库位置。上下文是递归处理的，因此，PATH包括任何子目录，而URL包括存储库及其子模块。</p><h2 id="本地目录"><a href="#本地目录" class="headerlink" title="本地目录"></a>本地目录</h2><p>最简单的一个使用当前目录作为上下文的构建命令：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker build .</span><br><span class="line"></span><br><span class="line">Sending build context to Docker daemon  6.51 MB</span><br></pre></td></tr></table></figure><h2 id="git仓库"><a href="#git仓库" class="headerlink" title="git仓库"></a>git仓库</h2><p>当URL参数指向Git存储库的位置时，该存储库将作为构建上下文。系统以递归方式获取存储库及其子模块。提交历史记录未保留。首先将存储库拉到本地主机上的临时目录中。成功之后，该目录将作为上下文发送到Docker守护程序。本地副本使您能够使用本地用户凭据，VPN等访问私有存储库。</p><p>Git URL在其片段部分接受上下文配置，并用冒号（:）分隔。第一部分代表Git将检出的引用，可以是分支，标签或远程引用。第二部分表示存储库中的子目录，该子目录将用作构建上下文。</p><p>例如，运行以下命令以使用docker分支中 称为的目录container：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker build https:&#x2F;&#x2F;github.com&#x2F;docker&#x2F;rootfs.git#container:docker</span><br></pre></td></tr></table></figure><h2 id="tar包"><a href="#tar包" class="headerlink" title="tar包"></a>tar包</h2><p>如果将URL传递到远程tar包，则URL本身将发送到守护程序：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker build http:&#x2F;&#x2F;server&#x2F;context.tar.gz</span><br></pre></td></tr></table></figure><p>下载操作将在运行Docker守护程序的主机上执行，该主机不一定与发出build命令的主机相同。Docker守护程序将获取context.tar.gz并将其用作构建上下文。Tar包上下文必须是符合标准tar UNIX格式的tar存档，并且可以使用“xz”，“bzip2”，“gzip”或“identity”（无压缩）格式中的任何一种进行压缩。</p><h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>最常用的2个参数</p><p>-t 打tag 将做好的镜像标记存储库名称及版本号</p><p>-f 指定dockerfile的路径</p><p>–no-cache  构建映像时不要使用缓存</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ docker build -f ctx&#x2F;Dockerfile http:&#x2F;&#x2F;server&#x2F;ctx.tar.gz</span><br><span class="line"></span><br><span class="line">Downloading context: http:&#x2F;&#x2F;server&#x2F;ctx.tar.gz [&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&gt;]    240 B&#x2F;240 B</span><br><span class="line">Step 1&#x2F;3 : FROM busybox</span><br><span class="line"> ---&gt; 8c2e06607696</span><br><span class="line">Step 2&#x2F;3 : ADD ctx&#x2F;container.cfg &#x2F;</span><br><span class="line"> ---&gt; e7829950cee3</span><br><span class="line">Removing intermediate container b35224abf821</span><br><span class="line">Step 3&#x2F;3 : CMD &#x2F;bin&#x2F;ls</span><br><span class="line"> ---&gt; Running in fbc63d321d73</span><br><span class="line"> ---&gt; 3286931702ad</span><br><span class="line">Removing intermediate container fbc63d321d73</span><br><span class="line">Successfully built 377c409b35e4</span><br></pre></td></tr></table></figure><p>这会将URL发送<a href="http://server/ctx.tar.gz到Docker守护程序，该守护程序下载并提取引用的tar包。" target="_blank" rel="noopener">http://server/ctx.tar.gz到Docker守护程序，该守护程序下载并提取引用的tar包。</a></p><p>-f ctx/Dockerfile 参数指定内部的路径ctx.tar.gz的Dockerfile，用于构建图像。其中的任何引用本地路径的ADD命令都Dockerfile必须相对于其中内容的根ctx.tar.gz。在上面的示例中，压缩包包含一个目录ctx/，因此该ADD ctx/container.cfg /操作可以按预期进行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t vieux&#x2F;apache:2.0 .</span><br></pre></td></tr></table></figure><p>使用当前目录Dockerfile作为上下文的构建，并将构建成功的镜像打tag为vieux/apache:2.0</p><h2 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h2><p>在Docker守护程序运行Dockerfile中的指令之前，它会对进行初步验证，Dockerfile如果语法不正确，则返回错误：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ docker build -t test&#x2F;myapp .</span><br><span class="line"></span><br><span class="line">Sending build context to Docker daemon 2.048 kB</span><br><span class="line">Error response from daemon: Unknown instruction: RUNCMD</span><br></pre></td></tr></table></figure><p>Docker守护程序以Dockerfile一对一的方式运行指令，如有必要，将每个指令的结果提交到新映像，然后最终输出新映像的ID。Docker守护程序将自动清理您发送的上下文。</p><p>请注意，每条指令都是独立运行的，并会导致创建新映像-因此RUN cd /tmp对下一条指令不会有任何影响。</p><h1 id="如何高效地构建一个镜像"><a href="#如何高效地构建一个镜像" class="headerlink" title="如何高效地构建一个镜像"></a>如何高效地构建一个镜像</h1><h2 id="使用多阶段构建方法"><a href="#使用多阶段构建方法" class="headerlink" title="使用多阶段构建方法"></a>使用多阶段构建方法</h2><p>多阶段构建有点像虚拟机模板内味，就是需要几个基础镜像，毕竟软件底层都是由一个一个的基础组成的，就像我们的window、centos、ubantu等等一样，我们需要一个基础Docker image，包含一类工程的基础运行环境（java类镜像你需要装jdk），装完系统后的加工则交给我们的上一层Dockerfile来完成。</p><p>为什么这样其实用中国一句老话来说通俗易懂，避免牵一发而动全身。假如你的A项目需要一个jdk1.7的环境 你的B项目需要一个jdk1.8的环境，你只需要做一个centos/ubantu的镜像并且能保证稳定，在此基础上build 2个不同的版本java:1.7 java:1.8即可让不通的项目运行在不通的镜像上，而你则只用专注java:1.7和java:1.8的Dockerfile即可。</p><p>对于Dockerfile来说，最好将命令从更改频率较低（以确保构建缓存可重用）到更改频率较高的顺序来布局整个镜像层级：</p><ul><li>底层  安装构建应用程序所需的工具   </li><li>中层  安装或更新库依赖关系</li><li>顶层  安装应用程序</li></ul><p>Go应用程序的Dockerfile可能类似于：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">FROM golang:1.11-alpine AS build</span><br><span class="line"></span><br><span class="line"># Install tools required for project</span><br><span class="line"># Run &#96;docker build --no-cache .&#96; to update dependencies</span><br><span class="line">RUN apk add --no-cache git</span><br><span class="line">RUN go get github.com&#x2F;golang&#x2F;dep&#x2F;cmd&#x2F;dep</span><br><span class="line"></span><br><span class="line"># List project dependencies with Gopkg.toml and Gopkg.lock</span><br><span class="line"># These layers are only re-built when Gopkg files are updated</span><br><span class="line">COPY Gopkg.lock Gopkg.toml &#x2F;go&#x2F;src&#x2F;project&#x2F;</span><br><span class="line">WORKDIR &#x2F;go&#x2F;src&#x2F;project&#x2F;</span><br><span class="line"># Install library dependencies</span><br><span class="line">RUN dep ensure -vendor-only</span><br><span class="line"></span><br><span class="line"># Copy the entire project and build it</span><br><span class="line"># This layer is rebuilt when a file changes in the project directory</span><br><span class="line">COPY . &#x2F;go&#x2F;src&#x2F;project&#x2F;</span><br><span class="line">RUN go build -o &#x2F;bin&#x2F;project</span><br><span class="line"></span><br><span class="line"># This results in a single layer image</span><br><span class="line">FROM scratch</span><br><span class="line">COPY --from&#x3D;build &#x2F;bin&#x2F;project &#x2F;bin&#x2F;project</span><br><span class="line">ENTRYPOINT [&quot;&#x2F;bin&#x2F;project&quot;]</span><br><span class="line">CMD [&quot;--help&quot;]</span><br></pre></td></tr></table></figure><h2 id="不要安装不必要的软件包"><a href="#不要安装不必要的软件包" class="headerlink" title="不要安装不必要的软件包"></a>不要安装不必要的软件包</h2><p>为了降低复杂性，依赖性，文件大小和构建时间，请避免即便它们“很容易安装”而安装多余或不必要的软件包。</p><p>比如不需要在数据库镜像中安装文本编辑器(vim)。</p><h2 id="解耦应用"><a href="#解耦应用" class="headerlink" title="解耦应用"></a>解耦应用</h2><p>即每个容器应该做好自己的，将应用程序解耦到多个容器中，可以更轻松地水平缩放和重复使用容器。</p><p>例如，一个Web应用程序可能由三个单独的容器组成，每个容器都有自己的唯一镜像，以分离的方式管理Web应用程序，数据库和内存中的缓存。</p><p>尽量不要将所有项目的运行环境融合在一个镜像里。根据您的最佳判断，使容器保持清洁和模块化。如果容器相互依赖，则可以使用Docker容器网络来确保这些容器可以通信。</p><h2 id="最小化层数"><a href="#最小化层数" class="headerlink" title="最小化层数"></a>最小化层数</h2><p>只有指令RUN，COPY，ADD会创建层。其他指令只会创建临时的中间镜像，并且不会增加构建的大小。</p><p>尽可能使用多阶段构建，并且仅将所需的工件复制到最终映像中。这样，您就可以在中间构建阶段中包含工具和调试信息，而无需增加最终映像的大小。</p><p>例如，一个java应用最顶层的镜像应该只存在jar包，而不用关注任何启动的环境准备等。</p><h2 id="利用缓存构建镜像-重中之重"><a href="#利用缓存构建镜像-重中之重" class="headerlink" title="利用缓存构建镜像(重中之重)"></a>利用缓存构建镜像(重中之重)</h2><p>构建镜像时，Docker会逐步执行Dockerfile中的指令。在检查每条指令时，Docker会在其缓存中查找可重用的现有镜像，而不是创建新的（重复的）镜像。</p><p>利用构建缓存也是上面提到4种高效构建的核心原因：使用多阶段构建方法、不要安装不必要的软件包、解耦应用、最小化层数。正是由于这些高效构建的方法，才使得利用构建缓存非查有必要。</p><p>利用缓存构建的好处包括：</p><ul><li>缩短构建、拉取、推送镜像的时间</li><li>基于一个基础镜像进行分类扩展</li><li>节省磁盘资源及容器运行时的大小。</li></ul><p>Docker遵循的基本规则概述如下：</p><ul><li>从已在缓存中的基础镜像开始，将下一条指令与从该基本镜像派生的所有子镜像进行比较，以查看是否其中一个是使用完全相同的指令构建的。如果不是，无法使用缓存。</li><li>在大多数情况下，只需将中的指令Dockerfile与基础镜像之一进行比较就足够了。但是，某些说明需要更多的检查和解释。</li><li>对于ADD和COPY指令，将检查镜像中文件的内容，并为每个文件计算一个校验和。这些校验和中不考虑文件的最后修改时间和最后访问时间。在高速缓存查找期间，将校验和与现有镜像中的校验和进行比较。如果文件中的任何内容（例如内容和元数据）发生了更改，则无法使用缓存</li><li>除了ADD和COPY命令之外，缓存检查不会查看容器中的文件来确定缓存是否匹配。例如，在处理RUN apt-get -y update命令时，不检查容器中更新的文件以确定是否存在缓存命中。在这种情况下，仅使用命令字符串本身来查找匹配项。</li></ul><p>如果发现缓存无效的情况，则所有后续Dockerfile命令都会生成新镜像，并且不使用缓存。</p><h1 id="实践"><a href="#实践" class="headerlink" title="实践"></a>实践</h1><p>其实关于构建镜像，最具挑战性的事情之一是保持图像尺寸变小。Dockerfile中的每条指令都在映像上添加了一层，您需要记住在移至下一层之前清除不需要的任何组件。要编写一个真正有效的Dockerfile，传统上，您需要使用Shell技巧和其他逻辑来使各层尽可能小，并确保每一层都具有上一层所需的工件，而没有其他任何东西。</p><p>例如，在执行RUN安装基础组件的时候尽量带上 &amp;&amp;运算符将多个命令压缩在一起，以避免在镜像中创建额外层。</p><h2 id="基础镜像"><a href="#基础镜像" class="headerlink" title="基础镜像"></a>基础镜像</h2><p>可以进入dockerhub上看到一个jdk8环境的Dockerfile</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">FROM ubuntu:xenial</span><br><span class="line">MAINTAINER ASCDC &lt;asdc.sinica@gmail.com&gt;</span><br><span class="line"></span><br><span class="line">RUN mkdir &#x2F;script</span><br><span class="line">ADD run.sh &#x2F;script&#x2F;run.sh</span><br><span class="line"></span><br><span class="line">RUN DEBIAN_FRONTEND&#x3D;noninteractive &amp;&amp; \</span><br><span class="line">chmod +x &#x2F;script&#x2F;*.sh &amp;&amp; \</span><br><span class="line">apt-get -qq update &amp;&amp; \</span><br><span class="line">apt-get -y -qq dist-upgrade &amp;&amp; \</span><br><span class="line">apt-get -qq install -y locales &amp;&amp; \</span><br><span class="line">locale-gen en_US.UTF-8 &amp;&amp; \</span><br><span class="line">export LANG&#x3D;en_US.UTF-8</span><br><span class="line">RUN DEBIAN_FRONTEND&#x3D;noninteractive &amp;&amp; apt-get -qq install -y vim screen wget git curl openjdk-8-jdk</span><br><span class="line"></span><br><span class="line">ENV JAVA_HOME &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-8-openjdk-amd64</span><br><span class="line"></span><br><span class="line">WORKDIR &#x2F;script</span><br><span class="line">ENTRYPOINT [&quot;&#x2F;script&#x2F;run.sh&quot;]</span><br></pre></td></tr></table></figure><p>当然，这只是一个例子，你可以根据自己的项目需求调整Dockerfile的内容，比如时区 TZ=Asia/Shanghai  如果你不需要wget 、git 、curl等，也可以不安装。</p><h2 id="项目镜像"><a href="#项目镜像" class="headerlink" title="项目镜像"></a>项目镜像</h2><p>将这个镜像下载到本地修改或者直接重写jdk8的Dockerfile都是不错选择，基础镜像制作完成后，就需要制作项目镜像了。</p><p>项目的镜像一般来说是一个经常变动的(jar包在不断更新迭代)，在基于基础镜像的之上这样再制作一个项目的Dockerfile就容易很多了。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">本地目录</span><br><span class="line">[root@localhost ~]# tree</span><br><span class="line">.</span><br><span class="line">├── xxx.jar</span><br><span class="line">├── Dockerfile</span><br><span class="line">└── run.sh</span><br><span class="line"></span><br><span class="line">Dockerfile内容如下，将jar包和启动脚本放到镜像里</span><br><span class="line"></span><br><span class="line">FROM jdk:1.8</span><br><span class="line">ADD xxx.jar &#x2F;</span><br><span class="line">COPY .&#x2F;run.sh &#x2F;run.sh</span><br><span class="line">RUN chmod u+x &#x2F;run.sh</span><br><span class="line">CMD [ &quot;&#x2F;run.sh&quot; ]</span><br><span class="line"></span><br><span class="line">run.sh内容如下 启动命令及调优参数</span><br><span class="line"></span><br><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">java -server -Xmx4000m -Xms4000m -Xmn2000m -Xss512k -XX:+DisableExplicitGC \</span><br><span class="line">     -XX:+UseConcMarkSweepGC -XX:+CMSParallelRemarkEnabled \</span><br><span class="line">     -XX:LargePageSizeInBytes&#x3D;128m -XX:+UseFastAccessorMethods \</span><br><span class="line">     -XX:+UseCMSInitiatingOccupancyOnly -XX:CMSInitiatingOccupancyFraction&#x3D;70 \</span><br><span class="line">     -jar &#x2F;xxx.jar</span><br><span class="line">     </span><br><span class="line">     </span><br><span class="line">制作镜像命令，在~目录执行</span><br><span class="line">docker build -t rugod.cn:1.0 .</span><br></pre></td></tr></table></figure><p>2个制作镜像过程种经常用到的命令</p><p>docker history images:tag 查看某个指定版本镜像的构建语句</p><p>docker search images:tag 在Docker Hub中搜索图像</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>如何高效制作镜像的过程就基本上讲完了，希望对大家有帮助，谢谢。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://qhh.me/2019/02/17/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-Docker-%E6%9E%84%E5%BB%BA%E4%B8%8A%E4%B8%8B%E6%96%87/" target="_blank" rel="noopener">深入理解-Docker-构建上下文</a></p><p><a href="https://docs.docker.com/develop/develop-images/dockerfile_best-practices/" target="_blank" rel="noopener">编写Dockerfile的最佳实践</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Dockerfile </tag>
            
            <tag> Docker </tag>
            
            <tag> Linux </tag>
            
            <tag> Devops </tag>
            
            <tag> 容器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Webhooks自动部署博客</title>
      <link href="2020/06/28/devops/devops-webhooks/"/>
      <url>2020/06/28/devops/devops-webhooks/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>618活动白嫖阿里云服务器1c2g 40g磁盘 1M带宽，搞了个域名备案后准备在服务器上搭建博客，关于自动部署这方面看了网上的几个帖子，准备用webhooks这种方式实现自动部署</p><h1 id="Webhook"><a href="#Webhook" class="headerlink" title="Webhook"></a>Webhook</h1><p>你可以通过定制 Webhook 来监测你在 Github.com 上的各种事件，最常见的莫过于 push 事件。如果你设置了一个监测 push 事件的 Webhook，那么每当你的这个项目有了任何提交，这个 Webhook 都会被触发，这时 Github 就会发送一个 HTTP POST 请求到你配置好的地址。</p><h1 id="部署webhooks"><a href="#部署webhooks" class="headerlink" title="部署webhooks"></a>部署webhooks</h1><h2 id="在服务器上下载webhooks"><a href="#在服务器上下载webhooks" class="headerlink" title="在服务器上下载webhooks"></a>在服务器上下载webhooks</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;</span><br><span class="line">wget https:&#x2F;&#x2F;github.com&#x2F;adnanh&#x2F;webhook&#x2F;releases&#x2F;download&#x2F;2.6.11&#x2F;webhook-linux-amd64.tar.gz</span><br><span class="line">tar -zvxf webhook-linux-amd64.tar.gz</span><br></pre></td></tr></table></figure><h2 id="创建webhooks工作目录-分项目"><a href="#创建webhooks工作目录-分项目" class="headerlink" title="创建webhooks工作目录(分项目)"></a>创建webhooks工作目录(分项目)</h2><p>以我的项目为例子，创建一个工作目录后，需要写一个脚本和一个json文件</p><p>deploy.sh 目的是 接收了webhooks消息执行的命令<br>hooks.json 目的是确认id(后文有用)、执行的脚本、执行脚本的工作目录</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">mkdir &#x2F;opt&#x2F;rugod.cn</span><br><span class="line"></span><br><span class="line">vim deploy.sh</span><br><span class="line"></span><br><span class="line">#!&#x2F;bin&#x2F;sh</span><br><span class="line">git fetch --all &amp;&amp; git pull   https:&#x2F;&#x2F;github.com&#x2F;chenyu1st&#x2F;chenyu1st.github.io.git </span><br><span class="line"></span><br><span class="line">vim hooks.json</span><br><span class="line">[</span><br><span class="line">  &#123;</span><br><span class="line">    &quot;id&quot;: &quot;rugod.cn-blog&quot;,</span><br><span class="line">    &quot;execute-command&quot;: &quot;&#x2F;opt&#x2F;rugod.cn&#x2F;deploy.sh&quot;,</span><br><span class="line">    &quot;command-working-directory&quot;: &quot;&#x2F;chenyu&#x2F;chenyu1st.github.io.git&quot;</span><br><span class="line">  &#125;</span><br><span class="line">]</span><br></pre></td></tr></table></figure><h2 id="启动webhook"><a href="#启动webhook" class="headerlink" title="启动webhook"></a>启动webhook</h2><p>在webhooks工作目录测试webhook</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">webhook -hooks hooks.json -verbose</span><br><span class="line">[webhook] 2020&#x2F;06&#x2F;28 00:21:59 version 2.6.11 starting</span><br><span class="line">[webhook] 2020&#x2F;06&#x2F;28 00:21:59 setting up os signal watcher</span><br><span class="line">[webhook] 2020&#x2F;06&#x2F;28 00:21:59 attempting to load hooks from hooks.json</span><br><span class="line">[webhook] 2020&#x2F;06&#x2F;28 00:21:59 found 1 hook(s) in file</span><br><span class="line">[webhook] 2020&#x2F;06&#x2F;28 00:21:59 loaded: rugod.cn-blog</span><br><span class="line">[webhook] 2020&#x2F;06&#x2F;28 00:21:59 serving hooks on http:&#x2F;&#x2F;0.0.0.0:9000&#x2F;hooks&#x2F;&#123;id&#125;</span><br></pre></td></tr></table></figure><p>带着实际的<a href="http://0.0.0.0:9000/hooks/{id}" target="_blank" rel="noopener">http://0.0.0.0:9000/hooks/{id}</a> 填到GitHub 网站对应项目页面 Settings → Webhooks 中即可</p><p>点击 Redeliver 可以重新测试</p><p>后台执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup webhook -hooks hooks.json -verbose &amp;</span><br></pre></td></tr></table></figure><p>这个时候博客有更新即发送http请求到服务器的监听位置，触发pull代码的操作</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://developer.github.com/webhooks/" target="_blank" rel="noopener">webhooks</a></p><p><a href="https://blog.cugxuan.cn/2019/03/23/Git/Use-Webhook-To-Update-Blog/" target="_blank" rel="noopener">使用 webhook 自动更新博客</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> 跟我学Devops </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Devops </tag>
            
            <tag> 自动化 </tag>
            
            <tag> CI/CD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入浅出Docker原理及实战(三)——制作Dockerfile</title>
      <link href="2020/06/27/docker/docker-idea-3/"/>
      <url>2020/06/27/docker/docker-idea-3/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><p>深入浅出Docker原理及实战系列第三篇，我主要分享如何制作一个Dockerfile，以及基本命令格式。</p><h1 id="Dockerfile简介"><a href="#Dockerfile简介" class="headerlink" title="Dockerfile简介"></a>Dockerfile简介</h1><p>Docker可以通过阅读Dockerfile的指令来自动构建镜像。 Dockerfile是一个文本文件，其中包含用户可以在命令行上调用组装镜像的所有命令。使用docker build命令可以创建自动构建流程，该构建连续执行多个命令行指令。</p><h1 id="制作Dockfile"><a href="#制作Dockfile" class="headerlink" title="制作Dockfile"></a>制作Dockfile</h1><p>Docker镜像由只读层组成，每个只读层代表一条Dockerfile指令。这些层是堆叠的，每个层都是上一层的变化的增量。下面是一个Dockerfile的内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">FROM ubuntu:18.04</span><br><span class="line">COPY . &#x2F;app</span><br><span class="line">RUN make &#x2F;app</span><br><span class="line">CMD python &#x2F;app&#x2F;app.py</span><br></pre></td></tr></table></figure><p>每条指令创建一层：</p><ul><li>FROM：基于ubuntu:18.04的镜像创建一个只读层。</li><li>COPY：从Docker客户端的当前目录添加文件。</li><li>RUN： 使用make构建应用程序</li><li>CMD： 指定在容器中运行什么命令。</li></ul><p>运行镜像并生成容器时，可以在基础层之上添加一个新的可写层（“容器层”）。对运行中的容器所做的所有更改（例如写入新文件，修改现有文件和删除文件）都将写入可写容器层。</p><h2 id="BuildKit"><a href="#BuildKit" class="headerlink" title="BuildKit"></a>BuildKit</h2><p>从版本18.09开始，Docker支持由moby / buildkit 项目提供的用于执行构建的新后端。与旧的实现相比，BuildKit后端提供了许多好处。例如，BuildKit可以：</p><ul><li>检测并跳过执行未使用的构建阶段</li><li>并行构建独立构建阶段</li><li>两次构建之间仅增量传输构建上下文中的已更改文件</li><li>在构建上下文中检测并跳过未使用的文件的传输</li><li>使用具有许多新功能的外部Dockerfile实现</li><li>避免与其他API产生副作用（中间图像和容器）</li><li>优先考虑构建缓存以进行自动修剪</li><li>要使用BuildKit后端，您需要DOCKER_BUILDKIT=1在CLI上设置环境变量 ，然后再调用docker build。</li></ul><p>要了解基于BuildKit的构建可用的实验性Dockerfile语法，<a href="https://github.com/moby/buildkit/blob/master/frontend/dockerfile/docs/experimental.md" target="_blank" rel="noopener">请参阅BuildKit存储库中的文档</a>。</p><p>注意！目前我还没有太了解这个功能，而且项目中dockerfile都没有引入，所以对于该功能不做深入了解。</p><h2 id="Dockfile格式"><a href="#Dockfile格式" class="headerlink" title="Dockfile格式"></a>Dockfile格式</h2><p>文件的指令不区分大小写。但是，约定是大写，以便更轻松地将它们与参数区分开。</p><p>Docker按顺序在Dockerfile中运行指令，Dockerfile必须以“FROM”指令开头。这可能在解析器指令，注释和全局范围的ARG之后。</p><p>FROM指令指定要从上一层镜像中构建。</p><p>FROM只能前面有一个或多个ARG指令，这些指令声明Dockerfile中FROM行中使用的参数</p><p>Docker会将以＃开头的行视为注释，除非该行是有效的解析器指令。</p><p>注释中不支持换行符。</p><h2 id="Dockerfile指令"><a href="#Dockerfile指令" class="headerlink" title="Dockerfile指令"></a>Dockerfile指令</h2><p>在Dockerfile中，每一条语句都是一个指令。</p><p>Dockerfile有以下指令列表：</p><table><thead><tr><th>部分</th><th>指令</th></tr></thead><tbody><tr><td>基础镜像信息</td><td>FROM</td></tr><tr><td>镜像操作指令</td><td>RUN、COPY、ADD、EXPOSE、WORKDIR、VOLUME等</td></tr><tr><td>容器启动时执行指令</td><td>CMD、ENTRYPOINT</td></tr></tbody></table><h3 id="解析器指令"><a href="#解析器指令" class="headerlink" title="解析器指令"></a>解析器指令</h3><p>解析器指令是可选的，并且会影响Dockerfile处理后续行的方式。解析器指令不会在构建中添加图层，也不会显示为构建步骤。解析器指令以形式写为特殊类型的注释# directive=value。单个指令只能使用一次。</p><p>支持以下解析器指令：</p><ul><li>syntax</li><li>escape</li></ul><p>syntax仅当使用BuildKit后端时才启用此功能，我还没有用BuildKit，所以到在此不讲。</p><p>escape写法</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># escape&#x3D;\</span><br></pre></td></tr></table></figure><p>该escape指令设置用来逃避的字符的字符 Dockerfile。如果未指定，则默认转义字符为\。</p><p>转义字符用于转义一行中的字符和转义换行符。这允许一条Dockerfile指令跨越多行。请注意，无论escape是否包含在Dockerfile，都不会在RUN命令中执行转义，除非在行末。</p><p>将转义符设置为`对Windows下尤其有用 ，其中目录路径分隔符为\。</p><p>一个简单的演示</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">如果不加escape指令</span><br><span class="line"></span><br><span class="line">FROM microsoft&#x2F;nanoserver</span><br><span class="line">COPY testfile.txt c:\\</span><br><span class="line">RUN dir c:\</span><br><span class="line"></span><br><span class="line">PS C:\John&gt; docker build -t cmd .</span><br><span class="line">Sending build context to Docker daemon 3.072 kB</span><br><span class="line">Step 1&#x2F;2 : FROM microsoft&#x2F;nanoserver</span><br><span class="line"> ---&gt; 22738ff49c6d</span><br><span class="line">Step 2&#x2F;2 : COPY testfile.txt c:\RUN dir c:</span><br><span class="line">GetFileAttributesEx c:RUN: The system cannot find the file specified.</span><br><span class="line">PS C:\John&gt;</span><br><span class="line"></span><br><span class="line">--------------------------------------------</span><br><span class="line">加了escape指令后</span><br><span class="line"></span><br><span class="line"># escape&#x3D;&#96;</span><br><span class="line"></span><br><span class="line">FROM microsoft&#x2F;nanoserver</span><br><span class="line">COPY testfile.txt c:\</span><br><span class="line">RUN dir c:\</span><br><span class="line"></span><br><span class="line">PS C:\John&gt; docker build -t succeeds --no-cache&#x3D;true .</span><br><span class="line">Sending build context to Docker daemon 3.072 kB</span><br><span class="line">Step 1&#x2F;3 : FROM microsoft&#x2F;nanoserver</span><br><span class="line"> ---&gt; 22738ff49c6d</span><br><span class="line">Step 2&#x2F;3 : COPY testfile.txt c:\</span><br><span class="line"> ---&gt; 96655de338de</span><br><span class="line">Removing intermediate container 4db9acbb1682</span><br><span class="line">Step 3&#x2F;3 : RUN dir c:\</span><br><span class="line"> ---&gt; Running in a2c157f842f5</span><br><span class="line"> Volume in drive C has no label.</span><br><span class="line"> Volume Serial Number is 7E6D-E0F7</span><br><span class="line"></span><br><span class="line"> Directory of c:\</span><br><span class="line"></span><br><span class="line">10&#x2F;05&#x2F;2016  05:04 PM             1,894 License.txt</span><br><span class="line">10&#x2F;05&#x2F;2016  02:22 PM    &lt;DIR&gt;          Program Files</span><br><span class="line">10&#x2F;05&#x2F;2016  02:14 PM    &lt;DIR&gt;          Program Files (x86)</span><br><span class="line">10&#x2F;28&#x2F;2016  11:18 AM                62 testfile.txt</span><br><span class="line">10&#x2F;28&#x2F;2016  11:20 AM    &lt;DIR&gt;          Users</span><br><span class="line">10&#x2F;28&#x2F;2016  11:20 AM    &lt;DIR&gt;          Windows</span><br><span class="line">           2 File(s)          1,956 bytes</span><br><span class="line">           4 Dir(s)  21,259,096,064 bytes free</span><br><span class="line"> ---&gt; 01c7f3bef04f</span><br><span class="line">Removing intermediate container a2c157f842f5</span><br><span class="line">Successfully built 01c7f3bef04f</span><br><span class="line">PS C:\John&gt;</span><br></pre></td></tr></table></figure><h3 id="Environment-replacement"><a href="#Environment-replacement" class="headerlink" title="Environment replacement"></a>Environment replacement</h3><p>环境变量（与ENV的声明），也可以在特定指令作为变量用来被解释 Dockerfile。转义也可以通过将类变量的语法包括在语句中而得到处理。</p><p>Dockerfile用 $variable_name或${variable_name}表示环境变量。它们被等效地对待，并且大括号语法通常用于解决变量名没有空格的问题，例如${foo}_bar</p><p>该${variable_name}语法还支持一些标准bash 修饰符，如下所示：</p><ul><li>${variable:-word}表示如果variable设置，则结果将是该值。如果variable未设置，则为word结果。</li><li>${variable:+word}指示如果variable设置了if，则将为word结果，否则结果为空字符串。</li></ul><p>在所有情况下，word都可以是任何字符串，包括其他环境变量。</p><p>可通过在变量前添加\来进行转义：例如，$foo或${foo}将分别转换为$foo和${foo}文字。</p><p>示例（解析的表示形式显示在之后#）：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">FROM busybox</span><br><span class="line">ENV foo &#x2F;bar</span><br><span class="line">WORKDIR $&#123;foo&#125;   # WORKDIR &#x2F;bar</span><br><span class="line">ADD . $foo       # ADD . &#x2F;bar</span><br><span class="line">COPY \$foo &#x2F;quux # COPY $foo &#x2F;quux</span><br></pre></td></tr></table></figure><p>在一条指令中，环境变量替换将对每个变量使用相同的值。</p><p>例如</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ENV abc&#x3D;hello</span><br><span class="line">ENV abc&#x3D;bye def&#x3D;$abc hjk&#x3D;$abc  #def&#x3D;hello  hjk&#x3D;hello</span><br><span class="line">ENV ghi&#x3D;$abc                   #ghi&#x3D;bye</span><br></pre></td></tr></table></figure><p>例子中def值为hello，而不是bye。但是， ghi=bye,因为它不是设置abc=bye这一指令的一部分。</p><h3 id="FROM"><a href="#FROM" class="headerlink" title="FROM"></a>FROM</h3><p>格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FROM [--platform&#x3D;&lt;platform&gt;] &lt;image&gt; [AS &lt;name&gt;]</span><br><span class="line">FROM [--platform&#x3D;&lt;platform&gt;] &lt;image&gt;[:&lt;tag&gt;] [AS &lt;name&gt;]</span><br><span class="line">FROM [--platform&#x3D;&lt;platform&gt;] &lt;image&gt;[@&lt;digest&gt;] [AS &lt;name&gt;]</span><br></pre></td></tr></table></figure><p>FROM指令初始化一个新的构建阶段，并为后续指令设置基本镜像。<br>因此，有效的Dockerfile必须以FROM指令开头。FROM的镜像可以是任何本地可以访问到仓库里的镜像-从公共存储库（docker hub）中拉出镜像特别容易启动。</p><p>其中注意以下5点：</p><ul><li>ARG是先于FROM之前。</li><li>一个Dockerfile可以出现多次FROM以创建多个镜像，也可以将一个构建阶段作为对另一个构建阶段的依赖。只需在每个新FROM指令之前记录一次提交输出的最后一个镜像ID。每个FROM指令清除由先前指令创建的任何状态。</li><li>通过将AS <name> 添加到FROM指令中，可以选择为新的构建阶段指定名称。该名称可以在后续版本FROM和 COPY –from=&lt;name|index&gt;说明中使用，以引用此阶段中构建的镜像。</li><li>该tag或digest值是可选的。如果两个都不选择，那么缺省情况下构建器将采用latest标签。如果构建器找不到该tag值，则返回错误。</li><li>–platform在FROM引用多平台镜像的情况下，可选标志可用于指定镜像的平台。例如，linux/amd64， linux/arm64，或windows/amd64。默认情况下，使用构建请求的目标平台（即本机）。</li></ul><p>了解ARG和FROM之间的交互方式</p><p>FROM支持由出现在第一个FROM之前的任何ARG指令声明的变量。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ARG  CODE_VERSION&#x3D;latest</span><br><span class="line">FROM base:$&#123;CODE_VERSION&#125;   #base:latest</span><br><span class="line">CMD  &#x2F;code&#x2F;run-app</span><br><span class="line"></span><br><span class="line">FROM extras:$&#123;CODE_VERSION&#125; #base:latest</span><br><span class="line">CMD  &#x2F;code&#x2F;run-extras</span><br></pre></td></tr></table></figure><p>在FROM之前声明的ARG在构建阶段之外，因此不能在FROM之后的任何指令中使用ARG的变量，如果要使用在第一个FROM之前声明的ARG的值，请使用ARG指令再次声明变量即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ARG VERSION&#x3D;latest</span><br><span class="line">FROM busybox:$VERSION</span><br><span class="line">ARG VERSION</span><br><span class="line">RUN echo $VERSION &gt; image_version</span><br></pre></td></tr></table></figure><h3 id="RUN"><a href="#RUN" class="headerlink" title="RUN"></a>RUN</h3><p>RUN有2种形式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RUN &lt;command&gt; (shell形式,命令在shell中运行,默认情况下在Linux是&#x2F;bin&#x2F;sh -c)</span><br><span class="line">RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;] (执行列表)</span><br></pre></td></tr></table></figure><p>该RUN指令将在当前镜像上方的新层中执行任何命令，并提交结果。生成的提交镜像将用于下一步的Dockerfile。</p><p>分层RUN指令和生成提交符合Docker的核心概念，在这些概念上，提交很方便，并且可以从映像历史记录的任何位置创建容器，就像源代码控制一样。</p><p>exec形式可以避免破坏shell字符串，并使用不包含指定shell可执行文件的基本映像运行RUN命令(例如bash)。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">在shell形式中，可以使用\将一条RUN指令继续到下一行。</span><br><span class="line">RUN &#x2F;bin&#x2F;bash -c &#39;source $HOME&#x2F;.bashrc; \</span><br><span class="line">echo $HOME&#39;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">它们合在一起相当于以下一行：</span><br><span class="line">RUN &#x2F;bin&#x2F;bash -c &#39;source $HOME&#x2F;.bashrc; echo $HOME&#39;</span><br><span class="line"></span><br><span class="line">要使用&#39;&#x2F; bin &#x2F; sh&#39;以外的其他shell，请使用exec形式传入所需的shell。例如：</span><br><span class="line"></span><br><span class="line">RUN [&quot;&#x2F;bin&#x2F;bash&quot;, &quot;-c&quot;, &quot;echo hello&quot;]</span><br></pre></td></tr></table></figure><hr><p>注意</p><p>exec表单被解析为JSON数组，这意味着必须在单词周围使用双引号（”）而非单引号（’）</p><p>RUN在一次构建期间，指令缓存不会自动失效。比如 RUN yum install -y vim 将在下一个构建中重用。RUN指令的缓存可以通过使用–no-cache 标志来使无效,例如docker build –no-cache。还可以由ADD和COPY指令来使无效。</p><h3 id="CMD"><a href="#CMD" class="headerlink" title="CMD"></a>CMD</h3><p>CMD有三种形式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]（exec形式，这是首选形式）</span><br><span class="line">CMD [&quot;param1&quot;,&quot;param2&quot;]（作为ENTRYPOINT的默认参数）</span><br><span class="line">CMD command （shell形式）</span><br></pre></td></tr></table></figure><p>CMD主要目的是为执行中的容器提供默认值。这些默认值可以包含一个可执行文件，也可以忽略该可执行文件，在这种情况下，您还必须指定一条ENTRYPOINT 指令。</p><p>注意！！！一个Dockerfile只能一个CMD指令。如果出现多个CMD 则只有最后一个CMD才会生效。</p><p>与shell形式不同，exec形式不会调用命令shell。这意味着不会进行常规的shell处理。例如， CMD [ “echo”, “$HOME” ]将不会对进行变量替换$HOME。如果要进行shell处理，则可以使用shell形式或直接执行shell，例如：CMD [ “sh”, “-c”, “echo $HOME” ]</p><p>如果CMD使用的shell形式，则将在中<command>执行 /bin/sh -c</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FROM ubuntu</span><br><span class="line">CMD echo &quot;This is a test.&quot; | wc -</span><br></pre></td></tr></table></figure><p>如果要在没有shell的情况下运行 <command> ，则必须将命令表示为JSON数组，并提供可执行文件的完整路径。 此数组形式是的首选格式CMD。任何其他参数必须在数组中分别表示为字符串：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">FROM ubuntu</span><br><span class="line">CMD [&quot;&#x2F;usr&#x2F;bin&#x2F;wc&quot;,&quot;--help&quot;]</span><br></pre></td></tr></table></figure><p>如果希望容器每次都运行相同的可执行文件，则应考虑ENTRYPOINT与CMD结合使用</p><p>如果docker run指定了参数，则它们将覆盖中指定的CMD默认参数。</p><p>最后重申一点CMD和RUN的区别：RUN实际上运行命令并提交结果；CMD在构建时不执行任何操作，而是在镜像启动后执行命令。</p><h3 id="LABEL"><a href="#LABEL" class="headerlink" title="LABEL"></a>LABEL</h3><p>格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LABEL &lt;key&gt;&#x3D;&lt;value&gt; &lt;key&gt;&#x3D;&lt;value&gt; &lt;key&gt;&#x3D;&lt;value&gt; ...</span><br></pre></td></tr></table></figure><p>该LABEL指令将元数据添加到镜像。一个LABEL是键值对。如果要在LABEL值中包含空格，请像在命令行分析中一样使用引号和反斜杠。</p><p>例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">LABEL &quot;com.example.vendor&quot;&#x3D;&quot;ACME Incorporated&quot;</span><br><span class="line">LABEL com.example.label-with-value&#x3D;&quot;foo&quot;</span><br><span class="line">LABEL version&#x3D;&quot;1.0&quot;</span><br><span class="line">LABEL description&#x3D;&quot;This text illustrates \</span><br><span class="line">that label-values can span multiple lines.&quot;</span><br></pre></td></tr></table></figure><p>一个镜像可以有多个标签。您可以在一行上指定多个标签</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">LABEL multi.label1&#x3D;&quot;value1&quot; multi.label2&#x3D;&quot;value2&quot; other&#x3D;&quot;value3&quot;</span><br><span class="line">LABEL multi.label1&#x3D;&quot;value1&quot; \</span><br><span class="line">      multi.label2&#x3D;&quot;value2&quot; \</span><br><span class="line">      other&#x3D;&quot;value3&quot;</span><br></pre></td></tr></table></figure><p>基础镜像（FROM中的镜像）中包含的标签会被后面的镜像继承。如果标签已经存在但具有不同的值，则最近应用的值将覆盖任何先前设置的值。</p><p>要查看镜像的标签，请使用docker image inspect命令。可以使用该–format选项仅显示标签。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">docker image inspect --format&#x3D;&#39;&#39; myimage</span><br><span class="line">&#123;</span><br><span class="line">  &quot;com.example.vendor&quot;: &quot;ACME Incorporated&quot;,</span><br><span class="line">  &quot;com.example.label-with-value&quot;: &quot;foo&quot;,</span><br><span class="line">  &quot;version&quot;: &quot;1.0&quot;,</span><br><span class="line">  &quot;description&quot;: &quot;This text illustrates that label-values can span multiple lines.&quot;,</span><br><span class="line">  &quot;multi.label1&quot;: &quot;value1&quot;,</span><br><span class="line">  &quot;multi.label2&quot;: &quot;value2&quot;,</span><br><span class="line">  &quot;other&quot;: &quot;value3&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="EXPOSE"><a href="#EXPOSE" class="headerlink" title="EXPOSE"></a>EXPOSE</h3><p>格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">EXPOSE &lt;port&gt; [&lt;port&gt;&#x2F;&lt;protocol&gt;...]</span><br></pre></td></tr></table></figure><p>EXPOSE指令通知Docker容器在运行时监听指定的网络端口。您可以指定端口是侦听TCP还是UDP，如果未指定协议，则默认值为TCP。</p><p>EXPOSE指令实际上并未发布端口。它充当构建映像的人员和运行容器的人员之间的一种文档类型，有关打算发布哪些端口的信息。要在运行容器时实际发布端口，请使用-p标记在docker run 发布和映射一个或多个端口，或者使用-P标记发布所有公开的端口并将它们映射到高阶端口。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">默认情况下，EXPOSE指定的是TCP</span><br><span class="line">EXPOSE 80</span><br><span class="line"></span><br><span class="line">指定UDP</span><br><span class="line">EXPOSE 80&#x2F;udp</span><br><span class="line"></span><br><span class="line">同时在TCP和UDP上公开</span><br><span class="line">EXPOSE 80&#x2F;tcp</span><br><span class="line">EXPOSE 80&#x2F;udp</span><br><span class="line"></span><br><span class="line">在这种情况下，docker run -p，则该端口仅对TCP公开一次，对于UDP公开一次。</span><br><span class="line">-p的端口在主机上使用临时的高阶主机端口，因此该端口对于TCP和UDP将是不同的。</span><br><span class="line"></span><br><span class="line">无论EXPOSE设置如何，都可以在运行时使用该-p标志覆盖它们。例如</span><br><span class="line">docker run -p 80:80&#x2F;tcp -p 80:80&#x2F;udp</span><br></pre></td></tr></table></figure><h3 id="ENV"><a href="#ENV" class="headerlink" title="ENV"></a>ENV</h3><p>格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ENV &lt;key&gt; &lt;value&gt;</span><br><span class="line">ENV &lt;key&gt;&#x3D;&lt;value&gt;</span><br></pre></td></tr></table></figure><p>ENV指令将环境变量<key>设置为<value>。此值将在构建阶段中所有后续指令的环境中使用，并且支持Environment replacement</p><p>ENV指令有两种形式。</p><p>第一种形式ENV <key> <value>会将一个变量设置为一个值。第一个空格之后的整个字符串将被视为<value>-包括空格字符。该值将为其他环境变量解释，因此如果不对引号字符进行转义，则将其删除。</p><p>第二种形式ENV <key>=<value> 允许一次设置多个变量。请注意，第二种形式在语法中使用等号（=），而第一种形式则不使用等号（=）。像命令行解析一样，引号和反斜杠可用于在值中包含空格。</p><p>例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ENV myName&#x3D;&quot;John Doe&quot; myDog&#x3D;Rex\ The\ Dog \</span><br><span class="line">    myCat&#x3D;fluffy</span><br><span class="line">和</span><br><span class="line">ENV myName John Doe</span><br><span class="line">ENV myDog Rex The Dog</span><br><span class="line">ENV myCat fluffy</span><br><span class="line"></span><br><span class="line">将在最终镜像中产生相同的效果</span><br></pre></td></tr></table></figure><p>在运行容器时，使用设置的环境变量将保留。可以使用docker inspect查看ENV的值，并使用更改它们docker run –env <key>=<value></p><p>注意！！！环境变量的持久性可能导致意外的副作用，如果要为单个命令设置值，只需要RUN <key>=<value> <command> 即可让command里使用key</p><h3 id="ADD"><a href="#ADD" class="headerlink" title="ADD"></a>ADD</h3><p>格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ADD [--chown&#x3D;&lt;user&gt;:&lt;group&gt;] &lt;src&gt;... &lt;dest&gt;</span><br><span class="line">ADD [--chown&#x3D;&lt;user&gt;:&lt;group&gt;] [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]</span><br></pre></td></tr></table></figure><p>ADD从目录或远程文件URL <src>中复制新文件， ，并将它们添加到镜像文件系统中的路径<dest>。</p><p>可以指定多个<src>资源，但是如果它们是文件或目录，则将其路径解释为相对于构建上下文源的路径。每个都<src>可能包含通配符，并且匹配将使用Go的 <a href="https://golang.org/pkg/path/filepath/#Match" target="_blank" rel="noopener">filepath.Match</a>规则完成</p><p>除非选择–chown标志指定给定的用户名，组名或UID / GID组合以请求对所添加内容的特定所有权，否则所有新文件和目录的UID和GID均为0。–chown标志的格式允许用户名和组名字符串或直接整数UID和GID任意组合。提供不带组名的用户名或不带GID的UID将使用与GID相同的数字UID。如果提供了用户名或组名，则将使用容器的根文件系统 /etc/passwd和/etc/group文件将名称分别转换为整数UID或GID。</p><p>例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 要添加所有以“hom”开头的文件：</span><br><span class="line">ADD hom?.txt &#x2F;mydir&#x2F;</span><br><span class="line"></span><br><span class="line"># 使用相对路径，并将“test.txt”添加到&lt;WORKDIR&gt;&#x2F;relativeDir&#x2F;</span><br><span class="line">ADD test.txt relativeDir&#x2F;</span><br><span class="line"></span><br><span class="line">ADD --chown&#x3D;55:mygroup files* &#x2F;somedir&#x2F;</span><br><span class="line"></span><br><span class="line">ADD --chown&#x3D;bin files* &#x2F;somedir&#x2F;</span><br></pre></td></tr></table></figure><p>注意！！！如果<src>的内容已更改，则遇到的第一个ADD指令将使Dockerfile中所有后续指令的缓存无效。这包括使高速缓存中的RUN指令无效。</p><h3 id="COPY"><a href="#COPY" class="headerlink" title="COPY"></a>COPY</h3><p>格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">COPY [--chown&#x3D;&lt;user&gt;:&lt;group&gt;] &lt;src&gt;... &lt;dest&gt;</span><br><span class="line">COPY [--chown&#x3D;&lt;user&gt;:&lt;group&gt;] [&quot;&lt;src&gt;&quot;,... &quot;&lt;dest&gt;&quot;]</span><br></pre></td></tr></table></figure><p>COPY从<src>复制新文件或目录，并将它们添加到容器的文件系统中，路径为<dest>。</p><p>可以指定多个<src>资源，但是文件和目录的路径将被解释为相对于构建上下文的来源。</p><h3 id="ENTRYPOINT"><a href="#ENTRYPOINT" class="headerlink" title="ENTRYPOINT"></a>ENTRYPOINT</h3><p>格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#EXEC的形式，这是优选的形式：</span><br><span class="line">ENTRYPOINT [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]</span><br><span class="line">#Shell的形式</span><br><span class="line">ENTRYPOINT command param1 param2</span><br></pre></td></tr></table></figure><p>ENTRYPOINT可以作为可执行文件运行的容器的配置，一般配合CMD使用。 </p><p>指定 ENTRYPOINT 为 exec 形式时，命令行上指定的参数会作为参数添加到 ENTRYPOINT 的参数列表中。</p><p>可以使用exec形式的ENTRYPOINT来设置相当稳定的默认命令和参数，然后使用两种形式的CMD来设置更可能被更改的其他默认值。</p><p>例如：</p><ul><li><p>EXEC形式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">FROM ubuntu</span><br><span class="line">ENTRYPOINT [&quot;top&quot;, &quot;-b&quot;]</span><br><span class="line">CMD [&quot;-c&quot;]</span><br><span class="line"></span><br><span class="line">docker build -t test:1.0 .</span><br><span class="line"></span><br><span class="line">docker run -it --rm --name test test:1.0 </span><br><span class="line"></span><br><span class="line">Mem: 1704520K used, 352148K free, 0K shrd, 0K buff, 140368121167873K cached</span><br><span class="line">CPU:   5% usr   0% sys   0% nic  94% idle   0% io   0% irq   0% sirq</span><br><span class="line">Load average: 0.08 0.03 0.05 2&#x2F;98 6</span><br><span class="line">  PID  PPID USER     STAT   VSZ %VSZ %CPU COMMAND</span><br><span class="line">    1     0 root     R     3164   0%   0% top -b -c </span><br><span class="line">    </span><br><span class="line">结果执行的是top -b </span><br><span class="line"></span><br><span class="line">docker run -it --rm --name test  test:1.0  -H</span><br><span class="line"></span><br><span class="line">top - 08:25:00 up  7:27,  0 users,  load average: 0.00, 0.01, 0.05</span><br><span class="line">Threads:   1 total,   1 running,   0 sleeping,   0 stopped,   0 zombie</span><br><span class="line">%Cpu(s):  0.1 us,  0.1 sy,  0.0 ni, 99.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">KiB Mem:   2056668 total,  1616832 used,   439836 free,    99352 buffers</span><br><span class="line">KiB Swap:  1441840 total,        0 used,  1441840 free.  1324440 cached Mem</span><br><span class="line"></span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND</span><br><span class="line">    1 root      20   0   19744   2336   2080 R  0.0  0.1   0:00.04 top -b -H</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">结果是执行top -b -H</span><br></pre></td></tr></table></figure></li><li><p>Shell形式</p></li></ul><p>shell形式可以为ENTRYPOINT指定一个纯字符串，它将在中执行/bin/sh -c。这种形式将使用shell处理来替代shell环境变量，并且将忽略任何CMD或docker run命令行参数。为了确保能够正确docker stop发出任何长期运行的ENTRYPOINT可执行文件信号，需要以下exec启动它</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">FROM ubuntu</span><br><span class="line">ENTRYPOINT exec top -b</span><br><span class="line"></span><br><span class="line">docker build -t test:1.0 .</span><br><span class="line"></span><br><span class="line">docker run -it --rm --name test test:1.0</span><br><span class="line"></span><br><span class="line">Mem: 1704520K used, 352148K free, 0K shrd, 0K buff, 140368121167873K cached</span><br><span class="line">CPU:   5% usr   0% sys   0% nic  94% idle   0% io   0% irq   0% sirq</span><br><span class="line">Load average: 0.08 0.03 0.05 2&#x2F;98 6</span><br><span class="line">  PID  PPID USER     STAT   VSZ %VSZ %CPU COMMAND</span><br><span class="line">    1     0 root     R     3164   0%   0% top -b</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">如果忘记添加exec到开头的ENTRYPOINT中</span><br><span class="line"></span><br><span class="line">FROM ubuntu</span><br><span class="line">ENTRYPOINT top -b</span><br><span class="line">CMD -H</span><br><span class="line"></span><br><span class="line">docker build -t test:1.0 .</span><br><span class="line"></span><br><span class="line">docker run -it --name test test:1.0 -c </span><br><span class="line"></span><br><span class="line">Mem: 1704184K used, 352484K free, 0K shrd, 0K buff, 140621524238337K cached</span><br><span class="line">CPU:   9% usr   2% sys   0% nic  88% idle   0% io   0% irq   0% sirq</span><br><span class="line">Load average: 0.01 0.02 0.05 2&#x2F;101 7</span><br><span class="line">USER        PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND</span><br><span class="line">root          1  0.4  0.0   2612   604 pts&#x2F;0    Ss+  09:16   0:00 &#x2F;bin&#x2F;sh -c top</span><br><span class="line">root          6  0.0  0.0   5956  3324 pts&#x2F;0    S+   09:16   0:00 top -b</span><br><span class="line">    </span><br><span class="line">从输出中可以看到top，指定ENTRYPOINT的不是PID 1,而且CMD中的参数-H无效,docker run带的-c参数也无效</span><br></pre></td></tr></table></figure><h3 id="VOLUME"><a href="#VOLUME" class="headerlink" title="VOLUME"></a>VOLUME</h3><p>格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">VOLUME [&quot;&#x2F;data&quot;]</span><br></pre></td></tr></table></figure><p>VOLUME指令创建具有指定名称的挂载点，并将其标记为保存本机或其他容器的外部安装的存储卷。</p><p>例子：</p><p>docker run命令使用基础镜像内指定位置上存在的任何数据初始化新创建的卷</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">FROM ubuntu</span><br><span class="line">RUN mkdir &#x2F;myvol</span><br><span class="line">RUN echo &quot;hello world&quot; &gt; &#x2F;myvol&#x2F;greeting</span><br><span class="line">VOLUME &#x2F;myvol</span><br></pre></td></tr></table></figure><p>Dockerfile生成一个镜像，docker run会创建一个新的挂载点/myvol并将该greeting文件复制 到新创建的卷中。</p><p>如果删除容器里的greeting，然后重启容器，该文件仍然被删除</p><p>但是如果删除容器里的greeting并且再删除容器，再创建一个新的容器，该文件则存在，因为实际上又执行了dockerfile里的RUN echo “hello world” &gt; /myvol/greeting 命令</p><p>注意点</p><ul><li>主机目录是在容器运行时声明的：主机目录（挂载点）本质上是依赖于主机的。这是为了保留镜像的可移植性，因为不能保证给定的主机目录在所有主机上都可用。因此无法从Dockerfile内挂载主机目录。</li><li>从Dockerfile中更改卷：如果在声明了卷之后有任何构建步骤更改了卷中的数据，则这些更改的指令将无效。</li></ul><h3 id="WORKDIR"><a href="#WORKDIR" class="headerlink" title="WORKDIR"></a>WORKDIR</h3><p>格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WORKDIR &#x2F;path&#x2F;to&#x2F;workdir</span><br></pre></td></tr></table></figure><p>WORKDIR会设置工作目录并成为后续Dockerfile里的RUN, CMD, ENTRYPOINT, COPY 和 ADD 的当前路径，如果WORKDIR不存在，即使以后的Dockerfile指令中未使用它也将被创建。</p><p>例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">WORKDIR &#x2F;a</span><br><span class="line">WORKDIR b</span><br><span class="line">WORKDIR c</span><br><span class="line">RUN pwd</span><br></pre></td></tr></table></figure><p>最后pwd的路径为 /a/b/c</p><p>WORKDIR能解析在此之前ENV设置的环境变量，而且只能使用Dockerfile中显示的环境变量</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ENV DIRPATH &#x2F;path</span><br><span class="line">WORKDIR $DIRPATH&#x2F;$DIRNAME</span><br><span class="line">RUN pwd</span><br></pre></td></tr></table></figure><p>最后pwd的路径为 /path/$DIRNAME</p><h3 id="ARG"><a href="#ARG" class="headerlink" title="ARG"></a>ARG</h3><p>格式：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ARG &lt;name&gt;[&#x3D;&lt;default value&gt;]</span><br></pre></td></tr></table></figure><p>该ARG指令定义了一个变量，用户可以在构建时docker build使用带有–build-arg <varname>=<value> 标志的命令将其传递给构建器。如果用户指定了未在Dockerfile中定义的构建参数，则构建会输出警告。</p><p>例子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FROM busybox</span><br><span class="line">ARG user1&#x3D;someuser</span><br><span class="line">ARG buildno&#x3D;1</span><br></pre></td></tr></table></figure><p>如果ARG具有默认值，并且在构建时未传递任何值，那么构建器将使用默认值。即user1=someuser、buildno=1</p><p>一个ARG变量定义只能在Dockerfile构建的一个阶段内的那一行到结束范围内生效，简而言之就是ARG声明的那一刻到下一个FROM中间有效</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">FROM busybox</span><br><span class="line">RUN echo SETTINGS</span><br><span class="line">ARG SETTINGS</span><br><span class="line">RUN .&#x2F;run&#x2F;setup $SETTINGS</span><br><span class="line"></span><br><span class="line">FROM busybox</span><br><span class="line">RUN echo SETTINGS</span><br><span class="line">ARG SETTINGS</span><br><span class="line">RUN .&#x2F;run&#x2F;other $SETTINGS</span><br><span class="line"></span><br><span class="line">docker build --build-arg SETTINGS&#x3D;hello .</span><br><span class="line"></span><br><span class="line">执行结果为：</span><br><span class="line">第一阶段的FROM过程</span><br><span class="line">RUN echo SETTINGS</span><br><span class="line">ARG hello</span><br><span class="line">RUN .&#x2F;run&#x2F;setup hello</span><br><span class="line"></span><br><span class="line">第二阶段的FROM过程</span><br><span class="line">RUN echo SETTINGS</span><br><span class="line">ARG hello</span><br><span class="line">RUN .&#x2F;run&#x2F;other hello</span><br></pre></td></tr></table></figure><p>ARG在它被定义的构建阶段范围进行。要在多个阶段使用ARG，每个阶段都必须包含ARG指令。</p><p>ARG或ENV会指定RUN指令可用的变量。使用ENV指令定义的环境变量 始终会覆盖ARG同名指令。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">FROM ubuntu</span><br><span class="line">ARG CONT_IMG_VER</span><br><span class="line">ENV CONT_IMG_VER v1.0.0</span><br><span class="line">RUN echo $CONT_IMG_VER</span><br><span class="line"></span><br><span class="line">docker build --build-arg CONT_IMG_VER&#x3D;v2.0.1 .</span><br></pre></td></tr></table></figure><p>在这种情况下，该RUN指令将使用v1.0.0而不是用户传递的ARG：v2.0.1。此行为类似于Shell脚本，其中局部作用域的变量从其定义的角度覆盖作为参数传递或从环境继承的变量。</p><p>使用上面的示例，但使用不同的ENV规范，可以在ARG和ENV指令之间创建更有用的交互：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">FROM ubuntu</span><br><span class="line">ARG CONT_IMG_VER</span><br><span class="line">ENV CONT_IMG_VER $&#123;CONT_IMG_VER:-v1.0.0&#125;</span><br><span class="line">RUN echo $CONT_IMG_VER  &gt; &#x2F;haha</span><br><span class="line"></span><br><span class="line">docker build --build-arg CONT_IMG_VER&#x3D;v2.0.1 -t test:1.5 .</span><br><span class="line">docker run --name test --rm -itd test:1.5</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">docker exec -it test cat &#x2F;haha</span><br><span class="line">v2.0.1</span><br></pre></td></tr></table></figure><p>与ARG指令不同，ENV值始终保留在生成的镜像中。使用此Dockerfile示例，CONT_IMG_VER它仍然保留在映像中，但其值将是指令第3行中的默认设置ENV,而ENV是ARG在docker bulid构建时传的参数v2.0.1 。</p><p>在此示例中，变量扩展技术可以从命令行传递参数，并利用ENV指令将其保留在最终映像中 。</p><h2 id="相似指令对比"><a href="#相似指令对比" class="headerlink" title="相似指令对比"></a>相似指令对比</h2><h3 id="RUN-and-CMD"><a href="#RUN-and-CMD" class="headerlink" title="RUN and CMD"></a>RUN and CMD</h3><p>RUN是针对镜像，在镜像构建的时候运行命令并提交结果，一个Dockerfile可以有很多个RUN命令</p><p>CMD是针对容器，在镜像构建的时候不执行任何操作，而是在镜像启动后执行命令，一个Dockerfile即使有很多个CMD命令，也只生效最后一个(原因在下面解释)</p><h3 id="COPY-and-ADD"><a href="#COPY-and-ADD" class="headerlink" title="COPY and ADD"></a>COPY and ADD</h3><p>COPY能够将构建命令所在的主机本地的文件或目录，复制到镜像文件系统。</p><p>ADD指令不仅能够将构建命令所在的主机本地的文件或目录，而且能够将远程URL所对应的文件或目录，作为资源复制到镜像文件系统。</p><p>满足同等功能的情况下，推荐使用COPY指令。ADD指令更擅长读取本地tar文件并解压缩。而且由于因为路径、资源更改而导致缓存失效的情况出现，我们更应该尽量少用ADD，而改用使用RUN wget或RUN curl替代，并且把这一步骤尽可能地放在Dockerfile的后面位置。</p><h3 id="ENTRYPOINT-and-CMD组合执行的命令"><a href="#ENTRYPOINT-and-CMD组合执行的命令" class="headerlink" title="ENTRYPOINT and CMD组合执行的命令"></a>ENTRYPOINT and CMD组合执行的命令</h3><ul><li>Dockerfile应至少指定CMD或ENTRYPOINT命令之一。</li><li>使用容器作为可执行文件时应定义ENTRYPOINT </li><li>CMD应该用作ENTRYPOINT在容器中定义命令或执行临时命令的默认参数的方式。</li><li>当使用其他参数运行容器时，CMD 将被覆盖。</li></ul><p>ENTRYPOINT应该被当做docker的可执行程序，CMD应该被当做ENTRYPOINT的默认参数。</p><p>组合列表：以df命令为例</p><table><thead><tr><th>CMD/ENTRYPOINT</th><th>No ENTRYPOINT</th><th>ENTRYPOINT du -H</th><th>ENTRYPOINT [“du”, “-H”]</th></tr></thead><tbody><tr><td>No CMD</td><td>不允许</td><td>/bin/sh -c du -H</td><td>du -H</td></tr><tr><td>CMD [“df”, “-h”]</td><td>df -h</td><td>/bin/sh -c du -H</td><td>du -H df -h</td></tr><tr><td>CMD [“-h”, “-T”]</td><td>-h -T</td><td>/bin/sh -c du -H</td><td>du -H -h -T</td></tr><tr><td>CMD df -h</td><td>/bin/sh -c df -h</td><td>/bin/sh -c du -H</td><td>du -H /bin/sh -c df -h</td></tr></tbody></table><ul><li>如果 ENTRYPOINT 使用了 shell 模式，CMD 指令会被忽略。</li><li>如果 ENTRYPOINT 使用了 exec 模式，CMD 指定的内容被追加为 ENTRYPOINT 指定命令的参数。</li></ul><p>结论：一起使用ENTRYPOINT和CMD时，务必同时使用两个指令的exec形式，这一点很重要。尝试使用shell形式，或者混合匹配shell和exec形式几乎不会给您想要的结果。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>Dockerfile基本命令和写法格式都讲完了，下期主要讲Dockerfile的构建底层实现原理。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://docs.docker.com/engine/reference/builder/" target="_blank" rel="noopener">Dockerfile官方文档参考</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Dockerfile </tag>
            
            <tag> Docker </tag>
            
            <tag> Linux </tag>
            
            <tag> Devops </tag>
            
            <tag> 容器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Helm简介及阿里云安装部署</title>
      <link href="2020/06/21/helm/helm-install/"/>
      <url>2020/06/21/helm/helm-install/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近新项目要通过Helm部署，然后我发现生产环境使用的是阿里云托管型kubernetes(全部都是node节点，无Mater)没有安装Helm，貌似还要用阿里云企业镜像服务，但是我感觉应该没有这么坑，因为线下用的是自己搭建的集群，直接安装Helm搭建私人仓库即可用。</p><p>周末加个班学习下Helm到底是咋回事，虽然一直在使用命令部署，不过还没深入研究下。</p><h1 id="Helm简介"><a href="#Helm简介" class="headerlink" title="Helm简介"></a>Helm简介</h1><p>Helm官网解释</p><ul><li>Helm是查找，共享和使用为 Kubernetes而构建的软件的最佳方法。</li><li>Helm帮助您管理Kubernetes应用程序-Helm Charts帮助您定义，安装和升级最复杂的Kubernetes应用程序。</li><li>Helm是CNCF的一个毕业项目，由Helm社区维护。</li></ul><p>翻译还挺有意思的</p><ul><li>Helm→头盔/舵</li><li>Chart→图表</li><li>Release→版本</li></ul><p>看了官方定义后，我大概了解了下几个重要定义(有不对的地方请指教)</p><h2 id="Helm是用于管理Chart的工具"><a href="#Helm是用于管理Chart的工具" class="headerlink" title="Helm是用于管理Chart的工具"></a>Helm是用于管理Chart的工具</h2><p>Helm是可简化Kubernetes应用程序安装和管理的工具。可以将其视为Kubernetes的apt / yum / homebrew。</p><p>功能有如下几点：</p><ul><li>查找并使用打包为Helm Charts的流行软件在Kubernetes中运行</li><li>将您自己的应用程序共享为Helm Charts</li><li>创建Kubernetes应用程序的可复制构建</li><li>智能管理您的Kubernetes清单文件</li><li>管理Helm软件包的发布</li></ul><p>其中最为重要的一点：查找并使用打包为Helm Charts的流行软件在Kubernetes中运行</p><p>实际运作就是Helm渲染Chart包并与Kubernetes API通信，也可以变相理解为代替了kubectl的功能去与Kubernetes API通信(对于运维来说)</p><h2 id="Chart是预先配置的Kubernetes资源包。"><a href="#Chart是预先配置的Kubernetes资源包。" class="headerlink" title="Chart是预先配置的Kubernetes资源包。"></a>Chart是预先配置的Kubernetes资源包。</h2><p>Chart是包含至少两项内容的Helm软件包：</p><ul><li>软件包说明（Chart.yaml）</li><li>一个或多个模板，其中包含Kubernetes清单文件</li></ul><p>Chart包可以存储在磁盘上，也可以从远程Chart仓库中获取（例如Debian或RedHat软件包）</p><p>其中的重点就是Chart的模板文件的编写，有以下几个概念：</p><ul><li>模板生成清单文件，这些文件是Kubernetes可以理解的YAML格式的资源描述</li><li>Helm模板语言</li><li>使用值</li><li>使用模板的技巧</li></ul><h2 id="Release-是一个的运行实例的-chart，具有特定的组合配置。"><a href="#Release-是一个的运行实例的-chart，具有特定的组合配置。" class="headerlink" title="Release 是一个的运行实例的 chart，具有特定的组合配置。"></a>Release 是一个的运行实例的 chart，具有特定的组合配置。</h2><p>安装Chart后，Helm库将创建一个发行版来跟踪该安装。</p><p>单个Chart可以多次安装到同一群集中，并创建许多不同的发行版。例如，通过helm install使用不同的发行版名称运行3次，可以安装三个PostgreSQL数据库。</p><h2 id="Release-Number-Release-Version"><a href="#Release-Number-Release-Version" class="headerlink" title="Release Number (Release Version)"></a>Release Number (Release Version)</h2><p>单个版本可以多次更新。顺序计数器用于跟踪发布的变化。在第helm install一个发行版之后，发行版将具有 发行版号 1。每次升级或回滚发行版时，发行版号都会递增。</p><h1 id="Helm架构"><a href="#Helm架构" class="headerlink" title="Helm架构"></a>Helm架构</h1><p>了解了上面的定义，我继续学习了Helm的架构，Helm也是经典的C/S架构(我怎么发现和Docker架构似曾相识)</p><h2 id="Helm-Client-是用户的命令行客户端-俗称终端-。客户端负责以下部分："><a href="#Helm-Client-是用户的命令行客户端-俗称终端-。客户端负责以下部分：" class="headerlink" title="Helm Client 是用户的命令行客户端(俗称终端)。客户端负责以下部分："></a>Helm Client 是用户的命令行客户端(俗称终端)。客户端负责以下部分：</h2><ul><li>本地 chart 开发</li><li>管理存储库</li><li>与 Tiller 服务交互</li><li>发送要安装的 chart</li><li>查询有关发布的信息</li><li>请求升级或卸载现有 release</li></ul><h2 id="Tiller-Server-是一个集群内服务，与-Helm-客户端进行交互，并与-Kubernetes-API-服务进行交互。服务负责以下内容："><a href="#Tiller-Server-是一个集群内服务，与-Helm-客户端进行交互，并与-Kubernetes-API-服务进行交互。服务负责以下内容：" class="headerlink" title="Tiller Server 是一个集群内服务，与 Helm 客户端进行交互，并与 Kubernetes API 服务进行交互。服务负责以下内容："></a>Tiller Server 是一个集群内服务，与 Helm 客户端进行交互，并与 Kubernetes API 服务进行交互。服务负责以下内容：</h2><ul><li>监听来自 Helm 客户端的传入请求</li><li>结合 chart 和配置来构建发布</li><li>将 chart 安装到 Kubernetes 中，然后跟踪后续 release</li><li>通过与 Kubernetes 交互来升级和卸载 chart</li></ul><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><p>Helm 客户端使用 Go 语言编写，并使用 gRPC 协议套件与 Tiller 服务进行交互。</p><p>Tiller 服务端也用 Go 编写。它提供了一个与客户端连接的 gRPC 服务，它使用 Kubernetes 客户端库与 Kubernetes 进行通信。目前，该库使用 REST + JSON。</p><p>Tiller 服务将信息存储在位于 Kubernetes 内的 ConfigMaps 中。它不需要自己的数据库。</p><p>如有可能，配置文件用YAML编写。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>基本了解了Helm之后我终于明白了，只需要在k8s集群内装一个Helm服务端(tiller)，然后在集群内任何一台机器上安装Helm客户端，即可通过Helm控制整个集群。</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><p>由于线下Helm版本为2.16.3，我就在集群内安装相同的版本保持同步(在不了解新版的特性情况下不敢跨版本安装，怕了怕了)</p><ul><li>根据系统下载所需版本<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -L -o helm-v2.16.3-linux-amd64.tar.gz https:&#x2F;&#x2F;file.choerodon.com.cn&#x2F;kubernetes-helm&#x2F;v2.16.3&#x2F;helm-v2.16.3-linux-amd64.tar.gz</span><br></pre></td></tr></table></figure></li><li>解压压缩包（以linux-amd64为例）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf helm-v2.16.3-linux-amd64.tar.gz</span><br></pre></td></tr></table></figure><ul><li>将文件移动到PATH目录中（以linux-amd64为例）<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv linux-amd64&#x2F;helm &#x2F;usr&#x2F;bin&#x2F;helm</span><br></pre></td></tr></table></figure></li><li>安装服务端tiller</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">helm init --tiller-image registry.cn-hangzhou.aliyuncs.com&#x2F;acs&#x2F;tiller:v2.16.3</span><br><span class="line"></span><br><span class="line"># 初始化参数选择</span><br><span class="line"># 1. 如果你当前在容器服务集群节点上，默认已经有初始化完成的 tiller ，只需要初始化 client。可以使用 skip-refresh 命令避免访问 google Chart 源：</span><br><span class="line">helm init --client-only --skip-refresh</span><br><span class="line"># 2. 如果你当前在自建的 Kubernetes 集群节点上，并且希望避免访问 google Chart 源，可以使用以下命令：</span><br><span class="line">helm init --skip-refresh</span><br></pre></td></tr></table></figure><p>部署完成后helm version查看下信息</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">helm version</span><br><span class="line">Client: &amp;version.Version&#123;SemVer:&quot;v2.16.3&quot;, GitCommit:&quot;1ee0254c86d4ed6887327dabed7aa7da29d7eb0d&quot;, GitTreeState:&quot;clean&quot;&#125;</span><br><span class="line">Server: &amp;version.Version&#123;SemVer:&quot;v2.16.3&quot;, GitCommit:&quot;1ee0254c86d4ed6887327dabed7aa7da29d7eb0d&quot;, GitTreeState:&quot;clean&quot;&#125;</span><br></pre></td></tr></table></figure><h1 id="部署第一个项目"><a href="#部署第一个项目" class="headerlink" title="部署第一个项目"></a>部署第一个项目</h1><p>准备文件目录，格式内容如下</p><ul><li>一个Chart.yaml文件 </li><li>一个Templates文件目录(存放各个k8s object信息的yaml文件) </li><li>一个values.yaml </li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s ~]# tree</span><br><span class="line">.</span><br><span class="line">└── demo</span><br><span class="line">    ├── Chart.yaml</span><br><span class="line">    ├── templates</span><br><span class="line">    │   ├── deployment.yaml</span><br><span class="line">    │   ├── _helpers.tpl</span><br><span class="line">    │   └── service.yaml</span><br><span class="line">    └── values.yaml</span><br></pre></td></tr></table></figure><p>常用命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">部署</span><br><span class="line"></span><br><span class="line">helm install -n 容器名 文件目录路径  --values values文件路径 --namespace 命名空间</span><br><span class="line"></span><br><span class="line">[root@k8s ~]# helm install -n demo .&#x2F;demo&#x2F; --values .&#x2F;demo&#x2F;values.yaml --namespace default</span><br><span class="line"></span><br><span class="line">滚动更新</span><br><span class="line"></span><br><span class="line">[root@k8s ~]# helm upgrade  demo .&#x2F;demo&#x2F; --values .&#x2F;demo&#x2F;values.yaml --namespace default</span><br><span class="line"></span><br><span class="line">删除实例</span><br><span class="line"></span><br><span class="line">[root@k8s ~]# helm delete demo --purge</span><br><span class="line"></span><br><span class="line">查看实例历史记录</span><br><span class="line">[root@k8s ~# helm history demo</span><br><span class="line">REVISIONUPDATED                 STATUS    CHART           APP VERSIONDESCRIPTION     </span><br><span class="line">1       Sun Jun 21 14:46:34 2020SUPERSEDEDdemo-0.1.01.0        Install complete</span><br><span class="line">2       Sun Jun 21 15:20:46 2020DEPLOYED  demo-0.1.01.0        Upgrade complete</span><br></pre></td></tr></table></figure><h1 id="问题记录"><a href="#问题记录" class="headerlink" title="问题记录"></a>问题记录</h1><h2 id="server和client版本不同"><a href="#server和client版本不同" class="headerlink" title="server和client版本不同"></a>server和client版本不同</h2><p>我在生产环境安装时出现了server和client版本不同的情况。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@k8snode ~]# helm init --tiller-image registry.cn-hangzhou.aliyuncs.com&#x2F;acs&#x2F;tiller:v2.16.3</span><br><span class="line">Creating &#x2F;root&#x2F;.helm </span><br><span class="line">Creating &#x2F;root&#x2F;.helm&#x2F;repository </span><br><span class="line">Creating &#x2F;root&#x2F;.helm&#x2F;repository&#x2F;cache </span><br><span class="line">Creating &#x2F;root&#x2F;.helm&#x2F;repository&#x2F;local </span><br><span class="line">Creating &#x2F;root&#x2F;.helm&#x2F;plugins </span><br><span class="line">Creating &#x2F;root&#x2F;.helm&#x2F;starters </span><br><span class="line">Creating &#x2F;root&#x2F;.helm&#x2F;cache&#x2F;archive </span><br><span class="line">Creating &#x2F;root&#x2F;.helm&#x2F;repository&#x2F;repositories.yaml </span><br><span class="line">Adding stable repo with URL: https:&#x2F;&#x2F;kubernetes-charts.storage.googleapis.com </span><br><span class="line">Adding local repo with URL: http:&#x2F;&#x2F;127.0.0.1:8879&#x2F;charts </span><br><span class="line">$HELM_HOME has been configured at &#x2F;root&#x2F;.helm.</span><br><span class="line">Warning: Tiller is already installed in the cluster.</span><br><span class="line"></span><br><span class="line">[root@k8snode ~]# helm version</span><br><span class="line">Client: &amp;version.Version&#123;SemVer:&quot;v2.16.3&quot;, GitCommit:&quot;1ee0254c86d4ed6887327dabed7aa7da29d7eb0d&quot;, GitTreeState:&quot;clean&quot;&#125;</span><br><span class="line">Server: &amp;version.Version&#123;SemVer:&quot;v2.14.1&quot;, GitCommit:&quot;5270352a09c7e8b6e8c9593002a73535276507c0&quot;, GitTreeState:&quot;clean&quot;</span><br></pre></td></tr></table></figure><p>我还很纳闷为什么提示Tiller is already installed in the cluster.原来阿里云托管型K8S已经装了tiller，然后我参照阿里云官网文档升级了tiller即可</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@k8snode ~]# helm init --tiller-image registry.cn-hangzhou.aliyuncs.com&#x2F;acs&#x2F;tiller:v2.16.3 --upgrade</span><br><span class="line">$HELM_HOME has been configured at &#x2F;root&#x2F;.helm.</span><br><span class="line"></span><br><span class="line">Tiller (the Helm server-side component) has been updated to registry.cn-hangzhou.aliyuncs.com&#x2F;acs&#x2F;tiller:v2.16.3 .</span><br><span class="line"></span><br><span class="line">[root@k8snode ~]# helm version</span><br><span class="line">Client: &amp;version.Version&#123;SemVer:&quot;v2.16.3&quot;, GitCommit:&quot;1ee0254c86d4ed6887327dabed7aa7da29d7eb0d&quot;, GitTreeState:&quot;clean&quot;&#125;</span><br><span class="line">Server: &amp;version.Version&#123;SemVer:&quot;v2.16.3&quot;, GitCommit:&quot;1ee0254c86d4ed6887327dabed7aa7da29d7eb0d&quot;, GitTreeState:&quot;clean&quot;&#125;</span><br></pre></td></tr></table></figure><h2 id="Helm拉不到阿里云内部的镜像"><a href="#Helm拉不到阿里云内部的镜像" class="headerlink" title="Helm拉不到阿里云内部的镜像"></a>Helm拉不到阿里云内部的镜像</h2><p>第一个项目启动就报错</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Failed to apply default image tag &quot;registry.cn-beijing.aliyuncs.com&#x2F;xxx&quot;: couldn&#39;t parse image reference &quot;registry.cn-beijing.aliyuncs.com&#x2F;xxx&quot;: invalid reference format</span><br></pre></td></tr></table></figure><p>helm拉取镜像的格式要求不对 </p><p>镜像号名称应为 testv1这种类型 不建议带有 {. / - =} 这类字符</p><h2 id="阿里云免密插件"><a href="#阿里云免密插件" class="headerlink" title="阿里云免密插件"></a>阿里云免密插件</h2><p>继续启动，还是报错，我服了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Back-off pulling image &quot;registry.cn-beijing.aliyuncs.com&#x2F;gyjx&#x2F;blank-demo:2020.6.19-160604-master-2d82100f&quot;</span><br></pre></td></tr></table></figure><p>what the fuck?我用docker pull 都可以 为什么helm不行，后来问了下阿里云客服才发现helm是集群层面需要配置认证信息，只在节点上login是不行的，而且默认的拉取镜像的命名空间为default，如果需要所有命名空间都拉镜像需要添加一个配置项。</p><p>阿里云有个配置项叫acr-configuration  位于namespace=kube-system 的ConfigMap下。</p><p>配置文件格式如下</p><table><thead><tr><th>配置项</th><th>配置项说明</th><th>默认值</th></tr></thead><tbody><tr><td>service-account</td><td>使免密插件作用于指定的服务账号</td><td>default 若要配置多个请以逗号分隔， 若为“*”， 表示支持Namespace下的所有ServiceAccount</td></tr><tr><td>acr-registry-info</td><td>容器镜像的实例信息数组，yaml多行字符串格式，每个实例以三元组方式配置。</td><td>空，表示免密拉取本地Region的默认容器镜像实例仓库。</td></tr><tr><td>watch-namespace</td><td>期望能免密拉取镜像的Namespace。</td><td>default 说明 当取值为all时，表示期望所有Namespace都能免密拉取。如果需要配置多个Namespace时，以逗号分隔。</td></tr><tr><td>expiring-threshold</td><td>本地Cache Token过期阈值。</td><td>15m（建议使用15m）。</td></tr></tbody></table><h2 id="我一共添加了4对key-value到acr-configuration"><a href="#我一共添加了4对key-value到acr-configuration" class="headerlink" title="我一共添加了4对key-value到acr-configuration"></a>我一共添加了4对key-value到acr-configuration</h2><table><thead><tr><th>key</th><th>value</th></tr></thead><tbody><tr><td>watch-namespace</td><td>all</td></tr><tr><td>expiring-threshold</td><td>15m</td></tr><tr><td>acr-registry-info</td><td>- instanceId: “”</td></tr><tr><td>service-account</td><td>default</td></tr></tbody></table><p>注意！！！配置完成后</p><p>需要升级一个组件aliyun-acr-credential-helper到v20.03.16.0-36d5d7e-aliyun</p><p>否则免密插件的配置不生效</p><h1 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h1><p>周末加班还是比较有收获的，既学习了新的知识，又完成了部分下周上线前的部署准备工作，关于Helm的更多用法和Template的模板构建我会在后期补上。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://helm.sh/docs/" target="_blank" rel="noopener">Helm官方文档</a></p><p><a href="https://github.com/helm/helm" target="_blank" rel="noopener">Helm项目说明</a></p><p><a href="https://help.aliyun.com/document_detail/159750.html?spm=a2c4g.11186623.6.578.6cf01f77cZYYiC" target="_blank" rel="noopener">阿里云使用免密插件拉取容器镜像</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Helm </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
            <tag> Helm </tag>
            
            <tag> 阿里云 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>部署Mysql监控工具pmm</title>
      <link href="2020/06/18/mysql/mysql-pmm/"/>
      <url>2020/06/18/mysql/mysql-pmm/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>测试人员需要对项目进行压测，有需求查看mysql在高并发的场景下各个指标数据，我问了下公司的dba，推荐pmm这个工具</p><h1 id="要求"><a href="#要求" class="headerlink" title="要求"></a>要求</h1><ul><li>mysql服务端需要以下要求：</li></ul><p>centos：7.6</p><p>mysql:5.7.28</p><p>假设ip是172.31.26.11</p><ul><li>grafana服务器需要以下要求</li></ul><p>centos：7.6</p><p>docker：19.03</p><p>假设ip是172.31.26.12</p><p>建议grafana和mysql服务端放在不同的机器上，因为一个grafana可以监控好几个mysql服务端指标</p><h1 id="安装grafana服务器"><a href="#安装grafana服务器" class="headerlink" title="安装grafana服务器"></a>安装grafana服务器</h1><p>一共就3步</p><p>拉镜像</p><p>创建持久化存储卷</p><p>创建容器的运行实例</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker  pull  percona&#x2F;pmm-server:latest</span><br><span class="line">docker  create -v &#x2F;opt&#x2F;prometheus&#x2F;data -v &#x2F;opt&#x2F;consul-data -v &#x2F;var&#x2F;lib&#x2F;mysql  -v &#x2F;var&#x2F;lib&#x2F;grafana --name  pmm-data   percona&#x2F;pmm-server:latest  &#x2F;bin&#x2F;true</span><br><span class="line">docker  run  -d -p 80:80 --volumes-from pmm-data --name pmm-server --restart always  percona&#x2F;pmm-server:latest</span><br></pre></td></tr></table></figure><p>注意创建容器的时候要考虑到80端口是否被占用</p><h1 id="安装percona到mysql服务端"><a href="#安装percona到mysql服务端" class="headerlink" title="安装percona到mysql服务端"></a>安装percona到mysql服务端</h1><p>下载percona到mysql服务端，如果有多个mysql服务端，需要每个都安装percona</p><p>pmm-admin config  –server 指向grafana服务器的ip</p><p>–client-name 添加你的主机名，如果不定义就是本机的hostname</p><p>pmm-admin  add 指向本机（mysql服务端）ip</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;www.percona.com&#x2F;downloads&#x2F;pmm-client&#x2F;pmm-client-1.1.1&#x2F;binary&#x2F;tarball&#x2F;pmm-client-1.1.1.tar.gz</span><br><span class="line">tar -zxvf pmm-client-1.1.1.tar.gz</span><br><span class="line">cd pmm-client-1.1.1</span><br><span class="line">.&#x2F;install</span><br><span class="line">pmm-admin config  --server 172.31.26.12 --client-name dev-mysql </span><br><span class="line">pmm-admin  add  mysql  --user  root  --password  &#39;123456&#39;    --host  172.31.26.11 --port  3306</span><br></pre></td></tr></table></figure><p>添加完成后打开<a href="http://172.31.26.12:80" target="_blank" rel="noopener">http://172.31.26.12:80</a></p><p>选择Mysql Overview看Mysql监控大盘即可</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Mysql/pmm/pmm.jpg"  alt="pmm.jpg"></p><h1 id="报错"><a href="#报错" class="headerlink" title="报错"></a>报错</h1><p>在创建容器的时候报错</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# docker  run  -d -p 80:80 --volumes-from pmm-data --name pmm-server --restart always  percona&#x2F;pmm-server:latest  </span><br><span class="line">e6b329a2617e13ab96d7a3a99716e1c61a2680b26682a71d1631bc17828ec739</span><br><span class="line">docker: Error response from daemon: driver failed programming external connectivity on endpoint pmm-server (7cd37db8f2b05e9232058ded5237c7e5tables --wait -t nat -A DOCKER -p tcp -d 0&#x2F;0 --dport 80 -j DNAT --to-destination 172.17.0.4:80 ! -i docker0: iptables: No chain&#x2F;target&#x2F;match</span><br><span class="line"> (exit status 1)).</span><br></pre></td></tr></table></figure><p>百度了一下，大概原因就是使用的centos7服务器，在部署docker的过程中，因端口问题有启停firewalld服务，在centos7里使用firewalld代替了iptables。在启动firewalld之后，iptables还会被使用，属于引用的关系。所以在docker run的时候，iptables list里没有docker chain，重启docker engine服务后会被加入到iptables list里面。（有必要深入研究一下docker network）</p><hr><p>解决方法</p><p>大部分说都是重启docker，我感觉很不靠谱，如果是生产环境，谁敢重启docker啊，然后再找了一下docker官网的排错指南，发现了这个问题。</p><p>答案特别简单,很有可能你意见关闭了防火墙，那么打开后再执行创建容器的命令,创建成功再关闭防火墙</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# systemctl start firewalld</span><br><span class="line">[root@localhost ~]# docker  run  -d -p 80:80 --volumes-from pmm-data --name pmm-server --restart always  percona&#x2F;pmm-server:latest  </span><br><span class="line">e6b329a2617e13ab96d7a3a99716e1c61a2680b26682a71d1631bc17828ec739</span><br><span class="line">[root@localhost ~]# systemctl stop firewalld</span><br></pre></td></tr></table></figure><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p> <a href="https://success.docker.com/article/iptables-error-when-starting-container-with-docker-run" target="_blank" rel="noopener">iptables error when starting container with docker</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
            <tag> Pmm </tag>
            
            <tag> Grafana </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>生产环境部署高可用RocketMQ</title>
      <link href="2020/06/18/rocketmq/rocketmq-install/"/>
      <url>2020/06/18/rocketmq/rocketmq-install/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>阿里云企业级RocketMQ费用较高，不如自建MQ，这个任务又交给我了，由于我正好认识一个RocketMQ社区的大佬，参与MQ的改良，找大佬取了下经。</p><h1 id="RocketMQ介绍"><a href="#RocketMQ介绍" class="headerlink" title="RocketMQ介绍"></a>RocketMQ介绍</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>RocketMQ 是一款分布式、队列模型的消息中间件，具有以下特点： </p><p>能够保证严格的消息顺序 提供丰富的消息拉取模式 高效的订阅者水平扩展能力 实时的消息订阅机制 亿级消息堆积能力 </p><p>选用理由： </p><ul><li>强调集群无单点，可扩展，任意一点高可用，水平可扩展。 </li><li>海量消息堆积能力，消息堆积后，写入低延迟。 </li><li>支持上万个队列 </li><li>消息失败重试机制 </li><li>消息可查询 </li><li>开源社区活跃 </li><li>成熟度（经过双十一考验） </li></ul><h2 id="关键概念"><a href="#关键概念" class="headerlink" title="关键概念"></a>关键概念</h2><h3 id="主题与标签"><a href="#主题与标签" class="headerlink" title="主题与标签"></a>主题与标签</h3><p>主题 Tpoic：第一级消息类型，书的标题 </p><p>标签 Tags：第二级消息类型，书的目录，可以基于 Tag 做消息过滤 </p><p>例如： </p><ul><li>主题： 订单交易 </li><li>标签：<br>订单交易-创建<br>订单交易-付款<br>订单交易-完成 </li></ul><h3 id="发送与订阅群组"><a href="#发送与订阅群组" class="headerlink" title="发送与订阅群组"></a>发送与订阅群组</h3><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/RocketMQ/rocketmq.jpg"  alt="rocketmq.jpg"></p><p>生产组：用于消息的发送。 </p><p>消费组：用于消息的订阅处理。 </p><p>生产组和消费组，方便扩缩机器，增减处理能力，集群组的名字，用于标记用途中的一 员。每次只会随机的发给每个集群中的一员。 </p><h1 id="RocketMQ-集群方式"><a href="#RocketMQ-集群方式" class="headerlink" title="RocketMQ 集群方式"></a>RocketMQ 集群方式</h1><p>推荐的几种 Broker 集群部署方式，这里的 Slave 不可写，但可读，类似于 Mysql 主备方式。 </p><h2 id="单个-Master"><a href="#单个-Master" class="headerlink" title="单个 Master"></a>单个 Master</h2><p>这种方式风险较大，一旦Broker重启或者宕机时，会导致整个服务不可用，不建议线上环境使用。 </p><h2 id="多-Master-模式"><a href="#多-Master-模式" class="headerlink" title="多 Master 模式"></a>多 Master 模式</h2><p>一个集群无 Slave，全是 Master，例如 2 个 Master 或者 3 个 Master    </p><ul><li>优点：配置简单，单个 Master 宕机或重启维护对应用无影响，在磁盘配置为 RAID10 时，即使机器宕机不可恢复情况下，由与 RAID10 磁盘非常可靠，消息也不会丢（异步刷盘丢失少量消息，同步刷盘一条不丢）。性能最高。     </li><li>缺点：单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息 实时性会受到受到影响。   </li></ul><p>启动方式：</p><ul><li>先启动 NameServer    </li><li>在机器 A，启动第一个 Master    </li><li>在机器 B，启动第二个 Master </li></ul><h2 id="多-Master-多-Slave-模式，异步复制"><a href="#多-Master-多-Slave-模式，异步复制" class="headerlink" title="多 Master 多 Slave 模式，异步复制"></a>多 Master 多 Slave 模式，异步复制</h2><p>   每个 Master 配置一个 Slave，有多对 Master-Slave，HA 采用异步复制方式，主备有短 暂消息延迟，毫秒级。</p><ul><li>优点：即使磁盘损坏，消息丢失的非常少，且消息实时性不会受影响，因为 Master 宕 机后，消费者仍然可以从 Slave 消费，此过程对应用透明。不需要人工干预。性能同多 Master 模式几乎一样。    </li><li>缺点：Master 宕机，磁盘损坏情况，会丢失少量消息。  </li></ul><p>启动方式：</p><ul><li>先启动 NameServer    </li><li>在机器 A，启动第一个 Master   </li><li>在机器 B，启动第二个 Master    </li><li>在机器 C，启动第一个 Slave    </li><li>在机器 D，启动第二个 Slave </li></ul><h2 id="多-Master-多-Slave-模式，同步双写"><a href="#多-Master-多-Slave-模式，同步双写" class="headerlink" title="多 Master 多 Slave 模式，同步双写"></a>多 Master 多 Slave 模式，同步双写</h2><p>   每个 Master 配置一个 Slave，有多对 Master-Slave，HA 采用同步双写方式，主备都写 成功，向应用返回成功。   </p><ul><li>优点：数据与服务都无单点，Master 宕机情况下，消息无延迟，服务可用性与数据可 用性都非常高    </li><li>缺点：性能比异步复制模式略低，大约低 10%左右，发送单个消息的 RT 会略高。目 前主宕机后，备机不能自动切换为主机，后续会支持自动切换功能。 </li></ul><p>启动方式：  </p><ul><li>先启动 NameServer    </li><li>在机器 A，启动第一个 Master    </li><li>在机器 B，启动第二个 Master    </li><li>在机器 C，启动第一个 Slave    </li><li>在机器 D，启动第二个 Slave    </li></ul><p>以上 Broker 与 Slave 配对是通过指定相同的 brokerName 参数来配对，Master 的 BrokerId 必须是 0，Slave 的 BrokerId 必须是大与 0 的数。另外一个 Master 下面可以挂 载多个 Slave，同一 Master 下的多个 Slave 通过指定不同的 BrokerId 来区分。 </p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>MQ每种部署方式都有优缺点，不过我们生产环境的业务是需要全程无人干预，不考虑性能情况，希望MQ高可用，做好监控报警规则即可。</p><p>综上我选择 多 Master 多 Slave 模式，异步复制模式</p><h1 id="RocketMQ部署异步复制模式"><a href="#RocketMQ部署异步复制模式" class="headerlink" title="RocketMQ部署异步复制模式"></a>RocketMQ部署异步复制模式</h1><p>部署环境双主双从异步复制，由于生产环境机器只配备了2台高性能主机，16c 32g，我准备做一个伪集群。</p><h2 id="服务器环境"><a href="#服务器环境" class="headerlink" title="服务器环境"></a>服务器环境</h2><table><thead><tr><th>IP</th><th>角色</th></tr></thead><tbody><tr><td>172.31.26.22</td><td>nameServer1,broker-a,broker-b-slave</td></tr><tr><td>172.31.26.23</td><td>nameServer2,broker-b,broker-a-slave</td></tr></tbody></table><h2 id="安装环境"><a href="#安装环境" class="headerlink" title="安装环境"></a>安装环境</h2><table><thead><tr><th>需求</th><th>版本</th></tr></thead><tbody><tr><td>操作系统</td><td>centos7.6</td></tr><tr><td>JDK</td><td>1.8</td></tr><tr><td>RocketMQ版本</td><td>rocketmq-all-4.3.2-bin-release.zip</td></tr><tr><td>RocketMQ控制台</td><td>rocketmq-console-ng-1.0.0.jar</td></tr><tr><td>RocketMQ目录</td><td>/opt</td></tr><tr><td>RocketMQ日志</td><td>/opt/rocketmq-all-4.3.2-bin-release/logs/</td></tr><tr><td>时间同步</td><td>ntpdate ntp1.aliyun.com</td></tr></tbody></table><p>MQ安装包及控制台链接如下：</p><p>链接：<a href="https://pan.baidu.com/s/1OO6uPNQYasYRa0NRrjwDwQ" target="_blank" rel="noopener">https://pan.baidu.com/s/1OO6uPNQYasYRa0NRrjwDwQ</a><br>提取码：1997<br>复制这段内容后打开百度网盘手机App，操作更方便哦</p><h2 id="部署过程"><a href="#部署过程" class="headerlink" title="部署过程"></a>部署过程</h2><p>将rocketmq-all-4.3.2-bin-release.zip、rocketmq-console-ng-1.0.0.jar放到任意一台服务器上，配置完成然后分发到其他服务器上即可。</p><h3 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-26-22 ~]# cd &#x2F;opt&#x2F;</span><br><span class="line">[root@VM-26-22 ~]# unzip rocketmq-all-4.3.2-bin-release.zip</span><br></pre></td></tr></table></figure><h3 id="修改jvm启动参数"><a href="#修改jvm启动参数" class="headerlink" title="修改jvm启动参数"></a>修改jvm启动参数</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-26-22 ~]# cd &#x2F;opt&#x2F;rocketmq-all-4.3.2-bin-release&#x2F;bin</span><br><span class="line">[root@VM-26-22 bin]# tree</span><br><span class="line">.</span><br><span class="line">├── cachedog.sh</span><br><span class="line">├── cleancache.sh</span><br><span class="line">├── cleancache.v1.sh</span><br><span class="line">├── mqadmin</span><br><span class="line">├── mqadmin.cmd</span><br><span class="line">├── mqadmin.xml</span><br><span class="line">├── mqbroker</span><br><span class="line">├── mqbroker.cmd</span><br><span class="line">├── mqbroker.numanode0</span><br><span class="line">├── mqbroker.numanode1</span><br><span class="line">├── mqbroker.numanode2</span><br><span class="line">├── mqbroker.numanode3</span><br><span class="line">├── mqbroker.xml</span><br><span class="line">├── mqnamesrv</span><br><span class="line">├── mqnamesrv.cmd</span><br><span class="line">├── mqnamesrv.xml</span><br><span class="line">├── mqshutdown</span><br><span class="line">├── mqshutdown.cmd</span><br><span class="line">├── os.sh</span><br><span class="line">├── play.cmd</span><br><span class="line">├── play.sh</span><br><span class="line">├── README.md</span><br><span class="line">├── runbroker.cmd</span><br><span class="line">├── runbroker.sh</span><br><span class="line">├── runserver.cmd</span><br><span class="line">├── runserver.sh</span><br><span class="line">├── setcache.sh</span><br><span class="line">├── startfsrv.sh</span><br><span class="line">├── tools.cmd</span><br><span class="line">└── tools.sh</span><br></pre></td></tr></table></figure><p>找到 runserver.sh 和broker.sh<br>查看系统参数</p><p>由于我不太懂jvm调优，但是大佬说32g的机器运行1个namesrv和2个borker就可以用官方自带的配置，不过以后我对这个参数调优会研究一下，先这么装吧。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim runserver.sh</span><br><span class="line">-server -Xms4g -Xmx4g -Xmn2g</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vim runbroker.sh</span><br><span class="line">-server -Xms8g -Xmx8g -Xmn4g</span><br></pre></td></tr></table></figure><h3 id="修改broker-conf"><a href="#修改broker-conf" class="headerlink" title="修改broker.conf"></a>修改broker.conf</h3><p>一共有4个配置文件，现在我们一次性配置好,由于有一些默认配置，不需要修改的我就没有列上，如果对消息队列自动开启topic及调整消息大小等有要求可以自行百度添加这些参数。</p><p>下面的配置的IP根据实际IP替换即可</p><p>注意：本配置默认不自动创建topic，需要手动添加</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-26-22 ~]# cd &#x2F;opt&#x2F;rocketmq-all-4.3.2-bin-release&#x2F;conf&#x2F;2m-2s-async</span><br><span class="line">[root@VM-26-22 2m-2s-async]# tree</span><br><span class="line">.</span><br><span class="line">├── broker-a.properties</span><br><span class="line">├── broker-a-s.properties</span><br><span class="line">├── broker-b.properties</span><br><span class="line">└── broker-b-s.properties</span><br></pre></td></tr></table></figure><hr><p>主节点broker配置</p><p>vim broker-a.properties</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">brokerClusterName&#x3D;DefaultCluster</span><br><span class="line">#broker名字，注意此处不同的配置文件填写的不一样</span><br><span class="line">brokerName&#x3D;broker-a</span><br><span class="line">brokerIP1&#x3D;172.31.26.22</span><br><span class="line">#nameServer 地址，分号分割 </span><br><span class="line">namesrvAddr&#x3D;172.31.26.22:9876;172.31.26.23:9876 </span><br><span class="line">#0 表示 Master，&gt;0 表示 Slave </span><br><span class="line">brokerId&#x3D;0 </span><br><span class="line">#Broker 对外服务的监听端口</span><br><span class="line">listenPort&#x3D;10911 </span><br><span class="line">#删除文件时间点，默认凌晨 4 点 </span><br><span class="line">deleteWhen&#x3D;04 </span><br><span class="line">#文件保留时间，默认 48 小时 </span><br><span class="line">fileReservedTime&#x3D;24</span><br><span class="line">#存储路径 </span><br><span class="line">storePathRootDir&#x3D;&#x2F;opt&#x2F;rocketmq-all-4.3.2-bin-release&#x2F;store-a </span><br><span class="line">#Broker的角色</span><br><span class="line">brokerRole&#x3D;Master </span><br><span class="line">#刷盘方式  ASYNC_FLUSH  异步刷盘  SYNC_FLUSH  同步刷盘 </span><br><span class="line">flushDiskType&#x3D;ASYNC_FLUSH</span><br></pre></td></tr></table></figure><p>vim broker-b.properties</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">brokerClusterName&#x3D;DefaultCluster</span><br><span class="line">brokerName&#x3D;broker-b</span><br><span class="line">brokerIP1&#x3D;172.31.26.23</span><br><span class="line">namesrvAddr&#x3D;172.31.26.22:9876;172.31.26.23:9876 </span><br><span class="line">brokerId&#x3D;0</span><br><span class="line">deleteWhen&#x3D;04</span><br><span class="line">fileReservedTime&#x3D;24</span><br><span class="line">brokerRole&#x3D;Master</span><br><span class="line">flushDiskType&#x3D;ASYNC_FLUSH</span><br><span class="line">listenPort&#x3D;10911</span><br><span class="line">storePathRootDir&#x3D;&#x2F;opt&#x2F;rocketmq-all-4.3.2-bin-release&#x2F;store-b</span><br></pre></td></tr></table></figure><hr><p>从节点broker配置</p><p>vim broker-a-s.properties</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">brokerClusterName&#x3D;DefaultCluster</span><br><span class="line">brokerIP1&#x3D;172.31.26.23</span><br><span class="line">namesrvAddr&#x3D;172.31.26.22:9876;172.31.26.23:9876 </span><br><span class="line">brokerName&#x3D;broker-a</span><br><span class="line">brokerId&#x3D;1</span><br><span class="line">deleteWhen&#x3D;04</span><br><span class="line">fileReservedTime&#x3D;24</span><br><span class="line">brokerRole &#x3D; SLAVE</span><br><span class="line">flushDiskType&#x3D;ASYNC_FLUSH</span><br><span class="line">listenPort&#x3D;10921</span><br><span class="line">storePathRootDir&#x3D;&#x2F;opt&#x2F;rocketmq-all-4.3.2-bin-release&#x2F;store-a</span><br></pre></td></tr></table></figure><p>vim broker-b-s.properties</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">brokerClusterName&#x3D;DefaultCluster</span><br><span class="line">brokerIP1&#x3D;172.31.26.22</span><br><span class="line">namesrvAddr&#x3D;172.31.26.22:9876;172.31.26.23:9876 </span><br><span class="line">brokerName&#x3D;broker-b</span><br><span class="line">brokerId&#x3D;1</span><br><span class="line">deleteWhen&#x3D;04</span><br><span class="line">fileReservedTime&#x3D;24</span><br><span class="line">brokerRole &#x3D; SLAVE</span><br><span class="line">flushDiskType&#x3D;ASYNC_FLUSH</span><br><span class="line">listenPort&#x3D;10921</span><br><span class="line">storePathRootDir&#x3D;&#x2F;opt&#x2F;rocketmq-all-4.3.2-bin-release&#x2F;store-b</span><br></pre></td></tr></table></figure><h3 id="创建日志目录并分发"><a href="#创建日志目录并分发" class="headerlink" title="创建日志目录并分发"></a>创建日志目录并分发</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-26-22 ~]#cd &#x2F;opt&#x2F;rocketmq-all-4.3.2-bin-release&#x2F;</span><br></pre></td></tr></table></figure><p>修改完成后将mq所有文件夹拷到每一台服务器上</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-26-22 ~]#scp -r &#x2F;opt&#x2F;rocketmq-all-4.3.2-bin-release  root@172.31.26.23:&#x2F;opt&#x2F;</span><br></pre></td></tr></table></figure><h3 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h3><p>启动方式参考上面所说的,由于部署方式是伪集群，所以将机器C、D的从节点放到B、A机器上运行。</p><ul><li>先启动 172.31.26.22、172.31.26.23的NameServer    </li><li>在机器 172.31.26.22，启动第一个 broker-a   </li><li>在机器 172.31.26.23，启动第二个 broker-b    </li><li>在机器 172.31.26.23，启动第一个 broker-a-s    </li><li>在机器 172.31.26.22，启动第二个 broker-b-s </li><li>在机器 172.31.26.22，启动rocketmq-console-ng-1.0.0.jar</li></ul><p>先进入2台服务器分别启动NameServer </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;rocketmq-all-4.3.2-bin-release&#x2F;bin</span><br><span class="line">nohup sh mqnamesrv &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>在机器172.31.26.22 执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;rocketmq-all-4.3.2-bin-release&#x2F;bin</span><br><span class="line">nohup sh mqbroker -c ..&#x2F;conf&#x2F;2m-2s-async&#x2F;broker-a.properties -n&quot;172.31.26.22:9876;172.31.26.23:9876&quot; &gt; ..&#x2F;logs&#x2F;broker-a.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>在机器172.31.26.23 执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;rocketmq-all-4.3.2-bin-release&#x2F;bin</span><br><span class="line">nohup sh mqbroker -c ..&#x2F;conf&#x2F;2m-2s-async&#x2F;broker-b.properties -n&quot;172.31.26.22:9876;172.31.26.23:9876&quot; &gt; ..&#x2F;logs&#x2F;broker-b.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>在机器172.31.26.23 执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;rocketmq-all-4.3.2-bin-release&#x2F;bin</span><br><span class="line">nohup sh mqbroker -c ..&#x2F;conf&#x2F;2m-2s-async&#x2F;broker-a-s.properties -n&quot;172.31.26.22:9876;172.31.26.23:9876&quot; &gt; ..&#x2F;logs&#x2F;broker-a.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>在机器172.31.26.22 执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt&#x2F;rocketmq-all-4.3.2-bin-release&#x2F;bin</span><br><span class="line">nohup sh mqbroker -c ..&#x2F;conf&#x2F;2m-2s-async&#x2F;broker-b-s.properties -n&quot;172.31.26.22:9876;172.31.26.23:9876&quot; &gt; ..&#x2F;logs&#x2F;broker-b.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>在机器172.31.26.22 找到rocketmq-console-ng-1.0.0.jar的目录 执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup java -jar rocketmq-console-ng-1.0.0.jar --server.port&#x3D;8080 --rocketmq.config.namesrvAddr&#x3D;&#39;172.31.26.22:9876;172.31.26.23:9876&#39; &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>安装完成打开 <a href="http://172.31.26.22:8080" target="_blank" rel="noopener">http://172.31.26.22:8080</a> 即可看到MQ控制台<br><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/RocketMQ/rocketmq-console.jpg"  alt="rocketmq-console.jpg"></p><h1 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h1><p>至此生产环境MQ搭建完成，本篇还有参数调优的方面没有介绍，而且部署方式也是伪集群，不是真正的高可用，如果有资源的话最好每台机器都部署一个broker，最后附上大佬博客，在此感谢。</p><p><a href="http://wuwenliang.net/" target="_blank" rel="noopener">http://wuwenliang.net/</a></p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="http://wuwenliang.net/2019/01/09/%E8%B7%9F%E6%88%91%E5%AD%A6RocketMQ-1-1-%E4%B9%8B%E5%AE%89%E8%A3%85RocketMQ/" target="_blank" rel="noopener">跟我学RocketMQ</a></p><p><a href="https://rocketmq.apache.org/docs/quick-start/" target="_blank" rel="noopener">Apache-RocketMQ</a></p><p><a href="https://github.com/apache/rocketmq/tree/master/docs/cn" target="_blank" rel="noopener">Github-RocketMQ</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> RocketMQ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RocketMQ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kubernetes可视化界面及监控安装</title>
      <link href="2020/06/17/kubernetes/Kubernetes-dashboard/"/>
      <url>2020/06/17/kubernetes/Kubernetes-dashboard/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>刚刚部署完压测环境kubernertes(以下简称k8s),测试人员需要对项目进行压测，我需要组装一个监控系统帮助测试人员更好地测试个项目性能，百度了很多方案，目前选择了Kubernetes-dashboard+heapster+influxdb+grafana这种方案。</p><h1 id="要求说明"><a href="#要求说明" class="headerlink" title="要求说明"></a>要求说明</h1><table><thead><tr><th>项目</th><th>版本号</th><th>targetPort</th><th>nodePort</th></tr></thead><tbody><tr><td>kubernetes</td><td>1.15</td><td></td><td></td></tr><tr><td>kubernetes-dashboard</td><td>v1.10.1</td><td>9090</td><td>32666</td></tr><tr><td>heapster-amd64</td><td>v1.5.4</td><td>8082</td><td></td></tr><tr><td>heapster-grafana-amd64</td><td>v5.0.4</td><td>3000</td><td>31234</td></tr><tr><td>heapster-influxdb-amd64</td><td>v1.5.2</td><td>8086</td><td>30444</td></tr></tbody></table><p>确保nodeport在整个k8s集群内唯一，版本号k8s和kubernetes-dashboard 有一些对应关系</p><p>kubernetes-dashboard的这个版本我没有做权限控制，比较麻烦，如果需要</p><p>heapster-grafana-amd64 是为了进一步监控每个容器的cpu、内存等更为具体的使用情况，如果你只需要kubernetes-dashboard的基础监控（页面上直观看到）那么只用装heapster-influxdb-amd64和heapster-amd64</p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><h2 id="Kubernetes-dashboard"><a href="#Kubernetes-dashboard" class="headerlink" title="Kubernetes-dashboard"></a>Kubernetes-dashboard</h2><p>Kubernetes Dashboard 是 Kubernetes 集群的基于 Web 的通用 UI。它允许用户管理在群集中运行的应用程序并对其进行故障排除，以及管理群集本身。</p><p>由于Kubernetes API版本之间的重大更改，某些功能可能无法在仪表板中正常运行，这也导致了kubernetes-dashboard的兼容性问题比较严重，最好一个版本使用一个版本最稳定的dashboard。</p><p>比如kubernetes-dashboard 新版本：v2.0.0 兼容 Kubernetes 版本：1.18以上，对以下的版本不兼容。</p><p>如果想安装高版本可以看 <a href="https://blog.csdn.net/baidu_38432732/article/details/105741967?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase" target="_blank" rel="noopener">Kubernetes 部署 Kubernetes-Dashboard v2.0.0</a></p><p>而本文kubernetes-dashboard：v1.10.1 兼容 kubernetes：1.15版本</p><h2 id="Heapster"><a href="#Heapster" class="headerlink" title="Heapster"></a>Heapster</h2><p>Heapster是容器集群监控和性能分析工具，天然的支持Kubernetes和CoreOS。</p><p>Kubernetes有个出名的监控agent—cAdvisor。在每个kubernetes Node上都会运行cAdvisor，它会收集本机以及容器的监控数据(cpu,memory,filesystem,network,uptime)。在较新的版本中，K8S已经将cAdvisor功能集成到kubelet组件中。每个Node节点可以直接进行web访问。</p><p>Heapster是一个收集者，Heapster可以收集Node节点上的cAdvisor数据，将每个Node上的cAdvisor的数据进行汇总，还可以按照kubernetes的资源类型来集合资源，比如Pod、Namespace，可以分别获取它们的CPU、内存、网络和磁盘的metric。默认的metric数据聚合时间间隔是1分钟。还可以把数据导入到第三方工具(如InfluxDB)。</p><p>Kubernetes原生dashboard的监控图表信息来自heapster。在Horizontal Pod Autoscaling中也用到了Heapster，HPA将Heapster作为Resource Metrics API，向其获取metric。</p><h2 id="InfluxDB"><a href="#InfluxDB" class="headerlink" title="InfluxDB"></a>InfluxDB</h2><p>InfluxDB是一个开源的时序数据库，使用GO语言开发，特别适合用于处理和分析资源监控数据这种时序相关数据。而InfluxDB自带的各种特殊函数如求标准差，随机取样数据，统计数据变化比等，使数据统计和实时分析变得十分方便。</p><p>时序数据库产品的发明都是为了解决传统关系型数据库在时序数据存储和分析上的不足和缺陷，这类产品被统一归类为时序数据库。针对时序数据的特点对写入、存储、查询等流程进行了优化，这些优化与时序数据的特点息息相关：</p><ul><li><p>存储成本：<br>利用时间递增、维度重复、指标平滑变化的特性，合理选择编码压缩算法，提高数据压缩比；<br>通过预降精度，对历史数据做聚合，节省存储空间。</p></li><li><p>高并发写入：<br>批量写入数据，降低网络开销；<br>数据先写入内存，再周期性的dump为不可变的文件存储。</p></li><li><p>低查询延时，高查询并发：<br>优化常见的查询模式，通过索引等技术降低查询延时；<br>通过缓存、routing等技术提高查询并发。</p></li></ul><h2 id="Grafana"><a href="#Grafana" class="headerlink" title="Grafana"></a>Grafana</h2><p>Grafana是一个跨平台的开源的度量分析和可视化工具，可以通过将采集的数据查询然后可视化的展示，并及时通知。它主要有以下六大特点：</p><ul><li><p>展示方式：快速灵活的客户端图表，面板插件有许多不同方式的可视化指标和日志，官方库中具有丰富的仪表盘插件，比如热图、折线图、图表等多种展示方式；</p></li><li><p>数据源：Graphite，InfluxDB，OpenTSDB，Prometheus，Elasticsearch，CloudWatch和KairosDB等；</p></li><li><p>通知提醒：以可视方式定义最重要指标的警报规则，Grafana将不断计算并发送通知，在数据达到阈值时通过Slack、PagerDuty等获得通知；</p></li><li><p>混合展示：在同一图表中混合使用不同的数据源，可以基于每个查询指定数据源，甚至自定义数据源；</p></li><li><p>注释：使用来自不同数据源的丰富事件注释图表，将鼠标悬停在事件上会显示完整的事件元数据和标记；</p></li><li><p>过滤器：Ad-hoc过滤器允许动态创建新的键/值过滤器，这些过滤器会自动应用于使用该数据源的所有查询。</p></li></ul><h1 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h1><h2 id="下载安装"><a href="#下载安装" class="headerlink" title="下载安装"></a>下载安装</h2><p><a href="https://github.com/chenyu1st/kubernetes-dashboard" target="_blank" rel="noopener">项目文件信息链接</a></p><p>一共有5个yaml文件及2个json文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-26-11 ~]# tree</span><br><span class="line">├── kubernetes-dashboard</span><br><span class="line">│   ├── grafana.yaml</span><br><span class="line">│   ├── heapster-rbac.yaml</span><br><span class="line">│   ├── heapster.yaml</span><br><span class="line">│   ├── kubernetes-dashboard.yaml</span><br><span class="line">│   └── influxdb.yaml</span><br><span class="line"></span><br><span class="line">确认kubernetes-dashboard目录的yaml文件正确（json先不用管）</span><br><span class="line"></span><br><span class="line">[root@vm-26-11 ~]# kubectl create -f kubernetes-dashboard</span><br></pre></td></tr></table></figure><p>kubernetes-dashboard访问地址：</p><p><a href="http://nodeip:32666/" target="_blank" rel="noopener">http://nodeip:32666/</a></p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Kubernetes/kubernetes-dashboard.jpg"  alt="kubernetes-dashboard.jpg"></p><h2 id="配置grafana"><a href="#配置grafana" class="headerlink" title="配置grafana"></a>配置grafana</h2><p>grafana访问地址：<a href="http://nodeip:31234/" target="_blank" rel="noopener">http://nodeip:31234/</a></p><p>选择添加 Dashboard模板（上面下载的json文件）</p><p>kubernetes-node-statistics_rev1.json</p><p>kubernetes-pod-statistics_rev1.json</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Kubernetes/grafana-import.jpg"  alt="grafana-import.jpg"></p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Kubernetes/grafana-node.jpg"  alt="grafana-node.jpg"></p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Kubernetes/grafana-pod.jpg"  alt="grafana-pod.jpg"></p><h1 id="问题排查"><a href="#问题排查" class="headerlink" title="问题排查"></a>问题排查</h1><p>下面有几个问题，我记录下当时的排坑操作</p><h2 id="kubernetes-dashboard"><a href="#kubernetes-dashboard" class="headerlink" title="kubernetes-dashboard"></a>kubernetes-dashboard</h2><p>大视报没有开权限控制，所以只用保证镜像号在国内可以找到就行，这里我用的事阿里云的镜像号<br>registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.10.1</p><h2 id="heapster"><a href="#heapster" class="headerlink" title="heapster"></a>heapster</h2><ul><li>权限控制</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">E0409 06:05:27.448890 1 reflector.go:190] k8s.io&#x2F;heapster&#x2F;metrics&#x2F;util&#x2F;util.go:30: Failed to list *v1.Node: nodes is forbidden: User &quot;system:serviceaccount:kube-system:heapster&quot; cannot list nodes at the cluster scope</span><br><span class="line"></span><br><span class="line">报错原因是无权访问，这个需要创建heapster-rbac.yaml就行</span><br></pre></td></tr></table></figure><ul><li>端口不通</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">E0302 06:11:05.004391       1 manager.go:101] Error in scraping containers from kubelet:172.16.8.12:10255: failed to get all container stats from Kubelet URL </span><br><span class="line"></span><br><span class="line">&quot;http:&#x2F;&#x2F;172.16.8.12:10255&#x2F;stats&#x2F;container&#x2F;&quot;: Post http:&#x2F;&#x2F;172.16.8.12:10255&#x2F;stats&#x2F;container&#x2F;: dial tcp 172.16.8.12:10255: getsockopt: connection refused</span><br><span class="line"></span><br><span class="line">报错原因是10255端口不通（k8s默认使用10250作为kubelet端口）</span><br><span class="line">需要将heapster的</span><br><span class="line">- --source&#x3D;kubernetes:https:&#x2F;&#x2F;kubernetes.default</span><br><span class="line">改为</span><br><span class="line">- --source&#x3D;kubernetes:kubernetes:https:&#x2F;&#x2F;kubernetes.default?useServiceAccount&#x3D;true&amp;kubeletHttps&#x3D;true&amp;kubeletPort&#x3D;10250&amp;insecure&#x3D;true</span><br></pre></td></tr></table></figure><h2 id="grafana"><a href="#grafana" class="headerlink" title="grafana"></a>grafana</h2><p>导入2个json文件后可以看到node、namespace的整体资源，但是看不了pod的资源，大视报显示的namespace的pod资源都是none。</p><p>我觉得很奇怪，但是又不太懂这个监控组件。<br>找了很久，在kubernetes-pod-statistics_rev1.json里找到了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&quot;query&quot;: &quot;SHOW TAG VALUES FROM \&quot;uptime\&quot; WITH KEY&#x3D;pod_name WHERE \&quot;namespace_name\&quot;&#x3D;&#39;$ns&#39;&quot;,</span><br><span class="line">&quot;refresh&quot;: 1,</span><br><span class="line">&quot;regex&quot;: &quot;&#x2F;^(.*)-\\d&#123;9,&#125;-\\w&#123;5,&#125;$&#x2F;&quot;,</span><br></pre></td></tr></table></figure><p>虽然我不知道作者为什么把pod的查找结果还给过滤一道（真心不懂）<br>但是把”regex”: “/^(.*)-\d{9,}-\w{5,}$/“改成        “regex”: “” 保存，就可以看到pod的资源监控情况了。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>我花了接近一天的时间才慢慢把坑排完，看国内文章大部分都是转载，纯水文，关键时候还是看各种官方文档才能找出问题。不过最后还是按时完成任务，完美！</p><h1 id="附件"><a href="#附件" class="headerlink" title="附件"></a>附件</h1><p>如果下载很慢，可以直接粘贴下面的yaml文件。</p><h2 id="kubernetes-dashboard-yaml"><a href="#kubernetes-dashboard-yaml" class="headerlink" title="kubernetes-dashboard.yaml"></a>kubernetes-dashboard.yaml</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br></pre></td><td class="code"><pre><span class="line"># Copyright 2017 The Kubernetes Authors.</span><br><span class="line">#</span><br><span class="line"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span><br><span class="line"># you may not use this file except in compliance with the License.</span><br><span class="line"># You may obtain a copy of the License at</span><br><span class="line">#</span><br><span class="line">#     http:&#x2F;&#x2F;www.apache.org&#x2F;licenses&#x2F;LICENSE-2.0</span><br><span class="line">#</span><br><span class="line"># Unless required by applicable law or agreed to in writing, software</span><br><span class="line"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span><br><span class="line"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span><br><span class="line"># See the License for the specific language governing permissions and</span><br><span class="line"># limitations under the License.</span><br><span class="line"></span><br><span class="line"># Configuration to deploy release version of the Dashboard UI compatible with</span><br><span class="line"># Kubernetes 1.8.</span><br><span class="line">#</span><br><span class="line"># Example usage: kubectl create -f &lt;this_file&gt;</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">    # Allows editing resource and makes sure it is created first.</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: EnsureExists</span><br><span class="line">  name: kubernetes-dashboard-certs</span><br><span class="line">  namespace: kube-system</span><br><span class="line">type: Opaque</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Secret</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">    # Allows editing resource and makes sure it is created first.</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: EnsureExists</span><br><span class="line">  name: kubernetes-dashboard-key-holder</span><br><span class="line">  namespace: kube-system</span><br><span class="line">type: Opaque</span><br><span class="line">---</span><br><span class="line"># ------------------- Dashboard Service Account ------------------- #</span><br><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard-admin</span><br><span class="line">  namespace: kube-system</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"># ------------------- Dashboard Role &amp; Role Binding ------------------- #</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes-dashboard-admin</span><br><span class="line">  namespace: kube-system</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: kubernetes-dashboard-admin</span><br><span class="line">  namespace: kube-system</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">    name: cluster-watcher</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &#39;*&#39;</span><br><span class="line">  resources:</span><br><span class="line">  - &#39;*&#39;</span><br><span class="line">  verbs:</span><br><span class="line">  - &#39;get&#39;</span><br><span class="line">  - &#39;list&#39;</span><br><span class="line">- nonResourceURLs:</span><br><span class="line">  - &#39;*&#39;</span><br><span class="line">  verbs:</span><br><span class="line">  - &#39;get&#39;</span><br><span class="line">  - &#39;list&#39;</span><br><span class="line">- apiGroups: [&quot;&quot;]</span><br><span class="line">  resources: [&quot;secrets&quot;]</span><br><span class="line">  resourceNames: [&quot;kubernetes-dashboard-key-holder&quot;, &quot;kubernetes-dashboard-certs&quot;]</span><br><span class="line">  verbs: [&quot;get&quot;, &quot;update&quot;, &quot;delete&quot;]</span><br><span class="line">  # Allow Dashboard to get and update &#39;kubernetes-dashboard-settings&#39; config map.</span><br><span class="line">- apiGroups: [&quot;&quot;]</span><br><span class="line">  resources: [&quot;configmaps&quot;]</span><br><span class="line">  resourceNames: [&quot;kubernetes-dashboard-settings&quot;]</span><br><span class="line">  verbs: [&quot;get&quot;, &quot;update&quot;]</span><br><span class="line">  # Allow Dashboard to get metrics from heapster.</span><br><span class="line">- apiGroups: [&quot;&quot;]</span><br><span class="line">  resources: [&quot;services&quot;]</span><br><span class="line">  resourceNames: [&quot;heapster&quot;]</span><br><span class="line">  verbs: [&quot;proxy&quot;]</span><br><span class="line">---</span><br><span class="line"># ------------------- Dashboard Deployment ------------------- #</span><br><span class="line">apiVersion: apps&#x2F;v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io&#x2F;mode: Reconcile</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: kubernetes-dashboard</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: kubernetes-dashboard</span><br><span class="line">      annotations:</span><br><span class="line">        scheduler.alpha.kubernetes.io&#x2F;critical-pod: &#39;&#39;</span><br><span class="line">        seccomp.security.alpha.kubernetes.io&#x2F;pod: &#39;docker&#x2F;default&#39;</span><br><span class="line">    spec:</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      containers:</span><br><span class="line">      - name: kubernetes-dashboard</span><br><span class="line">       # image: registry.cn-beijing.aliyuncs.com&#x2F;kubernetes-cn&#x2F;kubernetes-dashboard-amd64:v1.10.1</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com&#x2F;google_containers&#x2F;kubernetes-dashboard-amd64:v1.10.1</span><br><span class="line">        resources:</span><br><span class="line">          #limits:</span><br><span class="line">          #  cpu: 100m</span><br><span class="line">          #  memory: 300Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 50m</span><br><span class="line">            memory: 200Mi</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 9090</span><br><span class="line">          protocol: TCP</span><br><span class="line">        args:</span><br><span class="line">          #- --auto-generate-certificates</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: kubernetes-dashboard-certs</span><br><span class="line">          mountPath: &#x2F;certs</span><br><span class="line">        - name: tmp-volume</span><br><span class="line">          mountPath: &#x2F;tmp</span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            scheme: HTTP</span><br><span class="line">            path: &#x2F;</span><br><span class="line">            port: 9090</span><br><span class="line">          initialDelaySeconds: 30</span><br><span class="line">          timeoutSeconds: 30</span><br><span class="line">      volumes:</span><br><span class="line">      - name: kubernetes-dashboard-certs</span><br><span class="line">        secret:</span><br><span class="line">          secretName: kubernetes-dashboard-certs</span><br><span class="line">      - name: tmp-volume</span><br><span class="line">        emptyDir: &#123;&#125;</span><br><span class="line">      serviceAccountName: kubernetes-dashboard-admin</span><br><span class="line">      tolerations:</span><br><span class="line">      - key: node-role.kubernetes.io&#x2F;master</span><br><span class="line">        effect: NoSchedule</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"># ------------------- Dashboard Service ------------------- #</span><br><span class="line"></span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - port: 443</span><br><span class="line">      targetPort: 9090</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">kind: Service</span><br><span class="line">apiVersion: v1</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  name: kubernetes-dashboard-external</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">    - port: 9090</span><br><span class="line">      targetPort: 9090</span><br><span class="line">      nodePort: 32666</span><br><span class="line">  type: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br></pre></td></tr></table></figure><h2 id="influxdb-yaml"><a href="#influxdb-yaml" class="headerlink" title="influxdb.yaml"></a>influxdb.yaml</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: monitoring-influxdb</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        task: monitoring</span><br><span class="line">        k8s-app: influxdb</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: influxdb</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com&#x2F;google_containers&#x2F;heapster-influxdb-amd64:v1.5.2 </span><br><span class="line">        volumeMounts:</span><br><span class="line">        - mountPath: &#x2F;data</span><br><span class="line">          name: influxdb-storage</span><br><span class="line">      volumes:</span><br><span class="line">      - name: influxdb-storage</span><br><span class="line">        emptyDir: &#123;&#125;</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    task: monitoring</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &#39;true&#39;</span><br><span class="line">    kubernetes.io&#x2F;name: monitoring-influxdb</span><br><span class="line">  name: monitoring-influxdb</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - port: 8086</span><br><span class="line">    targetPort: 8086</span><br><span class="line">    nodePort: 30444</span><br><span class="line">    name: http</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: influxdb</span><br></pre></td></tr></table></figure><h2 id="heapster-yaml"><a href="#heapster-yaml" class="headerlink" title="heapster.yaml"></a>heapster.yaml</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: heapster</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        task: monitoring</span><br><span class="line">        k8s-app: heapster</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: heapster</span><br><span class="line">      containers:</span><br><span class="line">      - name: heapster</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com&#x2F;google_containers&#x2F;heapster-amd64:v1.5.4</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        command:</span><br><span class="line">        - &#x2F;heapster</span><br><span class="line">        - --source&#x3D;kubernetes:https:&#x2F;&#x2F;kubernetes.default?useServiceAccount&#x3D;true&amp;kubeletHttps&#x3D;true&amp;kubeletPort&#x3D;10250&amp;insecure&#x3D;true</span><br><span class="line">        - --sink&#x3D;influxdb:http:&#x2F;&#x2F;monitoring-influxdb:8086</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    task: monitoring</span><br><span class="line">    # For use as a Cluster add-on (https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes&#x2F;tree&#x2F;master&#x2F;cluster&#x2F;addons)</span><br><span class="line">    # If you are NOT using this as an addon, you should comment out this line.</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &#39;true&#39;</span><br><span class="line">    kubernetes.io&#x2F;name: Heapster</span><br><span class="line">  name: heapster</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 8082</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: heapster</span><br></pre></td></tr></table></figure><h2 id="heapster-rbac-yaml"><a href="#heapster-rbac-yaml" class="headerlink" title="heapster-rbac.yaml"></a>heapster-rbac.yaml</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: heapster</span><br><span class="line">  namespace: kube-system</span><br><span class="line"></span><br><span class="line">---</span><br><span class="line"></span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">apiVersion: rbac.authorization.k8s.io&#x2F;v1beta1</span><br><span class="line">metadata:</span><br><span class="line">  name: heapster</span><br><span class="line">subjects:</span><br><span class="line">  - kind: ServiceAccount</span><br><span class="line">    name: heapster</span><br><span class="line">    namespace: kube-system</span><br><span class="line">roleRef:</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br></pre></td></tr></table></figure><h2 id="grafana-yaml"><a href="#grafana-yaml" class="headerlink" title="grafana.yaml"></a>grafana.yaml</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions&#x2F;v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: monitoring-grafana</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        task: monitoring</span><br><span class="line">        k8s-app: grafana</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: grafana</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com&#x2F;google_containers&#x2F;heapster-grafana-amd64:v5.0.4</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 3000</span><br><span class="line">          protocol: TCP</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - mountPath: &#x2F;etc&#x2F;ssl&#x2F;certs</span><br><span class="line">          name: ca-certificates</span><br><span class="line">          readOnly: true</span><br><span class="line">        - mountPath: &#x2F;var</span><br><span class="line">          name: grafana-storage</span><br><span class="line">        env:</span><br><span class="line">        - name: INFLUXDB_HOST</span><br><span class="line">          value: monitoring-influxdb</span><br><span class="line">        - name: GF_SERVER_HTTP_PORT</span><br><span class="line">          value: &quot;3000&quot;</span><br><span class="line">          # The following env variables are required to make Grafana accessible via</span><br><span class="line">          # the kubernetes api-server proxy. On production clusters, we recommend</span><br><span class="line">          # removing these env variables, setup auth for grafana, and expose the grafana</span><br><span class="line">          # service using a LoadBalancer or a public IP.</span><br><span class="line">        - name: GF_AUTH_BASIC_ENABLED</span><br><span class="line">          value: &quot;false&quot;</span><br><span class="line">        - name: GF_AUTH_ANONYMOUS_ENABLED</span><br><span class="line">          value: &quot;true&quot;</span><br><span class="line">        - name: GF_AUTH_ANONYMOUS_ORG_ROLE</span><br><span class="line">          value: Admin</span><br><span class="line">        - name: GF_SERVER_ROOT_URL</span><br><span class="line">          # If you&#39;re only using the API Server proxy, set this value instead:</span><br><span class="line">          # value: &#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;kube-system&#x2F;services&#x2F;monitoring-grafana&#x2F;proxy</span><br><span class="line">          value: &#x2F;</span><br><span class="line">      volumes:</span><br><span class="line">      - name: ca-certificates</span><br><span class="line">        hostPath:</span><br><span class="line">          path: &#x2F;etc&#x2F;ssl&#x2F;certs</span><br><span class="line">      - name: grafana-storage</span><br><span class="line">        emptyDir: &#123;&#125;</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    # For use as a Cluster add-on (https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;kubernetes&#x2F;tree&#x2F;master&#x2F;cluster&#x2F;addons)</span><br><span class="line">    # If you are NOT using this as an addon, you should comment out this line.</span><br><span class="line">    kubernetes.io&#x2F;cluster-service: &#39;true&#39;</span><br><span class="line">    kubernetes.io&#x2F;name: monitoring-grafana</span><br><span class="line">  name: monitoring-grafana</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  # In a production setup, we recommend accessing Grafana through an external Loadbalancer</span><br><span class="line">  # or through a public IP.</span><br><span class="line">  # type: LoadBalancer</span><br><span class="line">  # You could also use NodePort to expose the service at a randomly-generated port</span><br><span class="line">  type: NodePort</span><br><span class="line">  ports:</span><br><span class="line">  - port: 80</span><br><span class="line">    targetPort: 3000</span><br><span class="line">    nodePort: 31234</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: grafana</span><br></pre></td></tr></table></figure><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://github.com/kubernetes-retired/heapster" target="_blank" rel="noopener">Heapster-Github</a></p><p><a href="https://github.com/kubernetes-retired/heapster/blob/master/docs/influxdb.md" target="_blank" rel="noopener">在具有InfluxDB后端和Grafana UI的Kubernetes集群中运行Heapster</a></p><p><a href="https://grafana.com/grafana/dashboards?orderBy=name&direction=asc" target="_blank" rel="noopener">Grafana的Dashboards模板</a></p><p><a href="https://blog.csdn.net/liukuan73/article/details/78704395" target="_blank" rel="noopener">kubernetes监控方案之：heapster+influxdb+grafana详解</a></p><p><a href="https://blog.csdn.net/liukuan73/article/details/79950329" target="_blank" rel="noopener">时序数据库介绍和使用</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Kubernetes </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Kubernetes </tag>
            
            <tag> kubernetes-dashboard </tag>
            
            <tag> heapster </tag>
            
            <tag> grafana </tag>
            
            <tag> influxdb </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入浅出Docker原理及实战(二)——Docker的安装及常用命令</title>
      <link href="2020/06/09/docker/docker-idea-2/"/>
      <url>2020/06/09/docker/docker-idea-2/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><p>深入浅出Docker原理及实战系列第二篇，遵循先运用后理解的思想，我主要讲解docker的安装过程及常用命令，可以帮助大家快速上手docker(你先用起来，再去理解原理)。</p><h1 id="安装docker"><a href="#安装docker" class="headerlink" title="安装docker"></a>安装docker</h1><h2 id="操作系统要求"><a href="#操作系统要求" class="headerlink" title="操作系统要求"></a>操作系统要求</h2><p>要安装Docker Engine，需要CentOS 7的稳定版本。</p><p>当前稳定版本：CentOS Linux release 7.6.1810 (Core)</p><p>建议使用overlay2存储驱动程序。</p><h2 id="卸载旧版本"><a href="#卸载旧版本" class="headerlink" title="卸载旧版本"></a>卸载旧版本</h2><p>较旧的Docker版本称为docker或docker-engine。如果已安装这些程序，请卸载它们以及相关的依赖项。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@dev-master-01 ~]#yum remove docker \</span><br><span class="line">                        docker-client \</span><br><span class="line">                        docker-client-latest \</span><br><span class="line">                        docker-common \</span><br><span class="line">                        docker-latest \</span><br><span class="line">                        docker-latest-logrotate \</span><br><span class="line">                        docker-logrotate \</span><br><span class="line">                        docker-engine</span><br></pre></td></tr></table></figure><p>如果yum报告没有安装这些软件包，那就可以了。</p><p>/var/lib/docker/的内容（包括镜像，容器，卷和网络）被保留。 Docker Engine软件包现在称为docker-ce。</p><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>您可以根据需要以不同的方式安装Docker Engine：</p><ul><li>大多数用户会设置Docker的存储库并从中进行安装，以简化安装和升级任务。这是推荐的方法。</li><li>一些用户下载并手动安装RPM软件包，并完全手动管理升级。这在诸如在无法访问互联网的空白系统上安装Docker的情况下非常有用。</li></ul><h3 id="yum安装"><a href="#yum安装" class="headerlink" title="yum安装"></a>yum安装</h3><h4 id="设置yum源"><a href="#设置yum源" class="headerlink" title="设置yum源"></a>设置yum源</h4><p>安装yum-utils软件包（提供yum-config-manager实用程序）并设置稳定的存储库。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ yum install -y yum-utils</span><br><span class="line"></span><br><span class="line">$ yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https:&#x2F;&#x2F;download.docker.com&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo</span><br></pre></td></tr></table></figure><h4 id="安装DOCKER引擎"><a href="#安装DOCKER引擎" class="headerlink" title="安装DOCKER引擎"></a>安装DOCKER引擎</h4><p>安装最新版本的Docker Engine和容器：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ yum install -y docker-ce docker-ce-cli containerd.io</span><br></pre></td></tr></table></figure><p>要安装特定版本的Docker Engine，请在存储库中列出可用版本，然后选择并安装：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ yum list docker-ce --showduplicates | sort -r</span><br><span class="line"></span><br><span class="line">docker-ce.x86_64  3:18.09.1-3.el7                     docker-ce-stable</span><br><span class="line">docker-ce.x86_64  3:18.09.0-3.el7                     docker-ce-stable</span><br><span class="line">docker-ce.x86_64  18.06.1.ce-3.el7                    docker-ce-stable</span><br><span class="line">docker-ce.x86_64  18.06.0.ce-3.el7                    docker-ce-stable</span><br></pre></td></tr></table></figure><p>通过完全限定的软件包名称安装特定版本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install docker-ce-&lt;VERSION_STRING&gt; docker-ce-cli-&lt;VERSION_STRING&gt; containerd.io    </span><br><span class="line"></span><br><span class="line">例如：docker-ce-18.09.1</span><br></pre></td></tr></table></figure><h4 id="配置docker源"><a href="#配置docker源" class="headerlink" title="配置docker源"></a>配置docker源</h4><p>一般拉取镜像都是从docker hub拉取，速度较慢，切换成阿里源镜像会快很多</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vim   &#x2F;etc&#x2F;docker&#x2F;daemon.json</span><br><span class="line">添加</span><br><span class="line">&#123;</span><br><span class="line">  &quot;registry-mirrors&quot;: [&quot;https:&#x2F;&#x2F;wghlmi3i.mirror.aliyuncs.com&quot;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h4><p>systemctl start docker</p><p>验证</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">[root@dev-master-01 datarouter]# docker version</span><br><span class="line">Client: Docker Engine - Community</span><br><span class="line"> Version:           19.03.4</span><br><span class="line"> API version:       1.40</span><br><span class="line"> Go version:        go1.12.10</span><br><span class="line"> Git commit:        9013bf583a</span><br><span class="line"> Built:             Fri Oct 18 15:52:22 2019</span><br><span class="line"> OS&#x2F;Arch:           linux&#x2F;amd64</span><br><span class="line"> Experimental:      false</span><br><span class="line"></span><br><span class="line">Server: Docker Engine - Community</span><br><span class="line"> Engine:</span><br><span class="line">  Version:          19.03.4</span><br><span class="line">  API version:      1.40 (minimum version 1.12)</span><br><span class="line">  Go version:       go1.12.10</span><br><span class="line">  Git commit:       9013bf583a</span><br><span class="line">  Built:            Fri Oct 18 15:50:54 2019</span><br><span class="line">  OS&#x2F;Arch:          linux&#x2F;amd64</span><br><span class="line">  Experimental:     false</span><br><span class="line"> containerd:</span><br><span class="line">  Version:          1.2.10</span><br><span class="line">  GitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339</span><br><span class="line"> runc:</span><br><span class="line">  Version:          1.0.0-rc8+dev</span><br><span class="line">  GitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657</span><br><span class="line"> docker-init:</span><br><span class="line">  Version:          0.18.0</span><br><span class="line">  GitCommit:        fec3683</span><br></pre></td></tr></table></figure><h3 id="rpm安装"><a href="#rpm安装" class="headerlink" title="rpm安装"></a>rpm安装</h3><p>如果无法使用Docker的存储库安装Docker，则可以下载该.rpm发行版的 文件并手动安装。每次要升级Docker Engine时，都需要下载一个新文件。</p><ul><li>转到<a href="https://download.docker.com/linux/centos/" target="_blank" rel="noopener">https://download.docker.com/linux/centos/</a> 并选择您的CentOS版本。然后浏览x86_64/stable/Packages/ 并下载.rpm您要安装的Docker版本的文件。</li><li>安装Docker Engine，将下面的路径更改为您下载Docker软件包的路径。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install &#x2F;path&#x2F;to&#x2F;package.rpm</span><br></pre></td></tr></table></figure></li><li>启动Docker<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl start docker</span><br></pre></td></tr></table></figure></li></ul><h1 id="docker常用命令-CLI"><a href="#docker常用命令-CLI" class="headerlink" title="docker常用命令(CLI)"></a>docker常用命令(CLI)</h1><p>下面从仓库、镜像、容器、其他方面来讲述docker的常用命令。</p><h2 id="Registry"><a href="#Registry" class="headerlink" title="Registry"></a>Registry</h2><p>关于仓库最主要的几个命令有login logout</p><h3 id="login"><a href="#login" class="headerlink" title="login"></a>login</h3><ul><li>作用：登录Docker仓库</li><li>用法：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker login [OPTIONS] [SERVER]</span><br></pre></td></tr></table></figure></li></ul><table><thead><tr><th>OPTIONS</th><th>描述</th></tr></thead><tbody><tr><td>–password , -p</td><td>密码</td></tr><tr><td>–username , -u</td><td>用户名</td></tr></tbody></table><ul><li>eg: <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker login -u admin -p Harbor12345  development.docker.cn:5000</span><br></pre></td></tr></table></figure></li></ul><h3 id="logout"><a href="#logout" class="headerlink" title="logout"></a>logout</h3><ul><li><p>作用：从Docker仓库注销</p></li><li><p>用法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker logout [SERVER]</span><br></pre></td></tr></table></figure></li><li><p>eg: </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker logout  development.docker.cn:5000</span><br></pre></td></tr></table></figure></li></ul><h2 id="Images"><a href="#Images" class="headerlink" title="Images"></a>Images</h2><p>关于镜像最主要的几个命令有pull、push、tag、rmi</p><h3 id="pull"><a href="#pull" class="headerlink" title="pull"></a>pull</h3><ul><li>作用：从镜像仓库中拉取镜像</li><li>用法：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull [OPTIONS] NAME[:TAG]</span><br></pre></td></tr></table></figure></li></ul><table><thead><tr><th>OPTIONS</th><th>描述</th></tr></thead><tbody><tr><td>–all-tags , -a</td><td>下载存储库中所有标记的镜像</td></tr><tr><td>–quiet , -q</td><td>禁止详细输出</td></tr></tbody></table><ul><li>eg：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull ubuntu:14.04</span><br></pre></td></tr></table></figure></li></ul><p>大多数镜像都将在Docker Hub的基础镜像之上创建。也可以手动指定要从中提取镜像仓库的路径。例如，如果已经设置了本地仓库，则可以指定从中提取的路径。</p><ul><li>eg：本地的harbor仓库url为development.docker.cn:5000，要从harbor仓库里拉取镜像前必须先登陆</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker login -u admin -p Harbor12345  development.docker.cn:5000</span><br><span class="line">docker pull development.docker.cn:5000&#x2F;test&#x2F;nginx:0.0.1</span><br></pre></td></tr></table></figure><h3 id="tag"><a href="#tag" class="headerlink" title="tag"></a>tag</h3><ul><li><p>作用：创建一个引用了SOURCE_IMAGE的标签TARGET_IMAGE</p></li><li><p>用法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker tag SOURCE_IMAGE[:TAG] TARGET_IMAGE[:TAG]</span><br></pre></td></tr></table></figure></li><li><p>扩展说明:镜像名称由斜杠分隔的名称组成，可以选择以镜像仓库的主机名作为前缀。主机名必须符合标准DNS规则，但不得包含下划线。标签名称必须是有效的ASCII，并且可以包含小写和大写字母，数字，下划线，句点和破折号。标签名称不能以句点或破折号开头，并且最多可以包含128个字符。</p></li><li><p>eg：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# docker tag development.docker.cn:5000&#x2F;test&#x2F;nginx:0.0.1  test.docker.cn:5000&#x2F;test&#x2F;nginx:0.0.1</span><br><span class="line">[root@localhost ~]# docker images -a</span><br><span class="line">REPOSITORY                                                          TAG                        IMAGE ID            CREATED             SIZE</span><br><span class="line">development.docker.cn:5000&#x2F;test&#x2F;nginx                               0.0.1                    730908c6f40c        6 days ago          1.38GB</span><br><span class="line">test.docker.cn:5000&#x2F;test&#x2F;nginx                                      0.0.1                    730908c6f40c        6 days ago          1.38GB</span><br></pre></td></tr></table></figure></li></ul><h3 id="push"><a href="#push" class="headerlink" title="push"></a>push</h3><ul><li><p>作用：将镜像推送到镜像仓库</p></li><li><p>用法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker push  NAME[:TAG]</span><br></pre></td></tr></table></figure></li><li><p>eg：  </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker push test.docker.cn:5000&#x2F;test&#x2F;nginx:0.0.1</span><br></pre></td></tr></table></figure></li></ul><h3 id="rmi"><a href="#rmi" class="headerlink" title="rmi"></a>rmi</h3><ul><li>作用：删除一个或多个镜像</li><li>用法：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rmi [OPTIONS] IMAGE [IMAGE...]</span><br></pre></td></tr></table></figure><table><thead><tr><th>OPTIONS</th><th>描述</th></tr></thead><tbody><tr><td>–force , -f</td><td>强制删除</td></tr><tr><td>–no-prune</td><td>不要删除未加标签的镜像</td></tr></tbody></table><ul><li>eg：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rmi development.docker.cn:5000&#x2F;test&#x2F;nginx:0.0.1</span><br></pre></td></tr></table></figure><p>如果使用-f标志并指定图像的短ID或长ID，则此命令将取消标记并删除所有与指定ID匹配的图像。</p><ul><li>eg：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">$ docker images -a</span><br><span class="line"></span><br><span class="line">REPOSITORY                TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">test1                     latest              fd484f19954f        23 seconds ago      7 B (virtual 4.964 MB)</span><br><span class="line">test                      latest              fd484f19954f        23 seconds ago      7 B (virtual 4.964 MB)</span><br><span class="line">test2                     latest              fd484f19954f        23 seconds ago      7 B (virtual 4.964 MB)</span><br><span class="line"></span><br><span class="line">$ docker rmi -f fd484f19954f</span><br><span class="line"></span><br><span class="line">Untagged: test1:latest</span><br><span class="line">Untagged: test:latest</span><br><span class="line">Untagged: test2:latest</span><br><span class="line">Deleted: fd484f19954f4920da7ff372b5067f5b7ddb2fd3830cecd17b96ea9e286ba5b8</span><br></pre></td></tr></table></figure><h2 id="Container"><a href="#Container" class="headerlink" title="Container"></a>Container</h2><p>关于容器最主要的几个命令有run、cp、exec、log、rm、diff、start/stop</p><h3 id="run"><a href="#run" class="headerlink" title="run"></a>run</h3><ul><li>作用：一是创建和启动一个新的容器，二是启动时通过加选项和参数在容器运行命令；</li><li>用法：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run [OPTIONS] IMAGE [COMMAND] [ARG...]</span><br></pre></td></tr></table></figure></li></ul><table><thead><tr><th>OPTIONS</th><th>描述</th></tr></thead><tbody><tr><td>–attach , -a</td><td>附加到STDIN，STDOUT或STDERR</td></tr><tr><td>–detach , -d</td><td>在后台运行容器并打印容器ID</td></tr><tr><td>–env , -e</td><td>设置环境变量</td></tr><tr><td>–hostname , -h</td><td>容器主机名</td></tr><tr><td>–name</td><td>给你容器起个名字，以后可以使用这个名字启动或者停止容器</td></tr><tr><td>–interactive , -i</td><td>即使未连接STDIN也保持打开状态</td></tr><tr><td>–tty , -t</td><td>分配伪TTY</td></tr><tr><td>–volume , -v</td><td>绑定挂载卷</td></tr><tr><td>–publish , -p</td><td>将容器的端口映射到主机</td></tr><tr><td>–privileged</td><td>赋予此容器扩展的特权</td></tr><tr><td>–rm</td><td>退出时自动删除容器</td></tr><tr><td>–user , -u</td><td>用户名或UID</td></tr></tbody></table><p>扩展说明:<br>run是创建和启动容器的核心命令，参数较多，我在此只列举了常用的参数。</p><p>docker run命令首先creates是在指定镜像上的可写容器层，然后starts使用指定命令。也就是说， docker run相当于API /containers/create，然后 /containers/(id)/start。</p><p>如果要重新启动已停止的容器，使其之前的所有更改保持不变应该用docker start 而不是用run。</p><p>举几个例子：</p><ul><li>名称并分配伪TTY(-t)</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --name test -it debian</span><br><span class="line"></span><br><span class="line">root@d6c0fe130dba:&#x2F;# exit 13</span><br><span class="line">$ echo $?</span><br><span class="line">13</span><br><span class="line">$ docker ps -a | grep test</span><br><span class="line">d6c0fe130dba        debian:7            &quot;&#x2F;bin&#x2F;bash&quot;         26 seconds ago      Exited (13) 17 seconds ago                         test</span><br></pre></td></tr></table></figure><p>本示例运行一个test使用debian:latest 镜像命名的容器。-it指示docker分配一个伪TTY连接到所述容器的stdin; bash在容器中创建一个交互式外壳。在该示例中，bash通过输入退出外壳程序 exit 13。此退出代码将传递给的调用者 docker run，并记录在test容器的元数据中。</p><ul><li>完整的容器功能（特权）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -t -i --rm ubuntu bash</span><br><span class="line">root@bc338942ef20:&#x2F;# mount -t tmpfs none &#x2F;mnt</span><br><span class="line">mount: permission denied</span><br></pre></td></tr></table></figure><p>在默认情况下，最有潜在危险的内核能力下降;包括cap_sys_admin（挂载文件系统所需）。但是，该–privileged标志将允许它运行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -t -i --privileged ubuntu bash</span><br><span class="line">root@50e3f57e16e6:&#x2F;# mount -t tmpfs none &#x2F;mnt</span><br><span class="line">root@50e3f57e16e6:&#x2F;# df -h</span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">none            1.9G     0  1.9G   0% &#x2F;mnt</span><br></pre></td></tr></table></figure><p>该–privileged标志为容器提供了所有功能，并且还device解除了cgroup控制器强制执行的所有限制。换句话说，容器可以完成主机可以做的几乎所有事情。存在此标志是为了允许特殊用例，例如在Docker中运行Docker。</p><ul><li>映射或暴露端口（-p，-expose）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --name nginx -p 8888:80&#x2F;tcp -it -d nginx</span><br></pre></td></tr></table></figure><p>这会将nignx容器的80端口绑定到主机8888上0.0.0.0的TCP端口。我们还可以指定udp和sctp端口。<a href="https://docs.docker.com/network/links/" target="_blank" rel="noopener">《Docker用户指南》</a> 详细解释了如何在Docker中操作端口。</p><ul><li>设置环境变量（-e，-env，-env文件）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker run -e MYVAR1 --env MYVAR2&#x3D;foo --env-file .&#x2F;env.list ubuntu bash</span><br></pre></td></tr></table></figure><p>使用-e，–env和–env-file用在运行的容器中设置简单（非数组）环境变量，或覆盖正在运行的映像的Dockerfile中定义的变量。</p><p>可以使用导出到本地环境的变量：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">export VAR1&#x3D;value1</span><br><span class="line">export VAR2&#x3D;value2</span><br><span class="line"></span><br><span class="line">$ docker run --env VAR1 --env VAR2 ubuntu env | grep VAR</span><br><span class="line">VAR1&#x3D;value1</span><br><span class="line">VAR2&#x3D;value2</span><br></pre></td></tr></table></figure><ul><li>给容器挂载存储卷（-v path:path),将本地的目录挂载到容器里，当绑定安装的卷的主机目录不存在时，Docker将为自动在主机上创建此目录。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -u root -d --name jenkins -p 8080:8080 -v &#x2F;data&#x2F;jenkins:&#x2F;data&#x2F;jenkins -v &#x2F;var&#x2F;run&#x2F;docker.sock:&#x2F;var&#x2F;run&#x2F;docker.sock    jenkinsci&#x2F;jenkins:lts ;</span><br></pre></td></tr></table></figure><p>通过绑定安装docker unix套接字和静态链接的docker二进制文件，可以为容器提供创建和操作主机的Docker守护程序的完全访问权限。</p><h3 id="cp"><a href="#cp" class="headerlink" title="cp"></a>cp</h3><ul><li>作用：在容器和本地文件系统之间复制文件/文件夹</li><li>用法：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATH|-</span><br><span class="line">docker cp [OPTIONS] SRC_PATH|- CONTAINER:DEST_PATH</span><br></pre></td></tr></table></figure></li></ul><table><thead><tr><th>OPTIONS</th><th>描述</th></tr></thead><tbody><tr><td>–archive , -a</td><td>将所有权设置为文件源的用户和主要组</td></tr><tr><td>–follow-link , -L</td><td>始终遵循SRC_PATH中的符号链接</td></tr><tr><td>- 扩展说明</td><td></td></tr></tbody></table><p>cp命令的行为类似于Unix cp -a命令，因为如果可能，将以递归方式复制目录并保留权限。所有权设置为目的地的用户和主要组。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">假设使用路径分隔符&#x2F;的第一个参数SRC_PATH和的第二个参数DEST_PATH，其行为如下：</span><br><span class="line"></span><br><span class="line">SRC_PATH 指定一个文件</span><br><span class="line">        DEST_PATH 不存在</span><br><span class="line">            该文件将保存到在以下位置创建的文件中 DEST_PATH</span><br><span class="line">        DEST_PATH 不存在并以 &#x2F;</span><br><span class="line">            错误条件：目标目录必须存在。</span><br><span class="line">        DEST_PATH 存在并且是一个文件</span><br><span class="line">            目标被源文件的内容覆盖</span><br><span class="line">        DEST_PATH 存在并且是目录</span><br><span class="line">            使用以下文件中的基本名称将文件复制到此目录中： SRC_PATH</span><br><span class="line">SRC_PATH 指定目录</span><br><span class="line">        DEST_PATH 不存在</span><br><span class="line">            DEST_PATH被创建为目录，并将源目录的内容复制到该目录中</span><br><span class="line">        DEST_PATH 存在并且是一个文件</span><br><span class="line">            错误条件：无法将目录复制到文件</span><br><span class="line">        DEST_PATH 存在并且是目录</span><br><span class="line">            SRC_PATH不以&#x2F;. 结尾</span><br><span class="line">                源目录复制到该目录</span><br><span class="line">            SRC_PATH以&#x2F;.  结尾</span><br><span class="line">                源目录的内容被复制到该目录中</span><br></pre></td></tr></table></figure><p>根据上述规则，该命令要求SRC_PATH和DEST_PATH存在。如果SRC_PATH是本地的并且是符号链接，则默认情况下将复制符号链接而不是目标链接。要复制链接目标而不是链接，请指定-L选项。</p><ul><li>eg：  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">从容器里面拷文件到宿主机</span><br><span class="line">docker cp -a project:&#x2F;opt&#x2F;abc.txt &#x2F;home&#x2F;</span><br><span class="line">从宿主机拷文件到容器里面</span><br><span class="line">docker cp &#x2F;home&#x2F;abc.txt project:&#x2F;opt&#x2F;</span><br></pre></td></tr></table></figure></li></ul><h3 id="exec"><a href="#exec" class="headerlink" title="exec"></a>exec</h3><ul><li><p>作用：在正在运行的容器中运行命令</p></li><li><p>用法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec [OPTIONS] CONTAINER COMMAND [ARG...]</span><br></pre></td></tr></table></figure><p>exec命令的参数和run命令的参数很多类似<br>OPTIONS | 描述</p></li><li><p>–|—</p></li><li><p>-detach , -d         |  分离模式：在后台运行命令</p></li><li><p>-env , -e |设置环境变量</p></li><li><p>-interactive , -i|即使未连接STDIN也保持打开状态</p></li><li><p>-privileged|赋予命令扩展权限</p></li><li><p>-tty , -t|    分配伪TTY</p></li><li><p>-user , -u|用户名或UID</p></li><li><p>-workdir , -w|容器内的工作目录</p></li><li><p>扩展说明</p></li></ul><p>使用docker exec容器启动的命令仅在容器的主进程（PID 1）正在运行时运行，如果重新启动容器，则该命令不会重新启动。</p><p>COMMAND将在容器的默认目录中运行。如果基础映像在其Dockerfile中具有使用WORKDIR指令指定的自定义目录，则将使用该目录。</p><p>举几个例子：</p><ul><li><p>bash在容器上执行一个交互式shell</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it nginx  bash</span><br></pre></td></tr></table></figure></li><li><p>在当前bash会话中设置环境变量</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it -e VAR&#x3D;1 nginx bash</span><br></pre></td></tr></table></figure><p>这将在nginx容器中创建一个新的Bash会话，且它的环境变量$VAR设置为“1”。请注意，此环境变量仅在当前Bash会话上有效。</p><ul><li>命令在创建容器时在相同的工作目录中运行。</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ docker exec -it ubuntu_bash pwd</span><br><span class="line">&#x2F;</span><br><span class="line">$ docker exec -it -w &#x2F;root ubuntu_bash pwd</span><br><span class="line">&#x2F;root</span><br></pre></td></tr></table></figure><h3 id="log"><a href="#log" class="headerlink" title="log"></a>log</h3><ul><li><p>作用：提取容器的日志</p></li><li><p>用法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker logs [OPTIONS] CONTAINER</span><br></pre></td></tr></table></figure><p>OPTIONS | 描述</p></li><li><p>–|—</p></li><li><p>-details         |  显示提供给日志的其他详细信息</p></li><li><p>-follow , -f |跟踪日志输出</p></li><li><p>-since|显示自时间戳记以来的日志或相对时间</p></li><li><p>-tail    |赋予命令扩展权限</p></li><li><p>-timestamps , -t|    显示时间戳</p></li><li><p>-until|在时间戳或相对时间之前显示日志</p></li><li><p>eg：</p></li></ul><p>为了在特定时间点之前检索日志，请运行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ docker run --name test -d busybox sh -c &quot;while true; do $(echo date); sleep 1; done&quot;</span><br><span class="line">$ date</span><br><span class="line">Tue 14 Nov 2017 16:40:00 CET</span><br><span class="line">$ docker logs -f --until&#x3D;2s</span><br><span class="line">Tue 14 Nov 2017 16:40:00 CET</span><br><span class="line">Tue 14 Nov 2017 16:40:01 CET</span><br><span class="line">Tue 14 Nov 2017 16:40:02 CET</span><br></pre></td></tr></table></figure><p>查看指定时间后的日志，只显示最后100行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker logs -f -t --since&#x3D;&quot;2018-02-08&quot; --tail&#x3D;100 CONTAINER_ID</span><br></pre></td></tr></table></figure><p>查看最近30分钟的日志:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker logs --since 30m CONTAINER_ID</span><br></pre></td></tr></table></figure><p>查看某时间之后的日志：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker logs -t --since&#x3D;&quot;2018-02-08T13:23:37&quot; CONTAINER_ID</span><br></pre></td></tr></table></figure><p>查看某时间段日志：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker logs -t --since&#x3D;&quot;2018-02-08T13:23:37&quot; --until &quot;2018-02-09T12:23:37&quot; CONTAINER_ID</span><br></pre></td></tr></table></figure><h3 id="rm"><a href="#rm" class="headerlink" title="rm"></a>rm</h3><ul><li>作用：删除一个或多个容器</li><li>用法：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker rm [OPTIONS] CONTAINER [CONTAINER...]</span><br></pre></td></tr></table></figure>OPTIONS | 描述</li><li>–|—</li><li>-force , -f |      强制删除正在运行的容器</li><li>-link , -l |删除指定的链接</li><li>-volumes , -v|    删除与容器关联的匿名卷</li></ul><p>举几个例子：</p><ul><li>强制删除运行中的容器</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker rm --force redis</span><br><span class="line">redis</span><br></pre></td></tr></table></figure><ul><li>删除所有停止的容器</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker rm $(docker ps -a -q)</span><br></pre></td></tr></table></figure><p>此命令删除所有停止的容器。docker ps -a -q上面的命令 返回所有现有的容器ID，并将其传递给rm删除它们的命令。正在运行的容器不会被删除。</p><ul><li>删除容器及匿名卷</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ docker rm -v redis</span><br><span class="line">redis</span><br></pre></td></tr></table></figure><p>该命令将删除容器及其关联的任何卷。请注意，如果使用名称指定了卷，则不会将其删除。</p><ul><li>删除容器，并且选择性地去除卷<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ docker create -v awesome:&#x2F;foo -v &#x2F;bar --name hello redis</span><br><span class="line">hello</span><br><span class="line">$ docker rm -v hello</span><br></pre></td></tr></table></figure>在此示例中，存储卷/foo保持不变，但是的匿名卷/bar被移除。</li></ul><h3 id="diff"><a href="#diff" class="headerlink" title="diff"></a>diff</h3><ul><li><p>作用：检查容器文件系统上文件或目录的更改</p></li><li><p>用法：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker diff CONTAINER</span><br></pre></td></tr></table></figure></li><li><p>eg:</p></li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# docker diff nginx</span><br><span class="line">C &#x2F;root</span><br><span class="line">A &#x2F;root&#x2F;.bash_history</span><br><span class="line">C &#x2F;run</span><br><span class="line">A &#x2F;run&#x2F;nginx.pid</span><br><span class="line">C &#x2F;var</span><br><span class="line">C &#x2F;var&#x2F;cache</span><br><span class="line">C &#x2F;var&#x2F;cache&#x2F;nginx</span><br><span class="line">A &#x2F;var&#x2F;cache&#x2F;nginx&#x2F;proxy_temp</span><br><span class="line">A &#x2F;var&#x2F;cache&#x2F;nginx&#x2F;scgi_temp</span><br><span class="line">A &#x2F;var&#x2F;cache&#x2F;nginx&#x2F;uwsgi_temp</span><br><span class="line">A &#x2F;var&#x2F;cache&#x2F;nginx&#x2F;client_temp</span><br><span class="line">A &#x2F;var&#x2F;cache&#x2F;nginx&#x2F;fastcgi_temp</span><br></pre></td></tr></table></figure><table><thead><tr><th>符号</th><th>描述</th></tr></thead><tbody><tr><td>A</td><td>添加了文件或目录</td></tr><tr><td>D</td><td>文件或目录已删除</td></tr><tr><td>C</td><td>文件或目录已更改</td></tr></tbody></table><h3 id="stop"><a href="#stop" class="headerlink" title="stop"></a>stop</h3><ul><li>作用：停止一个或多个运行中的容器</li><li>用法：docker stop [OPTIONS] CONTAINER [CONTAINER…]</li></ul><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–time , -t</td><td>等待杀死的秒数，然后将其杀死</td></tr><tr><td>- eg：</td><td></td></tr></tbody></table><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker stop  nginx</span><br></pre></td></tr></table></figure><h3 id="start"><a href="#start" class="headerlink" title="start"></a>start</h3><ul><li>作用：启动一个或多个已停止的容器</li><li>用法：docker start  CONTAINER [CONTAINER…]</li><li>eg：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ docker start  nginx</span><br></pre></td></tr></table></figure><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="volume"><a href="#volume" class="headerlink" title="volume"></a>volume</h3><ul><li>作用：存储卷管理</li></ul><p>举几个常用的例子：</p><ul><li>新建存储卷</li></ul><p>docker volume create  [OPTIONS] [VOLUME]</p><table><thead><tr><th>OPTIONS</th><th>描述</th></tr></thead><tbody><tr><td>–driver , -d 默认    local</td><td>指定卷驱动程序名称</td></tr><tr><td>–label</td><td>设置卷的元数据</td></tr><tr><td>–name</td><td>指定卷名</td></tr><tr><td>–opt , -o</td><td>设置驱动程序特定选项</td></tr><tr><td><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">创建一个卷,并启动一个容器引用该存储卷</span><br><span class="line">$ docker volume create hello</span><br><span class="line">hello</span><br><span class="line">docker run -itd  --name mysql -p 3306:3306  --privileged&#x3D;true  -v hello:&#x2F;var&#x2F;lib&#x2F;mysql -e MYSQL_ROOT_PASSWORD&#x3D;123456  mysql</span><br><span class="line"></span><br><span class="line">创建一个tmpfs名为foo 大小为100MB和uid1000的卷。</span><br><span class="line">$ docker volume create --driver local \</span><br><span class="line">    --opt type&#x3D;tmpfs \</span><br><span class="line">    --opt device&#x3D;tmpfs \</span><br><span class="line">    --opt o&#x3D;size&#x3D;100m,uid&#x3D;1000 \</span><br><span class="line">    foo</span><br><span class="line"></span><br><span class="line">从nfs中挂载&#x2F;path&#x2F;to&#x2F;dirin rw模式 192.168.1.1：</span><br><span class="line">$ docker volume create --driver local \</span><br><span class="line">    --opt type&#x3D;nfs \</span><br><span class="line">    --opt o&#x3D;addr&#x3D;192.168.1.1,rw \</span><br><span class="line">    --opt device&#x3D;:&#x2F;path&#x2F;to&#x2F;dir \</span><br><span class="line">    foo</span><br></pre></td></tr></table></figure></td><td></td></tr></tbody></table><ul><li>列出卷清单</li></ul><p>docker volume ls [OPTIONS]<br>OPTIONS | 描述<br>—|—<br>–filter , -f|      提供过滤器值（例如’dangling = true’）<br>–format |    使用Go模板打印漂亮的卷<br>–quiet , -q|    仅显示卷名</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ docker volume ls</span><br><span class="line"></span><br><span class="line">DRIVER              VOLUME NAME</span><br><span class="line">local               rosemary</span><br><span class="line">local               tyler</span><br></pre></td></tr></table></figure><ul><li>删除所有未使用的本地卷</li></ul><p>docker volume prune [OPTIONS]<br>OPTIONS | 描述<br>—|—<br>–filter |      提供过滤器值（例如’label =’）<br>–force , -f |        不提示确认</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ docker volume prune</span><br><span class="line"></span><br><span class="line">WARNING! This will remove all local volumes not used by at least one container.</span><br><span class="line">Are you sure you want to continue? [y&#x2F;N] y</span><br><span class="line">Deleted Volumes:</span><br><span class="line">07c7bdf3e34ab76d921894c2b834f073721fccfbbcba792aa7648e3a7a664c2e</span><br><span class="line">my-named-vol</span><br><span class="line"></span><br><span class="line">Total reclaimed space: 36 B</span><br></pre></td></tr></table></figure><h3 id="ps"><a href="#ps" class="headerlink" title="ps"></a>ps</h3><ul><li>作用：列出容器</li><li>用法：docker ps [OPTIONS]</li></ul><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–all , -a</td><td>显示所有容器（默认显示为正在运行）</td></tr><tr><td>–filter , -f</td><td>根据提供的条件过滤输出</td></tr><tr><td>–format</td><td>使用Go模板打印漂亮的容器</td></tr><tr><td>–last , -n</td><td>显示n个最后创建的容器（包括所有状态）</td></tr><tr><td>–latest , -l</td><td>显示最新创建的容器（包括所有状态）</td></tr><tr><td>–quiet , -q</td><td>仅显示数字ID</td></tr><tr><td>–size , -s</td><td>显示文件总大小</td></tr></tbody></table><ul><li>eg：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE                 COMMAND                  CREATED             STATUS              PORTS                               NAMES</span><br><span class="line">55a00a8af099        nginx                 &quot;nginx -g &#39;daemon of…&quot;   4 hours ago         Up 8 minutes        80&#x2F;tcp                              nginx</span><br><span class="line">1c12274de353        jenkinsci&#x2F;blueocean   &quot;&#x2F;sbin&#x2F;tini -- &#x2F;usr&#x2F;…&quot;   6 days ago          Up 6 days           0.0.0.0:8080-&gt;8080&#x2F;tcp, 50000&#x2F;tcp   jenkins</span><br></pre></td></tr></table></figure><h3 id="images"><a href="#images" class="headerlink" title="images"></a>images</h3><ul><li>作用：列出镜像</li><li>用法：docker images [OPTIONS] [REPOSITORY[:TAG]]</li></ul><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–all , -a</td><td>显示所有镜像（默认隐藏中间镜像）</td></tr><tr><td>–filter , -f</td><td>根据提供的条件过滤输出</td></tr><tr><td>–format</td><td>使用Go模板打印漂亮的容器</td></tr><tr><td>–digests</td><td>显示摘要</td></tr><tr><td>–quiet , -q</td><td>仅显示数字ID</td></tr></tbody></table><ul><li>eg：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ docker images java</span><br><span class="line"></span><br><span class="line">REPOSITORY          TAG                 IMAGE ID            CREATED             SIZE</span><br><span class="line">java                8                   308e519aac60        6 days ago          824.5 MB</span><br><span class="line">java                7                   493d82594c15        3 months ago        656.3 MB</span><br><span class="line">java                latest              2711b1d6f3aa        5 months ago        603.9 MB</span><br></pre></td></tr></table></figure><h3 id="system"><a href="#system" class="headerlink" title="system"></a>system</h3><ul><li>作用：管理Docker</li><li>用法：docker system COMMAND</li></ul><p>举几个常用的例子：</p><ul><li>显示Docker磁盘使用情况</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# docker system df -v</span><br><span class="line">Images space usage:</span><br><span class="line"></span><br><span class="line">REPOSITORY            TAG                 IMAGE ID            CREATED             SIZE                SHARED SIZE         UNIQUE SIZE         CONTAINERS</span><br><span class="line">jenkinsci&#x2F;blueocean   latest              b13e019d0f69        7 days ago          567.7MB             0B                  567.7MB             1</span><br><span class="line">nginx                 latest              9beeba249f3e        9 days ago          126.8MB             0B                  126.8MB             1</span><br><span class="line"></span><br><span class="line">Containers space usage:</span><br><span class="line"></span><br><span class="line">CONTAINER ID        IMAGE                 COMMAND                  LOCAL VOLUMES       SIZE                CREATED             STATUS              NAMES</span><br><span class="line">55a00a8af099        nginx                 &quot;nginx -g &#39;daemon of…&quot;   0                   47B                 4 hours ago         Up 12 minutes       nginx</span><br><span class="line">1c12274de353        jenkinsci&#x2F;blueocean   &quot;&#x2F;sbin&#x2F;tini -- &#x2F;usr&#x2F;…&quot;   2                   14.3MB              6 days ago          Up 6 days           jenkins</span><br><span class="line"></span><br><span class="line">Local Volumes space usage:</span><br><span class="line"></span><br><span class="line">VOLUME NAME                                                        LINKS               SIZE</span><br><span class="line">jenkins-data                                                       1                   0B</span><br><span class="line">3159d2edffe4e610a309e94edda2932296de1e2c73f0c48b9d6327c39f73580b   1                   340.1MB</span><br><span class="line"></span><br><span class="line">Build cache usage: 0B</span><br><span class="line"></span><br><span class="line">CACHE ID            CACHE TYPE          SIZE                CREATED             LAST USED           USAGE               SHARED</span><br><span class="line"></span><br><span class="line">#SHARED SIZE 是图像与另一图像共享的空间量（即它们的公共数据）</span><br><span class="line">#UNIQUE SIZE 是仅给定图像使用的空间量</span><br><span class="line">#SIZE是图像的虚拟大小，它是的总和SHARED SIZE与UNIQUE SIZE</span><br><span class="line">#未显示网络信息，因为它不占用磁盘空间。</span><br></pre></td></tr></table></figure><ul><li>显示系统范围的信息<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# docker system info</span><br><span class="line">Client:</span><br><span class="line"> Debug Mode: false</span><br><span class="line"></span><br><span class="line">Server:</span><br><span class="line"> Containers: 2</span><br><span class="line">  Running: 2</span><br><span class="line">  Paused: 0</span><br><span class="line">  Stopped: 0</span><br><span class="line"> Images: 2</span><br><span class="line"> Server Version: 19.03.4</span><br><span class="line"> Storage Driver: overlay2</span><br><span class="line">  Backing Filesystem: xfs</span><br><span class="line">  Supports d_type: true</span><br><span class="line">  Native Overlay Diff: true</span><br><span class="line"> Logging Driver: json-file</span><br><span class="line"> Cgroup Driver: cgroupfs</span><br><span class="line"> Plugins:</span><br><span class="line">  Volume: local</span><br><span class="line">  Network: bridge host ipvlan macvlan null overlay</span><br><span class="line">  Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog</span><br><span class="line"> Swarm: inactive</span><br><span class="line"> Runtimes: runc</span><br><span class="line"> Default Runtime: runc</span><br><span class="line"> Init Binary: docker-init</span><br><span class="line"> containerd version: b34a5c8af56e510852c35414db4c1f4fa6172339</span><br><span class="line"> runc version: 3e425f80a8c931f88e6d94a8c831b9d5aa481657</span><br><span class="line"> init version: fec3683</span><br><span class="line"> Security Options:</span><br><span class="line">  seccomp</span><br><span class="line">   Profile: default</span><br><span class="line"> Kernel Version: 5.3.11-1.el7.elrepo.x86_64</span><br><span class="line"> Operating System: CentOS Linux 7 (Core)</span><br><span class="line"> OSType: linux</span><br><span class="line"> Architecture: x86_64</span><br><span class="line"> CPUs: 8</span><br><span class="line"> Total Memory: 15.61GiB</span><br><span class="line"> Name: localhost.localdomain</span><br><span class="line"> ID: 6GIS:LCQT:PWIR:OT3H:P7FV:FJWL:KQIT:6DR3:ENQC:HIRQ:4NV2:D7OL</span><br><span class="line"> Docker Root Dir: &#x2F;var&#x2F;lib&#x2F;docker</span><br><span class="line"> Debug Mode: false</span><br><span class="line"> Registry: https:&#x2F;&#x2F;index.docker.io&#x2F;v1&#x2F;</span><br><span class="line"> Labels:</span><br><span class="line"> Experimental: false</span><br><span class="line"> Insecure Registries:</span><br><span class="line">  127.0.0.0&#x2F;8</span><br><span class="line"> Registry Mirrors:</span><br><span class="line">  https:&#x2F;&#x2F;1nj0zren.mirror.aliyuncs.com&#x2F;</span><br><span class="line">  https:&#x2F;&#x2F;docker.mirrors.ustc.edu.cn&#x2F;</span><br><span class="line">  http:&#x2F;&#x2F;f1361db2.m.daocloud.io&#x2F;</span><br><span class="line">  https:&#x2F;&#x2F;registry.docker-cn.com&#x2F;</span><br><span class="line"> Live Restore Enabled: false</span><br><span class="line"></span><br><span class="line">WARNING: bridge-nf-call-iptables is disabled</span><br><span class="line">WARNING: bridge-nf-call-ip6tables is disabled</span><br></pre></td></tr></table></figure></li><li>删除未使用的数据（一般磁盘空间不够需要执行这个命令来清理）</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker system prune [OPTIONS]</span><br></pre></td></tr></table></figure><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–all , -a</td><td>删除所有未使用的镜像，而不仅仅是悬空的镜像</td></tr><tr><td>–force , -f</td><td>不提示确认</td></tr><tr><td>–volumes</td><td>删除卷</td></tr></tbody></table><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">$ docker system prune -a</span><br><span class="line"></span><br><span class="line">WARNING! This will remove:</span><br><span class="line">        - all stopped containers</span><br><span class="line">        - all networks not used by at least one container</span><br><span class="line">        - all dangling images</span><br><span class="line">        - all build cache</span><br><span class="line">Are you sure you want to continue? [y&#x2F;N] y</span><br><span class="line"></span><br><span class="line">Deleted Containers:</span><br><span class="line">f44f9b81948b3919590d5f79a680d8378f1139b41952e219830a33027c80c867</span><br><span class="line">792776e68ac9d75bce4092bc1b5cc17b779bc926ab04f4185aec9bf1c0d4641f</span><br><span class="line"></span><br><span class="line">Deleted Networks:</span><br><span class="line">network1</span><br><span class="line">network2</span><br><span class="line"></span><br><span class="line">Deleted Images:</span><br><span class="line">untagged: hello-world@sha256:f3b3b28a45160805bb16542c9531888519430e9e6d6ffc09d72261b0d26ff74f</span><br><span class="line">deleted: sha256:1815c82652c03bfd8644afda26fb184f2ed891d921b20a0703b46768f9755c57</span><br><span class="line">deleted: sha256:45761469c965421a92a69cc50e92c01e0cfa94fe026cdd1233445ea00e96289a</span><br><span class="line"></span><br><span class="line">Total reclaimed space: 1.84kB</span><br></pre></td></tr></table></figure><h3 id="inspect"><a href="#inspect" class="headerlink" title="inspect"></a>inspect</h3><ul><li>作用：返回有关Docker对象的信息</li><li>用法：docker inspect [OPTIONS] NAME|ID [NAME|ID…]</li></ul><table><thead><tr><th>参数</th><th>描述</th></tr></thead><tbody><tr><td>–format, -f</td><td>使用Go模板打印漂亮的容器</td></tr><tr><td>–size , -s</td><td>如果类型为容器，则显示文件总大小</td></tr><tr><td>–type</td><td>返回指定类型的JSON</td></tr></tbody></table><ul><li>eg：</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">获得容器的基本信息</span><br><span class="line"></span><br><span class="line">docker inspect nginx</span><br><span class="line"></span><br><span class="line">获取实例的IP地址</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# docker inspect --format&#x3D;&#39;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&#39; nginx</span><br><span class="line">172.17.0.3</span><br><span class="line"></span><br><span class="line">获取实例的MAC地址</span><br><span class="line"></span><br><span class="line">[root@localhost ~]#  docker inspect --format&#x3D;&#39;&#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.MacAddress&#125;&#125;&#123;&#123;end&#125;&#125;&#39; nginx</span><br><span class="line">02:42:ac:11:00:03</span><br><span class="line"></span><br><span class="line">获取实例的日志路径</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# docker inspect --format&#x3D;&#39;&#123;&#123;.LogPath&#125;&#125;&#39; nginx</span><br><span class="line">&#x2F;var&#x2F;lib&#x2F;docker&#x2F;containers&#x2F;55a00a8af09993ab9c69ee570d7cdf0fb90ac9d76579d9640137311962d9eaab&#x2F;55a00a8af09993ab9c69ee570d7cdf0fb90ac9d76579d9640137311962d9eaab-json.log</span><br><span class="line"></span><br><span class="line">获取实例的镜像名称</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# docker inspect --format&#x3D;&#39;&#123;&#123;.Config.Image&#125;&#125;&#39; nginx</span><br><span class="line">nginx</span><br><span class="line"></span><br><span class="line">列出所有端口绑定,可以遍历数组和结果中的映射以产生简单的文本输出：</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# docker inspect --format&#x3D;&#39;&#123;&#123;range $p, $conf :&#x3D; .NetworkSettings.Ports&#125;&#125; &#123;&#123;$p&#125;&#125; -&gt; &#123;&#123;(index $conf 0).HostPort&#125;&#125; &#123;&#123;end&#125;&#125;&#39; &#96;docker ps -a -q&#96;</span><br><span class="line"></span><br><span class="line">获取JSON格式的返回信息</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# docker inspect --format&#x3D;&#39;&#123;&#123;json .Config&#125;&#125;&#39; nginx</span><br><span class="line">&#123;&quot;Hostname&quot;:&quot;55a00a8af099&quot;,&quot;Domainname&quot;:&quot;&quot;,&quot;User&quot;:&quot;&quot;,&quot;AttachStdin&quot;:false,&quot;AttachStdout&quot;:false,&quot;AttachStderr&quot;:false,&quot;ExposedPorts&quot;:&#123;&quot;80&#x2F;tcp&quot;:&#123;&#125;&#125;,&quot;Tty&quot;:true,&quot;OpenStdin&quot;:true,&quot;StdinOnce&quot;:false,&quot;Env&quot;:[&quot;PATH&#x3D;&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;local&#x2F;bin:&#x2F;usr&#x2F;sbin:&#x2F;usr&#x2F;bin:&#x2F;sbin:&#x2F;bin&quot;,&quot;NGINX_VERSION&#x3D;1.17.10&quot;,&quot;NJS_VERSION&#x3D;0.3.9&quot;,&quot;PKG_RELEASE&#x3D;1~buster&quot;],&quot;Cmd&quot;:[&quot;nginx&quot;,&quot;-g&quot;,&quot;daemon off;&quot;],&quot;Image&quot;:&quot;nginx&quot;,&quot;Volumes&quot;:null,&quot;WorkingDir&quot;:&quot;&quot;,&quot;Entrypoint&quot;:null,&quot;OnBuild&quot;:null,&quot;Labels&quot;:&#123;&quot;maintainer&quot;:&quot;NGINX Docker Maintainers &lt;docker-maint@nginx.com&gt;&quot;&#125;,&quot;StopSignal&quot;:&quot;SIGTERM&quot;&#125;</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>基本上常用的docker命令我都总结到这篇文章了，希望对大家有帮助，谢谢。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://docs.docker.com/engine/install/centos/" target="_blank" rel="noopener">docker安装官方文档</a></p><p><a href="https://docs.docker.com/reference/" target="_blank" rel="noopener">dockercli官方文档</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> Linux </tag>
            
            <tag> Devops </tag>
            
            <tag> 容器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跟我学Mysql之事务篇</title>
      <link href="2020/06/08/mysql/mysql-trx/"/>
      <url>2020/06/08/mysql/mysql-trx/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="事务"><a href="#事务" class="headerlink" title="事务"></a>事务</h1><p>数据库事务（简称:事务）是数据库管理系统执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成。事务的使用是数据库管理系统区别文件系统的重要特征之一。</p><p>事务拥有四个重要的特性：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability），人们习惯称之为 ACID 特性。下面我逐一对其进行解释。</p><ul><li><p>原子性（Atomicity）<br>事务开始后所有操作，要么全部做完，要么全部不做，不可能停滞在中间环节。事务执行过程中出错，会回滚到事务开始前的状态，所有的操作就像没有发生一样。例如，如果一个事务需要新增 100 条记录，但是在新增了 10 条记录之后就失败了，那么数据库将回滚对这 10 条新增的记录。也就是说事务是一个不可分割的整体，就像化学中学过的原子，是物质构成的基本单位。</p></li><li><p>一致性（Consistency）<br>指事务将数据库从一种状态转变为另一种一致的的状态。事务开始前和结束后，数据库的完整性约束没有被破坏。例如工号带有唯一属性，如果经过一个修改工号的事务后，工号变的非唯一了，则表明一致性遭到了破坏。</p></li><li><p>隔离性（Isolation）<br>要求每个读写事务的对象对其他事务的操作对象能互相分离，即该事务提交前对其他事务不可见。 也可以理解为多个事务并发访问时，事务之间是隔离的，一个事务不应该影响其它事务运行效果。这指的是在并发环境中，当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间。由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。例如一个用户在更新自己的个人信息的同时，是不能看到系统管理员也在更新该用户的个人信息（此时更新事务还未提交）。</p></li></ul><p>注：Mysql 通过锁机制来保证事务的隔离性。</p><ul><li>持久性（Durability）<br>事务一旦提交，则其结果就是永久性的。即使发生宕机的故障，数据库也能将数据恢复，也就是说事务完成后，事务对数据库的所有更新将被保存到数据库，不能回滚。这只是从事务本身的角度来保证，排除 RDBMS（关系型数据库管理系统，例如 Oracle、Mysql 等）本身发生的故障。</li></ul><p>注：Mysql 使用 redo log 来保证事务的持久性。</p><h1 id="事务的隔离级别（Transaction-Isolation-Levels）"><a href="#事务的隔离级别（Transaction-Isolation-Levels）" class="headerlink" title="事务的隔离级别（Transaction Isolation Levels）"></a>事务的隔离级别（Transaction Isolation Levels）</h1><p>事务隔离是数据库处理的基础之一。隔离是ACID中的I ；隔离级别是一种设置，用于在多个事务同时进行更改和执行查询时微调性能与结果的可靠性，一致性和可重复性之间的平衡。</p><p>Mysql/InnoDB 提供SQL标准所描述的所有四个事务隔离级别。</p><table><thead><tr><th>隔离级别</th><th>脏读</th><th>不能重复读</th><th>幻读</th></tr></thead><tbody><tr><td>未提交读(Read uncommitted)</td><td>能</td><td>能</td><td>能</td></tr><tr><td>已提交读(Read committed)</td><td>不能</td><td>能</td><td>能</td></tr><tr><td>可重复读(Repeatable read)</td><td>不能</td><td>不能</td><td>不能</td></tr><tr><td>可串行化（Serializable ）</td><td>不能</td><td>不能</td><td>不能</td></tr></tbody></table><h2 id="四个级别逐渐增强，每个级别解决一个问题。事务级别越高-性能越差-大多数情况都用rc隔离级别。"><a href="#四个级别逐渐增强，每个级别解决一个问题。事务级别越高-性能越差-大多数情况都用rc隔离级别。" class="headerlink" title="四个级别逐渐增强，每个级别解决一个问题。事务级别越高,性能越差,大多数情况都用rc隔离级别。"></a>四个级别逐渐增强，每个级别解决一个问题。事务级别越高,性能越差,大多数情况都用rc隔离级别。</h2><ul><li>未提交读(Read Uncommitted)：一个事务还未提交，它所做的变更就可以被别的事务看到</li><li>提交读(Read Committed)：一个事务提交之后，它所做的变更才可以被别的事务看到</li><li>可重复读(Repeated Read)：同一事务中的一致读取将读取第一次读取时候建立的 快照，InnoDB默认级别。消除了脏读、不可重复读、幻读，保证事务一致性</li><li>可串行化（Serializable）：隔离级别最高<br>串行化读，每次读都需要获得表级共享锁，读写间相互都会阻塞</li></ul><hr><ul><li>脏读: 脏读就是指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，这时，另外一个事务也访问这个数据，然后使用了这个数据。</li><li>不能重复读：是指在一个事务内，多次读同一数据。在这个事务还没有结束时，另外一个事务也访问该同一数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改，那么第一个事务两次读到的的数据可能是不一样的。这样就发生了在一个事务内两次读到的数据是不一样的，因此称为是不可重复读。</li><li>幻读：当同一查询在不同时间生成不同的行集时，在事务内就会发生 所谓的幻像问题。如果a事务 SELECT执行两次，但是第二次返回的行却不是第一次返回，则该行是“ phantom”行。</li></ul><h1 id="MVCC"><a href="#MVCC" class="headerlink" title="MVCC"></a>MVCC</h1><p>InnoDB是一个多版本的存储引擎MVCC（ multi-versioned storage engine）它保留有关已更改行的旧版本的信息，以支持诸如并发和回滚之类的事务功能。此信息存储在表空间中的数据结构中，该数据结构称为 回滚段InnoDB 使用回滚段中的信息来执行事务回滚中所需的撤消操作。它还使用该信息来构建行的早期版本，以实现一致的读取。</p><p>首先理解，MVCC是InnoDB存储引擎的特性，好处在于可以并发处理事务及回滚事务。</p><p>下面举个经典的例子</p><table><thead><tr><th>session 1</th><th>session 2</th></tr></thead><tbody><tr><td>start transaction;</td><td></td></tr><tr><td>select a from test; return a = 10</td><td></td></tr><tr><td>update test set a = 20;</td><td></td></tr><tr><td>-</td><td>start transaction;</td></tr><tr><td>-</td><td>select a from test; return ?</td></tr><tr><td>commit;</td><td></td></tr><tr><td>-</td><td>select a from test; return ?</td></tr></tbody></table><p>我们看下上面这个数据库日常操作的例子。</p><p>session 1修改了一条记录，没有提交；与此同时，session 2 来查询这条记录，这时候返回记录应该是多少呢？</p><p>session 1 提交之后 session 2 查询出来的又应该是多少呢？</p><p>由于Mysql支持多种隔离级别，这个问题是需要看session2的事务隔离级别的，情况如下:</p><ul><li><p>隔离级别为 READ-UNCOMMITTED 情况下:<br>无论session 1 是否commit，session 2 去查看都会看到的是修改后的结果，即 a = 20</p></li><li><p>隔离级别为 READ-COMMITTED 情况下:<br>session 1 在 commit 前，session 2查看到的还是 a =10 , commit之后看到的则是 a = 20</p></li><li><p>隔离级别为 REPEATABLE-READ 及 SERIALIZABLE 情况下:<br>无论 session 1 是否commit，session 2 去查看都会看到的是修改前的结果，即 a = 10</p></li></ul><p>其实不管隔离级别，我们也抛开数据库中的ACID，我们思考一个问题：众所周知，InnoDB的数据都是存储在B+tree里面的，修改后的数据到底要不要存储在实际的B+tree叶子节点，session2是怎么做到查询出来的结果还是10，而不是20呢？</p><p>在解释上述问题之前，我们需要继续了解4个基本概念</p><h2 id="undo-log（回滚日志）"><a href="#undo-log（回滚日志）" class="headerlink" title="undo log（回滚日志）"></a>undo log（回滚日志）</h2><p>Undo log是InnoDB MVCC事务特性的重要组成部分。当我们对记录做了变更操作时就会产生undo记录，Undo记录默认被记录到系统表空间(ibdata)中。</p><p>回滚日志分为插入和更新撤消日志。插入撤消日志仅在事务回滚时才需要，并且在事务提交后可以立即将其丢弃。更新撤消日志也用于一致的读取中，但是只有在不存在为其InnoDB分配了快照的事务后，才可以将其删除行。</p><h2 id="隐藏字段"><a href="#隐藏字段" class="headerlink" title="隐藏字段"></a>隐藏字段</h2><p>在内部，InnoDB向数据库中存储的每一行添加三个字段。</p><ul><li>6个字节的DB_TRX_ID字段表示插入或更新该行的最后一个事务的事务标识符</li><li>7个字节的DB_ROLL_PTR字段则表示指向该行回滚段的指针，回滚指针指向写入回滚段的撤消日志记录。如果行已更新，则撤消日志记录将包含在更新行之前重建行内容所必需的信息。</li><li>6字节的DB_ROW_ID字段包含一个行ID，该行ID随着插入新行而单调增加。如果表里没有主键则系统默认给这个字段上主键和聚簇索引，只不过不能被外部调用。</li></ul><p>为什么一个数据只有一个DB_TRX_ID，但是却可以回滚到以前的记录呢，其实就是因为DB_ROLL_PTR和undo log的存在。</p><p>如果你需要将某一行回滚到之前的版本则根据当前版本和 undo log 计算出来的。</p><p>假设上述例子：</p><p>select a from test; return a = 10     DB_TRX_ID=1 DB_ROLL_PTR=Null</p><p>update test set a = 20;    DB_TRX_ID=2 DB_ROLL_PTR=[2]→[1]</p><p>你需要回滚到DB_TRX_ID=1时a的值，操作为：通过DB_TRX_ID=2,a=20 以及DB_ROLL_PTR=[2]→[1]和undo log[2→1]你通过一些算法计算出了    DB_TRX_ID=1时a的值=10 再将结果更新。</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Mysql/trx/colums.jpg"  alt="colums.jpg"></p><h2 id="trx-sys（事务链表）"><a href="#trx-sys（事务链表）" class="headerlink" title="trx_sys（事务链表）"></a>trx_sys（事务链表）</h2><p>Mysql中的事务在开始到提交这段过程中，都会被保存到一个叫trx_sys的事务链表中，事务链表中保存的都是还未提交的事务，事务一旦被提交，则会被从事务链表中摘除。</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Mysql/trx/trx_sys.jpg"  alt="trx_sys.jpg"></p><h2 id="ReadView（一致性视图）"><a href="#ReadView（一致性视图）" class="headerlink" title="ReadView（一致性视图）"></a>ReadView（一致性视图）</h2><p>为了方便理解，我把ReadView看做一个数据结构，在SQL开始的时候被创建。这个数据结构中包含了3个主要的成员：ReadView[高水位, 低水位, trx_ids{}]</p><ul><li>高水位（low_limit_id） ：事务链表（trx_sys）ID最大值+1</li><li>低水位（up_limit_id） ：事务链表（trx_sys）ID最小值</li><li>trx_ids：事务链表（trx_sys）中事务的id集合</li></ul><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Mysql/trx/readview.jpg"  alt="readview.jpg"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">readview规则：</span><br><span class="line"></span><br><span class="line">1.DB_TRX_ID &lt;low_limit_id 则该行对于当前Read View是可见的</span><br><span class="line"></span><br><span class="line">2.DB_TRX_ID &gt;&#x3D;up_limit_id  则该行对于当前Read View是不可见的</span><br><span class="line"></span><br><span class="line">判断某行可不可见需要满足第一条规则，且不满足第二条规则，否则不可见</span><br></pre></td></tr></table></figure><p>不满足read view条件时候，从undo log里面获取数据DB_TRX_ID再进行对比，直到找到一个均满足这2个条件的即可</p><p>注意，ReadView是与SQL绑定的，而并不是事务，所以即使在同一个事务中，每次SQL启动时构造的ReadView的up_trx_id和low_trx_id也都是不一样的</p><h1 id="总结MVCC"><a href="#总结MVCC" class="headerlink" title="总结MVCC"></a>总结MVCC</h1><p>MVCC启动步骤：</p><ul><li>1.事务启动时, 创建快照; 基于整个库</li><li>2.旧数据存储在UNDO中，再通过DB_ROLL_PTR 回溯查找历史版本<br>如果当插入的是一条新数据时，记录上对应的回滚段指针为NULL<br>如果更新记录时，原记录将被放入到undo表空间中，并通过DB_ROLL_PTR指向该记录。</li><li>3.通过read view判断行记录是否可见</li></ul><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Mysql/trx/mvcc.png"  alt="mvcc.png"></p><p>MVCC使得数据库读不会对数据加锁，普通的SELECT请求不会加锁，提高了数据库的并发处理能力；</p><p>借助MVCC，数据库可以实现RC，RR等隔离级别，用户可以查看当前数据的前一个或者前几个历史版本。保证了ACID中的I特性（隔离性）。</p><h1 id="深入理解事务隔离级别RR和RC的区别"><a href="#深入理解事务隔离级别RR和RC的区别" class="headerlink" title="深入理解事务隔离级别RR和RC的区别"></a>深入理解事务隔离级别RR和RC的区别</h1><p>由于RR隔离级别下，在每个事务开始的时候，会将当前系统中的所有的活跃事务拷贝到一个列表中(read view)。</p><p>RC隔离级别下，在事务中的每个语句开始时，会将当前系统中的所有的活跃事务拷贝到一个列表中(read view) 。</p><p>再举个例子，从MVCC启动步骤来分析。</p><table><thead><tr><th>session 1</th><th>session 2</th><th>时刻</th></tr></thead><tbody><tr><td>insert test(a) values (10)</td><td></td><td>1</td></tr><tr><td>start transaction;</td><td></td><td>2</td></tr><tr><td>select a from test; return a = 10；</td><td></td><td>3</td></tr><tr><td>update test set a = 20;</td><td></td><td>4</td></tr><tr><td>-</td><td>start transaction;</td><td>5</td></tr><tr><td>-</td><td>select a from test; return ?</td><td>6</td></tr><tr><td>commit;</td><td></td><td>7</td></tr><tr><td>-</td><td>select a from test; return ?</td><td>8</td></tr></tbody></table><ul><li>时刻1 增加一行数据并自动提交，分析这行数据、trx_sys、readview</li></ul><table><thead><tr><th>DB_TRX_ID</th><th>DB_ROLL_PTR</th><th>DB_ROW_ID</th><th>colum a</th></tr></thead><tbody><tr><td>1</td><td>NULL</td><td>1</td><td>10</td></tr></tbody></table><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trx_sys&#x3D;[]</span><br></pre></td></tr></table></figure><ul><li>时刻2 session 1开启事务</li><li>时刻3 select a from test; return a = 10;分析这行数据、trx_sys、readview</li></ul><table><thead><tr><th>DB_TRX_ID</th><th>DB_ROLL_PTR</th><th>DB_ROW_ID</th><th>colum a</th></tr></thead><tbody><tr><td>1</td><td>NULL</td><td>1</td><td>10</td></tr></tbody></table><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">trx_sys&#x3D;[2] </span><br><span class="line"></span><br><span class="line">注意：查询不会改变的数据行的DB_TRX_ID，但是这条语句本身的DB_TRX_ID会递增，即为2，高低水位是以当前sql的DB_TRX_ID进行计算</span><br><span class="line"></span><br><span class="line">readview&#x3D;[low_limit_id(3),up_limit_id(2),trx_sys&#123;2&#125;]</span><br></pre></td></tr></table></figure><hr><p>根据readview规则：</p><p>DB_TRX_ID &lt;low_limit_id则该行对于当前Read View是可见的 </p><p>DB_TRX_ID &gt;= up_limit_id 则该行对于当前Read View是可见的</p><p>如果DB_TRX_ID(1) &lt;low_limit_id(3) 则该行对于当前Read View是可见的   </p><p>满足规则，则可见</p><p>如果DB_TRX_ID(1) &gt;= up_limit_id(2) 则该行对于当前Read View是不可见的</p><p>不满足规则，则可见</p><p>由于规则都可见，所以查询结果为DB_TRX_ID=1时的colum a=10</p><hr><ul><li>时刻4 update test set a = 20;分析这行数据、trx_sys、readview、undo log</li></ul><table><thead><tr><th>DB_TRX_ID</th><th>DB_ROLL_PTR</th><th>DB_ROW_ID</th><th>colum a</th></tr></thead><tbody><tr><td>2</td><td>DB_TRX_ID[1]</td><td>1</td><td>20</td></tr></tbody></table><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">trx_sys&#x3D;[3]→[2]</span><br><span class="line"></span><br><span class="line">readview&#x3D;[low_limit_id(4),up_limit_id(2)，trx_sys&#123;3，2&#125;]</span><br></pre></td></tr></table></figure><ul><li>时刻5 session 2开启事务</li><li>时刻6 select a from test;（获取快照）</li><li>分析这行的隐藏列、trx_sys、readview</li></ul><table><thead><tr><th>DB_TRX_ID</th><th>DB_ROLL_PTR</th><th>DB_ROW_ID</th><th>colum a</th></tr></thead><tbody><tr><td>2</td><td>DB_TRX_ID[1]</td><td>1</td><td>20</td></tr></tbody></table><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">trx_sys&#x3D;[4]→[3]→[2]</span><br><span class="line"></span><br><span class="line">readview&#x3D;[low_limit_id(5),up_limit_id(2)，trx_sys&#123;4,3,2&#125;]</span><br></pre></td></tr></table></figure><hr><p>根据readview规则：</p><p>DB_TRX_ID &lt;low_limit_id则该行对于当前Read View是可见的 </p><p>DB_TRX_ID &gt;= up_limit_id 则该行对于当Read View是不可见的</p><p>如果DB_TRX_ID(2) &lt;low_limit_id(5) 则该行对于当前Read View是可见的 </p><p>满足条件，则可见</p><p>如果DB_TRX_ID(2) &gt;= up_limit_id(2) 则该行对于当前Read View是不可见的  </p><p>满足条件，则不可见</p><p>结论：由于规则2满足，则该行对于当前Read View是不可见,则通过回滚指针DB_ROLL_PTR=[2]→[1]和undo log[2]→[1]计算出DB_TRX_ID=1时的行数据，则继续分析</p><p>如果DB_TRX_ID(1) &lt;low_limit_id(5) 则该行对于当前Read View是一定可见的   </p><p>满足条件，则可见</p><p>如果DB_TRX_ID(1) &gt;= up_limit_id(2) 则该行对于当前Read View是一定不可见的 </p><p>不满足条件，则可见</p><p>结论：则DB_TRX_ID[1]这行对当前read view可见</p><p>则查询结果为colum a=10</p><hr><ul><li>时刻7 session 1 提交事务</li></ul><table><thead><tr><th>DB_TRX_ID</th><th>DB_ROLL_PTR</th><th>DB_ROW_ID</th><th>colum</th></tr></thead><tbody><tr><td>2</td><td>DB_TRX_ID[1]</td><td>1</td><td>20</td></tr></tbody></table><p>提交事务后会把事务链表已提交的事务id去掉，则当前trx_sys为[4]</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trx_sys&#x3D;[4]</span><br></pre></td></tr></table></figure><ul><li>时刻8 select a from test</li></ul><p>注意，在此之前都所有结论都试用于rr和rc，而这里不同</p><h2 id="在rc的隔离级别下"><a href="#在rc的隔离级别下" class="headerlink" title="在rc的隔离级别下"></a>在rc的隔离级别下</h2><p>由于每次查询都是读取到最新的readview，所以本次查询的行数据如下</p><table><thead><tr><th>DB_TRX_ID</th><th>DB_ROLL_PTR</th><th>DB_ROW_ID</th><th>colum a</th></tr></thead><tbody><tr><td>2</td><td>DB_TRX_ID[1]</td><td>1</td><td>20</td></tr></tbody></table><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">trx_sys&#x3D;[5]→[4]</span><br><span class="line"></span><br><span class="line">readview&#x3D;[low_limit_id(6),up_limit_id(4)，trx_sys&#123;5,4&#125;]</span><br></pre></td></tr></table></figure><hr><p>根据readview规则：</p><p>DB_TRX_ID &lt;low_limit_id则该行对于当前Read View是可见的 </p><p>DB_TRX_ID &gt;= up_limit_id 则该行对于当Read View是不可见的</p><p>如果DB_TRX_ID(2) &lt;low_limit_id(6) 则该行对于当前Read View是可见的 </p><p>满足条件，则可见</p><p>如果DB_TRX_ID(2) &gt;= up_limit_id(4) 则该行对于当前Read View是不可见的  </p><p>不满足条件，则可见</p><p>结论：则DB_TRX_ID[2]这行对当前read view可见</p><p>则查询结果为colum a=20  </p><hr><h2 id="在rr的隔离级别下"><a href="#在rr的隔离级别下" class="headerlink" title="在rr的隔离级别下"></a>在rr的隔离级别下</h2><p>由于每次查询都是读取到第一次查询创建的readview，所以本次查询直接读取的是时刻6获取到的readview，即</p><p>readview=[low_limit_id(5),up_limit_id(2)，trx_sys{4,3,2}] </p><p>而通过这个readview计算出来的行数据为colum a=10</p><p>则查询结果为colum a=10</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>可能看到此时，你会觉得有点绕，为什么rc的隔离级别和rr的隔离级别在另外一个事务提交完了之后读取的数值是不一样的呢？</p><p>其实看看最上面的我对事务隔离级别的定义就能明白</p><p>在rc的隔离级别中，开启一个事务select都会是最新的readview</p><p>在rr的隔离级别中，开启一个事务，每个select都会读取第一次查询得到的readview</p><p>然后如果对readview的规则还不太理解，我再说一句：</p><p>一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：版本未提交，不可见；版本已提交，但是是在视图创建后提交的，不可见；版本已提交，而且是在视图创建前提交的，可见。</p><p>我觉得这样讲能更深地理解隔离级别的区别，至于隔离级别的不同是因为他们的底层原理不同：这里简单讲下，rr的隔离级别比rc多了一种锁————间隙锁（Gap Locks）。</p><p>间隙锁跟MVCC一起工作。实现事务处理：</p><p>在rr隔离级别：采用Gap Locks(间隙锁) 来解决幻读问题</p><p>在rc隔离级别：采用Record锁,不会出现脏读，但是会产生”幻读”问题. 也会出现可重复读</p><p>关于Mysql锁的概念我会在后面继续深入讲解，在此处就不做过多的深究了。</p><p>最后说一句，数据多版本(MVCC)是Mysql实现高性能的一个主要的一个主要方式，通过对普通的SELECT不加锁，直接利用MVCC读取指版本的值。不同的事务访问不同版本的数据快照，从而实现不同的事务隔离级别。虽然字面上是说具有多个版本的数据快照，但这并不意味着数据库必须拷贝数据，保存多份数据文件，这样会浪费大量的存储空间。InnoDB通过事务的undolog巧妙地实现了多版本的数据快照。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://mp.weixin.qq.com/s/tNA_-_MoYt1fJT0icyKbMg" target="_blank" rel="noopener">MVCC原理探究及Mysql源码实现分析</a></p><p><a href="http://www.sysdb.cn/index.php/2017/07/04/Mysql-mvcc/#more-33" target="_blank" rel="noopener">Mysql MVCC实现</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
            <tag> MVCC </tag>
            
            <tag> 事务 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker安装一套中间件</title>
      <link href="2020/06/07/docker/docker-install-middleware/"/>
      <url>2020/06/07/docker/docker-install-middleware/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>领导要我部署压测环境中间件，一套中间件以往都是建3台虚拟机，但是我这次想用docker部署，合理利用docker提高资源利用率以及维护方便。</p><h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><h2 id="硬件配置"><a href="#硬件配置" class="headerlink" title="硬件配置"></a>硬件配置</h2><ul><li>cpu:8c </li><li>内存:32g </li><li>硬盘:100g</li></ul><h2 id="软件配置"><a href="#软件配置" class="headerlink" title="软件配置"></a>软件配置</h2><ul><li>centos:7.6 </li><li>docker:19.03 </li><li>nacos:1.1.3  只做配置中心  单机</li><li>zk:3.4 只做注册中心   集群 </li><li>rocketmq:4.3.2 只做消息队列 集群</li><li>redis 5.0 缓存  集群</li></ul><h2 id="本地端口规划"><a href="#本地端口规划" class="headerlink" title="本地端口规划"></a>本地端口规划</h2><ul><li>nacos：8848</li><li>zk：<br>zoo1:2181<br>zoo2:2182<br>zoo3:2183</li><li>dubbo-admin:8080</li><li>rocketmq：<br>rmqnamesrv-a:9876<br>rmqnamesrv-b:9877<br>rmqbroker-a:10911<br>rmqbroker-b:10909<br>rmqconsole:9001</li><li>redis:{7010,7011,7012,7013,7014,7015}</li></ul><p>部署之前先确保以上端口没有被占用</p><h2 id="文件夹目录"><a href="#文件夹目录" class="headerlink" title="文件夹目录"></a>文件夹目录</h2><p>存放配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-26-21 ~]# mkdir -vp &#x2F;opt&#x2F;&#123;rocketmq4.3.2&#123;&#x2F;broker-a,&#x2F;broker-b&#125;,zookeeper&#125;</span><br><span class="line">[root@vm-26-21 ~]# cd &#x2F;opt</span><br><span class="line">[root@vm-26-21 opt]# tree</span><br><span class="line">├── rocketmq4.3.2</span><br><span class="line">│   ├── broker-a</span><br><span class="line">│   │   └── broker-a.conf</span><br><span class="line">│   ├── broker-b</span><br><span class="line">│   │   └── broker-b.conf</span><br><span class="line">│   └── mq.yml</span><br><span class="line">└── zookeeper</span><br><span class="line">    └── zk.yml</span><br></pre></td></tr></table></figure><hr><p>日志挂载</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-26-21 ~]# mkdir -vp &#x2F;data&#x2F;&#123;rocketmq4.3.2,zookeeper&#125;</span><br><span class="line">[root@vm-26-21 ~]# cd &#x2F;opt</span><br><span class="line">[root@vm-26-21 data]# tree</span><br><span class="line">├── rocketmq4.3.2</span><br><span class="line">└── zookeeper</span><br></pre></td></tr></table></figure><h1 id="nacos"><a href="#nacos" class="headerlink" title="nacos"></a>nacos</h1><p>我的部署方式是单机，因为只是当作配置中心而已，也是线下配置，不做持久化，只要机器足够稳定（不关机/不删除）我nacos都启动了1年，啥事没有。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">docker pull nacos&#x2F;nacos-server:1.1.3</span><br><span class="line">docker run --env MODE&#x3D;standalone --name nacos --restart always -d -p 8848:8848 nacos&#x2F;nacos-server:1.1.3</span><br><span class="line">启动成功后访问http:&#x2F;&#x2F;ip:8848&#x2F;nacos  </span><br><span class="line">账号密码为nacos&#x2F;nacos</span><br></pre></td></tr></table></figure><p>如果你的目的是做注册中心以及在生产环境等重要的环境部署，则需要用持久化部署，无论是docker或者物理部署，都需要一个数据库，具体部署过程我就不详细写了，直接看官网，足够详细。</p><p><a href="https://rugod.cn/2020/05/14/slb/slb-nacos/" target="_blank" rel="noopener">实现负载均衡器搭配Nacos集群的高可用框架</a></p><p><a href="https://nacos.io/zh-cn/docs/cluster-mode-quick-start.html" target="_blank" rel="noopener">nacos官网</a></p><h1 id="zk"><a href="#zk" class="headerlink" title="zk"></a>zk</h1><h2 id="创建配置文件"><a href="#创建配置文件" class="headerlink" title="创建配置文件"></a>创建配置文件</h2><p>vim /opt/zookeeper/zk.yml</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">version: &#39;3.1&#39;</span><br><span class="line"></span><br><span class="line">services:</span><br><span class="line">  zoo1:</span><br><span class="line">    image: zookeeper</span><br><span class="line">    restart: always</span><br><span class="line">    hostname: zoo1</span><br><span class="line">    ports:</span><br><span class="line">      - 2181:2181</span><br><span class="line">    environment:</span><br><span class="line">      ZOO_MY_ID: 1</span><br><span class="line">      ZOO_SERVERS: server.1&#x3D;0.0.0.0:2888:3888;2181 server.2&#x3D;zoo2:2888:3888;2181 server.3&#x3D;zoo3:2888:3888;2181</span><br><span class="line">    volumes:</span><br><span class="line">    - &#x2F;data&#x2F;zookeeper&#x2F;1&#x2F;:&#x2F;data    </span><br><span class="line">  zoo2:</span><br><span class="line">    image: zookeeper</span><br><span class="line">    restart: always</span><br><span class="line">    hostname: zoo2</span><br><span class="line">    ports:</span><br><span class="line">      - 2182:2181</span><br><span class="line">    environment:</span><br><span class="line">      ZOO_MY_ID: 2</span><br><span class="line">      ZOO_SERVERS: server.1&#x3D;zoo1:2888:3888;2181 server.2&#x3D;0.0.0.0:2888:3888;2181 server.3&#x3D;zoo3:2888:3888;2181</span><br><span class="line">    volumes:</span><br><span class="line">    - &#x2F;data&#x2F;zookeeper&#x2F;2&#x2F;:&#x2F;data   </span><br><span class="line">    </span><br><span class="line">  zoo3:</span><br><span class="line">    image: zookeeper</span><br><span class="line">    restart: always</span><br><span class="line">    hostname: zoo3</span><br><span class="line">    ports:</span><br><span class="line">      - 2183:2181</span><br><span class="line">    environment:</span><br><span class="line">      ZOO_MY_ID: 3</span><br><span class="line">      ZOO_SERVERS: server.1&#x3D;zoo1:2888:3888;2181 server.2&#x3D;zoo2:2888:3888;2181 server.3&#x3D;0.0.0.0:2888:3888;2181</span><br><span class="line">    volumes:</span><br><span class="line">    - &#x2F;data&#x2F;zookeeper&#x2F;3&#x2F;:&#x2F;data   </span><br><span class="line">  admin:</span><br><span class="line">    image: chenchuxin&#x2F;dubbo-admin</span><br><span class="line">    container_name: dubbo-admin</span><br><span class="line">    restart: always</span><br><span class="line">    ports:</span><br><span class="line">      - 8080:8080</span><br><span class="line">    environment:</span><br><span class="line">      - dubbo.registry.address&#x3D;zookeeper:&#x2F;&#x2F;$&#123;ip&#125;:2181</span><br><span class="line">      - dubbo.admin.root.password&#x3D;root</span><br><span class="line">      - dubbo.admin.guest.password&#x3D;guest</span><br><span class="line"></span><br><span class="line">注意点：</span><br><span class="line">1.要把dubbo.registry.address&#x3D;zookeeper:&#x2F;&#x2F;$&#123;ip&#125;:2181中的ip填为本机ip（不是容器ip）</span><br><span class="line">2.zk挂载的目录是&#x2F;data&#x2F;zookeeper&#x2F;&#123;1,2,3&#125;&#x2F;下 可以根据需求情况进行调整</span><br></pre></td></tr></table></figure><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose -f zk.yml up -d</span><br></pre></td></tr></table></figure><p>查看docker进程，并且打开dubbo-admin地址：</p><p>http://${ip}:8080<br>账号密码root/root</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">docker ps -a</span><br><span class="line">ecd8e83e8386        chenchuxin&#x2F;dubbo-admin     &quot;catalina.sh run&quot;        38 seconds ago      Up 37 seconds       0.0.0.0:8080-&gt;8080&#x2F;tcp                                 dubbo-admin</span><br><span class="line">a3265cddc63a        zookeeper                  &quot;&#x2F;docker-entrypoint.…&quot;   2 minutes ago       Up 37 seconds       2888&#x2F;tcp, 3888&#x2F;tcp, 8080&#x2F;tcp, 0.0.0.0:2182-&gt;2181&#x2F;tcp   zoo2</span><br><span class="line">1bcea74a1647        zookeeper                  &quot;&#x2F;docker-entrypoint.…&quot;   2 minutes ago       Up 37 seconds       2888&#x2F;tcp, 3888&#x2F;tcp, 8080&#x2F;tcp, 0.0.0.0:2183-&gt;2181&#x2F;tcp   zoo3</span><br><span class="line">ab4f3f15ce5e        zookeeper                  &quot;&#x2F;docker-entrypoint.…&quot;   2 minutes ago       Up 37 seconds       2888&#x2F;tcp, 3888&#x2F;tcp, 0.0.0.0:2181-&gt;2181&#x2F;tcp, 8080&#x2F;tcp   zoo1</span><br></pre></td></tr></table></figure><h1 id="rocketmq"><a href="#rocketmq" class="headerlink" title="rocketmq"></a>rocketmq</h1><h2 id="集群方式对比"><a href="#集群方式对比" class="headerlink" title="集群方式对比"></a>集群方式对比</h2><ul><li>多 master 模式<br>多个 master 节点组成集群，单个 master 节点宕机或者重启对应用没有影响。</li></ul><p>优点：性能最高<br>缺点：单个 master节点宕机期间，未被消费的消息在节点恢复之前不可用，消息的实时性就受到影响。<br>注意：使用同步刷盘可以保证消息不丢失，同时 Topic 相对应的 queue 应该分布在集群中各个节点，而不是只在某各节点上，否则，该节点宕机会对订阅该 topic 的应用造成影响。</p><ul><li>多 master 多 slave 异步复制模式<br>在多 master 模式的基础上，每个 master 节点都有至少一个对应的 slave，master<br>节点可读可写，但是 slave 只能读不能写，类似于 mysql 的主备模式。</li></ul><p>优点： 在 master 宕机时，消费者可以从 slave 读取消息，消息的实时性不会受影响，性能几乎和多 master 一样。<br>缺点：使用异步复制的同步方式有可能会有消息丢失的问题。</p><ul><li>多 master 多 slave 同步双写模式<br>同多 master 多 slave 异步复制模式类似，区别在于 master 和 slave 之间的数据同步方式。</li></ul><p>优点：同步双写的同步模式能保证数据不丢失。<br>缺点：发送单个消息 RT 会略长，性能相比异步复制低10%左右。</p><p>压测环境，我希望最大的利用中间件的性能，观察项目在高并发场景下的瓶颈（其实不用观察，大部分出在项目内部，都不会把中间件压垮，懂的都懂）。生产环境建议还是 多主多从异步复制模式。</p><h2 id="创建配置文件-1"><a href="#创建配置文件-1" class="headerlink" title="创建配置文件"></a>创建配置文件</h2><p>添加broker-a的配置信息</p><p>vim /opt/rocketmq4.3.2/broker-a/broker-a.conf</p><p>${ip}为你本机ip,注意更换</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">brokerClusterName &#x3D; rocketmq-cluster</span><br><span class="line">brokerName &#x3D; broker-a</span><br><span class="line">brokerId &#x3D; 0</span><br><span class="line">brokerIP1 &#x3D; $&#123;ip&#125;</span><br><span class="line">deleteWhen &#x3D; 04</span><br><span class="line">fileReservedTime &#x3D; 48</span><br><span class="line">namesrvAddr&#x3D; $&#123;ip&#125;:9876; $&#123;ip&#125;:9877</span><br><span class="line">autoCreateTopicEnable&#x3D;true</span><br><span class="line">#Broker 对外服务的监听端口,</span><br><span class="line">listenPort &#x3D; 10911</span><br><span class="line">#Broker角色</span><br><span class="line">#- ASYNC_MASTER 异步复制Master</span><br><span class="line">#- SYNC_MASTER 同步双写Master</span><br><span class="line">#- SLAVE</span><br><span class="line">brokerRole&#x3D;ASYNC_MASTER</span><br><span class="line">#刷盘方式</span><br><span class="line">#- ASYNC_FLUSH 异步刷盘</span><br><span class="line">#- SYNC_FLUSH 同步刷盘</span><br><span class="line">flushDiskType&#x3D;ASYNC_FLUSH</span><br></pre></td></tr></table></figure><p>添加broker-b的配置信息</p><p>vim /opt/rocketmq4.3.2/broker-b/broker-b.conf</p><p>${ip}为你本机ip,注意更换</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">brokerClusterName &#x3D; rocketmq-cluster</span><br><span class="line">brokerName &#x3D; broker-b</span><br><span class="line">brokerId &#x3D; 0</span><br><span class="line">brokerIP1 &#x3D; $&#123;ip&#125;</span><br><span class="line">deleteWhen &#x3D; 04</span><br><span class="line">fileReservedTime &#x3D; 48</span><br><span class="line">namesrvAddr&#x3D;$&#123;ip&#125;:9876;$&#123;ip&#125;:9877</span><br><span class="line">autoCreateTopicEnable&#x3D;true</span><br><span class="line">#Broker 对外服务的监听端口,</span><br><span class="line">listenPort &#x3D; 10909</span><br><span class="line">#Broker角色</span><br><span class="line">#- ASYNC_MASTER 异步复制Master</span><br><span class="line">#- SYNC_MASTER 同步双写Master</span><br><span class="line">#- SLAVE</span><br><span class="line">brokerRole&#x3D;ASYNC_MASTER</span><br><span class="line">#刷盘方式</span><br><span class="line">#- ASYNC_FLUSH 异步刷盘</span><br><span class="line">#- SYNC_FLUSH 同步刷盘</span><br><span class="line">flushDiskType&#x3D;ASYNC_FLUSH</span><br></pre></td></tr></table></figure><p>添加mq集群信息<br>vim /opt/rocketmq4.3.2/mq.yml </p><p>这一步很关键</p><ul><li>首先确保你本地已经创建/data/rocketmq4.3.2目录，并且你的配置文件信息为/opt/rocketmq4.3.2/broker-a/broker-a.conf和/opt/rocketmq4.3.2/broker-b/broker-b.conf</li><li>然后你选择image的版本均为rocketmq:4.3.2，如果想选择其他版本请将下面所有4.3.2换为你更改的</li><li>端口号确认不和其他冲突，尤其是rmqconsole的端口，我本地端口设为了9001</li><li>jvm调优，根据你机器性能的情况调整 JAVA_OPT_EXT: “-server -Xms4g -Xmx4g -Xmn2g” 参数，如果你技能内存很小，这个参数也需要对应调小，否则启动不了。</li></ul><p>如果都没问题，全部复制下面配置信息即可，不需要更任何东西</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line">version: &#39;3.5&#39;</span><br><span class="line">services:</span><br><span class="line">  rmqnamesrv-a:</span><br><span class="line">    image: rocketmqinc&#x2F;rocketmq:4.3.2</span><br><span class="line">    container_name: rmqnamesrv-a</span><br><span class="line">    ports:</span><br><span class="line">      - 9876:9876</span><br><span class="line">    volumes:</span><br><span class="line">      - &#x2F;data&#x2F;rocketmq4.3.2&#x2F;logs&#x2F;nameserver-a:&#x2F;opt&#x2F;logs</span><br><span class="line">      - &#x2F;data&#x2F;rocketmq4.3.2&#x2F;store&#x2F;nameserver-a:&#x2F;opt&#x2F;store</span><br><span class="line">    environment: </span><br><span class="line">      JAVA_OPT_EXT: &quot;-server -Xms4g -Xmx4g -Xmn2g&quot;</span><br><span class="line">    command: sh mqnamesrv</span><br><span class="line">    networks:</span><br><span class="line">        rmq:</span><br><span class="line">          aliases:</span><br><span class="line">            - rmqnamesrv-a</span><br><span class="line"></span><br><span class="line">  rmqnamesrv-b:</span><br><span class="line">    image: rocketmqinc&#x2F;rocketmq:4.3.2</span><br><span class="line">    container_name: rmqnamesrv-b</span><br><span class="line">    ports:</span><br><span class="line">      - 9877:9877</span><br><span class="line">    volumes:</span><br><span class="line">      - &#x2F;data&#x2F;rocketmq4.3.2&#x2F;logs&#x2F;nameserver-b:&#x2F;opt&#x2F;logs</span><br><span class="line">      - &#x2F;data&#x2F;rocketmq4.3.2&#x2F;store&#x2F;nameserver-b:&#x2F;opt&#x2F;store</span><br><span class="line">    environment:</span><br><span class="line">      JAVA_OPT_EXT: &quot;-server -Xms4g -Xmx4g -Xmn2g&quot;</span><br><span class="line">    command: sh mqnamesrv</span><br><span class="line">    networks:</span><br><span class="line">        rmq:</span><br><span class="line">          aliases:</span><br><span class="line">            - rmqnamesrv-b</span><br><span class="line"></span><br><span class="line">  rmqbroker-a:</span><br><span class="line">    image: rocketmqinc&#x2F;rocketmq:4.3.2</span><br><span class="line">    container_name: rmqbroker-a</span><br><span class="line">    ports:</span><br><span class="line">      - 10911:10911</span><br><span class="line">    volumes:</span><br><span class="line">      - &#x2F;data&#x2F;rocketmq4.3.2&#x2F;logs&#x2F;broker-a:&#x2F;opt&#x2F;logs</span><br><span class="line">      - &#x2F;data&#x2F;rocketmq4.3.2&#x2F;store&#x2F;broker-a:&#x2F;opt&#x2F;store</span><br><span class="line">      - &#x2F;opt&#x2F;rocketmq4.3.2&#x2F;broker-a&#x2F;broker-a.conf:&#x2F;opt&#x2F;rocketmq-4.3.2&#x2F;conf&#x2F;broker.conf </span><br><span class="line">    environment:</span><br><span class="line">        TZ: Asia&#x2F;Shanghai</span><br><span class="line">        NAMESRV_ADDR: &quot;rmqnamesrv-a:9876&quot;</span><br><span class="line">        JAVA_OPTS: &quot; -Duser.home&#x3D;&#x2F;opt&quot;</span><br><span class="line">        JAVA_OPT_EXT: &quot;-server -Xms8g -Xmx8g -Xmn4g&quot;</span><br><span class="line">    command: sh mqbroker -c &#x2F;opt&#x2F;rocketmq-4.3.2&#x2F;conf&#x2F;broker.conf autoCreateTopicEnable&#x3D;true &amp;</span><br><span class="line">    links:</span><br><span class="line">      - rmqnamesrv-a:rmqnamesrv-a</span><br><span class="line">      - rmqnamesrv-b:rmqnamesrv-b</span><br><span class="line">    networks:</span><br><span class="line">      rmq:</span><br><span class="line">        aliases:</span><br><span class="line">          - rmqbroker-a</span><br><span class="line"></span><br><span class="line">  rmqbroker-b:</span><br><span class="line">    image: rocketmqinc&#x2F;rocketmq:4.3.2</span><br><span class="line">    container_name: rmqbroker-b</span><br><span class="line">    ports:</span><br><span class="line">      - 10909:10909</span><br><span class="line">    volumes:</span><br><span class="line">      - &#x2F;data&#x2F;rocketmq4.3.2&#x2F;logs&#x2F;broker-b:&#x2F;opt&#x2F;logs</span><br><span class="line">      - &#x2F;data&#x2F;rocketmq4.3.2&#x2F;store&#x2F;broker-b:&#x2F;opt&#x2F;store</span><br><span class="line">      - &#x2F;opt&#x2F;rocketmq4.3.2&#x2F;broker-b&#x2F;broker-b.conf:&#x2F;opt&#x2F;rocketmq-4.3.2&#x2F;conf&#x2F;broker.conf </span><br><span class="line">    environment:</span><br><span class="line">        TZ: Asia&#x2F;Shanghai</span><br><span class="line">        NAMESRV_ADDR: &quot;rmqnamesrv-b:9876&quot;</span><br><span class="line">        JAVA_OPTS: &quot; -Duser.home&#x3D;&#x2F;opt&quot;</span><br><span class="line">        JAVA_OPT_EXT: &quot;-server -Xms8g -Xmx8g -Xmn4g&quot;</span><br><span class="line">    command: sh mqbroker -c &#x2F;opt&#x2F;rocketmq-4.3.2&#x2F;conf&#x2F;broker.conf autoCreateTopicEnable&#x3D;true &amp;</span><br><span class="line">    links:</span><br><span class="line">      - rmqnamesrv-a:rmqnamesrv-a</span><br><span class="line">      - rmqnamesrv-b:rmqnamesrv-b</span><br><span class="line">    networks:</span><br><span class="line">      rmq:</span><br><span class="line">        aliases:</span><br><span class="line">          - rmqbroker-b</span><br><span class="line">  rmqconsole:</span><br><span class="line">    image: styletang&#x2F;rocketmq-console-ng</span><br><span class="line">    container_name: rmqconsole</span><br><span class="line">    ports:</span><br><span class="line">      - 9001:8080</span><br><span class="line">    environment:</span><br><span class="line">        JAVA_OPTS: -Drocketmq.namesrv.addr&#x3D;rmqnamesrv-a:9876;rmqnamesrv-b:9877 -Dcom.rocketmq.sendMessageWithVIPChannel&#x3D;false -Dserver.port&#x3D;8080</span><br><span class="line">    networks:</span><br><span class="line">      rmq:</span><br><span class="line">        aliases:</span><br><span class="line">          - rmqconsole</span><br><span class="line">networks:</span><br><span class="line">  rmq:</span><br><span class="line">    name: rmq</span><br><span class="line">    driver: bridge</span><br></pre></td></tr></table></figure><h2 id="部署-1"><a href="#部署-1" class="headerlink" title="部署"></a>部署</h2><p>检查完上述注意要点，都没问题就开始部署了。<br>命令很简单</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker-compose -f &#x2F;opt&#x2F;rocketmq4.3.2&#x2F;mq.yml up -d</span><br></pre></td></tr></table></figure><p>然后打开rmqconsole页面 http:${ip}:9001</p><h1 id="redis"><a href="#redis" class="headerlink" title="redis"></a>redis</h1><p>redis集群部署参考我之前写过的文章，这里不水文了。</p><p><a href="https://rugod.cn/2020/05/27/docker/docker-install-db/" target="_blank" rel="noopener">docker安装redis集群</a></p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>这一次部署还是参考了比较多的文章，并在他们的基础上改进（添加dubbo-admin可视化工具及rmqconsole） 总体来说收获很多。话不多说，直接上部署完成的结果。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">[root@vm-26-21 rocketmq4.3.2]# docker ps -a</span><br><span class="line">CONTAINER ID        IMAGE                           COMMAND                  CREATED             STATUS              PORTS                                                    NAMES</span><br><span class="line">b11b4fa79636        rocketmqinc&#x2F;rocketmq:4.3.2      &quot;sh mqbroker -c &#x2F;opt…&quot;   About an hour ago   Up About an hour    9876&#x2F;tcp, 10911&#x2F;tcp, 0.0.0.0:10909-&gt;10909&#x2F;tcp            rmqbroker-b</span><br><span class="line">639ae2109d88        rocketmqinc&#x2F;rocketmq:4.3.2      &quot;sh mqbroker -c &#x2F;opt…&quot;   About an hour ago   Up About an hour    9876&#x2F;tcp, 10909&#x2F;tcp, 0.0.0.0:10911-&gt;10911&#x2F;tcp            rmqbroker-a</span><br><span class="line">7f0ae261d8dc        rocketmqinc&#x2F;rocketmq:4.3.2      &quot;sh mqnamesrv&quot;           About an hour ago   Up About an hour    10909&#x2F;tcp, 0.0.0.0:9876-&gt;9876&#x2F;tcp, 10911&#x2F;tcp             rmqnamesrv-a</span><br><span class="line">84b47ba9e473        styletang&#x2F;rocketmq-console-ng   &quot;sh -c &#39;java $JAVA_O…&quot;   About an hour ago   Up About an hour    0.0.0.0:9001-&gt;8080&#x2F;tcp                                   rmqconsole</span><br><span class="line">dd43db2703fe        rocketmqinc&#x2F;rocketmq:4.3.2      &quot;sh mqnamesrv&quot;           About an hour ago   Up About an hour    9876&#x2F;tcp, 10909&#x2F;tcp, 10911&#x2F;tcp, 0.0.0.0:9877-&gt;9877&#x2F;tcp   rmqnamesrv-b</span><br><span class="line">ecd8e83e8386        chenchuxin&#x2F;dubbo-admin          &quot;catalina.sh run&quot;        47 hours ago        Up 47 hours         0.0.0.0:8080-&gt;8080&#x2F;tcp                                   dubbo-admin</span><br><span class="line">a3265cddc63a        zookeeper                       &quot;&#x2F;docker-entrypoint.…&quot;   47 hours ago        Up 47 hours         2888&#x2F;tcp, 3888&#x2F;tcp, 8080&#x2F;tcp, 0.0.0.0:2182-&gt;2181&#x2F;tcp     zoo2</span><br><span class="line">1bcea74a1647        zookeeper                       &quot;&#x2F;docker-entrypoint.…&quot;   47 hours ago        Up 47 hours         2888&#x2F;tcp, 3888&#x2F;tcp, 8080&#x2F;tcp, 0.0.0.0:2183-&gt;2181&#x2F;tcp     zoo3</span><br><span class="line">ab4f3f15ce5e        zookeeper                       &quot;&#x2F;docker-entrypoint.…&quot;   47 hours ago        Up 47 hours         2888&#x2F;tcp, 3888&#x2F;tcp, 0.0.0.0:2181-&gt;2181&#x2F;tcp, 8080&#x2F;tcp     zoo1</span><br><span class="line">a9c2598d6809        nacos&#x2F;nacos-server:1.1.3        &quot;bin&#x2F;docker-startup.…&quot;   2 days ago          Up 2 days           0.0.0.0:8848-&gt;8848&#x2F;tcp                                   nacos</span><br><span class="line"></span><br><span class="line">[root@vm-26-21 rocketmq4.3.2]# free -h</span><br><span class="line">              total        used        free      shared  buff&#x2F;cache   available</span><br><span class="line">Mem:            31G         21G        6.1G        9.5M        3.9G        9.5G</span><br><span class="line">Swap:          8.0G          0B        8.0G</span><br><span class="line"></span><br><span class="line">[root@vm-26-21 rocketmq4.3.2]# top</span><br><span class="line">top - 14:52:55 up 2 days, 21:00,  1 user,  load average: 0.09, 0.13, 0.14</span><br><span class="line">Tasks: 247 total,   1 running, 246 sleeping,   0 stopped,   0 zombie</span><br><span class="line">%Cpu(s):  0.5 us,  0.9 sy,  0.0 ni, 98.6 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">KiB Mem : 32780056 total,  6395496 free, 22256968 used,  4127592 buff&#x2F;cache</span><br><span class="line">KiB Swap:  8388604 total,  8388604 free,        0 used.  9945644 avail Mem </span><br><span class="line">  scroll coordinates: y &#x3D; 1&#x2F;247 (tasks), x &#x3D; 1&#x2F;12 (fields)</span><br><span class="line">  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                       </span><br><span class="line">28370 3000      20   0   14.0g   8.4g  14632 S   7.0 27.0   4:59.92 java                                                                                          </span><br><span class="line">28405 3000      20   0   13.8g   8.4g  14488 S   7.0 27.0   4:49.68 java                                                                                          </span><br><span class="line">12884 root      20   0 6330552 613636  14000 S   1.0  1.9  33:52.27 java</span><br></pre></td></tr></table></figure><p>基本上还是mq占用资源较多，不过这还没开始压测，估计实际压测内存和cpu占用会高很多吧，用docker部署的好处就是可以提高资源利用（根据机器配置调整jvm启动参数），维护也更容易，挂了直接重启就ok，不需要去3台服务器上来回操作。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://www.cnblogs.com/qdhxhz/p/11096682.html" target="_blank" rel="noopener">Docker集群部署RocketMQ</a></p><p><a href="https://segmentfault.com/a/1190000006907443" target="_blank" rel="noopener">使用 Docker 一步搞定 ZooKeeper 集群的搭建</a></p><p><a href="https://nacos.io/zh-cn/" target="_blank" rel="noopener">nacos官网</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> Redis </tag>
            
            <tag> Nacos </tag>
            
            <tag> Zookeeper </tag>
            
            <tag> Rocketmq </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>个人总结(2020.5)</title>
      <link href="2020/06/07/summary/summary-2020-5/"/>
      <url>2020/06/07/summary/summary-2020-5/</url>
      
        <content type="html"><![CDATA[<h1 id="感慨"><a href="#感慨" class="headerlink" title="感慨"></a>感慨</h1><p>公司的月总结好久没写了，领导现在也没有强制要求，其实想了一下，对于个人发展来说，月总结还是有必要的，可以不断督促自己对学习、生活的追求并根据实际情况改进。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><h2 id="技术"><a href="#技术" class="headerlink" title="技术"></a>技术</h2><h3 id="文章"><a href="#文章" class="headerlink" title="文章"></a>文章</h3><p>5月我一共发布了12篇文章，从思想和技术都写了一些总结。</p><p>主要关于devops、负载均衡、自动化、高可用、容器化的文章。</p><h3 id="学习："><a href="#学习：" class="headerlink" title="学习："></a>学习：</h3><p>我学了大概2个星期的mysql，主要是对mysql的事务的理解、索引的原理、InnoDB引擎的原理以及对加锁的分析这4个方向，目的想在实战中有能力判断一个sql语句的合理性，毕竟作为一个运维，在上线前我需要执行许多sql，如果不仔细了解下mysql，全靠开发写的sql（不是不相信开发）而不懂他们写sql语句的优劣，我就只是一个莫得感情的执行者（虽然还有DBA和SEE平台帮助）。但是人总要成长的，我得有自己对mysql的理解，能判断什么情况执行什么sql，有没有什么风险，有没有可以优化的地方，这样对自己的提高的是很大的。因为我已经有了这么多机会（执行的机会），而从来不懂得分析，我无形中已经失去了很多锻炼自己理解的机会。</p><p>学了大概1个星期的docker底层原理及常用命令，虽然docker用的很早，不过还真没了解下docker的底层原理，了解后才发现原来一个100行的shell脚本就可以实现docker的基本功能，总的来说现在对容器化底层原理有了一个基本的认知，不过还不够深入，所以文章暂时也不发了，多深入了解后再写出自己的顶级理解的好文章。</p><p>总结的东西有点多还没发出来，6月应该能发完Mysql和docker的文章吧。</p><h2 id="生活"><a href="#生活" class="headerlink" title="生活"></a>生活</h2><h3 id="作息时间"><a href="#作息时间" class="headerlink" title="作息时间"></a>作息时间</h3><p>5月我的生活是很充实的，花了大时间在学习，总感觉时间过的很快，我每天的作息不是特别规律，经常熬夜，这个月超过12点睡觉一共有17天，平均睡觉时长为6小时51分钟。我决定在6月调整过来，每天尽量不熬夜，学习知识随时记录这样不会浪费更多时间在回想当初工作的过程上。</p><h3 id="做饭"><a href="#做饭" class="headerlink" title="做饭"></a>做饭</h3><p>这个月做了几次饭：2次可乐鸡翅，1次烧鸡腿，2次牛排，2次番茄鸡蛋，做了一个星期的早餐（煮面）。</p><p>总体来说每次做的饭都能吃，而且一次做饭比一次熟练，这样可以减少吃外卖的次数，有时间能多做下饭奖励自己哈哈，毕竟想让命掌握在自己的手里。</p><h3 id="锻炼"><a href="#锻炼" class="headerlink" title="锻炼"></a>锻炼</h3><p>这个月锻炼了7天，本来想着是每天都锻炼，然后定完计划后发现不太现实，每天学习的时间太少了，而且锻炼完回家洗澡就想放松（堕落），就很烦，没有一次锻炼完回来能安心学习的。不过听一位道教学者告诫我的，锻炼可以早上走走，不一定等晚上，要学会放松，走路的时候，注意，虚灵顶劲、松腰垂臀、沉肩坠肘云云，虽然我也不懂，不过6月可以试试，等不想学习的时候就去走走。</p><h1 id="对自己说"><a href="#对自己说" class="headerlink" title="对自己说"></a>对自己说</h1><p>5月可以说是我思想的升华期，许多大牛对我的指点让我对互联网整个行业的格局有了一定的认知，对未来充满了新的希望，想赶快成长，成为互联网的弄潮儿。</p><p>有想法就有行动：直接现象就是我在不停的学习，没有任何人任何事能阻止我学习，带来的就是各种从生活上挤时间。然后就出现了一个比较残酷的现实，在学习Mysql的时候我曾经一度走火入魔，把自己逼得很紧，想快速了解，但是又很难吃透，于是形成了恶性循环。</p><p>这段期间：我学习到难点的时候就会很烦，不想学，但是一停下来（不管是躺着休息还是玩游戏）我心里都会反复垂问我，不能自甘堕落，但是学又学不进去。打一把lol心态一崩就直接alt+f4，想睡觉心里却一直在想这个没过去的坎。整个人精神接近崩溃的边缘。</p><p>还好周围有一些人及时疏导我(年轻人不要给自己太大压力)，慢慢消化最终把这段时光度过。在此感谢我的室友、同学、朋友、领导这段时间对我不厌其烦进行疏导。</p><h1 id="向前看"><a href="#向前看" class="headerlink" title="向前看"></a>向前看</h1><p>6月我会在技术上对mysql、docker、k8s进行更深的学习，对生活进行更合理的安排，保证睡眠、锻炼、工作、学习互相不耽误。</p><h1 id="名言共勉"><a href="#名言共勉" class="headerlink" title="名言共勉"></a>名言共勉</h1><p>种一棵树最好的时间是十年前，其次是现在。</p><p>你每天忘记的事有上千件，何不也忘了这件事。</p><p>故常无欲，以观其妙；常有欲，以观其徼。</p><p>弱小的人才习惯嘲讽和否定，而内心强大的人从不吝啬赞美和鼓励。</p>]]></content>
      
      
      <categories>
          
          <category> 个人总结 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 个人总结 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>制作CentOS7.x镜像模板</title>
      <link href="2020/06/04/linux/centos7-install/"/>
      <url>2020/06/04/linux/centos7-install/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>最近公司需要安装很多虚拟机，一想到普通的Centos需要安装很多额外的东西就头痛，决定还是做一个优化过的镜像，以后直接用这个镜像做虚拟机的操作系统可以节省大量时间。</p><h1 id="选择虚拟化系统"><a href="#选择虚拟化系统" class="headerlink" title="选择虚拟化系统"></a>选择虚拟化系统</h1><p>我使用的VMware Esxi或VMware Workstation Pro</p><p><a href="https://www.cnblogs.com/lwenwu/p/9818366.html" target="_blank" rel="noopener">VMware Workstation Pro安装</a></p><h1 id="安装centos7-最小化系统"><a href="#安装centos7-最小化系统" class="headerlink" title="安装centos7 最小化系统"></a>安装centos7 最小化系统</h1><p>下载镜像  <a href="http://mirrors.aliyun.com/centos/7/isos/x86_64/" target="_blank" rel="noopener">阿里云centos镜像</a></p><p>如果是安装到虚拟机里直接看<br><a href="https://blog.csdn.net/capricorn90/article/details/52556174" target="_blank" rel="noopener">CentOS 7 最小化安装</a></p><p>里面注意几点就行：</p><ul><li>时区调为中国上海</li><li>安装语言选择英语（别整中文了，多学点英语没有什么不好）</li><li>磁盘如果懒得划分就按默认标准即可</li><li>密码一定要设置</li></ul><h1 id="制作镜像模板"><a href="#制作镜像模板" class="headerlink" title="制作镜像模板"></a>制作镜像模板</h1><p>进入操作系统</p><h2 id="改主机名-重新连接生效"><a href="#改主机名-重新连接生效" class="headerlink" title="改主机名(重新连接生效)"></a>改主机名(重新连接生效)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl set-hostname xxx</span><br></pre></td></tr></table></figure><h2 id="改yum源为阿里源-个人习惯，不喜勿喷"><a href="#改yum源为阿里源-个人习惯，不喜勿喷" class="headerlink" title="改yum源为阿里源(个人习惯，不喜勿喷)"></a>改yum源为阿里源(个人习惯，不喜勿喷)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">yum install -y epel-release  wget</span><br><span class="line">curl -o &#x2F;etc&#x2F;yum.repos.d&#x2F;CentOS-Base.repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;repo&#x2F;Centos-7.repo</span><br><span class="line">mv &#x2F;etc&#x2F;yum.repos.d&#x2F;epel.repo   &#x2F;etc&#x2F;yum.repos.d&#x2F;epel.repo.backup</span><br><span class="line">wget -O &#x2F;etc&#x2F;yum.repos.d&#x2F;epel.repo http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;repo&#x2F;epel-7.repo</span><br><span class="line">yum clean all</span><br><span class="line">yum makecache</span><br></pre></td></tr></table></figure><h2 id="yum安装插件-根据喜好增删"><a href="#yum安装插件-根据喜好增删" class="headerlink" title="yum安装插件(根据喜好增删)"></a>yum安装插件(根据喜好增删)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y lrzsz vim ntpdate yum-utils zip unzip tree  gcc gcc-c++</span><br></pre></td></tr></table></figure><h2 id="改dns-如果需要添加内网域名的话，否则可以不用这一步"><a href="#改dns-如果需要添加内网域名的话，否则可以不用这一步" class="headerlink" title="改dns(如果需要添加内网域名的话，否则可以不用这一步)"></a>改dns(如果需要添加内网域名的话，否则可以不用这一步)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vim &#x2F;etc&#x2F;resolv.conf</span><br><span class="line">添加dns</span><br><span class="line">nameserver 8.8.8.8</span><br><span class="line">nameserver xxxx</span><br></pre></td></tr></table></figure><h2 id="改密码"><a href="#改密码" class="headerlink" title="改密码"></a>改密码</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">echo    &#39;123456&#39;    |     passwd   --stdin  root</span><br></pre></td></tr></table></figure><p>echo的值为密码</p><h2 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br><span class="line">setenforce 0</span><br><span class="line">sed -i &quot;s&#x2F;SELINUX&#x3D;enforcing&#x2F;SELINUX&#x3D;disabled&#x2F;g&quot; &#x2F;etc&#x2F;selinux&#x2F;config</span><br></pre></td></tr></table></figure><h2 id="时间同步"><a href="#时间同步" class="headerlink" title="时间同步"></a>时间同步</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">crontab -e</span><br><span class="line">#一小时同步一次</span><br><span class="line">0 *&#x2F;1 * * * &#x2F;usr&#x2F;sbin&#x2F;ntpdate ntp1.aliyun.com &gt; &#x2F;dev&#x2F;null 2&gt;&amp;1; &#x2F;sbin&#x2F;hwclock -w</span><br></pre></td></tr></table></figure><h2 id="安装docker-不会还有人不装docker吧"><a href="#安装docker-不会还有人不装docker吧" class="headerlink" title="安装docker(不会还有人不装docker吧)"></a>安装docker(不会还有人不装docker吧)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">yum install -y yum-utils #如果在前面已经安装了则不用执行这个命令</span><br><span class="line">yum-config-manager \</span><br><span class="line">    --add-repo \</span><br><span class="line">    https:&#x2F;&#x2F;download.docker.com&#x2F;linux&#x2F;centos&#x2F;docker-ce.repo</span><br><span class="line"></span><br><span class="line">yum install -y docker-ce docker-ce-cli containerd.io</span><br><span class="line"></span><br><span class="line">vim &#x2F;etc&#x2F;docker&#x2F;daemon.json</span><br><span class="line">#添加国内镜像加速</span><br><span class="line">&#123;</span><br><span class="line">  &quot;registry-mirrors&quot;: [&quot;https:&#x2F;&#x2F;wghlmi3i.mirror.aliyuncs.com&quot;]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="提高资源限制上限-重新连接生效"><a href="#提高资源限制上限-重新连接生效" class="headerlink" title="提高资源限制上限(重新连接生效)"></a>提高资源限制上限(重新连接生效)</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;* soft nofile 65536&quot; &gt;&gt; &#x2F;etc&#x2F;security&#x2F;limits.conf         </span><br><span class="line">echo &quot;* hard nofile 65536&quot; &gt;&gt; &#x2F;etc&#x2F;security&#x2F;limits.conf</span><br></pre></td></tr></table></figure><h2 id="关闭Swap"><a href="#关闭Swap" class="headerlink" title="关闭Swap"></a>关闭Swap</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">swapoff -a</span><br><span class="line">free -h</span><br><span class="line">              total        used        free      shared  buff&#x2F;cache   available</span><br><span class="line">Mem:           3.7G        132M        3.4G         11M        173M        3.3G</span><br><span class="line">Swap:            0B          0B          0B</span><br></pre></td></tr></table></figure><h2 id="内核调优"><a href="#内核调优" class="headerlink" title="内核调优"></a>内核调优</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">echo &quot;vm.swappiness &#x3D; 1 &gt;&gt; &#x2F;etc&#x2F;sysctl.conf </span><br><span class="line">echo &quot;net.ipv6.conf.all.disable_ipv6 &#x3D; 1 &gt;&gt; &#x2F;etc&#x2F;sysctl.conf </span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure><h1 id="保存镜像"><a href="#保存镜像" class="headerlink" title="保存镜像"></a>保存镜像</h1><p>进入虚拟化控制台，导出为 OVF 格式即可</p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Centos </tag>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Docker安装Mysql、Mongodb、Redis及数据迁移</title>
      <link href="2020/05/27/docker/docker-install-db/"/>
      <url>2020/05/27/docker/docker-install-db/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>公司买了新磁盘、内存条，需要重新装机，领导要求这次要用docker部署数据库到服务器上。</p><h1 id="安装mysql"><a href="#安装mysql" class="headerlink" title="安装mysql"></a>安装mysql</h1><h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><p>宿主机需要安装docker<br>机器性能32c 128G 外挂硬盘到/data目录（数据库建议外挂磁盘）</p><h2 id="创建持久化存储文件目录"><a href="#创建持久化存储文件目录" class="headerlink" title="创建持久化存储文件目录"></a>创建持久化存储文件目录</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# mkdir -vp &#x2F;data&#x2F;mysql</span><br></pre></td></tr></table></figure><h2 id="创建配置文件"><a href="#创建配置文件" class="headerlink" title="创建配置文件"></a>创建配置文件</h2><p>[root@localhost ~]#vim /etc/my.cnf</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br></pre></td><td class="code"><pre><span class="line">[client]   </span><br><span class="line">user&#x3D;root</span><br><span class="line">password&#x3D;123456</span><br><span class="line">port    &#x3D; 3306</span><br><span class="line">socket &#x3D; &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql.sock </span><br><span class="line"></span><br><span class="line">[mysql]  </span><br><span class="line">prompt&#x3D;&quot;\u@data \R:\m:\s [\d]&gt; &quot; </span><br><span class="line">no-auto-rehash </span><br><span class="line">default-character-set&#x3D;utf8mb4  </span><br><span class="line"></span><br><span class="line">[mysqld]  </span><br><span class="line">user    &#x3D; mysql</span><br><span class="line">port    &#x3D; 3306</span><br><span class="line">#basedir &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql</span><br><span class="line">datadir &#x3D; &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;</span><br><span class="line">socket  &#x3D; &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql.sock</span><br><span class="line">secure_file_priv&#x3D;&#x2F;var&#x2F;lib&#x2F;mysql&#x2F;</span><br><span class="line">performance_schema &#x3D; 1</span><br><span class="line">character_set_server&#x3D;utf8mb4   </span><br><span class="line">open_files_limit &#x3D; 655350  </span><br><span class="line">transaction_isolation &#x3D; READ-COMMITTED</span><br><span class="line">interactive_timeout &#x3D; 31536000</span><br><span class="line">wait_timeout &#x3D; 31536000</span><br><span class="line">skip_name_resolve &#x3D; 1  </span><br><span class="line">lower_case_table_names&#x3D;1    </span><br><span class="line">back_log &#x3D; 1024</span><br><span class="line">max_connections &#x3D; 10240    </span><br><span class="line">max_connect_errors &#x3D; 1000000</span><br><span class="line">table_open_cache &#x3D; 20480</span><br><span class="line">table_definition_cache &#x3D; 20480</span><br><span class="line">table_open_cache_instances &#x3D; 64</span><br><span class="line">thread_stack &#x3D; 512K</span><br><span class="line">external-locking &#x3D; FALSE</span><br><span class="line">max_allowed_packet &#x3D; 32M</span><br><span class="line">sort_buffer_size &#x3D; 4M</span><br><span class="line">join_buffer_size &#x3D; 4M</span><br><span class="line">thread_cache_size &#x3D; 15360</span><br><span class="line">tmp_table_size &#x3D; 32M</span><br><span class="line">max_heap_table_size &#x3D; 32M</span><br><span class="line">lock_wait_timeout &#x3D; 3600</span><br><span class="line">explicit_defaults_for_timestamp &#x3D; 1</span><br><span class="line">sort_buffer_size &#x3D; 33554432</span><br><span class="line"></span><br><span class="line">slow_query_log_file &#x3D; &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;slow.log</span><br><span class="line">log-error &#x3D; &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;error.log</span><br><span class="line">log-bin &#x3D; &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mybinlog</span><br><span class="line">slow_query_log &#x3D; 1</span><br><span class="line">log_timestamps &#x3D; SYSTEM</span><br><span class="line">long_query_time &#x3D; 1</span><br><span class="line">log_queries_not_using_indexes &#x3D;1</span><br><span class="line">log_throttle_queries_not_using_indexes &#x3D; 60</span><br><span class="line">min_examined_row_limit &#x3D; 100</span><br><span class="line">log_slow_admin_statements &#x3D; 1</span><br><span class="line">log_slow_slave_statements &#x3D; 1</span><br><span class="line">expire_logs_days &#x3D; 7</span><br><span class="line">log_warnings &#x3D; 1</span><br><span class="line">binlog_cache_size &#x3D; 4M</span><br><span class="line">max_binlog_cache_size &#x3D; 4G</span><br><span class="line">max_binlog_size &#x3D; 1G</span><br><span class="line">binlog_checksum &#x3D; 1</span><br><span class="line">binlog_format &#x3D; row</span><br><span class="line">sync_binlog &#x3D; 1</span><br><span class="line"></span><br><span class="line">server-id &#x3D; 213306</span><br><span class="line">master_info_repository &#x3D; TABLE</span><br><span class="line">relay_log_info_repository &#x3D; TABLE</span><br><span class="line">gtid_mode &#x3D; on</span><br><span class="line">enforce-gtid-consistency &#x3D; on</span><br><span class="line">log_slave_updates  &#x3D; on</span><br><span class="line">enforce_gtid_consistency &#x3D; 1</span><br><span class="line">relay_log &#x3D; relay.log</span><br><span class="line">relay_log_recovery &#x3D; 1</span><br><span class="line">relay-log-purge &#x3D; 1</span><br><span class="line">binlog_gtid_simple_recovery &#x3D; 1</span><br><span class="line">slave_skip_errors &#x3D; ddl_exist_errors</span><br><span class="line">slave-rows-search-algorithms &#x3D; &#39;INDEX_SCAN,HASH_SCAN&#39;</span><br><span class="line"></span><br><span class="line">innodb_undo_directory &#x3D; &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;undolog</span><br><span class="line">internal_tmp_disk_storage_engine &#x3D; InnoDB</span><br><span class="line">innodb_page_size &#x3D; 8192</span><br><span class="line">innodb_buffer_pool_size &#x3D; 40960m</span><br><span class="line">innodb_buffer_pool_instances &#x3D; 4</span><br><span class="line">innodb_buffer_pool_load_at_startup &#x3D; 1</span><br><span class="line">innodb_buffer_pool_dump_at_shutdown &#x3D; 1</span><br><span class="line">innodb_data_file_path &#x3D; ibdata1:1G:autoextend</span><br><span class="line">innodb_flush_log_at_trx_commit &#x3D; 1</span><br><span class="line">innodb_log_buffer_size &#x3D; 32M</span><br><span class="line">innodb_log_file_size &#x3D; 1G</span><br><span class="line">innodb_log_files_in_group &#x3D; 4</span><br><span class="line">innodb_max_undo_log_size &#x3D; 4G</span><br><span class="line">innodb_undo_tablespaces &#x3D; 95</span><br><span class="line">innodb_io_capacity &#x3D; 2000</span><br><span class="line">innodb_io_capacity_max &#x3D; 4000</span><br><span class="line">innodb_flush_sync &#x3D; 0</span><br><span class="line">innodb_flush_neighbors &#x3D; 0</span><br><span class="line">innodb_lru_scan_depth &#x3D; 4000</span><br><span class="line">innodb_lock_wait_timeout &#x3D; 5</span><br><span class="line">innodb_write_io_threads &#x3D; 8</span><br><span class="line">innodb_read_io_threads &#x3D; 8</span><br><span class="line">innodb_purge_threads &#x3D; 4</span><br><span class="line">innodb_page_cleaners &#x3D; 4</span><br><span class="line">innodb_max_dirty_pages_pct &#x3D; 50</span><br><span class="line">innodb_flush_method &#x3D; O_DIRECT</span><br><span class="line">innodb_checksum_algorithm &#x3D; crc32</span><br><span class="line">innodb_rollback_on_timeout &#x3D; 1</span><br><span class="line">innodb_print_all_deadlocks &#x3D; 1</span><br><span class="line">innodb_file_per_table &#x3D; 1</span><br><span class="line">innodb_online_alter_log_max_size &#x3D; 4G</span><br><span class="line">innodb_stats_on_metadata &#x3D; 0</span><br><span class="line">innodb_checksums &#x3D; 1</span><br><span class="line">innodb_undo_logs &#x3D; 128</span><br><span class="line">innodb_status_file &#x3D; 1</span><br><span class="line">innodb_status_output &#x3D; 0</span><br><span class="line">innodb_status_output_locks &#x3D; 0</span><br><span class="line">innodb_large_prefix &#x3D; 1</span><br><span class="line">innodb_thread_concurrency &#x3D; 0</span><br><span class="line">innodb_sync_spin_loops &#x3D; 100</span><br><span class="line">innodb_spin_wait_delay &#x3D; 30</span><br><span class="line">innodb_open_files &#x3D; 655350  </span><br><span class="line">innodb_strict_mode &#x3D; 1</span><br><span class="line">innodb_sort_buffer_size &#x3D; 67108864</span><br><span class="line"></span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_innodb&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_server&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_dml&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_ddl&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_trx&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_os&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_purge&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_log&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_lock&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_buffer&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_index&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_ibuf_system&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_buffer_page&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_adaptive_hash&quot;</span><br></pre></td></tr></table></figure><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>#拉取镜像<br>[root@localhost ~]# docker pull mysql:5.7.28</p><p>#启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# docker run -itd --name mysql -p 3306:3306  --privileged&#x3D;true --restart always -v &#x2F;etc&#x2F;my.cnf:&#x2F;etc&#x2F;mysql&#x2F;my.cnf -v &#x2F;data&#x2F;mysql:&#x2F;var&#x2F;lib&#x2F;mysql -e MYSQL_ROOT_PASSWORD&#x3D;123456  mysql:5.7.28 </span><br><span class="line"></span><br><span class="line">参数说明：</span><br><span class="line">--privileged&#x3D;true 开启超级权限</span><br><span class="line">-v &#x2F;etc&#x2F;my.cnf:&#x2F;etc&#x2F;mysql&#x2F;my.cnf  把外面调优过后的配置文件挂载进去</span><br><span class="line">-v &#x2F;data&#x2F;mysql:&#x2F;var&#x2F;lib&#x2F;mysql</span><br><span class="line">把持久化存储文件目录挂载到容器内部  </span><br><span class="line">--restart always  Docker重启时，该容器自动启动</span><br></pre></td></tr></table></figure><p>error:如果启动失败，查看日志docker logs mysql提示</p><p>chown: cannot read directory ‘/var/lib/mysql/‘: Permission denied</p><p>容器中没有执行权限 //挂载外部数据卷时,无法启动容器, cannot read directory ‘/var/lib/mysql/‘: Permission denied 由</p><p>该原因为centOs7默认开启selinux安全模块,需要临时关闭该安全模块,或者添加目录到白名单 临时关闭selinux：su -c “setenforce 0” </p><p>#添加超级管理员账号admin<br>[root@localhost data]# docker exec -it mysql bash<br>root@1ef730747ed4:/# mysql -uroot -p123456<br>mysql&gt; GRANT ALL PRIVILEGES ON <em>.</em> TO ‘admin’@’%’ IDENTIFIED BY ‘123456’ WITH GRANT OPTION;<br>mysql&gt; flush privileges;<br>mysql&gt; exit</p><h2 id="管理"><a href="#管理" class="headerlink" title="管理"></a>管理</h2><p>docker stop/start mysql 关闭/启动</p><h2 id="数据迁移"><a href="#数据迁移" class="headerlink" title="数据迁移"></a>数据迁移</h2><p>旧数据库机器执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysqldump -uroot -p123456 --all-databases  &gt; all.sql</span><br><span class="line">scp all.sql root@新机器ip:&#x2F;root</span><br></pre></td></tr></table></figure><p>新数据库机器执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker cp &#x2F;root&#x2F;all.sql mysql:&#x2F;all.sql </span><br><span class="line">docker exec -it mysql bash  </span><br><span class="line">mysql -uroot -p123456 mysql &lt; all.sql</span><br></pre></td></tr></table></figure><h1 id="安装mongodb"><a href="#安装mongodb" class="headerlink" title="安装mongodb"></a>安装mongodb</h1><p>要求：<br>宿主机需要安装docker<br>外挂硬盘到/data目录（数据库建议外挂磁盘）</p><h2 id="安装-1"><a href="#安装-1" class="headerlink" title="安装"></a>安装</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#创建持久化存储文件目录</span><br><span class="line">mkdir -vp &#x2F;data&#x2F;mongo</span><br><span class="line">#拉取镜像</span><br><span class="line">docker pull mongo:4.2.6</span><br><span class="line"></span><br><span class="line">#启动mongo，由于数据需要迁移（包含了用户），所以不能先开启验证模式</span><br><span class="line">docker run -itd --name mongo -p 27017:27017 -v &#x2F;data&#x2F;mongo:&#x2F;data&#x2F;db mongo:4.2.6 </span><br><span class="line"></span><br><span class="line">-v &#x2F;data&#x2F;mongo:&#x2F;data&#x2F;db 把持久化存储文件目录挂载到容器内部</span><br></pre></td></tr></table></figure><h2 id="数据迁移-1"><a href="#数据迁移-1" class="headerlink" title="数据迁移"></a>数据迁移</h2><p>旧机器执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mongodump -h 127.0.0.1 --port 27017 -uroot -p123456 -o &#x2F;root&#x2F;mongodb&#x2F;</span><br><span class="line">scp -r &#x2F;root&#x2F;mongodb&#x2F; root@ip:&#x2F;root&#x2F;mongodb&#x2F;</span><br></pre></td></tr></table></figure><p>新机器执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">docker cp &#x2F;root&#x2F;mongodb&#x2F; mongo:&#x2F;</span><br><span class="line">docker exec -it mongo bash</span><br><span class="line">mongorestore &#x2F;mongodb&#x2F;</span><br></pre></td></tr></table></figure><h2 id="重启并开启权限验证"><a href="#重启并开启权限验证" class="headerlink" title="重启并开启权限验证"></a>重启并开启权限验证</h2><p>数据迁移完后，查看本地存储是否有数据了。如果存在继续后面的操作</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker rm -f mongo</span><br><span class="line">docker run -itd --name mongo --restart always -p 27017:27017 -v &#x2F;data&#x2F;mongo:&#x2F;data&#x2F;db mongo:4.2.6 --auth</span><br></pre></td></tr></table></figure><p>再次启动mongo就可以用以前的数据库账号密码登陆了</p><h2 id="管理-1"><a href="#管理-1" class="headerlink" title="管理"></a>管理</h2><p>docker stop/start mongo 关闭/启动</p><h1 id="安装redis"><a href="#安装redis" class="headerlink" title="安装redis"></a>安装redis</h1><p>要求redis版本&gt;5.0<br>宿主机需要安装docker<br>机器性能32c 128G 外挂硬盘到/data目录（数据库建议外挂磁盘）</p><h2 id="准备配置文件"><a href="#准备配置文件" class="headerlink" title="准备配置文件"></a>准备配置文件</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# mkdir -vp &#x2F;data&#x2F;redis-cluster</span><br><span class="line">[root@localhost ~]# cd &#x2F;data&#x2F;redis-cluster</span><br><span class="line">[root@localhost redis-cluster]# vi redis-cluster.tmpl</span><br><span class="line">添加以下内容  </span><br><span class="line">port $&#123;PORT&#125;</span><br><span class="line">cluster-enabled yes</span><br><span class="line">cluster-config-file nodes.conf</span><br><span class="line">cluster-node-timeout 5000</span><br><span class="line">cluster-announce-ip 172.31.26.53   #本机ip</span><br><span class="line">cluster-announce-port $&#123;PORT&#125;</span><br><span class="line">cluster-announce-bus-port 1$&#123;PORT&#125;</span><br><span class="line">appendonly yes</span><br><span class="line">protected-mode no</span><br><span class="line">#密码</span><br><span class="line">masterauth 123456     </span><br><span class="line">#密码</span><br><span class="line">requirepass 123456    </span><br><span class="line">bind 0.0.0.0</span><br><span class="line">timeout 300</span><br><span class="line">tcp-keepalive 300</span><br></pre></td></tr></table></figure><p>创建集群配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost redis-cluster]# for port in $(seq 7010 7015); do   mkdir -p .&#x2F;$&#123;port&#125;&#x2F;conf    &amp;&amp; PORT&#x3D;$&#123;port&#125; envsubst &lt; .&#x2F;redis-cluster.tmpl &gt; .&#x2F;$&#123;port&#125;&#x2F;conf&#x2F;redis.conf   &amp;&amp; mkdir -p .&#x2F;$&#123;port&#125;&#x2F;data; done</span><br></pre></td></tr></table></figure><p>创建完成后看下目录结构</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost redis-cluster]# tree</span><br><span class="line">├── 7010</span><br><span class="line">│   ├── conf</span><br><span class="line">│   │   └── redis.conf</span><br><span class="line">│   └── data</span><br><span class="line">├── 7011</span><br><span class="line">│   ├── conf</span><br><span class="line">│   │   └── redis.conf</span><br><span class="line">│   └── data</span><br><span class="line">├── 7012</span><br><span class="line">│   ├── conf</span><br><span class="line">│   │   └── redis.conf</span><br><span class="line">│   └── data</span><br><span class="line">├── 7013</span><br><span class="line">│   ├── conf</span><br><span class="line">│   │   └── redis.conf</span><br><span class="line">│   └── data</span><br><span class="line">├── 7014</span><br><span class="line">│   ├── conf</span><br><span class="line">│   │   └── redis.conf</span><br><span class="line">│   └── data</span><br><span class="line">├── 7015</span><br><span class="line">│   ├── conf</span><br><span class="line">│   │   └── redis.conf</span><br><span class="line">│   └── data</span><br><span class="line">└── redis-cluster.tmpl</span><br></pre></td></tr></table></figure><h2 id="拉镜像"><a href="#拉镜像" class="headerlink" title="拉镜像"></a>拉镜像</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker pull redis</span><br></pre></td></tr></table></figure><p>本示例镜像版本为latest，如果需要按照以下步骤安装集群，则只要要求redis版本是5.0以上 否则会出现问题</p><h2 id="创建容器并指定IP"><a href="#创建容器并指定IP" class="headerlink" title="创建容器并指定IP"></a>创建容器并指定IP</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost redis-cluster]# for port in $(seq 7010 7015); do    docker run -it -d -p $&#123;port&#125;:$&#123;port&#125; -p 1$&#123;port&#125;:1$&#123;port&#125;   --privileged&#x3D;true -v &#x2F;data&#x2F;redis-cluster&#x2F;$&#123;port&#125;&#x2F;conf&#x2F;redis.conf:&#x2F;usr&#x2F;local&#x2F;etc&#x2F;redis&#x2F;redis.conf   --privileged&#x3D;true -v &#x2F;data&#x2F;redis-cluster&#x2F;$&#123;port&#125;&#x2F;data:&#x2F;data   --restart always --name redis-$&#123;port&#125; --net host   --sysctl net.core.somaxconn&#x3D;1024 redis redis-server &#x2F;usr&#x2F;local&#x2F;etc&#x2F;redis&#x2F;redis.conf; done</span><br></pre></td></tr></table></figure><h2 id="创建集群"><a href="#创建集群" class="headerlink" title="创建集群"></a>创建集群</h2><p>进入容器</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost redis-cluster]# docker exec -it redis-7010 bash</span><br></pre></td></tr></table></figure><p>如果需要密码，需要在命令最后加上-a passwd</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">redis-cli --cluster create 172.31.26.53:7010 172.31.26.53:7011 172.31.26.53:7012 172.31.26.53:7013 172.31.26.53:7014 172.31.26.53:7015 --cluster-replicas 1 -a 123456</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>至此，mysql、mongodb、redis用docker部署完成，并完成迁移数据,如有问题请留言。</p><h1 id="部署问题"><a href="#部署问题" class="headerlink" title="部署问题"></a>部署问题</h1><p>1.mysql根据镜像不同需要调整里面挂载目录的路径，这点很坑，我出现过几次找不到挂载路径然后报错，因为容器里mysql启动是以你my.cnf为主的，所以你在my.cnf里没定义好那些容器里的路径就会启动失败，报错问题就是找不到相关路径。</p><p>2.mongodb最烦的就是数据导入的时候，如果你的用户名有密码，你需要开启免密登陆才能导入，我觉得特别搞笑，万一生产的数据库需要导入，总不至于要先关闭mongodb开启免密登陆，导入完再开启密码登陆吧。。。还是我没找到导入的好方法，求教！！！</p><p>3.redis集群创建的时候，按照<a href="https://www.jianshu.com/p/af8eb110a873" target="_blank" rel="noopener">Docker最新Redis-cluster 集群配置</a> 做会出现，本地网桥转发失败的情况，直观来看就是redis-cli create 集群的时候一直在等待，虽然你能看到这些本地网桥内的ip，但是他们就是不能加入，也是一个大坑，反正我直接将端口映射到本机就可以，搞不懂为啥那个作者非要一个网桥。。。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://docs.docker.com/engine/reference/commandline/run/" target="_blank" rel="noopener">Docker run官方文档</a></p><p><a href="https://www.jianshu.com/p/af8eb110a873" target="_blank" rel="noopener">Docker最新Redis-cluster 集群配置</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
            <tag> Docker </tag>
            
            <tag> Redis </tag>
            
            <tag> Mongodb </tag>
            
            <tag> 数据备份 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入浅出Docker原理及实战(一)——Docker的基本理念与原理</title>
      <link href="2020/05/24/docker/docker-idea-1/"/>
      <url>2020/05/24/docker/docker-idea-1/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><p>深入浅出Docker原理及实战系列第一篇，我想向大家阐述在Docker的基本理念与原理。</p><h1 id="Docker概述"><a href="#Docker概述" class="headerlink" title="Docker概述"></a>Docker概述</h1><p>Docker是一个用于开发，交付和运行应用程序的开放平台。Docker使我们能够将应用程序与基础架构分开，从而可以快速交付软件。借助Docker，我们可以以与管理应用程序相同的方式来管理基础架构。通过利用Docker的方法来快速交付，测试和部署代码，您可以大大减少编写代码和在生产环境中运行代码之间的延迟。</p><p>容器化越来越受欢迎，因为容器是：</p><ul><li>灵活：即使最复杂的应用程序也可以容器化。</li><li>轻量级：容器利用并共享主机内核，在系统资源方面比虚拟机效率更高。</li><li>可移植性：您可以在本地构建，部署到云并在任何地方运行。</li><li>松散耦合：容器是高度自给自足并封装的容器，使您可以在不破坏其他容器的情况下更换或升级它们。</li><li>可扩展：您可以在数据中心内增加并自动分布容器副本。</li><li>安全：容器将积极的约束和隔离应用于流程，而无需用户方面的任何配置。</li></ul><h1 id="Docker平台"><a href="#Docker平台" class="headerlink" title="Docker平台"></a>Docker平台</h1><p>Docker提供了在松散隔离的环境（称为容器）中打包和运行应用程序的功能。隔离和安全性使我们可以在给定主机上同时运行多个容器。容器是轻量级的，因为它们不需要虚拟机管理程序的额外负载，而是直接在主机的内核中运行。这意味着与使用虚拟机相比，可以在给定的硬件组合上运行更多的容器。我们甚至可以在实际上是虚拟机的主机中运行Docker容器！</p><p>Docker提供了工具和平台来管理容器的生命周期：</p><ul><li>使用容器开发应用程序及其支持组件。</li><li>容器成为分发和测试应用程序的单元。</li><li>准备就绪后，可以将应用程序作为容器或协调服务部署到生产环境中。</li></ul><p>Docker vs 虚拟机</p><p>容器在Linux上本地运行，并与其他容器共享主机的内核。它运行一个离散进程，不占用任何其他可执行文件更多的内存，从而使其轻巧。</p><p>相比之下，虚拟机（VM）运行成熟的“来宾”操作系统，并通过虚拟机管理程序对主机资源进行虚拟访问。通常，VM会产生大量开销，超出了应用程序逻辑所消耗的开销。</p><ul><li>容器时在linux上本机运行，并与其他容器共享主机的内核，它运行的一个独立的进程，不占用其他任何可执行文件的内存，非常轻量。</li><li>虚拟机运行的是一个完成的操作系统，通过虚拟机管理程序对主机资源进行虚拟访问，相比之下需要的资源更多</li></ul><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Docker/docker_esxi.png"  alt="Docker_esxi"></p><h1 id="Docker和Devops的关系"><a href="#Docker和Devops的关系" class="headerlink" title="Docker和Devops的关系"></a>Docker和Devops的关系</h1><p>DevOps 强调的是高效组织团队之间如何通过自动化的工具协作和沟通来完成软件的生命周期管理，从而更快、更频繁地交付更稳定的软件。有工具支持，运维关注代码，开发关注部署，效率和质量都能得到提升。</p><p>在软件日趋复杂的情况下，微服务架构是弹性扩展、快速迭代的优选，微服务有利于负责单个服务的小团队降低沟通成本、提升效率，众多的服务却也让研发需要关心环境交付，整个运维工作复杂度剧增。说到秒级启动、秒级自动修复、服务发现、弹性伸缩等等，使用虚拟机和使用容器并无质的差距，但有了Docker，最大的变化是环境交付可以提前，每个开发只需多花 5% 的时间，就能换取运维 200% 的劳动，并且提高稳定性。</p><h2 id="快速，一致地交付您的应用程序"><a href="#快速，一致地交付您的应用程序" class="headerlink" title="快速，一致地交付您的应用程序"></a>快速，一致地交付您的应用程序</h2><p>Docker允许开发人员使用提供您的应用程序和服务的本地容器在标准化环境中工作，从而简化了开发生命周期。容器非常适合持续集成和持续交付（CI / CD）工作流程。</p><p>流水线具体如下：</p><ul><li>开发人员在本地编写代码，并使用Docker容器与同事共享他们的工作。</li><li>他们使用Docker将其应用程序推送到测试环境中，并执行自动和手动测试。</li><li>当开发人员发现错误时，他们可以在开发环境中对其进行修复，然后将其重新部署到测试环境中以进行测试和验证。</li><li>测试完成后，将修补程序推送给生产环境就像将更新的映像推送到生产环境一样简单。</li></ul><h2 id="响应式部署和扩展"><a href="#响应式部署和扩展" class="headerlink" title="响应式部署和扩展"></a>响应式部署和扩展</h2><p>Docker基于容器的平台允许高度可移植的工作负载。Docker容器可以在开发人员的本地笔记本电脑上，数据中心中的物理或虚拟机上，云提供商上或混合环境中运行。</p><p>Docker的可移植性和轻量级的特性还使您可以轻松地动态管理工作负载，并根据业务需求指示实时扩展或拆除应用程序和服务。</p><h2 id="在同一硬件上运行更多工作负载"><a href="#在同一硬件上运行更多工作负载" class="headerlink" title="在同一硬件上运行更多工作负载"></a>在同一硬件上运行更多工作负载</h2><p>Docker轻巧快速。它为基于虚拟机管理程序的虚拟机提供了可行，经济高效的替代方案，因此您可以利用更多的计算能力来实现业务目标。Docker非常适合于高密度环境以及中小型部署，而您需要用更少的资源做更多的事情。</p><h1 id="Docker引擎"><a href="#Docker引擎" class="headerlink" title="Docker引擎"></a>Docker引擎</h1><p>Docker Engine是具有以下主要组件的客户端-服务器应用程序：</p><ul><li><p>服务器是一种长期运行的程序，称为守护程序进程（ Dockerd命令）。守护程序创建和管理Docker 对象，例如图像，容器，网络和卷。</p></li><li><p>REST API，它指定程序可以用来与守护程序进行通信并指示其操作的接口。</p></li><li><p>命令行界面（CLI）客户端（Docker命令）。<br>CLI使用Docker REST API通过脚本或直接CLI命令来控制Docker守护程序或与Docker守护程序进行交互。许多其他Docker应用程序都使用基础API和CLI。</p></li><li><p>Docker引擎组件流程</p></li></ul><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Docker/docker_engine.png"  alt="Docker_engine"></p><h1 id="Docker架构"><a href="#Docker架构" class="headerlink" title="Docker架构"></a>Docker架构</h1><p>Docker使用经典的CS架构，其中最重要的组成元素为Daemon、Client、Registries、Objects。</p><p>Docker Client（客户端）与Docker Daemon （守护进程）进行对话，该守护进程完成了构建，运行和分发Docker容器的繁重工作。Docker客户端和守护程序在UNIX套接字或网络接口上使用REST API进行通信。</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Docker/docker_cs.png"  alt="Docker_cs"></p><h2 id="Docker-Daemon"><a href="#Docker-Daemon" class="headerlink" title="Docker Daemon"></a>Docker Daemon</h2><p>Docker守护程序（Dockerd）监听Docker API请求并管理Docker对象，例如镜像，容器，网络和卷。守护程序还可以与其他守护程序通信以管理Docker服务。</p><h2 id="Docker-Client"><a href="#Docker-Client" class="headerlink" title="Docker Client"></a>Docker Client</h2><p>Docker客户端（Docker）是许多Docker用户与Docker交互的主要方式。当我们使用诸如之类的命令时Docker run，客户端会将这些命令发送到Dockerd，以执行这些命令。该Docker命令使用Docker API。Docker客户端可以与多个守护程序通信。</p><h2 id="Docker-Registries"><a href="#Docker-Registries" class="headerlink" title="Docker Registries"></a>Docker Registries</h2><p>Docker仓库存储Docker镜像。Docker Hub是任何人都可以使用的公共仓库，并且默认情况下，Docker已配置为在Docker Hub上查找镜像。我们也可以运行自己的私有仓库。如果使用Docker数据中心（DDC），则其中包括Docker可信仓库（DTR）。</p><p>使用Docker pull或Docker run命令时，所需的镜像将从配置的仓库中提取。使用该Docker push命令时，会将镜像推送到配置的仓库。</p><h2 id="Docker-Objects"><a href="#Docker-Objects" class="headerlink" title="Docker Objects"></a>Docker Objects</h2><p>我们一般使用Docker时，正在创建和使用镜像，容器，网络，卷，插件和其他对象。下面讲几个最重要的对象。</p><h3 id="IMAGES"><a href="#IMAGES" class="headerlink" title="IMAGES"></a>IMAGES</h3><p>镜像是一个只读模板，其中包含创建Docker容器的说明。通常，一个镜像基于另一个镜像，并进行一些其他自定义。</p><p>我们可以创建自己的镜像，也可以使用其他人在仓库中发布的镜像。要构建自己的镜像，我们可以使用简单的语法创建一个Dockerfile，以定义创建镜像并运行它所需的步骤。Dockerfile中的每个指令都会在镜像中创建一个层。当您更改Dockerfile并重建镜像时，仅重建那些已更改的层。与其他虚拟化技术相比，这是使镜像如此轻巧，小型和快速的部分原因。</p><h3 id="CONTAINERS"><a href="#CONTAINERS" class="headerlink" title="CONTAINERS"></a>CONTAINERS</h3><p>容器是镜像的可运行实例。我们可以使用Docker API或CLI创建，启动，停止，移动或删除容器。我们可以将容器连接到一个或多个网络，将存储连接到它，甚至根据其当前状态创建新镜像。</p><p>默认情况下，容器与其他容器及其主机之间的隔离程度相对较高。我们可以控制容器的网络，存储或其他基础子系统与其他容器或与主机的隔离程度。</p><p>容器由其映像以及在创建或启动时为其提供的任何配置选项定义。删除容器后，未存储在持久性存储中的状态更改将消失。</p><h3 id="SERVICES"><a href="#SERVICES" class="headerlink" title="SERVICES"></a>SERVICES</h3><p>服务允许扩展在多个Docker守护进程的容器。群集的每个成员都是Docker守护程序，所有守护程序都使用Docker API进行通信。服务允许我们定义所需的状态，例如在任何给定时间必须可用的服务副本的数量。默认情况下，该服务在所有工作节点之间是负载平衡的。对于消费者而言，Docker服务似乎是一个单独的应用程序。Docker Engine在Docker 1.12及更高版本中支持集群模式。</p><h3 id="VOLUME"><a href="#VOLUME" class="headerlink" title="VOLUME"></a>VOLUME</h3><p>数据卷，用于保存持久化数据。当我们将数据库例如MySQL运行在Docker容器中时，一般将数据通过Docker Volume保存在主机上，这样即使删除MySQL容器，数据依然保存在主机上，有效保证了数据的安全性。</p><h3 id="NETWORK"><a href="#NETWORK" class="headerlink" title="NETWORK"></a>NETWORK</h3><p>Docker使用Linux桥接，在宿主机虚拟一个Docker容器网桥(Docker0)，Docker启动一个容器时会根据Docker网桥的网段分配给容器一个IP地址，称为Container-IP，同时Docker网桥是每个容器的默认网关。因为在同一宿主机内的容器都接入同一个网桥，这样容器之间就能够通过容器的Container-IP直接通信。</p><p>Docker网桥是宿主机虚拟出来的，并不是真实存在的网络设备，外部网络是无法寻址到的，这也意味着外部网络无法通过直接Container-IP访问到容器。如果容器希望外部访问能够访问到，可以通过映射容器端口到宿主主机（端口映射），即Docker run创建容器时候通过 -p 或 -P 参数来启用，访问容器的时候就通过[宿主机IP]:[容器端口]访问容器。</p><h1 id="底层原理"><a href="#底层原理" class="headerlink" title="底层原理"></a>底层原理</h1><p>Docker用Go编写，并利用Linux内核的多个功能来交付其功能。</p><p>命名空间、控制组、联合文件系统、容器格式。</p><h2 id="Namespaces（命名空间）"><a href="#Namespaces（命名空间）" class="headerlink" title="Namespaces（命名空间）"></a>Namespaces（命名空间）</h2><p>Docker使用一种称为namespaces提供容器的隔离工作区的技术。运行容器时，Docker会为该容器创建一组命名空间。</p><p>这些名称空间提供了一层隔离。容器的每个方面都在单独的名称空间中运行，并且对其的访问仅限于该名称空间。</p><p>Docker Engine在Linux上使用以下名称空间：</p><ul><li>The pid namespace: 进程隔离 (PID: 进程ID).</li><li>The net namespace: 管理网络接口 (NET: 网络).</li><li>The ipc namespace: 管理访问IPC资源 (IPC: 进程间通信).</li><li>The mnt namespace: 管理文件系统挂载点 (MNT: 挂载).</li><li>The uts namespace: 隔离内核和版本标识符。 (UTS:Unix时间共享系统).</li></ul><h2 id="Control-groups（控制组）"><a href="#Control-groups（控制组）" class="headerlink" title="Control groups（控制组）"></a>Control groups（控制组）</h2><p>Linux上的Docker引擎还依赖于另一种称为控制组的技术。Cg将应用程序限制为一组特定的资源。控制组允许Docker Engine将可用的硬件资源共享给容器，并有选择地实施限制和约束。例如，CPU、内存。</p><h2 id="Union-file-systems（联合文件系统）"><a href="#Union-file-systems（联合文件系统）" class="headerlink" title="Union file systems（联合文件系统）"></a>Union file systems（联合文件系统）</h2><p>UnionFS是通过创建图层进行操作的文件系统,使其非常轻便且快速。Docker Engine使用UnionFS为容器提供构建模块。UnionFS可以把文件系统上多个目录(也叫分支)内容联合挂载到同一个目录下，而目录的物理位置是分开的。通俗来说，这个技术就是Docker image实现分层的技术基础，因为镜像就是从基础镜像上一层层叠加新的逻辑构成的，这种分层设计，一个优点就是资源共享。</p><h2 id="Container-format（容器格式）"><a href="#Container-format（容器格式）" class="headerlink" title="Container format（容器格式）"></a>Container format（容器格式）</h2><p>Docker Engine将命名空间，控制组和UnionFS组合到一个称为容器格式的包装器中。默认容器格式为libcontainer。未来，Docker可能会通过与BSD Jails或Solaris Zones等技术集成来支持其他容器格式。</p><p>libcontainer基于Go实现，用于创建具有名称空间，cgroup，功能和文件系统访问控制的软件包。使用libcontainer可以管理创建容器以及执行其他操作的容器的生命周期。它定义的容器是一个独立的执行环境，它共享主机系统的内核，并且（可选）与系统中的其他容器隔离。</p><p>容器是通过两步过程生成的。</p><p>第一步：要创建一个容器，我们首先必须初始化一个工厂实例，该实例将处理容器的创建和初始化。</p><p>第二步：一旦创建了工厂的实例，我们就可以创建一个配置文件来描述如何创建容器。</p><p>填充配置后，我们就可以创建一个容器。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>曾经有位高人指导过我学习的方法：故常无欲，以观其妙；常有欲，以观其徼。我在学习的过程中不断琢磨这句话的真正含义，本系列正是通过这个思想研究Docker出现的意义。从下篇开始，我将深入讲解Docker的每个技术点及作用。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><p><a href="https://docs.docker.com/get-started/overview/" target="_blank" rel="noopener">Docker官方文档</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> Linux </tag>
            
            <tag> Devops </tag>
            
            <tag> 容器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跟我学Devops之工具篇（Ansbile）</title>
      <link href="2020/05/17/devops/devops-ansible/"/>
      <url>2020/05/17/devops/devops-ansible/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><p>从自动化运维入门开始，第一个学习的自动化工具就是ansible。</p><h1 id="百度解释"><a href="#百度解释" class="headerlink" title="百度解释"></a>百度解释</h1><p>ansible是新出现的自动化运维工具，基于Python开发，集合了众多运维工具（puppet、cfengine、chef、func、fabric）的优点，实现了批量系统配置、批量程序部署、批量运行命令等功能。</p><p>ansible是基于模块工作的，本身没有批量部署的能力。真正具有批量部署的是ansible所运行的模块，ansible只是提供一种框架。主要包括：</p><ul><li>连接插件connection plugins：负责和被监控端实现通信；</li><li>host inventory：指定操作的主机，是一个配置文件里面定义监控的主机；</li><li>各种模块核心模块、command模块、自定义模块；</li><li>借助于插件完成记录日志邮件等功能；</li><li>playbook：剧本执行多个任务时，非必需可以让节点一次性运行多个任务。</li></ul><h1 id="个人理解"><a href="#个人理解" class="headerlink" title="个人理解"></a>个人理解</h1><p>用通俗的话来解释，ansbile可以分组，每个组里添加目标机器ip，通过密钥或者密码连接成功组里的机器后，你就可以用ansbile命令操作每个组的机器了。对于大规模的机器群来说，ansbile是必不可少的运维工具。</p><p>ansbile的特点：</p><ul><li>部署简单，只需在主控端部署Ansible环境，被控端无需做任何操作；</li><li>默认使用SSH协议对设备进行管理；</li><li>有大量常规运维操作模块，可实现日常绝大部分操作；</li><li>配置简单、功能强大、扩展性强；</li><li>支持API及自定义模块，可通过Python轻松扩展；</li><li>通过Playbooks来定制强大的配置、状态管理；</li><li>轻量级，无需在客户端安装agent，更新时，只需在操作机上进行一次更新即可；</li><li>提供一个功能强大、操作性强的Web管理界面和REST API接口——AWX平台。</li></ul><p>当然你可能不需要用到ansbile所有功能，以下是我认为实战中ansbile用的最爽的几个点：</p><ul><li>配置管理：将配置文件批量放到你指定组的机器某一目录下，或者指定路径后一次性修改指定组的机器该路径下的配置文件</li><li>应用部署：如java应用编译好成jar包，ansbile直接将jar包分发到指定组的机器某一目录下，执行启动命令</li><li>滚动发布：有人可能会问了，ansible也能滚动发布？其实只要了解滚动发布的原理，用ansbile一样可以做到。例如在生产环境利用负载均衡分发流量到底层存在多个运行java应用的实例中，那么滚动更新就是先控制一台组里的机器，杀进程，启动新的jar包，监控jar包启动成功等，如果这台组里的机器成功，则让后续组里的机器继续更新，否则终止。</li></ul><h1 id="开始ansible之旅"><a href="#开始ansible之旅" class="headerlink" title="开始ansible之旅"></a>开始ansible之旅</h1><h2 id="安装ansible"><a href="#安装ansible" class="headerlink" title="安装ansible"></a>安装ansible</h2><p>两种安装方式都行</p><ul><li>pip安装</li></ul><p>yum install python-pip</p><p>pip install ansible</p><ul><li>yum安装</li></ul><p>yum install epel-release -y</p><p>yum install ansible –y</p><p>安装完成后执行ansible –version</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# ansible --version</span><br><span class="line">ansible 2.9.7</span><br><span class="line">  config file &#x3D; &#x2F;etc&#x2F;ansible&#x2F;ansible.cfg</span><br><span class="line">  configured module search path &#x3D; [u&#39;&#x2F;root&#x2F;.ansible&#x2F;plugins&#x2F;modules&#39;, u&#39;&#x2F;usr&#x2F;share&#x2F;ansible&#x2F;plugins&#x2F;modules&#39;]</span><br><span class="line">  ansible python module location &#x3D; &#x2F;usr&#x2F;lib&#x2F;python2.7&#x2F;site-packages&#x2F;ansible</span><br><span class="line">  executable location &#x3D; &#x2F;usr&#x2F;bin&#x2F;ansible</span><br><span class="line">  python version &#x3D; 2.7.5 (default, Oct 30 2018, 23:45:53) [GCC 4.8.5 20150623 (Red Hat 4.8.5-36)]</span><br></pre></td></tr></table></figure><h2 id="配置ansible"><a href="#配置ansible" class="headerlink" title="配置ansible"></a>配置ansible</h2><h3 id="默认配置文件"><a href="#默认配置文件" class="headerlink" title="默认配置文件"></a>默认配置文件</h3><p>配置文件路径在/etc/ansible</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ansible]# pwd</span><br><span class="line">&#x2F;etc&#x2F;ansible</span><br><span class="line">[root@localhost ansible]# ll</span><br><span class="line">total 24</span><br><span class="line">-rw-r--r--. 1 root root 19985 Apr 19 05:24 ansible.cfg</span><br><span class="line">-rw-r--r--. 1 root root  1016 Apr 19 05:24 hosts</span><br><span class="line">drwxr-xr-x. 2 root root     6 Apr 19 05:24 roles</span><br></pre></td></tr></table></figure><p>修改ansible.cfg<br>将以下几个参数的注释去掉并修改</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">host_key_checking&#x3D; False   </span><br><span class="line">timeout &#x3D; 30  增加ssh的超时时间</span><br><span class="line">log_path &#x3D; &#x2F;var&#x2F;log&#x2F;ansible.log 存日志</span><br></pre></td></tr></table></figure><h3 id="主机清单"><a href="#主机清单" class="headerlink" title="主机清单"></a>主机清单</h3><p>ansible有2种连接主机清单的方式</p><h4 id="基于密码连接"><a href="#基于密码连接" class="headerlink" title="基于密码连接"></a>基于密码连接</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ansible]# vim &#x2F;etc&#x2F;ansible&#x2F;hosts</span><br><span class="line">#添加两个组dev、test</span><br><span class="line">[dev]</span><br><span class="line">172.31.22.31  ansible_ssh_port&#x3D;22 ansible_ssh_user&#x3D;root ansible_ssh_pass&#x3D;&quot;123456&quot;</span><br><span class="line">172.31.22.33  ansible_ssh_port&#x3D;22 ansible_ssh_user&#x3D;root ansible_ssh_pass&#x3D;&quot;123456&quot;</span><br><span class="line">172.31.22.35  ansible_ssh_port&#x3D;22 ansible_ssh_user&#x3D;root ansible_ssh_pass&#x3D;&quot;123456&quot;</span><br><span class="line"></span><br><span class="line">[test]</span><br><span class="line">172.31.24.31  ansible_ssh_port&#x3D;22 ansible_ssh_user&#x3D;root ansible_ssh_pass&#x3D;&quot;123456&quot;</span><br><span class="line">172.31.24.33  ansible_ssh_port&#x3D;22 ansible_ssh_user&#x3D;root ansible_ssh_pass&#x3D;&quot;123456&quot;</span><br><span class="line">172.31.24.35  ansible_ssh_port&#x3D;22 ansible_ssh_user&#x3D;root ansible_ssh_pass&#x3D;&quot;123456&quot;</span><br><span class="line"></span><br><span class="line">修改完后ping下该组主机是否都能连上</span><br><span class="line"></span><br><span class="line">[root@localhost ansible]# ansible dev -m ping</span><br><span class="line">172.31.22.33 | SUCCESS &#x3D;&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;&#x2F;usr&#x2F;bin&#x2F;python&quot;</span><br><span class="line">    &#125;, </span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br><span class="line">172.31.22.31 | SUCCESS &#x3D;&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;&#x2F;usr&#x2F;bin&#x2F;python&quot;</span><br><span class="line">    &#125;, </span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br><span class="line">172.31.22.35 | SUCCESS &#x3D;&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;&#x2F;usr&#x2F;bin&#x2F;python&quot;</span><br><span class="line">    &#125;, </span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="基于秘钥连接"><a href="#基于秘钥连接" class="headerlink" title="基于秘钥连接"></a>基于秘钥连接</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ansible]# ssh-keygen</span><br><span class="line">[root@localhost ansible]# for i in &#123;1,3,5&#125;; do ssh-copy-id -i 172.31.22.3$i ; done</span><br><span class="line">[root@localhost ansible]# for i in &#123;1,3,5&#125;; do ssh-copy-id -i 172.31.24.3$i ; done</span><br><span class="line">[root@localhost ansible]# vim &#x2F;etc&#x2F;ansible&#x2F;hosts</span><br><span class="line">#添加两个组dev、test</span><br><span class="line">[dev]</span><br><span class="line">172.31.22.31  </span><br><span class="line">172.31.22.33  </span><br><span class="line">172.31.22.35  </span><br><span class="line"></span><br><span class="line">[test]</span><br><span class="line">172.31.24.31  </span><br><span class="line">172.31.24.33  </span><br><span class="line">172.31.24.35  </span><br><span class="line"></span><br><span class="line">修改完后ping下该组主机是否都能连上</span><br><span class="line"></span><br><span class="line">[root@localhost ansible]# ansible test -m ping</span><br><span class="line">172.31.24.33 | SUCCESS &#x3D;&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;&#x2F;usr&#x2F;bin&#x2F;python&quot;</span><br><span class="line">    &#125;, </span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br><span class="line">172.31.24.31 | SUCCESS &#x3D;&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;&#x2F;usr&#x2F;bin&#x2F;python&quot;</span><br><span class="line">    &#125;, </span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br><span class="line">172.31.24.35 | SUCCESS &#x3D;&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;&#x2F;usr&#x2F;bin&#x2F;python&quot;</span><br><span class="line">    &#125;, </span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;ping&quot;: &quot;pong&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="ansbile常用模块"><a href="#ansbile常用模块" class="headerlink" title="ansbile常用模块"></a>ansbile常用模块</h2><p>下面举几个日常用的比较多的模块，没有列举完所有的，下列模块掌握之后日常对付批量操作虚拟机的任务是没问题的。</p><h3 id="ping模块"><a href="#ping模块" class="headerlink" title="ping模块"></a>ping模块</h3><p>测试主机连通性</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ansible $1 -m ping</span><br><span class="line"></span><br><span class="line">$1：组名    eg：dev</span><br></pre></td></tr></table></figure><h3 id="command模块"><a href="#command模块" class="headerlink" title="command模块"></a>command模块</h3><p>这个模块可以直接在远程主机上执行命令，并将结果返回本主机。</p><p>注意，该命令不支持| 管道命令</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ansible $1 -m command -a $2</span><br><span class="line"></span><br><span class="line">$1：组名    eg：dev</span><br><span class="line"></span><br><span class="line">$2：命令    eg:&#39;ip add&#39;</span><br></pre></td></tr></table></figure><h3 id="shell模块"><a href="#shell模块" class="headerlink" title="shell模块"></a>shell模块</h3><p>shell模块可以在远程主机上调用shell解释器运行命令，支持shell的各种功能，例如管道等。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ansible $1 -m shell -a $2</span><br><span class="line"></span><br><span class="line">$1：组名    eg：dev</span><br><span class="line"></span><br><span class="line">$2：命令    eg:&#39;ps -aux|grep java&#39;</span><br></pre></td></tr></table></figure><p>shell模块 vs command模块</p><p>这两个模块在很多情况下都能完成同样的工作，以下是两个模块之前的区别：</p><ul><li><p>command 模块命令将不会使用 shell 执行。</p></li><li><p>因此, 像 $HOME 这样的变量是不可用的。还有像&lt;, &gt;, |, ;, &amp;都将不可用。</p></li><li><p>shell 模块通过shell程序执行， 默认是/bin/sh, &lt;, &gt;, |, ;, &amp; 可用，但这样有潜在的 shell 注入风险。</p></li><li><p>command 模块更安全，因为他不受用户环境的影响。 也很大的避免了潜在的 shell 注入风险。</p></li></ul><h3 id="copy模块"><a href="#copy模块" class="headerlink" title="copy模块"></a>copy模块</h3><p>这个模块用于将文件复制到远程主机，同时支持给定内容生成文件和修改权限等。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">ansible $1 -m copy -a $2</span><br><span class="line"></span><br><span class="line">$1：组名    eg：dev</span><br><span class="line"></span><br><span class="line">$2：命令    eg：&#39;src&#x3D;&#x2F;data&#x2F;test.sh dest&#x3D;&#x2F;data mode&#x3D;777 &#39;</span><br><span class="line"></span><br><span class="line">参数详解</span><br><span class="line"></span><br><span class="line">src　　　　  #被复制到远程主机的本地文件。可以是绝对路径，也可以是相对路径。如果路径是一个目录，则会递归复制，用法类似于&quot;rsync&quot;</span><br><span class="line">content　　　#用于替换&quot;src&quot;，可以直接指定文件的值</span><br><span class="line">dest　　　　 #必选项，将源文件复制到的远程主机的绝对路径</span><br><span class="line">backup　　　 #当文件内容发生改变后，在覆盖之前把源文件备份，备份文件包含时间信息</span><br><span class="line">mode　　　　 #递归设定目录的权限，默认为系统默认权限</span><br><span class="line">force　　　　#当目标主机包含该文件，但内容不同时，设为&quot;yes&quot;，表示强制覆盖；设为&quot;no&quot;，表示目标主机的目标位置不存在该文件才复制。默认为&quot;yes&quot;</span><br><span class="line">others　　　 #所有的 file 模块中的选项可以在这里使用</span><br></pre></td></tr></table></figure><h3 id="fetch模块"><a href="#fetch模块" class="headerlink" title="fetch模块"></a>fetch模块</h3><p>该模块用于从远程某主机获取（复制）文件到本地。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">ansible $1 -m fetch -a $2</span><br><span class="line"></span><br><span class="line">$1：组名    eg：dev</span><br><span class="line"></span><br><span class="line">$2：命令    eg：&#39;src&#x3D;&#x2F;data&#x2F;test.sh dest&#x3D;&#x2F;data &#39;</span><br><span class="line"></span><br><span class="line">dest：用来存放文件的目录</span><br><span class="line">src：在远程拉取的文件，并且必须是一个file，不能是目录</span><br><span class="line"></span><br><span class="line">文件保存的路径是我们设置的接收目录下的被管制主机ip目录下</span><br><span class="line"></span><br><span class="line">[root@localhost data]# ansible dev -m fetch -a &#39;src&#x3D;&#x2F;data&#x2F;test.sh dest&#x3D;&#x2F;data&#39;</span><br><span class="line">172.31.22.33 | CHANGED &#x3D;&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: true, </span><br><span class="line">    &quot;checksum&quot;: &quot;d53a75b15c0c9eaf4633e26442f4cca32c600c00&quot;, </span><br><span class="line">    &quot;dest&quot;: &quot;&#x2F;data&#x2F;172.31.22.33&#x2F;data&#x2F;test.sh&quot;, </span><br><span class="line">    &quot;md5sum&quot;: &quot;2da6c61e985bf3cece7ece373c3976b0&quot;, </span><br><span class="line">    &quot;remote_checksum&quot;: &quot;d53a75b15c0c9eaf4633e26442f4cca32c600c00&quot;, </span><br><span class="line">    &quot;remote_md5sum&quot;: null</span><br><span class="line">&#125;</span><br><span class="line">172.31.22.31 | CHANGED &#x3D;&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: true, </span><br><span class="line">    &quot;checksum&quot;: &quot;d53a75b15c0c9eaf4633e26442f4cca32c600c00&quot;, </span><br><span class="line">    &quot;dest&quot;: &quot;&#x2F;data&#x2F;172.31.22.31&#x2F;data&#x2F;test.sh&quot;, </span><br><span class="line">    &quot;md5sum&quot;: &quot;2da6c61e985bf3cece7ece373c3976b0&quot;, </span><br><span class="line">    &quot;remote_checksum&quot;: &quot;d53a75b15c0c9eaf4633e26442f4cca32c600c00&quot;, </span><br><span class="line">    &quot;remote_md5sum&quot;: null</span><br><span class="line">&#125;</span><br><span class="line">172.31.22.35 | CHANGED &#x3D;&gt; &#123;</span><br><span class="line">    &quot;changed&quot;: true, </span><br><span class="line">    &quot;checksum&quot;: &quot;d53a75b15c0c9eaf4633e26442f4cca32c600c00&quot;, </span><br><span class="line">    &quot;dest&quot;: &quot;&#x2F;data&#x2F;172.31.22.35&#x2F;data&#x2F;test.sh&quot;, </span><br><span class="line">    &quot;md5sum&quot;: &quot;2da6c61e985bf3cece7ece373c3976b0&quot;, </span><br><span class="line">    &quot;remote_checksum&quot;: &quot;d53a75b15c0c9eaf4633e26442f4cca32c600c00&quot;, </span><br><span class="line">    &quot;remote_md5sum&quot;: null</span><br><span class="line">&#125;</span><br><span class="line">[root@localhost data]# ll</span><br><span class="line">total 28</span><br><span class="line">drwxr-xr-x.  3 root root 4096 May 15 10:08 172.31.22.31</span><br><span class="line">drwxr-xr-x.  3 root root 4096 May 15 10:08 172.31.22.33</span><br><span class="line">drwxr-xr-x.  3 root root 4096 May 15 10:08 172.31.22.35</span><br><span class="line">[root@localhost data]# cd 172.31.22.31&#x2F;data</span><br><span class="line">[root@localhost data]# ll</span><br><span class="line">total 4</span><br><span class="line">-rwxr-xr-x. 1 root root 352 May 15 10:08 test.sh</span><br></pre></td></tr></table></figure><h3 id="yum模块"><a href="#yum模块" class="headerlink" title="yum模块"></a>yum模块</h3><p>该模块主要用于软件的安装</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">ansible $1 -m yum -a $2</span><br><span class="line"></span><br><span class="line">$1：组名    eg：dev</span><br><span class="line"></span><br><span class="line">$2：命令    eg：&#39;name&#x3D;tree  state&#x3D;present&#39;</span><br><span class="line"></span><br><span class="line">name&#x3D;　　#所安装的包的名称</span><br><span class="line">state&#x3D;　　#present 安装， latest 安装最新的, absent 卸载软件。</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# ansible dev -m yum -a &#39;name&#x3D;tree  state&#x3D;present&#39;</span><br><span class="line">172.31.22.31 | SUCCESS &#x3D;&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;&#x2F;usr&#x2F;bin&#x2F;python&quot;</span><br><span class="line">    &#125;, </span><br><span class="line">    &quot;changed&quot;: false, </span><br><span class="line">    &quot;msg&quot;: &quot;&quot;, </span><br><span class="line">    &quot;rc&quot;: 0, </span><br><span class="line">    &quot;results&quot;: [</span><br><span class="line">        &quot;tree-1.6.0-10.el7.x86_64 providing tree is already installed&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">172.31.22.35 | CHANGED &#x3D;&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;&#x2F;usr&#x2F;bin&#x2F;python&quot;</span><br><span class="line">    &#125;, </span><br><span class="line">    &quot;changed&quot;: true, </span><br><span class="line">    &quot;changes&quot;: &#123;</span><br><span class="line">        &quot;installed&quot;: [</span><br><span class="line">            &quot;tree&quot;</span><br><span class="line">        ]</span><br><span class="line">    &#125;, </span><br><span class="line">    &quot;msg&quot;: &quot;&quot;, </span><br><span class="line">    &quot;rc&quot;: 0, </span><br><span class="line">    &quot;results&quot;: [</span><br><span class="line">        &quot;Loaded plugins: fastestmirror\nLoading mirror speeds from cached hostfile\n * base: mirrors.aliyun.com\n * elrepo: mirrors.tuna.tsinghua.edu.cn\n * epel: mirrors.tuna.tsinghua.edu.cn\n * extras: mirrors.aliyun.com\n * updates: mirrors.aliyun.com\nResolving Dependencies\n--&gt; Running transaction check\n---&gt; Package tree.x86_64 0:1.6.0-10.el7 will be installed\n--&gt; Finished Dependency Resolution\n\nDependencies Resolved\n\n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\n Package        Arch             Version                   Repository      Size\n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\nInstalling:\n tree           x86_64           1.6.0-10.el7              base            46 k\n\nTransaction Summary\n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\nInstall  1 Package\n\nTotal download size: 46 k\nInstalled size: 87 k\nDownloading packages:\nRunning transaction check\nRunning transaction test\nTransaction test succeeded\nRunning transaction\n  Installing : tree-1.6.0-10.el7.x86_64                                     1&#x2F;1 \n  Verifying  : tree-1.6.0-10.el7.x86_64                                     1&#x2F;1 \n\nInstalled:\n  tree.x86_64 0:1.6.0-10.el7                                                    \n\nComplete!\n&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br><span class="line">172.31.22.33 | CHANGED &#x3D;&gt; &#123;</span><br><span class="line">    &quot;ansible_facts&quot;: &#123;</span><br><span class="line">        &quot;discovered_interpreter_python&quot;: &quot;&#x2F;usr&#x2F;bin&#x2F;python&quot;</span><br><span class="line">    &#125;, </span><br><span class="line">    &quot;changed&quot;: true, </span><br><span class="line">    &quot;changes&quot;: &#123;</span><br><span class="line">        &quot;installed&quot;: [</span><br><span class="line">            &quot;tree&quot;</span><br><span class="line">        ]</span><br><span class="line">    &#125;, </span><br><span class="line">    &quot;msg&quot;: &quot;&quot;, </span><br><span class="line">    &quot;rc&quot;: 0, </span><br><span class="line">    &quot;results&quot;: [</span><br><span class="line">        &quot;Loaded plugins: fastestmirror\nLoading mirror speeds from cached hostfile\n * base: mirrors.aliyun.com\n * elrepo: mirrors.tuna.tsinghua.edu.cn\n * epel: mirrors.tuna.tsinghua.edu.cn\n * extras: mirrors.aliyun.com\n * updates: mirrors.aliyun.com\nResolving Dependencies\n--&gt; Running transaction check\n---&gt; Package tree.x86_64 0:1.6.0-10.el7 will be installed\n--&gt; Finished Dependency Resolution\n\nDependencies Resolved\n\n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\n Package        Arch             Version                   Repository      Size\n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\nInstalling:\n tree           x86_64           1.6.0-10.el7              base            46 k\n\nTransaction Summary\n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\nInstall  1 Package\n\nTotal download size: 46 k\nInstalled size: 87 k\nDownloading packages:\nRunning transaction check\nRunning transaction test\nTransaction test succeeded\nRunning transaction\n  Installing : tree-1.6.0-10.el7.x86_64                                     1&#x2F;1 \n  Verifying  : tree-1.6.0-10.el7.x86_64                                     1&#x2F;1 \n\nInstalled:\n  tree.x86_64 0:1.6.0-10.el7                                                    \n\nComplete!\n&quot;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>注意：已安装目标软件的机器不会再执行安装</p><h2 id="ansible-playbook"><a href="#ansible-playbook" class="headerlink" title="ansible playbook"></a>ansible playbook</h2><p>playbook 是 ansible 用于配置，部署，和管理被控节点的剧本。即写好一个剧本后，根据组的不同可以使用一个剧本来批量操作服务器，比如这个剧本制作好了后，可以给dev组安装java环境，安装完成后，还可以给test组安装，有点模板的意思。</p><h3 id="格式"><a href="#格式" class="headerlink" title="格式"></a>格式</h3><p>创建一个带.yml结尾的文本，文本内容应该遵循下面几点</p><ul><li>文件的第一行应该以 “—“ (三个连字符)开始，表明文件的开始。</li><li>在同一行中，#之后的内容表示注释。</li><li>YML中的列表元素以”-”开头然后紧跟着一个空格，后面为元素内容。</li><li>同一个列表中的元素应该保持相同的缩进。否则会被当做错误处理。</li><li>play中hosts，variables，roles，tasks等对象的表示方法都是键值中间以”:”分隔表示，”:”后面还要增加一个空格。</li></ul><p>Playbook的核心元素：</p><ul><li>Hosts：主机组</li><li>Tasks：任务列表</li><li>Variables：变量，设置方式有四种</li><li>Templates：包含了模板语法的文本文件——Jinja是一种现代且设计友好的Python模板语言，以Django的模板为模型。借助可选的沙盒模板执行环境，它可以快速，广泛地使用并且安全</li><li>Handlers：由特定条件触发的任务</li></ul><p>Playbooks配置文件的基础组件：</p><ul><li>Hosts：运行指定任务的目标主机</li><li>remoute_user：在远程主机上执行任务的用户</li><li>tasks：任务列表</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">格式：</span><br><span class="line">     tasks：</span><br><span class="line">　　　　　– name: TASK_NAME   </span><br><span class="line">　　　　　　module: arguments</span><br><span class="line">　　　　　　notify: HANDLER_NAME</span><br><span class="line">　　 handlers:</span><br><span class="line">　　　　　– name: HANDLER_NAME</span><br><span class="line">　　　　　　module: arguments</span><br><span class="line">　　　　　　</span><br><span class="line">handlers：任务，在特定条件下触发；接收到其它任务的通知时被触发；　　　</span><br><span class="line">　  (1) 某任务的状态在运行后为changed时，可通过“notify”通知给相应的handlers；</span><br><span class="line">　　(2) 任务可以通过“tags“打标签，而后可在ansible-playbook命令上使用-t指定进行调用；</span><br><span class="line">　　</span><br><span class="line">ansible-playbook命令的命令行中的-e vars&#x3D;VARS，这样就可以直接把自定义的变量传入。</span><br><span class="line"></span><br><span class="line">例如下面的playbook </span><br><span class="line">你需要改http_port 端口可以这样执行</span><br><span class="line"></span><br><span class="line">ansible-playbook ansible_httpd.yml -e http_port&#x3D;81 </span><br><span class="line"></span><br><span class="line">你需要定向执行tag：startapache的方法</span><br><span class="line"></span><br><span class="line">ansible-playbook ansible_httpd.yml -t startapache</span><br></pre></td></tr></table></figure><h3 id="官网的第一个的playbook"><a href="#官网的第一个的playbook" class="headerlink" title="官网的第一个的playbook"></a>官网的第一个的playbook</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# vim ansible_httpd.yml</span><br><span class="line">---</span><br><span class="line">- hosts: dev       #ansbile定义的组名</span><br><span class="line">  vars:            #变量,可以传到template里的httpd.j2里，也可以直接在yml文件里利用</span><br><span class="line">    http_port: 80   </span><br><span class="line">    max_clients: 200</span><br><span class="line">#远程执行的用户</span><br><span class="line">  remote_user: root  </span><br><span class="line">  tasks:</span><br><span class="line">  - name: ensure apache is at the latest version   #方法名</span><br><span class="line">#基础模块：参数</span><br><span class="line">    yum: pkg&#x3D;httpd state&#x3D;latest                   </span><br><span class="line">  - name: write the apache config file</span><br><span class="line">    template: src&#x3D;&#x2F;srv&#x2F;httpd.j2 dest&#x3D;&#x2F;etc&#x2F;httpd.conf</span><br><span class="line">#执行name为restart apache的方法</span><br><span class="line">    notify:         </span><br><span class="line">    - restart apache  </span><br><span class="line">  - name: ensure apache is running</span><br><span class="line">    service: name&#x3D;httpd state&#x3D;started </span><br><span class="line">    tag:startapache</span><br><span class="line">#这里的restart apache和上面的触发是配对的。这就是handlers的作用。相当于tag</span><br><span class="line">  handlers:          </span><br><span class="line">    - name: restart apache</span><br><span class="line">      service: name&#x3D;httpd state&#x3D;restarted   #重启服务器</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>ansible最基本的知识就梳理到这了，其实对于大部分场景已经够用了。如果需要定制化长期使用ansible编排，推荐用ansbile-playbook的模式，这样对于大型集群维护更方便，例如改脚本、配置更新、重启等。如果是偶尔用ansbile可以直接使用普通命令。本文展示的ansible只是一个入门教程，实际使用中对于更多丰富模块的利用、以及优化ansible的性能的方法可以看下面参考资料的官方文档。</p><p>下期通过ansible配合jenkins展现实战中ansbile的可用性。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://docs.ansible.com/" target="_blank" rel="noopener">ansible官方文档</a></p><p><a href="https://jinja.palletsprojects.com/en/2.11.x/" target="_blank" rel="noopener">jinja2官方文档</a></p><p><a href="https://www.cnblogs.com/keerya/p/7987886.html#_label0_0" target="_blank" rel="noopener">自动化运维工具——ansible详解（一）</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> 跟我学Devops </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Devops </tag>
            
            <tag> 自动化 </tag>
            
            <tag> Ansible </tag>
            
            <tag> Python </tag>
            
            <tag> Jinja </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>实现负载均衡器搭配Nacos集群的高可用框架</title>
      <link href="2020/05/14/slb/slb-nacos/"/>
      <url>2020/05/14/slb/slb-nacos/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><p>本文接上期，教大家在项目中的如何利用负载均衡和高可用组件搭建nacos集群。</p><p>架构图如下<br><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/SLB/nacos_ha.jpg"  alt="nacos_ha.jpg"></p><h1 id="准备"><a href="#准备" class="headerlink" title="准备"></a>准备</h1><p>请确保是在环境中安装使用:</p><ul><li>64 bit JDK 1.8+；下载.配置。</li><li>Maven 3.2.x+；下载.配置。</li><li>3个或3个以上Nacos节点才能构成集群。</li><li>keepalived</li><li>nginx</li><li>mysql5.7.28</li></ul><table><thead><tr><th>服务器</th><th>IP</th></tr></thead><tbody><tr><td>nginx+keepalived(主)</td><td>172.31.26.11</td></tr><tr><td>nginx+keepalived(备)</td><td>172.31.26.12</td></tr><tr><td>mysql</td><td>172.31.26.13</td></tr><tr><td>nacos-01</td><td>172.31.26.14</td></tr><tr><td>nacos-02</td><td>172.31.26.15</td></tr><tr><td>nacos-03</td><td>172.31.26.16</td></tr><tr><td>VIP</td><td>172.31.26.200</td></tr></tbody></table><h1 id="安装启动步骤"><a href="#安装启动步骤" class="headerlink" title="安装启动步骤"></a>安装启动步骤</h1><h2 id="数据库"><a href="#数据库" class="headerlink" title="数据库"></a>数据库</h2><table><thead><tr><th>服务器</th><th>IP</th></tr></thead><tbody><tr><td>mysql</td><td>172.31.26.13</td></tr></tbody></table><h3 id="安装Mysql"><a href="#安装Mysql" class="headerlink" title="安装Mysql"></a>安装Mysql</h3><p><a href="https://rugod.cn/2020/05/01/mysql/mysql-install/" target="_blank" rel="noopener">离线安装Mysql5.7.28及调优</a></p><h3 id="初始化-MySQL-数据库"><a href="#初始化-MySQL-数据库" class="headerlink" title="初始化 MySQL 数据库"></a>初始化 MySQL 数据库</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;******************************************&#x2F;</span><br><span class="line">&#x2F;*   数据库全名 &#x3D; nacos_config   *&#x2F;</span><br><span class="line">&#x2F;*   表名称 &#x3D; config_info   *&#x2F;</span><br><span class="line">&#x2F;******************************************&#x2F;</span><br><span class="line">CREATE TABLE &#96;config_info&#96; (</span><br><span class="line">  &#96;id&#96; bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#39;id&#39;,</span><br><span class="line">  &#96;data_id&#96; varchar(255) NOT NULL COMMENT &#39;data_id&#39;,</span><br><span class="line">  &#96;group_id&#96; varchar(255) DEFAULT NULL,</span><br><span class="line">  &#96;content&#96; longtext NOT NULL COMMENT &#39;content&#39;,</span><br><span class="line">  &#96;md5&#96; varchar(32) DEFAULT NULL COMMENT &#39;md5&#39;,</span><br><span class="line">  &#96;gmt_create&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,</span><br><span class="line">  &#96;gmt_modified&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;,</span><br><span class="line">  &#96;src_user&#96; text COMMENT &#39;source user&#39;,</span><br><span class="line">  &#96;src_ip&#96; varchar(20) DEFAULT NULL COMMENT &#39;source ip&#39;,</span><br><span class="line">  &#96;app_name&#96; varchar(128) DEFAULT NULL,</span><br><span class="line">  &#96;tenant_id&#96; varchar(128) DEFAULT &#39;&#39; COMMENT &#39;租户字段&#39;,</span><br><span class="line">  &#96;c_desc&#96; varchar(256) DEFAULT NULL,</span><br><span class="line">  &#96;c_use&#96; varchar(64) DEFAULT NULL,</span><br><span class="line">  &#96;effect&#96; varchar(64) DEFAULT NULL,</span><br><span class="line">  &#96;type&#96; varchar(64) DEFAULT NULL,</span><br><span class="line">  &#96;c_schema&#96; text,</span><br><span class="line">  PRIMARY KEY (&#96;id&#96;),</span><br><span class="line">  UNIQUE KEY &#96;uk_configinfo_datagrouptenant&#96; (&#96;data_id&#96;,&#96;group_id&#96;,&#96;tenant_id&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin COMMENT&#x3D;&#39;config_info&#39;;</span><br><span class="line"></span><br><span class="line">&#x2F;******************************************&#x2F;</span><br><span class="line">&#x2F;*   数据库全名 &#x3D; nacos_config   *&#x2F;</span><br><span class="line">&#x2F;*   表名称 &#x3D; config_info_aggr   *&#x2F;</span><br><span class="line">&#x2F;******************************************&#x2F;</span><br><span class="line">CREATE TABLE &#96;config_info_aggr&#96; (</span><br><span class="line">  &#96;id&#96; bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#39;id&#39;,</span><br><span class="line">  &#96;data_id&#96; varchar(255) NOT NULL COMMENT &#39;data_id&#39;,</span><br><span class="line">  &#96;group_id&#96; varchar(255) NOT NULL COMMENT &#39;group_id&#39;,</span><br><span class="line">  &#96;datum_id&#96; varchar(255) NOT NULL COMMENT &#39;datum_id&#39;,</span><br><span class="line">  &#96;content&#96; longtext NOT NULL COMMENT &#39;内容&#39;,</span><br><span class="line">  &#96;gmt_modified&#96; datetime NOT NULL COMMENT &#39;修改时间&#39;,</span><br><span class="line">  &#96;app_name&#96; varchar(128) DEFAULT NULL,</span><br><span class="line">  &#96;tenant_id&#96; varchar(128) DEFAULT &#39;&#39; COMMENT &#39;租户字段&#39;,</span><br><span class="line">  PRIMARY KEY (&#96;id&#96;),</span><br><span class="line">  UNIQUE KEY &#96;uk_configinfoaggr_datagrouptenantdatum&#96; (&#96;data_id&#96;,&#96;group_id&#96;,&#96;tenant_id&#96;,&#96;datum_id&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin COMMENT&#x3D;&#39;增加租户字段&#39;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#x2F;******************************************&#x2F;</span><br><span class="line">&#x2F;*   数据库全名 &#x3D; nacos_config   *&#x2F;</span><br><span class="line">&#x2F;*   表名称 &#x3D; config_info_beta   *&#x2F;</span><br><span class="line">&#x2F;******************************************&#x2F;</span><br><span class="line">CREATE TABLE &#96;config_info_beta&#96; (</span><br><span class="line">  &#96;id&#96; bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#39;id&#39;,</span><br><span class="line">  &#96;data_id&#96; varchar(255) NOT NULL COMMENT &#39;data_id&#39;,</span><br><span class="line">  &#96;group_id&#96; varchar(128) NOT NULL COMMENT &#39;group_id&#39;,</span><br><span class="line">  &#96;app_name&#96; varchar(128) DEFAULT NULL COMMENT &#39;app_name&#39;,</span><br><span class="line">  &#96;content&#96; longtext NOT NULL COMMENT &#39;content&#39;,</span><br><span class="line">  &#96;beta_ips&#96; varchar(1024) DEFAULT NULL COMMENT &#39;betaIps&#39;,</span><br><span class="line">  &#96;md5&#96; varchar(32) DEFAULT NULL COMMENT &#39;md5&#39;,</span><br><span class="line">  &#96;gmt_create&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,</span><br><span class="line">  &#96;gmt_modified&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;,</span><br><span class="line">  &#96;src_user&#96; text COMMENT &#39;source user&#39;,</span><br><span class="line">  &#96;src_ip&#96; varchar(20) DEFAULT NULL COMMENT &#39;source ip&#39;,</span><br><span class="line">  &#96;tenant_id&#96; varchar(128) DEFAULT &#39;&#39; COMMENT &#39;租户字段&#39;,</span><br><span class="line">  PRIMARY KEY (&#96;id&#96;),</span><br><span class="line">  UNIQUE KEY &#96;uk_configinfobeta_datagrouptenant&#96; (&#96;data_id&#96;,&#96;group_id&#96;,&#96;tenant_id&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin COMMENT&#x3D;&#39;config_info_beta&#39;;</span><br><span class="line"></span><br><span class="line">&#x2F;******************************************&#x2F;</span><br><span class="line">&#x2F;*   数据库全名 &#x3D; nacos_config   *&#x2F;</span><br><span class="line">&#x2F;*   表名称 &#x3D; config_info_tag   *&#x2F;</span><br><span class="line">&#x2F;******************************************&#x2F;</span><br><span class="line">CREATE TABLE &#96;config_info_tag&#96; (</span><br><span class="line">  &#96;id&#96; bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#39;id&#39;,</span><br><span class="line">  &#96;data_id&#96; varchar(255) NOT NULL COMMENT &#39;data_id&#39;,</span><br><span class="line">  &#96;group_id&#96; varchar(128) NOT NULL COMMENT &#39;group_id&#39;,</span><br><span class="line">  &#96;tenant_id&#96; varchar(128) DEFAULT &#39;&#39; COMMENT &#39;tenant_id&#39;,</span><br><span class="line">  &#96;tag_id&#96; varchar(128) NOT NULL COMMENT &#39;tag_id&#39;,</span><br><span class="line">  &#96;app_name&#96; varchar(128) DEFAULT NULL COMMENT &#39;app_name&#39;,</span><br><span class="line">  &#96;content&#96; longtext NOT NULL COMMENT &#39;content&#39;,</span><br><span class="line">  &#96;md5&#96; varchar(32) DEFAULT NULL COMMENT &#39;md5&#39;,</span><br><span class="line">  &#96;gmt_create&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,</span><br><span class="line">  &#96;gmt_modified&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;,</span><br><span class="line">  &#96;src_user&#96; text COMMENT &#39;source user&#39;,</span><br><span class="line">  &#96;src_ip&#96; varchar(20) DEFAULT NULL COMMENT &#39;source ip&#39;,</span><br><span class="line">  PRIMARY KEY (&#96;id&#96;),</span><br><span class="line">  UNIQUE KEY &#96;uk_configinfotag_datagrouptenanttag&#96; (&#96;data_id&#96;,&#96;group_id&#96;,&#96;tenant_id&#96;,&#96;tag_id&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin COMMENT&#x3D;&#39;config_info_tag&#39;;</span><br><span class="line"></span><br><span class="line">&#x2F;******************************************&#x2F;</span><br><span class="line">&#x2F;*   数据库全名 &#x3D; nacos_config   *&#x2F;</span><br><span class="line">&#x2F;*   表名称 &#x3D; config_tags_relation   *&#x2F;</span><br><span class="line">&#x2F;******************************************&#x2F;</span><br><span class="line">CREATE TABLE &#96;config_tags_relation&#96; (</span><br><span class="line">  &#96;id&#96; bigint(20) NOT NULL COMMENT &#39;id&#39;,</span><br><span class="line">  &#96;tag_name&#96; varchar(128) NOT NULL COMMENT &#39;tag_name&#39;,</span><br><span class="line">  &#96;tag_type&#96; varchar(64) DEFAULT NULL COMMENT &#39;tag_type&#39;,</span><br><span class="line">  &#96;data_id&#96; varchar(255) NOT NULL COMMENT &#39;data_id&#39;,</span><br><span class="line">  &#96;group_id&#96; varchar(128) NOT NULL COMMENT &#39;group_id&#39;,</span><br><span class="line">  &#96;tenant_id&#96; varchar(128) DEFAULT &#39;&#39; COMMENT &#39;tenant_id&#39;,</span><br><span class="line">  &#96;nid&#96; bigint(20) NOT NULL AUTO_INCREMENT,</span><br><span class="line">  PRIMARY KEY (&#96;nid&#96;),</span><br><span class="line">  UNIQUE KEY &#96;uk_configtagrelation_configidtag&#96; (&#96;id&#96;,&#96;tag_name&#96;,&#96;tag_type&#96;),</span><br><span class="line">  KEY &#96;idx_tenant_id&#96; (&#96;tenant_id&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin COMMENT&#x3D;&#39;config_tag_relation&#39;;</span><br><span class="line"></span><br><span class="line">&#x2F;******************************************&#x2F;</span><br><span class="line">&#x2F;*   数据库全名 &#x3D; nacos_config   *&#x2F;</span><br><span class="line">&#x2F;*   表名称 &#x3D; group_capacity   *&#x2F;</span><br><span class="line">&#x2F;******************************************&#x2F;</span><br><span class="line">CREATE TABLE &#96;group_capacity&#96; (</span><br><span class="line">  &#96;id&#96; bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;主键ID&#39;,</span><br><span class="line">  &#96;group_id&#96; varchar(128) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;Group ID，空字符表示整个集群&#39;,</span><br><span class="line">  &#96;quota&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;配额，0表示使用默认值&#39;,</span><br><span class="line">  &#96;usage&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;使用量&#39;,</span><br><span class="line">  &#96;max_size&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;单个配置大小上限，单位为字节，0表示使用默认值&#39;,</span><br><span class="line">  &#96;max_aggr_count&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;聚合子配置最大个数，，0表示使用默认值&#39;,</span><br><span class="line">  &#96;max_aggr_size&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值&#39;,</span><br><span class="line">  &#96;max_history_count&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;最大变更历史数量&#39;,</span><br><span class="line">  &#96;gmt_create&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,</span><br><span class="line">  &#96;gmt_modified&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;,</span><br><span class="line">  PRIMARY KEY (&#96;id&#96;),</span><br><span class="line">  UNIQUE KEY &#96;uk_group_id&#96; (&#96;group_id&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin COMMENT&#x3D;&#39;集群、各Group容量信息表&#39;;</span><br><span class="line"></span><br><span class="line">&#x2F;******************************************&#x2F;</span><br><span class="line">&#x2F;*   数据库全名 &#x3D; nacos_config   *&#x2F;</span><br><span class="line">&#x2F;*   表名称 &#x3D; his_config_info   *&#x2F;</span><br><span class="line">&#x2F;******************************************&#x2F;</span><br><span class="line">CREATE TABLE &#96;his_config_info&#96; (</span><br><span class="line">  &#96;id&#96; bigint(64) unsigned NOT NULL,</span><br><span class="line">  &#96;nid&#96; bigint(20) unsigned NOT NULL AUTO_INCREMENT,</span><br><span class="line">  &#96;data_id&#96; varchar(255) NOT NULL,</span><br><span class="line">  &#96;group_id&#96; varchar(128) NOT NULL,</span><br><span class="line">  &#96;app_name&#96; varchar(128) DEFAULT NULL COMMENT &#39;app_name&#39;,</span><br><span class="line">  &#96;content&#96; longtext NOT NULL,</span><br><span class="line">  &#96;md5&#96; varchar(32) DEFAULT NULL,</span><br><span class="line">  &#96;gmt_create&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,</span><br><span class="line">  &#96;gmt_modified&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,</span><br><span class="line">  &#96;src_user&#96; text,</span><br><span class="line">  &#96;src_ip&#96; varchar(20) DEFAULT NULL,</span><br><span class="line">  &#96;op_type&#96; char(10) DEFAULT NULL,</span><br><span class="line">  &#96;tenant_id&#96; varchar(128) DEFAULT &#39;&#39; COMMENT &#39;租户字段&#39;,</span><br><span class="line">  PRIMARY KEY (&#96;nid&#96;),</span><br><span class="line">  KEY &#96;idx_gmt_create&#96; (&#96;gmt_create&#96;),</span><br><span class="line">  KEY &#96;idx_gmt_modified&#96; (&#96;gmt_modified&#96;),</span><br><span class="line">  KEY &#96;idx_did&#96; (&#96;data_id&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin COMMENT&#x3D;&#39;多租户改造&#39;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#x2F;******************************************&#x2F;</span><br><span class="line">&#x2F;*   数据库全名 &#x3D; nacos_config   *&#x2F;</span><br><span class="line">&#x2F;*   表名称 &#x3D; tenant_capacity   *&#x2F;</span><br><span class="line">&#x2F;******************************************&#x2F;</span><br><span class="line">CREATE TABLE &#96;tenant_capacity&#96; (</span><br><span class="line">  &#96;id&#96; bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT &#39;主键ID&#39;,</span><br><span class="line">  &#96;tenant_id&#96; varchar(128) NOT NULL DEFAULT &#39;&#39; COMMENT &#39;Tenant ID&#39;,</span><br><span class="line">  &#96;quota&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;配额，0表示使用默认值&#39;,</span><br><span class="line">  &#96;usage&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;使用量&#39;,</span><br><span class="line">  &#96;max_size&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;单个配置大小上限，单位为字节，0表示使用默认值&#39;,</span><br><span class="line">  &#96;max_aggr_count&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;聚合子配置最大个数&#39;,</span><br><span class="line">  &#96;max_aggr_size&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值&#39;,</span><br><span class="line">  &#96;max_history_count&#96; int(10) unsigned NOT NULL DEFAULT &#39;0&#39; COMMENT &#39;最大变更历史数量&#39;,</span><br><span class="line">  &#96;gmt_create&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,</span><br><span class="line">  &#96;gmt_modified&#96; datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;,</span><br><span class="line">  PRIMARY KEY (&#96;id&#96;),</span><br><span class="line">  UNIQUE KEY &#96;uk_tenant_id&#96; (&#96;tenant_id&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin COMMENT&#x3D;&#39;租户容量信息表&#39;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">CREATE TABLE &#96;tenant_info&#96; (</span><br><span class="line">  &#96;id&#96; bigint(20) NOT NULL AUTO_INCREMENT COMMENT &#39;id&#39;,</span><br><span class="line">  &#96;kp&#96; varchar(128) NOT NULL COMMENT &#39;kp&#39;,</span><br><span class="line">  &#96;tenant_id&#96; varchar(128) default &#39;&#39; COMMENT &#39;tenant_id&#39;,</span><br><span class="line">  &#96;tenant_name&#96; varchar(128) default &#39;&#39; COMMENT &#39;tenant_name&#39;,</span><br><span class="line">  &#96;tenant_desc&#96; varchar(256) DEFAULT NULL COMMENT &#39;tenant_desc&#39;,</span><br><span class="line">  &#96;create_source&#96; varchar(32) DEFAULT NULL COMMENT &#39;create_source&#39;,</span><br><span class="line">  &#96;gmt_create&#96; bigint(20) NOT NULL COMMENT &#39;创建时间&#39;,</span><br><span class="line">  &#96;gmt_modified&#96; bigint(20) NOT NULL COMMENT &#39;修改时间&#39;,</span><br><span class="line">  PRIMARY KEY (&#96;id&#96;),</span><br><span class="line">  UNIQUE KEY &#96;uk_tenant_info_kptenantid&#96; (&#96;kp&#96;,&#96;tenant_id&#96;),</span><br><span class="line">  KEY &#96;idx_tenant_id&#96; (&#96;tenant_id&#96;)</span><br><span class="line">) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;utf8 COLLATE&#x3D;utf8_bin COMMENT&#x3D;&#39;tenant_info&#39;;</span><br><span class="line"></span><br><span class="line">CREATE TABLE &#96;users&#96; (</span><br><span class="line">&#96;username&#96; varchar(50) NOT NULL PRIMARY KEY,</span><br><span class="line">&#96;password&#96; varchar(500) NOT NULL,</span><br><span class="line">&#96;enabled&#96; boolean NOT NULL</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">CREATE TABLE &#96;roles&#96; (</span><br><span class="line">&#96;username&#96; varchar(50) NOT NULL,</span><br><span class="line">&#96;role&#96; varchar(50) NOT NULL,</span><br><span class="line">UNIQUE INDEX &#96;idx_user_role&#96; (&#96;username&#96; ASC, &#96;role&#96; ASC) USING BTREE</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">CREATE TABLE &#96;permissions&#96; (</span><br><span class="line">    &#96;role&#96; varchar(50) NOT NULL,</span><br><span class="line">    &#96;resource&#96; varchar(512) NOT NULL,</span><br><span class="line">    &#96;action&#96; varchar(8) NOT NULL,</span><br><span class="line">    UNIQUE INDEX &#96;uk_role_permission&#96; (&#96;role&#96;,&#96;resource&#96;,&#96;action&#96;) USING BTREE</span><br><span class="line">);</span><br><span class="line"></span><br><span class="line">INSERT INTO users (username, password, enabled) VALUES (&#39;nacos&#39;, &#39;$2a$10$EuWPZHzz32dJN7jexM34MOeYirDdFAZm2kuWj7VEOJhhZkDrxfvUu&#39;, TRUE);</span><br><span class="line"></span><br><span class="line">INSERT INTO roles (username, role) VALUES (&#39;nacos&#39;, &#39;ROLE_ADMIN&#39;);</span><br></pre></td></tr></table></figure><h2 id="nacos集群"><a href="#nacos集群" class="headerlink" title="nacos集群"></a>nacos集群</h2><table><thead><tr><th>服务器</th><th>IP</th></tr></thead><tbody><tr><td>nacos-01</td><td>172.31.26.14</td></tr><tr><td>nacos-02</td><td>172.31.26.15</td></tr><tr><td>nacos-03</td><td>172.31.26.16</td></tr></tbody></table><p>以下是每台节点都需要执行的操作</p><h3 id="安装java"><a href="#安装java" class="headerlink" title="安装java"></a>安装java</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install -y java-1.8.0-openjdk</span><br><span class="line">yum install -y java-devel</span><br></pre></td></tr></table></figure><h3 id="安装maven"><a href="#安装maven" class="headerlink" title="安装maven"></a>安装maven</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;opt</span><br><span class="line">wget https:&#x2F;&#x2F;mirrors.tuna.tsinghua.edu.cn&#x2F;apache&#x2F;maven&#x2F;maven-3&#x2F;3.6.3&#x2F;binaries&#x2F;apache-maven-3.6.3-bin.tar.gz</span><br><span class="line">tar -zxvf apache-maven-3.6.3-bin.tar.gz</span><br><span class="line">mv apache-maven-3.6.3 maven</span><br><span class="line"></span><br><span class="line">配置环境变量</span><br><span class="line">vi &#x2F;etc&#x2F;profile </span><br><span class="line">export M2_HOME&#x3D;&#x2F;opt&#x2F;maven                       </span><br><span class="line">export PATH&#x3D;$PATH:$JAVA_HOME&#x2F;bin:$M2_HOME&#x2F;bin</span><br><span class="line">修改完后source &#x2F;etc&#x2F;profile</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# mvn -v</span><br><span class="line">Apache Maven 3.6.3 (cecedd343002696d0abb50b32b541b8a6ba2883f)</span><br><span class="line">Maven home: &#x2F;opt&#x2F;maven</span><br><span class="line">Java version: 1.8.0_252, vendor: Oracle Corporation, runtime: &#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-1.8.0-openjdk-1.8.0.252.b09-2.el7_8.x86_64&#x2F;jre</span><br><span class="line">Default locale: en_US, platform encoding: UTF-8</span><br><span class="line">OS name: &quot;linux&quot;, version: &quot;5.3.11-1.el7.elrepo.x86_64&quot;, arch: &quot;amd64&quot;, family: &quot;unix&quot;</span><br></pre></td></tr></table></figure><h3 id="安装nacos"><a href="#安装nacos" class="headerlink" title="安装nacos"></a>安装nacos</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https:&#x2F;&#x2F;github.com&#x2F;alibaba&#x2F;nacos&#x2F;releases&#x2F;download&#x2F;1.1.3&#x2F;nacos-server-1.1.3.tar.gz</span><br><span class="line">tar -zxvf nacos-server-1.1.3.tar.gz</span><br></pre></td></tr></table></figure><h3 id="cluster-conf-配置"><a href="#cluster-conf-配置" class="headerlink" title="cluster.conf 配置"></a>cluster.conf 配置</h3><p>vim /opt/nacos/conf/cluster.conf </p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#添加集群信息</span><br><span class="line"># ip:port</span><br><span class="line">172.31.26.14:8848</span><br><span class="line">172.31.26.15:8848</span><br><span class="line">172.31.26.16:8848</span><br></pre></td></tr></table></figure><h3 id="application-properties-配置"><a href="#application-properties-配置" class="headerlink" title="application.properties 配置"></a>application.properties 配置</h3><p>vim /opt/nacos/conf/application.properties</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#添加数据库连接信息</span><br><span class="line">db.num&#x3D;1    </span><br><span class="line">db.url.0&#x3D;jdbc:mysql:&#x2F;&#x2F;172.31.26.13:3306&#x2F;nacos_config?characterEncoding&#x3D;utf8&amp;connectTimeout&#x3D;1000&amp;socketTimeout&#x3D;3000&amp;autoReconnect&#x3D;true</span><br><span class="line">db.user&#x3D;admin   </span><br><span class="line">db.password&#x3D;123456</span><br></pre></td></tr></table></figure><h3 id="启动集群"><a href="#启动集群" class="headerlink" title="启动集群"></a>启动集群</h3><p>进入每台nacos节点，启动</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# cd &#x2F;opt&#x2F;nacos&#x2F;bin</span><br><span class="line">[root@localhost bin]# sh startup.sh </span><br><span class="line">&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-1.8.0-openjdk-1.8.0.252.b09-2.el7_8.x86_64&#x2F;bin&#x2F;java  -server -Xms2g -Xmx2g -Xmn1g -XX:MetaspaceSize&#x3D;128m -XX:MaxMetaspaceSize&#x3D;320m -XX:-OmitStackTraceInFastThrow -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath&#x3D;&#x2F;opt&#x2F;nacos&#x2F;logs&#x2F;java_heapdump.hprof -XX:-UseLargePages -Djava.ext.dirs&#x3D;&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-1.8.0-openjdk-1.8.0.252.b09-2.el7_8.x86_64&#x2F;jre&#x2F;lib&#x2F;ext:&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;java-1.8.0-openjdk-1.8.0.252.b09-2.el7_8.x86_64&#x2F;lib&#x2F;ext:&#x2F;opt&#x2F;nacos&#x2F;plugins&#x2F;cmdb:&#x2F;opt&#x2F;nacos&#x2F;plugins&#x2F;mysql -Xloggc:&#x2F;opt&#x2F;nacos&#x2F;logs&#x2F;nacos_gc.log -verbose:gc -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles&#x3D;10 -XX:GCLogFileSize&#x3D;100M -Dnacos.home&#x3D;&#x2F;opt&#x2F;nacos -Dloader.path&#x3D;&#x2F;opt&#x2F;nacos&#x2F;plugins&#x2F;health -jar &#x2F;opt&#x2F;nacos&#x2F;target&#x2F;nacos-server.jar  --spring.config.location&#x3D;classpath:&#x2F;,classpath:&#x2F;config&#x2F;,file:.&#x2F;,file:.&#x2F;config&#x2F;,file:&#x2F;opt&#x2F;nacos&#x2F;conf&#x2F; --logging.config&#x3D;&#x2F;opt&#x2F;nacos&#x2F;conf&#x2F;nacos-logback.xml --server.max-http-header-size&#x3D;524288</span><br><span class="line">nacos is starting with cluster</span><br><span class="line">nacos is starting，you can check the &#x2F;opt&#x2F;nacos&#x2F;logs&#x2F;start.out</span><br></pre></td></tr></table></figure><h2 id="nginx-keepalived"><a href="#nginx-keepalived" class="headerlink" title="nginx+keepalived"></a>nginx+keepalived</h2><table><thead><tr><th>服务器</th><th>IP</th></tr></thead><tbody><tr><td>nginx+keepalived(主)</td><td>172.31.26.11</td></tr><tr><td>nginx+keepalived(备)</td><td>172.31.26.12</td></tr></tbody></table><p>以下是每台节点都需要执行的操作</p><h3 id="安装nginx"><a href="#安装nginx" class="headerlink" title="安装nginx"></a>安装nginx</h3><p>yum install epel-release -y<br>yum install nginx httpd-tools -y</p><h3 id="配置nginx"><a href="#配置nginx" class="headerlink" title="配置nginx"></a>配置nginx</h3><p>vim /etc/nginx/nginx.conf 添加下面的配置到http{}中</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">upstream nacos &#123;</span><br><span class="line">    #server nacos地址:端口号 </span><br><span class="line">    #weight表示权重   默认情况下为1。</span><br><span class="line">    #max_fails 设置在fail_timeout 参数设置的持续时间内应与服务器通信失败的尝试次数，以认为服务器在fail_timeout参数设置的持续时间内不可用 。</span><br><span class="line">    #fail_timeout 在指定次数的不成功尝试与服务器通信的时间内应该碰巧认为服务器不可用</span><br><span class="line">    server 172.31.26.14:8848 weight&#x3D;4 max_fails&#x3D;2 fail_timeout&#x3D;30s;   </span><br><span class="line">    server 172.31.26.15:8848 weight&#x3D;4 max_fails&#x3D;2 fail_timeout&#x3D;30s;</span><br><span class="line">    server 172.31.26.16:8848 weight&#x3D;4 max_fails&#x3D;2 fail_timeout&#x3D;30s;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line"> listen       80;</span><br><span class="line"> server_name  nacoscluster.com;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">location &#x2F; &#123;</span><br><span class="line">     proxy_pass http:&#x2F;&#x2F;nacos&#x2F; ;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="启动-关闭nginx"><a href="#启动-关闭nginx" class="headerlink" title="启动/关闭nginx"></a>启动/关闭nginx</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">nginx    启动</span><br><span class="line">nginx -s stop   关闭</span><br><span class="line">nginx -s reload 重启</span><br></pre></td></tr></table></figure><h3 id="安装keepalived"><a href="#安装keepalived" class="headerlink" title="安装keepalived"></a>安装keepalived</h3><p>yum install -y keepalived</p><h3 id="配置keepalived"><a href="#配置keepalived" class="headerlink" title="配置keepalived"></a>配置keepalived</h3><p>vim /etc/keepalived/keepalived.conf</p><p>主节点的配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line">global_defs &#123;</span><br><span class="line">   router_id nginx_master    # 设置nginx master的id，在一个网络应该是唯一的</span><br><span class="line">   script_user root</span><br><span class="line">   enable_script_security</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#VRRP脚本定义</span><br><span class="line">vrrp_script chk_nginx</span><br><span class="line">&#123;</span><br><span class="line">    script &quot;&#x2F;etc&#x2F;keepalived&#x2F;check_nginx.sh&quot;</span><br><span class="line">    interval 2</span><br><span class="line">    weight -2   #若脚本返回为1 则减这台机器keepalived的实时权重</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER            # 指定keepalived的角色，MASTER为主，BACKUP为备</span><br><span class="line">    interface ens192          # 当前进行vrrp通讯的网络接口卡(当前centos的网卡)</span><br><span class="line">    virtual_router_id 51    # 虚拟路由编号，主从要一致</span><br><span class="line">    priority 100         # 权重，数值越大，获取处理请求的优先级越高</span><br><span class="line">    unicast_src_ip  172.31.26.51   #本机ip</span><br><span class="line">    unicast_peer &#123;</span><br><span class="line">        172.31.26.52      #对端ip</span><br><span class="line">    &#125;</span><br><span class="line">    advert_int 1            # 检查间隔，默认为1s(vrrp组播周期秒数)</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">         chk_nginx</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">       172.31.26.200</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>备用节点的配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">global_defs &#123;</span><br><span class="line">   router_id nginx_backup</span><br><span class="line">   script_user root</span><br><span class="line">   enable_script_security</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">#VRRP脚本定义</span><br><span class="line">vrrp_script chk_nginx</span><br><span class="line">&#123;</span><br><span class="line">    script &quot;&#x2F;etc&#x2F;keepalived&#x2F;check_nginx.sh&quot;</span><br><span class="line">    interval 2</span><br><span class="line">    weight -2    </span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface ens192</span><br><span class="line">    virtual_router_id 51</span><br><span class="line">    priority 99    #权重要比主节点低</span><br><span class="line">    unicast_src_ip  172.31.26.52   #本机ip</span><br><span class="line">    unicast_peer &#123;</span><br><span class="line">        172.31.26.51      #对端ip</span><br><span class="line">    &#125;</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">         chk_nginx</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        172.31.26.200</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>写nginx监控检查脚本，放到/etc/keepalived目录下</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cd &#x2F;etc&#x2F;keepalived</span><br><span class="line">vim check_nginx.sh</span><br><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">A&#x3D;&#96;ps -C nginx --no-header |wc -l&#96;  #检查nginx进程是否存在</span><br><span class="line">if [ $A -eq 0 ];then</span><br><span class="line">    &#x2F;usr&#x2F;sbin&#x2F;nginx                #重启nginx</span><br><span class="line">    echo &quot;1&quot;</span><br><span class="line">    if [ &#96;ps -C nginx --no-header |wc -l&#96; -eq 0 ];then    #nginx重启失败</span><br><span class="line">        exit 1</span><br><span class="line">    else</span><br><span class="line">        exit 0</span><br><span class="line">    fi</span><br><span class="line">else</span><br><span class="line">    exit 0</span><br><span class="line">fi</span><br></pre></td></tr></table></figure><p>写完后记得加可执行的权限,脚本监控nginx进程，如果不存在则重启，如果重启失败则返回1,keepalived配置文件通过返回值为1可以实时减2点keepalived的权重，若主机的实时权重低于备用机，则触发VIP切换，由备用机代理VIP。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod +x check_nginx.sh</span><br></pre></td></tr></table></figure><p>验证脚本是否可行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh  check_nginx.sh</span><br></pre></td></tr></table></figure><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/SLB/keepalived_check.jpg"  alt="keepalived_check.jpg"></p><p>nginx进程不存在则重启，验证成功</p><h3 id="启动keepalived"><a href="#启动keepalived" class="headerlink" title="启动keepalived"></a>启动keepalived</h3><p>systemctl start keepalived</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">主节点</span><br><span class="line">[root@localhost nginx]# ip add</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link&#x2F;loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1&#x2F;8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1&#x2F;128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens192: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000</span><br><span class="line">    link&#x2F;ether 00:50:56:99:10:75 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.31.26.51&#x2F;24 brd 172.31.26.255 scope global noprefixroute ens192</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet 172.31.26.200&#x2F;32 scope global ens192</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">       </span><br><span class="line">备用节点</span><br><span class="line">[root@localhost nginx]# ip add</span><br><span class="line">1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000</span><br><span class="line">    link&#x2F;loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00</span><br><span class="line">    inet 127.0.0.1&#x2F;8 scope host lo</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet6 ::1&#x2F;128 scope host </span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">2: ens192: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000</span><br><span class="line">    link&#x2F;ether 00:50:56:99:84:51 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.31.26.52&#x2F;24 brd 172.31.26.255 scope global noprefixroute ens192</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br></pre></td></tr></table></figure><p>主节点会生成虚拟ip172.31.26.200 而备用节点不会生成172.31.26.200</p><h2 id="域名映射"><a href="#域名映射" class="headerlink" title="域名映射"></a>域名映射</h2><p>将nacoscluster.com映射到172.31.26.200上</p><p>将nacoscluster.com的请求都转发到下面的3台服务器上，</p><h1 id="验证"><a href="#验证" class="headerlink" title="验证"></a>验证</h1><h2 id="访问页面"><a href="#访问页面" class="headerlink" title="访问页面"></a>访问页面</h2><p>访问页面 <a href="http://www.nacoscluster.com/nacos" target="_blank" rel="noopener">www.nacoscluster.com/nacos</a> 可以正常打开页面说明高可用集群配置完成</p><p>接下来开始验证这个集群是否真的高可用</p><h2 id="程序循环读取nacos中的配置文件"><a href="#程序循环读取nacos中的配置文件" class="headerlink" title="程序循环读取nacos中的配置文件"></a>程序循环读取nacos中的配置文件</h2><p>读取操作由我和lilu.org.cn的博主及xiongyj.cn的博主合作一起将这个实验做完，在此感谢他们。</p><h2 id="关闭主机nginx"><a href="#关闭主机nginx" class="headerlink" title="关闭主机nginx"></a>关闭主机nginx</h2><p>注意，为了方便测试keepalived的实时权重增减，在这里先修改脚本<br>check_nginx.sh，注释这一行，否则nginx重启看不到VIP漂移的效果。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;usr&#x2F;sbin&#x2F;nginx                #重启nginx</span><br></pre></td></tr></table></figure><p>主机执行关闭nginx</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost keepalived]# nginx -s stop</span><br></pre></td></tr></table></figure><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/SLB/keepalived_nginx_down.jpg"  alt="keepalived_nginx_down.jpg"><br>主机 </p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/SLB/keepalived_nginx_up.jpg"  alt="keepalived_nginx_uo.jpg"><br>备用机</p><p>由图可以看出，主机nginx挂掉后，权重由100-2=98 低于备用机的99 VIP切换。</p><p>程序循环读取数据成功</p><h2 id="关闭主机keepalived"><a href="#关闭主机keepalived" class="headerlink" title="关闭主机keepalived"></a>关闭主机keepalived</h2><p>主机执行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost keepalived]# systemctl stop keepalived</span><br></pre></td></tr></table></figure><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/SLB/keepalived_down.jpg"  alt="keepalived_down.jpg"><br>主机 </p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/SLB/keepalived_up.jpg"  alt="keepalived_up.jpg"><br>备用机</p><p>由图可以看出，主机keepailived关闭服务后，VIP直接切换到备用机</p><p>程序循环读取数据成功</p><h2 id="关闭nacos"><a href="#关闭nacos" class="headerlink" title="关闭nacos"></a>关闭nacos</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost bin]# sh shutdown.sh</span><br><span class="line">The nacosServer(36354) is running...</span><br><span class="line">Send shutdown request to nacosServer(36354) OK</span><br></pre></td></tr></table></figure><p>访问<a href="http://www.nacoscluster.com/nacos仍然可以打开，说明nginx反向代理没问题" target="_blank" rel="noopener">www.nacoscluster.com/nacos仍然可以打开，说明nginx反向代理没问题</a></p><p>程序循环读取数据成功</p><h1 id="结束"><a href="#结束" class="headerlink" title="结束"></a>结束</h1><p>至此，keepalived+nginx+nacos+mysql高可用集群搭建完成，实战中还是查询了许多文档，不懂就问度娘，踩过好多坑，还有意外的收获（详情见总结）。</p><p>补充几点此集群搭建的不足之处，如果觉得建议好可以按照我的思路做下去：</p><ul><li>mysql若是放在生产环境建议主备集群搭建，本篇图简单没有这么做</li><li>nignx的轮询算法本篇用的加权轮询，实际上根据nacos的服务器性能差异可以采用其他的负载均衡调度算法，本篇nacos服务器配置均等，所以加权无所谓。</li></ul><h1 id="报错总结"><a href="#报错总结" class="headerlink" title="报错总结"></a>报错总结</h1><h2 id="keepalived主从切换失败"><a href="#keepalived主从切换失败" class="headerlink" title="keepalived主从切换失败"></a>keepalived主从切换失败</h2><p>如果两节点的上联交换机禁用了组播，则只能采用vrrp单播通告的方式。需要在vrrp_instance VI_1 {}中添加</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">主节点</span><br><span class="line">unicast_src_ip  172.31.26.51   #本机ip</span><br><span class="line">unicast_peer &#123;</span><br><span class="line">    172.31.26.52      #对端ip</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">备用节点</span><br><span class="line">unicast_src_ip  172.31.26.52   #本机ip</span><br><span class="line">unicast_peer &#123;</span><br><span class="line">    172.31.26.51      #对端ip</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="keepalived从主节点切换成备用节点后，vip已经生成到备用节点上，但是却不能访问"><a href="#keepalived从主节点切换成备用节点后，vip已经生成到备用节点上，但是却不能访问" class="headerlink" title="keepalived从主节点切换成备用节点后，vip已经生成到备用节点上，但是却不能访问"></a>keepalived从主节点切换成备用节点后，vip已经生成到备用节点上，但是却不能访问</h2><p>跟踪iptables规则发现，默认的iptables规则仅允许22端口和icmp报文通过，需要删除规则</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost keepalived ~]# iptables -F #删除所有iptables规则</span><br><span class="line">[root@localhost keepalived ~]# iptables -X #删除除默认链之外的所有iptables链</span><br></pre></td></tr></table></figure><h2 id="关闭Linux防火墙Selinux和firewalld"><a href="#关闭Linux防火墙Selinux和firewalld" class="headerlink" title="关闭Linux防火墙Selinux和firewalld"></a>关闭Linux防火墙Selinux和firewalld</h2><p>systemctl stop firewalld<br>systemctl disable firewalld<br>setenforce 0<br>sed -i “s/SELINUX=enforcing/SELINUX=disabled/g” /etc/selinux/config </p><h2 id="nacos"><a href="#nacos" class="headerlink" title="nacos"></a>nacos</h2><p>1.中途出现nacos用域名连接失败的情况</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">spring:</span><br><span class="line">  application:</span><br><span class="line">    name: lilu</span><br><span class="line">  profiles:</span><br><span class="line">    active: dev</span><br><span class="line">  cloud:</span><br><span class="line">    nacos:</span><br><span class="line">      config:</span><br><span class="line">        server-addr: nacoscluster.com</span><br></pre></td></tr></table></figure><p>查询资料才知道地址必须为nacoscluster.com+端口<br>也就是 nacoscluster.com:80</p><p>2.我将后台nacos全部断掉连接后，他们的程序调用nacos仍然有返回值，经Debug后发现请求超时，但是还是能传回来值，而且这个值一直不更新。我们几个百思不得其解，关了ide、关了服务器都不行，一个连接不上nacos的程序居然能有返回，经xiongyj.cn的博主查看源代码发现，nacos有备份策略。</p><p>由于我不是学java的，具体源码就不展开说了，大概意思就是nacos每读取一次配置后就保留到本地，当程序还是通过相同的nacos地址去读取配置的时候，即使连接不上，但是不会报连接失败的错误，而是会从本地去读最后一次连接时的配置文件。</p><p>这样一来，如果你只把nacos当配置中心，即使nacos集群都挂掉了，也不会影响服务，当然，如果你把nacos当注册中心的话那还是会有影响。</p><p>壮哉我大阿里，nacos这个中间件设计的真心高可用，考虑太周全了。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://nacos.io/zh-cn/docs/cluster-mode-quick-start.html" target="_blank" rel="noopener">nacos官网</a></p><p><a href="https://blog.51cto.com/13599730/2161622" target="_blank" rel="noopener">keepalived主备节点都配置vip，vip切换异常案例分析</a></p><p><a href="https://www.cnblogs.com/netonline/p/7642595.html" target="_blank" rel="noopener">Keepalived两节点出现双VIP的情况</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> SLB </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nacos </tag>
            
            <tag> SLB </tag>
            
            <tag> 负载均衡 </tag>
            
            <tag> Keepalived </tag>
            
            <tag> HA </tag>
            
            <tag> Cluster </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Mongodb3.4离线升级到4.2</title>
      <link href="2020/05/12/mongodb/mongodb-update/"/>
      <url>2020/05/12/mongodb/mongodb-update/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>生产环境使用的mongodb用的是4.2，线下开发测试环境一直用的是3.4，有需求要用到mongodb的新特性，准备开始升级。</p><h1 id="调查"><a href="#调查" class="headerlink" title="调查"></a>调查</h1><p>由于是线下环境的升级，所以暂时关闭mongodb没有影响，如果是生产环境在线升级建议找下其他文档。</p><h2 id="直接升级"><a href="#直接升级" class="headerlink" title="直接升级"></a>直接升级</h2><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Mongodb/mongodb-update.jpg"  alt="mongodb-update.jpg"></p><p>官方说明服务升级需要上一个特定版本</p><p>如果按照官方来做，我需要先升级3.4到3.6 再从3.6升级到4.0 最后从4.0升级到4.2 </p><p>emmmmmm，人傻了</p><h2 id="删除重装"><a href="#删除重装" class="headerlink" title="删除重装"></a>删除重装</h2><p>调研了网上的文档，没找到用这种方式去升级的例子，但是感觉问题不大。</p><h1 id="备份重装"><a href="#备份重装" class="headerlink" title="备份重装"></a>备份重装</h1><h2 id="备份"><a href="#备份" class="headerlink" title="备份"></a>备份</h2><p>注意 mongodump并且不能作为正在进行分片事务的4.2+分片群集的备份策略的一部分，因为使用创建的备份 不能保持分片事务的原子性保证。</p><p>由于应用中不涉及mongodb事务，所以使用mongodump/mongorestore直接全库导入导出即可。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">导出</span><br><span class="line">mongodump -h IP --port 端口 -u 用户名 -p 密码 -d 数据库 -o 文件存在路径 </span><br><span class="line">导入</span><br><span class="line">mongorestore -h IP --port 端口 -u 用户名 -p 密码 -d 数据库 --drop 文件存在路径</span><br></pre></td></tr></table></figure><p>如果想导出所有数据库，可以去掉-d</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@dev-data-01 mongodb]# pwd</span><br><span class="line">&#x2F;root&#x2F;mongodb</span><br><span class="line">[root@dev-data-01 mongodb]# mongodump -h 127.0.0.1 --port 27017 -uroot -p123456 -o &#x2F;root&#x2F;mongodb&#x2F;</span><br><span class="line">[root@dev-data-01 mongodb]# ll</span><br><span class="line">total 8</span><br><span class="line">drwxr-xr-x. 2 root root 4096 May 12 15:13 admin</span><br><span class="line">drwxr-xr-x. 2 root root   98 May 12 15:13 mercury</span><br><span class="line">drwxr-xr-x. 2 root root 4096 May 12 15:13 xc_cms</span><br></pre></td></tr></table></figure><p>这样就导出来了</p><h2 id="重装"><a href="#重装" class="headerlink" title="重装"></a>重装</h2><p>重装我踩过很多坑，但是都在一个博客中找到了所有的报错解决方案，写的比较全面，详情请看参考资料</p><p>我用的是yum安装，如果是用二进制包安装的思路也一样</p><p>1.停止mongodb服务</p><p>2.卸载mongodb及日志、数据等</p><p>3.重装新的mongodb</p><h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop mongod</span><br><span class="line">yum erase $(rpm -qa | grep mongodb-org)  #卸载</span><br><span class="line">rm -rf &#x2F;var&#x2F;log&#x2F;mongodb   #删除日志</span><br><span class="line">rm -rf &#x2F;var&#x2F;lib&#x2F;mongo     #删除数据</span><br><span class="line">rm -rf &#x2F;etc&#x2F;yum.repos.d&#x2F;mongodb-org-3.4.repo #删除原mongodb的yum源</span><br></pre></td></tr></table></figure><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">添加yum源</span><br><span class="line">vim &#x2F;etc&#x2F;yum.repos.d&#x2F;mongodb-org-4.2.repo</span><br><span class="line"></span><br><span class="line">[mongodb-org-4.2]</span><br><span class="line">name&#x3D;MongoDB Repository</span><br><span class="line">baseurl&#x3D;https:&#x2F;&#x2F;repo.mongodb.org&#x2F;yum&#x2F;redhat&#x2F;$releasever&#x2F;mongodb-org&#x2F;4.2&#x2F;x86_64&#x2F;</span><br><span class="line">gpgcheck&#x3D;1</span><br><span class="line">enabled&#x3D;1</span><br><span class="line">gpgkey&#x3D;https:&#x2F;&#x2F;www.mongodb.org&#x2F;static&#x2F;pgp&#x2F;server-4.2.asc</span><br><span class="line"></span><br><span class="line">安装</span><br><span class="line">yum install mongodb-org -y</span><br><span class="line"></span><br><span class="line">配置</span><br><span class="line">vim &#x2F;etc&#x2F;mongod.conf</span><br><span class="line">将bindIp: 127.0.0.1改成bindIp: 0.0.0.0 </span><br><span class="line"></span><br><span class="line">启动</span><br><span class="line">systemctl start mongod</span><br><span class="line"></span><br><span class="line">查看状态</span><br><span class="line">systemctl status mongod</span><br></pre></td></tr></table></figure><h3 id="导入"><a href="#导入" class="headerlink" title="导入"></a>导入</h3><p>注意！ 在导入数据前不要开启安全认证，否则可能出现权限不足等问题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@dev-data-01 mongodb]# mongorestore &#x2F;root&#x2F;mongodb&#x2F;</span><br><span class="line"></span><br><span class="line">修改配置文件，开启密码验证</span><br><span class="line">vim &#x2F;etc&#x2F;mongod.conf</span><br><span class="line"></span><br><span class="line">security:</span><br><span class="line">       authorization: enabled</span><br><span class="line">       </span><br><span class="line">重启mongodb</span><br><span class="line">systemctl restart mongod</span><br></pre></td></tr></table></figure><p>至此，mongodb升级完成<del>~</del></p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://www.jb51.net/article/109091.htm" target="_blank" rel="noopener">Mongodb常见错误与解决方法小结(Mongodb中经常出现的错误)</a></p><p><a href="https://docs.mongodb.com/manual/core/backups/" target="_blank" rel="noopener">Mongodb官方备份命令</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Mongodb </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mongodb </tag>
            
            <tag> 数据备份 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浅谈高可用的负载均衡集群实现原理及方案</title>
      <link href="2020/05/11/slb/slb-ha/"/>
      <url>2020/05/11/slb/slb-ha/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><p>现在很多企业的应用都上云了，利用各种云平台的负载均衡组件，可以通过流量分发扩展应用系统对外的服务能力，通过消除单点故障提升应用系统的可用性。下面就来聊聊最常用的互联网高可用的负载均衡集群实现方案。</p><h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><p>在介绍架构之前，为了避免部分读者对架构设计中的一些概念不了解，下面对几个最基础的概念进行介绍。</p><h2 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h2><p>负载均衡建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。</p><p>当请求发送到系统时，通过某些方式把请求均匀分发到多个节点上，使系统中每个节点能够均匀的处理请求负载，则可认为系统是负载均衡的。</p><h2 id="高可用"><a href="#高可用" class="headerlink" title="高可用"></a>高可用</h2><p>系统中部分节点失效时，其他节点能够接替它继续提供服务，则可认为系统具有高可用性。</p><h2 id="集群和分布式"><a href="#集群和分布式" class="headerlink" title="集群和分布式"></a>集群和分布式</h2><p>两者很类似，但是却有区别。</p><ul><li><p>集群：将几台服务器集中在一起，实在同一个业务。</p></li><li><p>分布式：指将不同的业务分布到不同的地方。</p></li></ul><p>分布式的每一个节点，都可以用来做集群。而集群不一定就是分布式了。</p><p>例如：zk 1主2从 整体是集群 业务是注册中心 但是主节点和2个从节点是分布式系统 处理不同的问题</p><h1 id="实现负载均衡的组件及原理"><a href="#实现负载均衡的组件及原理" class="headerlink" title="实现负载均衡的组件及原理"></a>实现负载均衡的组件及原理</h1><p>现在网络中常见的的负载均衡主要分为两种：</p><ul><li><p>硬件：常见的硬件有比较昂贵的NetScaler、F5、Radware和Array等商用的负载均衡器，不过商用负载均衡由于可以建立在四~七层协议之上，因此适用面更广所以有其不可替代性，</p><pre><code>他的优点就是有专业的维护团队来对这些服务进行维护、缺点就是花销太大，所以对于规模较小的网络服务来说暂时还没有需要使用。</code></pre></li><li><p>软件：比较常见的有LVS、Nginx、HAproxy等，</p><pre><code>其中LVS是建立在四层协议上面的，而另外Nginx和HAproxy是建立在七层协议之上的</code></pre></li></ul><p>本文主要讲解如何通过软件实现负载均衡。</p><h2 id="组件特点"><a href="#组件特点" class="headerlink" title="组件特点"></a>组件特点</h2><h3 id="nginx"><a href="#nginx" class="headerlink" title="nginx"></a>nginx</h3><ul><li>工作在网络的7层之上，可以针对http应用做一些分流的策略，比如针对域名、目录结构</li><li>Nginx对网络的依赖比较小</li><li>Nginx安装和配置比较简单，测试起来比较方便</li><li>也可以承担高的负载压力且稳定，一般能支撑超过1万次的并发</li><li>Nginx可以通过端口检测到服务器内部的故障，比如根据服务器处理网页返回的状态码、超时等等，并且会把返回错误的请求重新提交到另一个节点，不过其中缺点就是不支持url来检测；</li><li>Nginx对请求的异步处理可以帮助节点服务器减轻负载；</li><li>Nginx能支持http和Email，这样就在适用范围上面小很多；</li><li>不支持Session的保持、对Big request，header的支持不是很好，另外默认的只有Round-robin和IP-hash两种负载均衡算法。</li></ul><h3 id="lvs"><a href="#lvs" class="headerlink" title="lvs"></a>lvs</h3><ul><li>抗负载能力强、是工作在网络4层之上仅作分发之用，没有流量的产生；</li><li>配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率；</li><li>工作稳定，自身有完整的双机热备方案；</li><li>无流量，保证了均衡器IO的性能不会收到大流量的影响；</li><li>应用范围比较广，可以对所有应用做负载均衡；</li><li>LVS需要向IDC多申请一个IP来做Visual IP，因此需要一定的网络知识，所以对操作人的要求比较高。</li></ul><h3 id="HAProxy"><a href="#HAProxy" class="headerlink" title="HAProxy"></a>HAProxy</h3><ul><li>HAProxy是工作在网络7层之上。</li><li>能够补充Nginx的一些缺点比如Session的保持，Cookie的引导等工作</li><li>支持url检测后端的服务器出问题的检测会有很好的帮助。</li><li>更多的负载均衡策略比如：动态加权轮循(Dynamic Round Robin)，加权源地址哈希(Weighted Source Hash)，加权URL哈希和加权参数哈希(Weighted Parameter Hash)已经实现</li><li>单纯从效率上来讲HAProxy更会比Nginx有更出色的负载均衡速度。</li><li>HAProxy可以对Mysql进行负载均衡，对后端的DB节点进行检测和负载均衡。</li></ul><h3 id="traefik"><a href="#traefik" class="headerlink" title="traefik"></a>traefik</h3><ul><li>Golang编写，单文件部署，与系统无关，同时也提供小尺寸Docker镜像。</li><li>支持Docker/Etcd后端，天然连接我们的微服务集群。</li><li>内置Web UI，管理相对方便。</li><li>自动配置ACME(Let’s Encrypt)证书功能。</li><li>性能尚可，我们也没有到压榨LB性能的阶段，易用性更重要。</li><li>Restful API支持。</li><li>支持后端健康状态检查，根据状态自动配置。</li><li>支持WebSocket和HTTP/2。</li><li>traefik近几年火起来最重要的原因之一就是能够与常见的微服务系统直接整合，可以实现自动化动态配置。</li></ul><p>下面用一图说明traefik的特点<br><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/SLB/traefik.jpg"  alt="traefik.jpg"></p><h2 id="主流算法"><a href="#主流算法" class="headerlink" title="主流算法"></a>主流算法</h2><ul><li>轮询调度(Round Robin 简称’RR’) 就是按依次循环的方式将请求调度到不同的服务器上，该算法最大的特点就是实现简单。轮询算法假设所有的服务器处理请求的能力都一样的，调度器会将所有的请求平均分配给每个真实服务器。</li><li>加权轮询(Weight Round Robin 简称’WRR’) 主要是对轮询算法的一种优化与补充，传入的请求按顺序被分配到集群中服务器，但是会考虑提前为每台服务器分配的权重。例如，能力最强的服务器A给的权重是100，同时能力最低的服务器给的权重是50。这意味着在服务器B接收到第一个 请求之前前，服务器A会连续的接受到2个请求，以此类推。</li><li>随机（Random）<br>通过系统的随机算法，根据后端服务器的列表大小值来随机选取其中的一台服务器进行访问。基于概率统计的理论，吞吐量越大，随机算法的效果越接近于轮询算法的效果。</li><li>加权随机（Weight Random）<br>与加权轮询法一样，加权随机法也根据后端机器的配置，系统的负载分配不同的权重。不同的是，它是按照权重随机请求后端服务器，而非顺序。</li><li>最少连接数(Least Connection)<br>以上两种方法都没有考虑的是系统不能识别在给定的时间里保持了多少连接。最小连接数算法比较灵活和智能，由于后端服务器的配置不尽相同，对于请求的处理有快有慢，它是根据后端服务器当前的连接情况，动态地选取其中当前积压连接数最少的一台服务器来处理当前的请求，尽可能地提高后端服务的利用效率，将负责合理地分流到每一台服务器。</li><li>源IP哈希(Source IP Hash) 源地址哈希的思想是根据获取客户端的IP地址，通过哈希函数计算得到的一个数值，用该数值对服务器列表的大小进行取模运算，得到的结果便是客户端要访问服务器的序号。</li></ul><h1 id="增强负载均衡器可用性（HA）"><a href="#增强负载均衡器可用性（HA）" class="headerlink" title="增强负载均衡器可用性（HA）"></a>增强负载均衡器可用性（HA）</h1><h2 id="什么是keepalived"><a href="#什么是keepalived" class="headerlink" title="什么是keepalived"></a>什么是keepalived</h2><p>Keepalived是用C语言编写的路由软件。该项目的主要目标是为Linux系统和基于Linux的基础结构提供负载均衡和高可用性的简单而强大的功能。Keepalived实现了一组检查器，以根据其运行状况动态，自适应地维护和管理负载平衡的服务器池。另一方面，VRRP实现了高可用性协议。VRRP是路由器故障转移的基础砖。此外，Keepalived还实现了一组VRRP有限状态机的挂钩，从而提供了低级和高速协议交互。</p><h2 id="VRRP协议"><a href="#VRRP协议" class="headerlink" title="VRRP协议"></a>VRRP协议</h2><p>虚拟路由器冗余协议（Virtual Router Redundancy Protocol ）</p><p>VRRP是一种选择协议，它可以把一个虚拟路由器的责任动态分配到局域网上的 VRRP 路由器中的一台。控制虚拟路由器 IP 地址的 VRRP 路由器称为主路由器，它负责转发数据包到这些虚拟 IP 地址。</p><h2 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h2><p>keepalived也是模块化设计，不同模块复杂不同的功能，下面是keepalived的组件</p><p>core check vrrp libipfwc libipvs-2.4 libipvs-2.6</p><ul><li>core：是keepalived的核心，复杂主进程的启动和维护，全局配置文件的加载解析等</li><li>check：负责healthchecker(健康检查)，包括了各种健康检查方式，以及对应的配置的解析包括LVS的配置解析</li><li>vrrp：VRRPD子进程，VRRPD子进程就是来实现VRRP协议的</li><li>libipfwc：iptables(ipchains)库，配置LVS会用到</li><li>libipvs*：配置LVS会用到</li></ul><p>keepalived启动后会有三个进程<br>父进程：内存管理，子进程管理等等<br>子进程：VRRP子进程<br>子进程：healthcheckers子进程</p><h1 id="设计nginx-keepalived-nacos-mysql实现配置及注册中心高可用框架"><a href="#设计nginx-keepalived-nacos-mysql实现配置及注册中心高可用框架" class="headerlink" title="设计nginx+keepalived+nacos+mysql实现配置及注册中心高可用框架"></a>设计nginx+keepalived+nacos+mysql实现配置及注册中心高可用框架</h1><p>本文设计的框架是基于nacos官方文档针对生产环境的nacos搭建的补充。</p><p>naocs框架为<br><a href="http://nacos.com:port/openAPI">http://nacos.com:port/openAPI</a> 域名 + VIP模式，可读性好，而且换ip方便</p><p>nginx作为负载均衡器，keepalived保证nginx的高可用</p><p>具体实现如图<br><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/SLB/nacos_ha.jpg"  alt="nacos_ha.jpg"></p><p>本期不做部署说明，下期具体说明如何在实战中部署此架构。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="http://thesecretlivesofdata.com/raft/" target="_blank" rel="noopener">分布式共识算法图解</a></p><p><a href="https://blog.csdn.net/cc1949/article/details/79063439" target="_blank" rel="noopener">网络7层协议图解</a></p><p><a href="https://blog.csdn.net/liuxl57805678/article/details/103033268" target="_blank" rel="noopener">淘宝双11，亿级流量高并发是怎么抗住的？看完这篇你就明白了!</a></p><p><a href="https://blog.csdn.net/selina361/article/details/79949689?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-2.nonecase" target="_blank" rel="noopener">几种常见负载均衡比较</a></p><p><a href="https://www.keepalived.org/" target="_blank" rel="noopener">keepalived官网</a></p><p><a href="https://nacos.io/zh-cn/docs/cluster-mode-quick-start.html" target="_blank" rel="noopener">nacos官网</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> SLB </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Nacos </tag>
            
            <tag> SLB </tag>
            
            <tag> 负载均衡 </tag>
            
            <tag> Keepalived </tag>
            
            <tag> HA </tag>
            
            <tag> Cluster </tag>
            
            <tag> 调度算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>顶级理解之游戏人生（DNF篇）</title>
      <link href="2020/05/09/king/king-dnf/"/>
      <url>2020/05/09/king/king-dnf/</url>
      
        <content type="html"><![CDATA[<blockquote><p>   当一个人拥有了顶级理解，那么他就没有任何烦恼。   - 宇神之息  </p></blockquote><p>声明: 顶级理解系列全部是本人的主观看法，望不喜勿喷，求同存异。</p><hr><p>本文分享了宇神之息在DNF里的经历，映射一个人的成长经历。</p><p>开局先声明我的DNF游戏年龄，10年，2009-2019。</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/King/dnf.png"  alt="dnf.png"></p><p>没从头入坑，也没能等到关服就离开。</p><h1 id="游戏阶段"><a href="#游戏阶段" class="headerlink" title="游戏阶段"></a>游戏阶段</h1><p>我玩dnf可以分为3个阶段</p><ul><li>开心阶段</li><li>奋斗阶段</li><li>疲累阶段</li></ul><p>如果你对dnf不感兴趣，可以直接跳过这几个阶段，直奔结论。。。</p><h2 id="开心阶段"><a href="#开心阶段" class="headerlink" title="开心阶段"></a>开心阶段</h2><p>开始阶段我认为最极致的游戏，最纯粹的享受玩游戏的过程。</p><p>这个阶段应该都是老玩家才有的体验，对于2018年后入坑的玩家们可能感受不到。</p><p>60-85版本的乐趣在于，打怪升级、爆装备、师徒关系、成就感等等。</p><ul><li>那个时代满级比较难，不和现在一样，随便创新号到满级一天就可以完成。</li><li>装备的爆率低，ss更是难得有一件，因为深渊都打不赢，能出紫套装、粉装都可以高兴很久很久，纯粹的快乐</li><li>拜师带人刷图，50多级的带30多级的刷图打不过也很正常，怪物血量高，伤害高，不像现在秒秒秒。</li><li>那时候的DNF完成这些事最大的乐趣就是获得成就感，是其他街机游戏所不能比拟的</li></ul><h2 id="奋斗阶段"><a href="#奋斗阶段" class="headerlink" title="奋斗阶段"></a>奋斗阶段</h2><p>奋斗阶段得从我大学室友罗某拉我回坑说起了，当时刚刚安图恩副本已经开了一年多了，但是由于ss没有普及，即使过了一年，能打团本的人仍然很少。我从这个时候开始打造自己已经脱坑4年的号，从异界打起，我的瞎子开始做暗影九，打舰炮；做假猪6，守震颤；那一年春节，买一套年套，有了年宠，开始打擎天；到后面刷深渊终于集齐魔战套，开始打火山。等到卢克副本开了后，我就成为第一批开荒人员，打了一年副本毕业。</p><hr><p>开始<br><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/King/kaihuang.png"  alt="kaihuang.png"><br>结束<br><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/King/luke.png"  alt="luke.png"></p><hr><p>就和我说说里一样，一年的时间卢克全勤，一次不漏，因为我热爱这个游戏，所以我能坚持下来。</p><h2 id="疲累阶段"><a href="#疲累阶段" class="headerlink" title="疲累阶段"></a>疲累阶段</h2><p>从95级开始，超时空漩涡、伊西斯副本，策划似乎已经觉得dnf模式就是如此了，打团本，升级装备，再出新团本，再升级新装备。一直如此的模式导致dnf玩家流逝的越来越多，因为副本不再像以前那么难，甚至到了一出大副本当天就有金团（花钱，带人的团）出现。</p><p>而且以前投入少，收获多，现在投入多，收获少。说个很简单的道理，马服特色：用薪创造游戏，没钱玩个毛。<br><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/King/chongqian.jpg"  alt="chongqian.jpg"></p><ul><li><p>以前投入基本上只有时间，充钱只是次要的，你就可以愉快的游戏，刷图，pk，充分体验游戏乐趣</p></li><li><p>现在你不仅要肝，更要氪，不然团本没人要你，pk你装备垃圾，技术再好也很容易一个失误就直接被人一个技能秒了（旭旭宝宝大蹦秒人），再拿出乌龟卢克时期很流行的一幅图。</p></li></ul><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/King/jiaban.jpg"  alt="jiaban.jpg"></p><h1 id="一叶知秋"><a href="#一叶知秋" class="headerlink" title="一叶知秋"></a>一叶知秋</h1><p>阿拉德大陆也可以是现实某一部分的映射。</p><h2 id="阶段"><a href="#阶段" class="headerlink" title="阶段"></a>阶段</h2><p>在dnf里的团本时期分为4个阶段：开荒团、稳定团、流水团、金团。</p><p>这个和现实中某一行业的发展时期很像，多的也不扯，就拿互联网行业来说。</p><h3 id="开荒阶段："><a href="#开荒阶段：" class="headerlink" title="开荒阶段："></a>开荒阶段：</h3><ul><li>dnf：所有成员打造最顶尖装备，练习不同职业的手法到极致，学习副本的机制</li><li>互联网：最好的大学的学生，学习互联网知识，把国外最顶尖的技术引回国内</li></ul><p>当开荒成功后，这一领域的人们集合起来创立了不同的团队、公司，有大有小，良莠不齐。</p><h3 id="稳定阶段："><a href="#稳定阶段：" class="headerlink" title="稳定阶段："></a>稳定阶段：</h3><ul><li>dnf：为了将团队扩展大，团本开始大面积招人，让自己的小号也能划水。</li><li>互联网：最早的一批创业者创业稳定后，开始大面积招揽人才为自己打工，这也是目前互联网的现状。</li></ul><h3 id="流水阶段："><a href="#流水阶段：" class="headerlink" title="流水阶段："></a>流水阶段：</h3><ul><li>dnf：团队扩大到一定地步后，由于人太多了，需要选几个团长，每个团长都开团若干个小时，甚至同时开多个团本，由于团队很大，打团不怕没人来，骗奶骗c，自己划水的现象比比皆是。</li><li>互联网：企业越扩越大，开始成立分公司，让开荒的人都当老板，典型的BAT，而且名声大，不怕没人来。</li></ul><h3 id="金团："><a href="#金团：" class="headerlink" title="金团："></a>金团：</h3><ul><li>dnf：金团就是互联网的培训机构，比如某马程序员，为了能达到进入这些领域的门槛，你需要花钱来过图/学习。</li></ul><h2 id="门槛"><a href="#门槛" class="headerlink" title="门槛"></a>门槛</h2><p>阶段说清楚了后，再说门槛问题。我的理解：门槛就是你进入某一行业的最低标准。</p><p>dnf的团本发展都以流水团、金团的大规模出现而展现出游戏最辉煌的时候。因为流水团打的越快，奖励越多。流水团每次申请的人那么多，作为团长怎么选择？肯定是装备越好，团本通关次数越多的人越优先放进团阿，这就是门槛。但是你如果没有装备，又想体验打团的乐趣，怎么办？你只能坐金团或者py（开玩笑），提升装备，然后达到进入流水团的门槛。</p><p>互联网时代已经过了开荒阶段了，现在大部分技术都已经成熟了，虽然整个社会没有像dnf策划在控制团本的更新换代，但是生产力的提高注定了整个时代会往前进步。现在互联网公司越来越多，想入这一行的人也越来越多，公司老板招人看什么？学历，技术就是门槛。那你又没学历，又没技术，还想吃这行的饭，怎么办呢？没学历就考研，没技术就坐金团（培训），让别人带你入门，或者你自学技术。然后先进入一家互联网的企业。</p><h1 id="打工-创业-变成了以前我最讨厌的样子"><a href="#打工-创业-变成了以前我最讨厌的样子" class="headerlink" title="打工-创业-变成了以前我最讨厌的样子"></a>打工-创业-变成了以前我最讨厌的样子</h1><p>当年我加入了一个安图恩的大团队后，开始从舰炮养老c成长到火山c，成为火山c之后我并没有得到团长的尊重，反而成为了团长专职带划水的角色，美其名曰，有能力就要带酱油阿，不然白培养你干嘛，直到有一天我为了要一个划水位而和团长发生了冲突。我拉了一批都忍受不了团长的网友，退出了那个团队，自己开团，建公会建群，喊喇叭招人，慢慢把群壮大起来。然后我发现我也成了和团长一样的人，自己只有2个火山c，却可以划8个小号，每次开团都先上奶c，等人快满了立即换小号划水，然后骗大奶大c（俗称野人），让野人免费给你打工带小号，然后你轻轻松松就能获得通关奖励。以前开团还是遵循互带原则，你带我划水我带你划水，到了后来，我变本加厉，大号开金团赚钱，小号纯划水，不贡献自己的力量，反而把自己最核心的力量拿去吃独食。这个时候很多看到这估计会骂我，怎么这么没良心，其实我也想骂我，但是为什么我会变的这样呢，变得和以前那个团长一样，变成了我最讨厌的样子。我至今也想不明白，这难道就是一个人创业的必经之路吗，能力越强的人都是喜欢压榨别人的人？如果你也有答案，可以给我留言。</p><h1 id="游戏人生"><a href="#游戏人生" class="headerlink" title="游戏人生"></a>游戏人生</h1><p>写这篇文章的目的其实是反思。</p><p>当前达到dnf游戏人生的最高境界就是努力打造成全服装备最好的，技术也要最牛逼，打桩打出最高的伤害才牛逼，成为这个行业的领头羊。（类似旭旭宝宝这样，虽然装备天下第一，但是老被吐槽手法，但是已经足够耀眼，我粉宝哥，陷于才华，忠于人品。）</p><p>那么人一生的最高境界是什么呢，抱歉，我现在也不知道，但是通过dnf，我也体验了一把从一个小白成长起来的过程。</p><hr><blockquote><p>现世报–不是做的越多，能力越强就越牛逼</p></blockquote><p>在现实中我也是一个刚刚从大学毕业进入互联网这一行的小白，目前我也成为一个被压榨的打工仔，我的公司培养我学习成长，直到能够独立承接公司的所有业务，但是我明明有资格划小号了，但是公司还是让我使劲地带酱油（压榨），而且又不让我划水（涨钱），美其名曰我培养了你，你就该为我打工报恩。和dnf一样，如果某天，某件事成了我压垮我的最后一根稻草，我也会辞职，但是现实不和dnf一样，一个更新换代的副本需要由上一届副本的顶级人物开荒，我得先成为某一领域的专家才能考虑拉人创业，不然只能换流水团，说不定某个团长赏识我的才华，让我打一个c就能随意划水（涨钱）。如果你也有答案，可以给我留言。</p><h1 id="返本归元"><a href="#返本归元" class="headerlink" title="返本归元"></a>返本归元</h1><p>我花了5298个小时在阿拉德大陆畅玩，得到的最终不过是一些数据罢了，人走茶凉，我最好的朋友们都离开了，我还何苦一个人留下？</p><p>最后提醒下能研读我这篇文章的人，适度游戏益脑，沉迷游戏伤身。</p><p>不要把游戏看成现实的写照，回归现实吧。努力学习，早日成为那个人上人。</p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> 顶级理解 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 顶级理解 </tag>
            
            <tag> DNF </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>顶级理解之互联网的后浪</title>
      <link href="2020/05/05/king/king-backwave/"/>
      <url>2020/05/05/king/king-backwave/</url>
      
        <content type="html"><![CDATA[<blockquote><p>当一个人拥有了顶级理解，那么他就没有任何烦恼。   - 宇神之息  </p></blockquote><p>声明: 顶级理解系列全部是本人的主观看法，也许在你看来以我现在的阅历不能对某些事物有着精准的判断，望不喜勿喷，求同存异。</p><hr><p>最近一个月我受到了很多大佬前辈们的教导，见证了社会中一件件大事件的发生，欣赏了一些对互联网反思、总结的文章，我感触挺多。和身边的朋友交谈中他们无一不说，宇哥，感觉你最近变得成熟了，受了什么刺激吗。其实是这次疫情的出现，让我更加真实地看见了自己的微不足道，反思自己从小到大的经历，总结并不断提高自己，规划未来的那个自己，梦想有一天成为互联网中的后浪，能奔涌前进！</p><h1 id="正文开始"><a href="#正文开始" class="headerlink" title="正文开始"></a>正文开始</h1><p>最近B站的后浪很火，如果没有看过的可以点击下面的传送门，一览何冰老师的慷慨致辞。当我看完后浪后，我心情久久不能平静，又反复观看几次，体会着上一代人对我们这一代人的羡慕、敬意、感激。后浪展示了是最好的时代，这也是最好的青春。时代的馈赠、个人的探索，汇聚成青春的蓬勃、生命的丰盛。一次与青年的对话，让人沉思青春的价值、成长的意义。</p><p><a href="https://www.bilibili.com/video/BV1FV411d7u7?from=search&seid=6731801181146737106" target="_blank" rel="noopener">后浪</a></p><p>关于后浪，网上的评论褒贬不一。</p><p>有人表示，《后浪》所描绘的，不过是物质条件最优越的年轻人处境：他们跳伞、玩Cosplay、喜欢汉服、摄影和潜水，他们容貌俊俏、鲜衣怒马，才能有享受自由人生的权利，而更多的人还在苦苦为生存挣扎。</p><p>诚然，B站版的后浪确实展示了最优越的年轻人的选择的权利，他们出身优越能有这么多选择，但是这并不是后浪所要展示的价值观，如果你觉得后浪所展示的价值观太脱离实际，我建议你看看央视版的后浪。</p><p>我认为大部分年轻人在当今社会一样具有很多选择的权力。比起我们上一辈，我们多了什么选择呢，借用后浪里的话：</p><hr><p>人类积攒了几千年的财富</p><p>所有的知识、见识、智慧和艺术</p><p>像是专门为你们准备的礼物</p><p>科技繁荣</p><p>文化繁茂</p><p>城市繁华</p><p>现代文明的成果</p><p>被层层打开</p><p>可以尽情享用</p><hr><p>其中这里就不得不说到互联网，现代文明的成果离不开互联网的贡献，我们在互联网中可以选择很多，并且我坚信，这应该是这个社会能够赋予每个年轻人最基本的选择权力之一。</p><ul><li>互联网的无限包容性，打破了以往的信息不对称，使得人们能轻而易举地获取信息、接收知识。</li><li>互联网带来的新变化、新机遇、新格局，使得竞争变得更为激烈、更为直接、更为透明，并永无停止地在挑战着既有市场的旧格局、旧规则。墨守成规已经没有出路，互联网信息时代已经提出了必须要面对新形势下的新挑战这个迫在眉睫的课题。</li><li>相对于现实世界，互联网又是另一个虚拟世界，一个新的世界。人们既生活在现实世界中，也存在于互联网虚拟世界里，实现中，相当一部分人甚至是无法生活在没有网络的世界里的。</li><li>互联网直接或间接的为人进行赋能，互联网新工具新技术新思维让人不再局限于双手双脚，但却拥有比原来还要高级还要强大的能力，并不断突破自我，面对新机遇不再显得束手无策，不管你认不认可，互联网以一种看不见的力量推动着社会历史的变迁。</li></ul><p>互联网时代正在改变和影响我们的生活，那么一个新青年怎么才能成为互联网行业中一朵真正的后浪呢？我认为需要要有以下3点，洞察格局、提升技术、不忘初心。</p><h1 id="洞察格局"><a href="#洞察格局" class="headerlink" title="洞察格局"></a>洞察格局</h1><p>当前中国的互联网格局是什么？当前世界的互联网格局是什么？我们身处的互联网环境是怎么样？</p><p>我不能够清晰准确地回答大家，但是我看到过一篇文章，这么来形容中国互联网的历史。有助于大家提高自己的格局。</p><h2 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h2><p><a href="https://www.36kr.com/p/5100918" target="_blank" rel="noopener">中国互联网史就是一部流氓史</a></p><p>该文章主要说明了国内的互联网环境很差。主要归结于几点：</p><ul><li>绑架史：被插件困挠的20年</li><li>抄袭史：创新是互联网企业的绊脚石</li><li>低俗史：从社会精英到网络喷子</li><li>盗版史：知识产权是个什么玩意儿</li><li>垄断史：从去中心化到中心化</li></ul><p>引用里面的一大段话</p><hr><p>www的设计者Tim Berners-Lee认为互联网本来是去中心化的拓扑结构，每个人都可以建设自己的网站，但现在，互联网已经完全成为一种中心化结构。域名你要去新网或者万网（已经阿里系的了），服务器你可能只会选择腾讯云或者阿里云。这还不是最坏的结果，毕竟你还能建个属于自己的网站。比这个更恐怖的是苹果的出现，它用iOS系统和iPhone牢牢的把每一家互联网公司给锁死，唯一能够与之抗衡的是Google / Facebook / Amazon……但这些公司你同样会觉得它们与苹果没什么两样。</p><p>中国的互联网公司的中心化有过之而无不及，甚至可以说，中国互联网的发展史就是BAT三足鼎立的历史，1998年的腾讯、1999年的阿里、2000年的百度。似乎在20年前，宿命已经注定。虽然2008年移动互联网出现后稍有变数，但只要百度不再出昏招，新晋小巨头TMD（今日头条、美团、滴滴）还是很难超越的。</p><p>现在新的创业公司都不想建立自己的网站了，服务在公众号里完成，商品在淘宝上开个店，新闻在头条里发布……何必要自己建立一个中心点呢，流量是哪里来？还不如寄生在一个大平台上面。 </p><p>今日互联网的中心化也不完全是市场竞争的结果，大公司用流量控制住所有新的可能，一旦有新物种出现，弄不死你就抄袭个同类产品压制你，如果还弄不死你那就收购你，反正总有一种流氓手段可以搞定你。</p><p>互联网已经彻底中心化了，我们以为互联网会给每个人带来自由，现在才发现，互联网其实在剥夺我们的思考。20年来互联网的中心化就是垄断化，最后我们的命运将被控制在几个人手里。</p><hr><p>我从中得到的结论就是，国内互联网的格局都由大厂控制住了，小公司很难有撼动整个国内互联网的能力，那么跟着大厂的步伐走才是正道吗？恕我不能回答。</p><h2 id="TOP"><a href="#TOP" class="headerlink" title="TOP"></a>TOP</h2><p>给大家上两张图及链接，中国VS世界。在2019年中国互联网前10强里只有2个公司进入了世界前10强，阿里、腾讯。</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/King/2019ITTOP.png"  alt="中国"></p><p><a href="https://baike.baidu.com/item/%E4%B8%AD%E5%9B%BD%E4%BA%92%E8%81%94%E7%BD%91%E4%BC%81%E4%B8%9A100%E5%BC%BA/9835904?fr=aladdin" target="_blank" rel="noopener">2019年中国互联网企业100强</a></p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/King/2019ITTOP.jpg"  alt="世界"></p><p><a href="http://www.nbyoho.com/news/1660218504261509241.html" target="_blank" rel="noopener">互联网iT业全年数据公布 2019年全球十大IT企业排名出炉了</a></p><hr><h2 id="贡献"><a href="#贡献" class="headerlink" title="贡献"></a>贡献</h2><p>仍然给大家上两条链接，中国VS世界。国外的开源公司帖子不好找，只能找到2017年的开源公司列表。这些帖子说明，阿里给国内做出的贡献很大，世界企业给世界的互联网企业贡献更大，而中国处在互联网的洪流中，显得微不足道。</p><p><a href="https://www.infoq.cn/article/G4O6JUhJF*Tsv9eWM0L6" target="_blank" rel="noopener">2019年中国互联网公司开源项目调研报告</a></p><p><a href="https://juejin.im/entry/59d16eb551882516662bffba" target="_blank" rel="noopener">2017年全球 35 大开源公司都在这里！</a></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>通过互联网企业排名和贡献比较，一方面我感叹中国和世界的互联网技术的差距之大，另一方面我也看到了近几年中国在尽全力追赶世界互联网的脚步。</p><p>国内的开源技术越来越多，国内很多中小型公司渐渐模仿了阿里系、腾讯系、百度系的架构体系。在我眼里，阿里可谓是中国的谷歌，真正的科技公司，许多Java类的框架不开则以，一开惊人。阿里云的标签是什么？为了无法计算的价值。正是阿里的无私奉献，国内的许多公司纷纷享用着中国人自己开源的东西。</p><p>而谷歌的开源项目更是多如牛毛，被国外程序员称为开源巨献。2014年Google推出Kubernetes，被誉为容器化发展的里程碑，世界所有的顶级技术人员为它添砖加瓦，一直至今，Kubernertes的生态系统继续增长着。</p><p>我希望看到这的你们能对整个互联网的格局有一个新的认识，不要总觉得自己学的知识已经足够了，不要夜郎自大认为自己学的知识特别牛，其实有很多都是别人玩剩下的东西。没事多看看国外的技术论坛、博客，不要局限于国内的技术。</p><h1 id="提升技术"><a href="#提升技术" class="headerlink" title="提升技术"></a>提升技术</h1><p>很多人会问我，你学的知识很多，好像什么都懂点，我应该怎么和你一样？其实每个人不一定要学谁，找到适合自己的才是最好的。</p><p>我很惭愧：</p><ul><li>我在2018年11月之前没有使用过linux操作系统</li><li>我在2019年9月才开始接触这个5年前就已经火起来的kubernetes，至今仍不能说精通它。</li><li>我在2019年12月之前没有用过云平台，不知道云为何物</li><li>我在2020年4月22日之前还没有对自己的学习知识进行过全面的总结</li></ul><p>我技术成长在最快的时间段就是在2019年10-12月3个月内，先应用后学习，是我认为学习效率至快的法宝。因为我们的脚步已经很慢了，没有时间和经历再从头学起了，从项目中体会、学习、理解才能最快地了解某一技术是干嘛用的，然后通过时间、经验的累积，慢慢深入了解这些技术底层的原理，吃懂吃透。</p><p>看到这，我相信你们能够明白一个道理，技术是永远学不完的，但是你得去不断总结自己的知识技术，不断反思，时不时洞察格局，至少得知道自己是什么水平，如果水平低了就应该赶紧补习，追上潮流。我也是不断的逼自己学习，我也不想掉队，我也想成为运维行业的领军人物，所以只能不断的学习！</p><p>给大家推荐一个方法：不管哪行哪业，如果你觉得你提升不了技术了或者没有动力学下去，那么请看下你所在岗位的招聘网站，看看现在市场招聘的技术你是否都会？行业的平均水平在哪？你的工资是否高与市场的平均水平？如果些条件你都不能满足，你就有了学习的动力及方向，望共勉之。</p><h1 id="不忘初心"><a href="#不忘初心" class="headerlink" title="不忘初心"></a>不忘初心</h1><p>如果你看过人民的名义，你应该会记得高育良书记曾慷慨激昂地说过这样一句话：中国的改革开放可以说是浩浩荡荡，每个人都身处洪流之中，期间，有许多人凭着自身的努力或者说幸运站在了潮头之上，这潮头之上是风光无限，诱惑无限，也风险无限，就看你如何把握了。看未来远不如看过去，要来得清楚，激昂和困惑，交织在每个人都心头，所以说要留一份敬畏在心中，看别的东西可以模糊，但看底线一定要看得清晰。</p><p>虽然高育良是反派，但是我认为他说的话挺有格局。（不愧是大教授）即使他最后被逮捕判刑，我仍认为他的守住了自己的底线，而且他也没有主观上贪污腐败，只是被环境的影响太严重，一失足成千古恨，所以不忘初心真不是一件简单的事。</p><p>最近刷B站看了许多郑强教授的演讲，浙江大学教授讲话，句句振聋发聩。我感觉我的价值观正在被他的演讲所引导，引用他的两段话。</p><hr><p>我说我郑强同志苦口婆心的把高分子知识教了你们,后面过两天你们到美国去,在杜邦公司就职,然后那个导弹的那个防漏圈,都是高分子的圈,全你们做的,然后过两天“嘟”飞回来把我炸死了。</p><p>教育应该让中国懂得自尊。但是现在我们看到外国人就低头，女生看到外国的男人都想讨好。同志们，在外国人面前我们多么地没有尊严。在留学的日本京都大学的人当中，我是唯一回来的，但日本人反而敬重我，因为我活得有灵魂，活得有骨气。</p><hr><p>郑强教授告诉我做人不能忘本，不能忘记养育自己的父母和国家，而我的初心就是守住这个底线，尽自己的力量做对国家有贡献的事情。</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>我是一个喜欢学历史的人，以古为鉴，可知兴替，中国历代的发展都是由兴到衰，由衰到兴。而中国从1840年至今创造了一系列奇迹：</p><ul><li>综合国力从衰败到日益强盛</li><li>人民生活水平从贫困到基本全面小康</li><li>国际地位从任人宰割到屹立世界东方</li></ul><p>从1840年的虚弱落后，到1949年的历史低点后奋起，再到今天的强国新貌，时光荏苒，斗转星移，真正是换了人间！</p><p>而我们应该更居安思危，在互联网时代中，中国的技术正处在蓬勃增长的状态，但是依旧不可否认我们与国外的差距，所以我们更应该争做互联网的后浪，拿出舍我其谁的精神，勇往直前地冲到最前沿，成为一个国家最好看的风景！</p><p>看完我的文章，我希望你关闭页面的时候能够变得：</p><ul><li>善良 </li><li>勇敢 </li><li>无私 </li><li>无所畏惧</li><li>是心里有火 眼里有光</li><li>表达自我 拥抱世界</li></ul><p>共勉之。</p>]]></content>
      
      
      <categories>
          
          <category> 顶级理解 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 顶级理解 </tag>
            
            <tag> 互联网 </tag>
            
            <tag> 后浪 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>顶级理解之成长（2018.9-2020.5）</title>
      <link href="2020/05/05/king/king-growup/"/>
      <url>2020/05/05/king/king-growup/</url>
      
        <content type="html"><![CDATA[<blockquote><p>   当一个人拥有了顶级理解，那么他就没有任何烦恼。   - 宇神之息  </p></blockquote><p>声明: 顶级理解系列全部是本人的主观看法，望不喜勿喷，求同存异。</p><hr><p>本文记录了宇神之息的成长以及我对成长的理解。</p><h1 id="实习时期前（2018）"><a href="#实习时期前（2018）" class="headerlink" title="实习时期前（2018）"></a>实习时期前（2018）</h1><p>实习前连以下技术是什么都不知道。</p><p>Linux、mac、git、gitlab、python、nginx、docker、openstack。</p><h1 id="实习时期后（2019）"><a href="#实习时期后（2019）" class="headerlink" title="实习时期后（2019）"></a>实习时期后（2019）</h1><p>我已经会一些Linux、git、docker的基本命令，能够用python轻松写一些脚本，会简单地配置nginx的转发，使用openstack创建虚拟机（仅此而已），修过同事的mac电脑。</p><h1 id="毕业后2个月（2019）"><a href="#毕业后2个月（2019）" class="headerlink" title="毕业后2个月（2019）"></a>毕业后2个月（2019）</h1><p>大学毕业后3个月内，我补充了我的网络、计算机知识、做网线、帮同事安装打印机、配置公司AD域及邮箱、平常排查下同事的电脑问题。这时我俨然成为了一名桌面运维工程师，但是我觉得一直做这些重复的事很没意思，我准备要利用我在实习期间学习的东西了。</p><h1 id="自学运维技术（2019）"><a href="#自学运维技术（2019）" class="headerlink" title="自学运维技术（2019）"></a>自学运维技术（2019）</h1><p>公司给我配置了6台虚拟机，1个月的时间内，我把公司实战用到的各种技术都过了一遍（安装、了解），并记录成文档。</p><p>docker、Harbor、jenkins、jira、confluence、gitlab、lvs、keepalived、Nginx、ELK、maven、Rocketmq、Zookpeer、Nacos、Redis、memcached、Mysql、Skywalking、zabbix、nagios、yapi</p><h1 id="第一次上线部署（2019）"><a href="#第一次上线部署（2019）" class="headerlink" title="第一次上线部署（2019）"></a>第一次上线部署（2019）</h1><p>俗话说的好，最好的经验都是实战中练起来的。9月，公司架构调整，需要从总部迁移4个项目到分部来，为了能让我接手运维相关工作，总部派了一位资深运维工程师华哥来分部带我上项目，通过前期1个月的自学，我带着问题请教他，他对我的问题讲解的很深，每种技术他都能讲到原理层，我很佩服他。</p><p>不到7天的时间，华哥把上面大部分技术都给我讲了一遍，以及怎么去实战应用，我如获至宝并将这些技术详细记录到文档，这些文档到现在已经成为我工作中不可或缺的学习资料。</p><p>9月4日，这一天我可能很难忘记，公司的一个大业务需要在这天进行上线部署。我特别紧张，敲命令都检查得很仔细。项目发布用的是jenkins，当我改好项目配置文件后，开始构建，结果报错了，生产环境的项目启动失败，我不知所措，只能让华哥处理。这个错误我也可能很难忘记，因为数据库新增了一个表，而项目连接的用户应该添加这个表，不然就没有权限访问。现在看似很简单的一个问题，只需要DBA授权这个账户即可。华哥当时立马打电话联系DBA，让他授权，然后执行了一些当时我完全看不懂的操作。最后项目发布完成，验收通过，从始至终我都是懵逼状态。</p><h1 id="先应用后学习（2019）"><a href="#先应用后学习（2019）" class="headerlink" title="先应用后学习（2019）"></a>先应用后学习（2019）</h1><p>从9月4日后，看着总部运维同事的上线文档，我一步一步将分布的业务全部接完了，Kubernetes开始进入到我的视线。由于历史原因，公司老的项目是单机部署（进入服务器，java -jar启动），新的项目用的都是Kubernetes。这么一个庞大的容器编排工具当初在我眼里不过就是发布的时候的一条命令helm upgrade就能滚动发布项目了，而里面的技术我至今也没能全部吃透。</p><h1 id="从0到1的成长（2019）"><a href="#从0到1的成长（2019）" class="headerlink" title="从0到1的成长（2019）"></a>从0到1的成长（2019）</h1><p>11月，公司分部要上线一个全新的业务，需要分部团队独立完成，不再依赖总部的技术人员。此时我虽然已经能独立承接发布需求，但是都是基于老的项目，点一点按钮，就能发布了，对于里面的机制原理还是不太熟悉。公司分部也需要一个完整的技术体系，一个资深网络工程师天哥和一个资深运维工程师峰哥就带着我一个小菜鸡开干啦。</p><ul><li>机房建设：总部向分部寄了好几台720xd，天哥规划好分公司网络拓扑结构后，开始配置交换机及防火墙、建立分部有线/无线/虚拟网络，这些做好后，他开始教我拆服务器装硬盘和内存条，以及部署esxi集群，然后峰哥带我把一个centos镜像做成虚拟机的模板。</li><li>环境建设：天哥划分了开发环境/测试环境/压测环境，峰哥带着我一起部署Kubernetes集群、Mysql、Redis集群、Zookeeper集群、Nacos集群、RocketMQ集群、Jenkins、Harbor等等到开发环境，过了一遍后，剩下的2个环境就由我自己搭建了。</li><li>生产部署：我们预估项目所需的配置，整理预算，申请资金，注册阿里云账号，购买各种资源。</li><li>Devops：峰哥带着我制作Kubernetes的容器模板、写shell脚本用Jenkins打通从开发→测试→生产的流程。</li></ul><h1 id="至今（2020）"><a href="#至今（2020）" class="headerlink" title="至今（2020）"></a>至今（2020）</h1><p>一条Devops道路打通后，剩下的事就是继续优化及完善。</p><p>安全：</p><ul><li>部署生产堡垒机，规范操作</li><li>部署数据库审计平台，规范sql</li><li>安装插件，扫描漏洞</li><li>写日常巡检脚本，监控生产环境资源状态</li></ul><p>优化：</p><ul><li>自动发布脚本优化</li><li>生产环境各个组件降配，提高资源利用率</li></ul><p>提升：</p><ul><li>深入学习各个组件原理</li></ul><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>我很幸运</p><p>半年前</p><ul><li>能有这么多良师益友带我快速学习成长</li><li>能负责一个分公司所有的上线部署业务</li><li>能学习并应用一个公有云平台的部分组件</li><li>见证并参与到一个公司业务从0到1建成的过程</li></ul><p>我很不幸</p><p>现在</p><ul><li>当初带我良师益友已经有几位展翅高飞不在我身边</li><li>已经过了高速成长期，学习曲线明显变慢</li><li>管理的事情变得越来越多，工作越来越繁琐</li></ul><p>何其有幸又何其不幸，这就是成长。</p><p>成长也意味一个人在能力的提升的同时也获得了更多的权力，承担了更大的责任。</p><p>做到一个公司不可代替的人物就是我目前对成长的顶级理解。不可代替性（0%-100%），你能到达一个公司不可代替性的百分之多少就能真正地成长多少！</p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> 顶级理解 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 顶级理解 </tag>
            
            <tag> 互联网 </tag>
            
            <tag> 运维 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跟我学Devops之思想篇（二）</title>
      <link href="2020/05/04/devops/devops-idea-2/"/>
      <url>2020/05/04/devops/devops-idea-2/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="微服务架构简介"><a href="#微服务架构简介" class="headerlink" title="微服务架构简介"></a>微服务架构简介</h1><h2 id="百度解释"><a href="#百度解释" class="headerlink" title="百度解释"></a>百度解释</h2><p>微服务架构是一项在云中部署应用和服务的新技术。大部分围绕微服务的争论都集中在容器或其他技术是否能很好的实施微服务，而红帽说API应该是重点。</p><p>微服务可以在“自己的程序”中运行，并通过“轻量级设备与HTTP型API进行沟通”。关键在于该服务可以在自己的程序中运行。通过这一点我们就可以将服务公开与微服务架构（在现有系统中分布一个API）区分开来。在服务公开中，许多服务都可以被内部独立进程所限制。如果其中任何一个服务需要增加某种功能，那么就必须缩小进程范围。在微服务架构中，只需要在特定的某种服务中增加所需功能，而不影响整体进程的架构。</p><p>微服务的基本思想在于考虑围绕着业务领域组件来创建应用，这些应用可独立地进行开发、管理和加速。在分散的组件中使用微服务云架构和平台，使部署、管理和服务功能交付变得更加简单。</p><p>使用微服务构建现代化应用程序是很有意义的，因为它让你既利用了扩展横向扩展架构，也利用纵向扩展架构；还额外得到API的组合，且在整个业务中可重复利用。</p><h2 id="个人从工作中理解什么叫微服务架构"><a href="#个人从工作中理解什么叫微服务架构" class="headerlink" title="个人从工作中理解什么叫微服务架构"></a>个人从工作中理解什么叫微服务架构</h2><p>一个公司的核心业务购买商品系统用微服务架构和传统架构</p><ul><li>用微服务框架是这样的</li></ul><ol><li>一个登陆注册功能，一个查询商品功能，一个商品库存功能，一个购买功能，这些功能通过API互相调用，并且每个功能能做成独立的应用分别部署到容器里上，一个容器挂掉/更新不会影响整个项目的运行。</li><li>用这种框架的好处在于在这个系统第一次上线到生产环境后并且能保持核心业务正常运行的情况下，项目后期的更新只是某个功能应用的更新，不会影响整个生产环境的稳定性。</li><li>如果你只需要改一个查询商品的功能，即使这个功能后期上线的时候出现了逻辑问题，但是也不会影响核心流程（购买），并且你可以通过容器编排工具kubernetes快速将这一个功能回滚到上一个版本。</li></ol><ul><li>用传统框架是这样的<br>所有的功能写到一个应用中，启动慢，内容太多，后期更新迭代只会越来越难，上线部署风险大（需要重启整个大项目），特别得出现了逻辑问题需要技术人员定位问题，以及回退项目，造成用户体验不好。</li></ul><p>举个简单的例子，如果支付宝、微信这样的大应用用传统框架更新，更新完发现某个功能不能用需要回退重启，造成了短暂几分钟不能打开应用，这种损失是无法估量的。而用微服务架构，即使更新后出现了问题，也只会找更新的那个应用组件，定位问题+回退重启，这种方式可以在用户无感知的情况下进行，影响也会小很多。</p><h1 id="Devops和微服务的关系"><a href="#Devops和微服务的关系" class="headerlink" title="Devops和微服务的关系"></a>Devops和微服务的关系</h1><p>一些企业总是避开定期投资架构解耦和现代化技术，因此现在无法摆脱巨大的产品架构，使得发布变成无法预测。从某种程度上来说，微服务架构和Devops相辅相成，devops和微服务架构的存在都是为了解决这么一个问题：全世界的所有组织都试图频繁地发布高质量的产品，来提高客户的满意度。</p><h2 id="微服务架构和DevOps允许分散开的团队控制他们自己的命运"><a href="#微服务架构和DevOps允许分散开的团队控制他们自己的命运" class="headerlink" title="微服务架构和DevOps允许分散开的团队控制他们自己的命运"></a>微服务架构和DevOps允许分散开的团队控制他们自己的命运</h2><p>微服务架构就是关于把一件事做好，从设计一个由许多“服务”集中到一个的庞然大物中，这是一种范式转变。对庞大系统的扼杀催生了更小的微服务，并加速了庞大笨重团队的瓦解，研发变成了多个更小（更灵活）的团队。</p><p>此外，权力分散也正好符合DevOps的核心原则，缩小了两者之间的差距：</p><ul><li>UI、中间层和后台专家，他们倾向于在自己的筒仓中操作。</li><li>业务、产品管理、开发、QA、发布、安全、运营，以及其他成员，这些人都倾向于在自己的部门工作。</li></ul><p>最重要的是，微服务架构和DevOps都支持产品模型和项目模型，即5-7个成员团队设计、构建、测试、发布、监控和维护他们在开发/测试、阶段和生产上的应用。</p><h2 id="区分开的服务可以作为独立的、可展开的构件发布"><a href="#区分开的服务可以作为独立的、可展开的构件发布" class="headerlink" title="区分开的服务可以作为独立的、可展开的构件发布"></a>区分开的服务可以作为独立的、可展开的构件发布</h2><ul><li>大多数组织都倾注于设计和实施有弹性的持续交付管道，这可以帮助他们：在一个安全的、受保护的和可审计的方式下测试新功能。</li><li>很快从失败中恢复，而不去影响客户。</li></ul><p>尽管整体架构模式是成功的，但微服务提供的模块性使发布能够快速地以增量的方式进行。DevOps也支持小批量的规模，并允许小型团队拥有服务并将其交付。这样的设计能使微服务和DevOps在和谐地发挥作用，以帮助组织扩大规模。</p><h2 id="微服务和DevOps提高了测试周期，并且加速推向市场"><a href="#微服务和DevOps提高了测试周期，并且加速推向市场" class="headerlink" title="微服务和DevOps提高了测试周期，并且加速推向市场"></a>微服务和DevOps提高了测试周期，并且加速推向市场</h2><p>一些组织常常面临激烈的竞争，或者至少是保持不掉队。他们想建立可持续的商业模式，这样就可以让新想法迅速付诸实践，而不会消磨团队精力。然而，用庞大僵化的系统来实现这一目标是有可能的，但与颗粒状的微服务相比，可能性要小得多。下面就是原因。</p><p>一个庞然的系统经常导致一场“庞大测试”：</p><ul><li>系统在重要的一段时间内被设计和实施，在此期间团队成员可能多次改动。</li><li>可能不允许单独测试，因为测试用例、设计测试数据和测试配置没有被设计用来独立执行。</li><li>由于添加新的测试用例，每个新版本就越来越大。有时候，即使是在生产中不常用的功能，也会有缓慢的、归档的过期测试。在测试存档过程中可能存在不确定性，因为可能没有一个人完全理解系统架构。</li></ul><p>颗粒度的微服务通过独立的、可部署版本的构建被发布到生产中，这些构件分别被验证。微服务相互作用，提供特定的客户用例，因此需要智能集成测试。在集成测试期间，这些邻近的服务中有一些是由它们的测试替身和清晰定义的合约来表示的。测试替身和合约应该被重视，并且应该由拥有、交付和维护真实服务和接口的小团队拥有。</p><h1 id="微服务架构面临的挑战"><a href="#微服务架构面临的挑战" class="headerlink" title="微服务架构面临的挑战"></a>微服务架构面临的挑战</h1><ol><li>运维开销。更多的服务也就意味着更多的运维，产品团队需要保证所有的相关服务都有完善的监控等基础设施，传统的架构开发者只需要保证一个应用正常运行，而现在却需要保证几十甚至上百道工序高效运转，这是一个艰巨的任务。</li><li>DevOps要求。使用微服务架构后，这就意味着团队需要高品质的DevOps和自动化技术。而现在，这样的全栈式人才很少。</li><li>隐式接口。服务和服务之间通过接口来“联系”，当某一个服务更改接口格式时，可能涉及到此接口的所有服务都需要做调整。</li><li>重复劳动。在很多的服务中可能都会使用到同一个功能，而这一功能点没有足够大到提供一个服务的程度，这个时候可能不同的服务团队都会单独开发这一功能，重复的业务逻辑，这违背了良好的软件工程中的很多原则。</li><li>分布式系统的复杂性。微服务通过REST API或消息来将不同的服务联系起来，这在之前可能只是一个简单的远程过程调用。分布式系统也就意味着开发者需要考虑网络延迟、容错、消息序列化、不可靠的网络、异步、版本控制、负载等，而面对如此多的微服务都需要分布式时，整个产品需要有一整套完整的机制来保证各个服务可以正常运转。</li></ol><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>我认为微服务架构已经成为了互联网企业最重要的技术之一，配合Devops能更加简化了软件的交付方法，如持续交付和持续部署，并帮助生成可伸缩的交付管道。</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://baike.baidu.com/item/%E5%BE%AE%E6%9C%8D%E5%8A%A1%E6%9E%B6%E6%9E%84" target="_blank" rel="noopener">百度百科-微服务架构</a></p><p><a href="http://dockone.io/article/5976" target="_blank" rel="noopener">微服务给DevOps带来了什么？</a></p><p><a href="https://blog.csdn.net/enweitech/article/details/51819839" target="_blank" rel="noopener">时下流行devops关键词：分布式架构、一体化架构和微服务架构</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> 跟我学Devops </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Devops </tag>
            
            <tag> 微服务 </tag>
            
            <tag> Rest Api </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>跟我学Devops之思想篇（一）</title>
      <link href="2020/05/03/devops/devops-idea-1/"/>
      <url>2020/05/03/devops/devops-idea-1/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="Devops简介"><a href="#Devops简介" class="headerlink" title="Devops简介"></a>Devops简介</h1><p>DevOps（Development和Operations的组合词）是一组过程、方法与系统的统称，用于促进开发（应用程序/软件工程）、技术运营和质量保障（QA）部门之间的沟通、协作与整合。</p><p>它是一种重视“软件开发人员（Dev）”和“IT运维技术人员（Ops）”之间沟通合作的文化、运动或惯例。透过自动化“软件交付”和“架构变更”的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。</p><p>它的出现是由于软件行业日益清晰地认识到：为了按时交付软件产品和服务，开发和运维工作必须紧密合作。</p><p>下面用一张图来表示Devops的思想<br><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Blog/devops.jpg"  alt="devopsjpg"></p><h2 id="敏捷开发"><a href="#敏捷开发" class="headerlink" title="敏捷开发"></a>敏捷开发</h2><p>敏捷开发以用户的需求进化为核心，采用迭代、循序渐进的方法进行软件开发。在敏捷开发中，软件项目在构建初期被切分成多个子项目，各个子项目的成果都经过测试，具备可视、可集成和可运行使用的特征。换言之，就是把一个大项目分为多个相互联系，但也可独立运行的小项目，并分别完成，在此过程中软件一直处于可使用状态。</p><h2 id="敏捷部署"><a href="#敏捷部署" class="headerlink" title="敏捷部署"></a>敏捷部署</h2><p>敏捷部署是通过自动化工具或脚本来达到项目自动发布的目的。强大的部署自动化手段确保部署任务的可重复性、减少部署出错的可能性。</p><h1 id="个人从工作中理解什么叫Devops"><a href="#个人从工作中理解什么叫Devops" class="headerlink" title="个人从工作中理解什么叫Devops"></a>个人从工作中理解什么叫Devops</h1><p>我们公司的项目应用大多以Java为主，用的微服务架构。那么在实际项目中应用到devops中是怎么样的呢？详情可以看下图。<br><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Devops/CICD.png"  alt="devopsjpg"></p><h2 id="整个流程可以细分成3个阶段"><a href="#整个流程可以细分成3个阶段" class="headerlink" title="整个流程可以细分成3个阶段"></a>整个流程可以细分成3个阶段</h2><h3 id="开发阶段"><a href="#开发阶段" class="headerlink" title="开发阶段"></a>开发阶段</h3><ul><li>开发团队提交代码到gitlab的dev分支</li><li>从gitlab拉去dev分支代码</li><li>单元测试</li><li>maven编译打成jar包</li><li>sonar质量检查</li><li>Dockerfile将jar包打成image</li><li>将image推送到Harbor仓库</li><li>开发环境服务器拉取Harbor仓库image并创建容器</li><li>验证相关功能正常</li></ul><h3 id="测试阶段"><a href="#测试阶段" class="headerlink" title="测试阶段"></a>测试阶段</h3><ul><li>测试环境服务器拉取Harbor仓库image并创建容器</li><li>验证相关功能正常</li><li>通知开发合并分支到master分支</li><li>从gitlab拉去master分支代码</li><li>单元测试</li><li>maven编译打成jar包</li><li>sonar质量检查</li><li>Dockerfile将jar包打成image</li><li>将image推送到Harbor仓库</li><li>测试环境服务器拉取Harbor仓库image并创建容器</li><li>验证相关功能正常</li></ul><h3 id="投产阶段"><a href="#投产阶段" class="headerlink" title="投产阶段"></a>投产阶段</h3><ul><li>将Harbor仓库image推送到生产环境Harbor</li><li>生产环境服务器拉取生产环境Harbor仓库image并滚动发布</li><li>测试、产品人员验收</li></ul><h2 id="细分阶段的好处"><a href="#细分阶段的好处" class="headerlink" title="细分阶段的好处"></a>细分阶段的好处</h2><p>这样分阶段的Devops流程好处在于允许分散开的团队控制他们自己的命运：</p><ul><li>开发人员只用关心自己的分支代码功能、代码质量，不用考虑部署、测试。</li><li>测试人员只用关心开发人员的代码功能、回归、自动化、性能测试等，不用考虑部署流程。</li><li>运维人员只用关心将镜像发布到生产环境，不用考虑，代码功能、测试。</li></ul><p>这样的流水线设计是需要一段时间的，但是设计完成后可以一劳永逸，每个团队都能专注自己的工作。也许以前你是开发，你还需要负责部署、测试；也许以前你是测试，你还需要推送镜像到生产环境；有了Devops后，你只需要在jenkins点下构建按钮，选择环境就可以实现一键发布了，专注自己领域的事有利于提高整个团队的工作效率！</p><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>作为一个运维人员，当我学习到了Devops思想后就深深的认同这一点：所有的人工操作都要转换成自动化。</p><p>Devops七荣七耻与大家共勉</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Devops/HonorandDisgrace.png"  alt="devops.jpg"></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> 跟我学Devops </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Devops </tag>
            
            <tag> 自动化 </tag>
            
            <tag> CI/CD </tag>
            
            <tag> 敏捷开发 </tag>
            
            <tag> 敏捷部署 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>离线安装Mysql5.7.28及调优</title>
      <link href="2020/05/01/mysql/mysql-install/"/>
      <url>2020/05/01/mysql/mysql-install/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h1><ul><li>操作系统centos7.6</li><li>机器性能32C 64G 外挂2TSSD到/data目录（数据库建议外挂磁盘）  </li><li>mysql-5.7.28-linux-glibc2.12-x86_64.tar.gz</li><li>下载链接</li><li><a href="https://cdn.mysql.com//Downloads/MySQL-5.7/mysql-5.7.28-linux-glibc2.12-x86_64.tar.gz" target="_blank" rel="noopener">https://cdn.mysql.com//Downloads/MySQL-5.7/mysql-5.7.28-linux-glibc2.12-x86_64.tar.gz</a></li><li>百度网盘链接</li><li>链接：<a href="https://pan.baidu.com/s/1xmy-Qq0lsdHwHSl7kF-xeQ" target="_blank" rel="noopener">https://pan.baidu.com/s/1xmy-Qq0lsdHwHSl7kF-xeQ</a> 提取码：1997 </li></ul><h1 id="安装步骤"><a href="#安装步骤" class="headerlink" title="安装步骤"></a>安装步骤</h1><h2 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; groupadd mysql</span><br><span class="line">shell&gt; useradd -r -g mysql -s &#x2F;bin&#x2F;false mysql</span><br><span class="line">shell&gt; mkdir -vp &#x2F;data&#x2F;mysql&#x2F;mysql3306&#x2F;&#123;data,logs,tmp&#125;</span><br><span class="line">shell&gt; mkdir -vp &#x2F;opt&#x2F;mysql</span><br><span class="line">shell&gt; cd &#x2F;opt&#x2F;mysql&#x2F;</span><br><span class="line">shell&gt; tar zxvf mysql-5.7.28-linux-glibc2.12-x86_64.tar.gz</span><br><span class="line">shell&gt; cd &#x2F;usr&#x2F;local</span><br><span class="line">shell&gt; ln -s &#x2F;opt&#x2F;mysql&#x2F;mysql-5.7.28-linux-glibc2.12-x86_64  mysql</span><br></pre></td></tr></table></figure><h2 id="优化配置文件"><a href="#优化配置文件" class="headerlink" title="优化配置文件"></a>优化配置文件</h2><p>里面的参数都是在适用于本文环境准备机器配置的基础上调优后的结果，如果你想安装Mysql的机器配置与于本文环境准备机器配置相差很大请不要盲目复制，请看下面3大配置项内容里具体参数的讲解，太长不看可以直接看总结的配置文件。</p><h3 id="客户端默认设置内容"><a href="#客户端默认设置内容" class="headerlink" title="客户端默认设置内容"></a>客户端默认设置内容</h3><ul><li>socket 可以根据实际磁盘挂载的目录进行调整<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[client]   #客户端默认设置内容</span><br><span class="line"></span><br><span class="line">user&#x3D;root</span><br><span class="line">password&#x3D;123456</span><br><span class="line">port    &#x3D; 3306</span><br><span class="line">socket &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql3306&#x2F;data&#x2F;mysql.sock </span><br><span class="line">#避免MySQL的外部锁定，减少出错几率增强稳定性。</span><br></pre></td></tr></table></figure></li></ul><h3 id="使用mysql命令登录mysql数据库时的默认设置"><a href="#使用mysql命令登录mysql数据库时的默认设置" class="headerlink" title="使用mysql命令登录mysql数据库时的默认设置"></a>使用mysql命令登录mysql数据库时的默认设置</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[mysql]  #代表我们使用mysql命令登录mysql数据库时的默认设置</span><br><span class="line"></span><br><span class="line">#参数对于做运维的人来说很重要。我们登入mysql数据库后，mysql的提示符只是一个很简单内容 mysql&gt;,没有其他任何信息。通过--prompt&#x3D;name可以自定义提示信息，通过配置显示登入的主机地址，登陆用户名，当前时间，当前数据库schema等待。个人强烈要求加上登入主机名，登陆用户名，当前库这三项加入提示内容。</span><br><span class="line">prompt&#x3D;&quot;\u@dev-data-01 \R:\m:\s [\d]&gt; &quot; </span><br><span class="line">#自动补全的意思，就像我们在linux命令行里输入命令的时候，使用tab键的功能是一样的</span><br><span class="line">no-auto-rehash </span><br><span class="line">#utf8mb4兼容utf8，且比utf8能表示更多的字符，是utf8字符集的超集。</span><br><span class="line">default-character-set&#x3D;utf8mb4</span><br></pre></td></tr></table></figure><h3 id="数据库自身的默认设置"><a href="#数据库自身的默认设置" class="headerlink" title="数据库自身的默认设置"></a>数据库自身的默认设置</h3><p>数据库自身配置分为4项 </p><ul><li><p>basic settings    </p></li><li><p>log settings</p></li><li><p>replication settings</p></li><li><p>innodb settings</p></li></ul><h4 id="basic-settings"><a href="#basic-settings" class="headerlink" title="basic settings"></a>basic settings</h4><ul><li><p>datadir 可以根据实际磁盘挂载的目录进行调整</p></li><li><p>socket 可以根据实际磁盘挂载的目录进行调整</p></li><li><p>secure_file_priv 可以根据实际磁盘挂载的目录进行调整</p></li><li><p>skip_name_resolve  如果你的mysql主机查询DNS很慢或是有很多客户端主机时会导致连接很慢，是因为开发的机器是不能够连接外网的，所以DNS解析是不可能完成的，这时就需要禁用</p></li><li><p>external-locking 如果是单机部署需要禁用</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">[mysqld]  #代表数据库自身的默认设置</span><br><span class="line">########basic settings########</span><br><span class="line">user    &#x3D; mysql</span><br><span class="line">port    &#x3D; 3306</span><br><span class="line">basedir &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql</span><br><span class="line">datadir &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql3306&#x2F;data</span><br><span class="line">socket  &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql3306&#x2F;mysql.sock</span><br><span class="line">#参数是用来限制LOAD DATA, SELECT ... OUTFILE, and LOAD_FILE()传到哪个指定目录的，不配置不能用这个命令导出文件。</span><br><span class="line">secure_file_priv&#x3D;&#x2F;data&#x2F;mysql</span><br><span class="line">#该变量的值是ON或 OFF指示是否启用了性能模式。</span><br><span class="line">performance_schema &#x3D; 1</span><br><span class="line">#服务器安装时指定的默认字符集设定。</span><br><span class="line">character_set_server&#x3D;utf8mb4   </span><br><span class="line">#操作系统允许mysqld打开的文件数量。</span><br><span class="line">open_files_limit &#x3D; 655350  </span><br><span class="line">#事务隔离级别为READ COMMITTED。</span><br><span class="line">transaction_isolation &#x3D; READ-COMMITTED</span><br><span class="line">#针对交互式连接服务器关闭连接前等待活动的秒数，例如mysql客户端连接数据库。</span><br><span class="line">interactive_timeout &#x3D; 31536000</span><br><span class="line">#针对非交互式连接服务器关闭连接前等待活动的秒数，例如通过jdbc连接数据库。</span><br><span class="line">wait_timeout &#x3D; 31536000</span><br><span class="line">#客户端连接是否解析主机名。0，mysqld在检查客户端连接时解析主机名；1，mysqld仅使用IP编号。</span><br><span class="line">skip_name_resolve &#x3D; 1  </span><br><span class="line">#说明是否数据目录所在的文件系统对文件名的大小写敏感。1说明对文件名的大小写不敏感。</span><br><span class="line">lower_case_table_names&#x3D;1    </span><br><span class="line">#在MySQL暂时停止回答新请求之前的短时间内可以堆叠多少个请求。仅当您期望在短时间内有大量连接时，才需要增加此数量。</span><br><span class="line">back_log &#x3D; 1024</span><br><span class="line">#指定MySQL允许的最大连接进程数。如果在访问论坛时经常出现Too Many Connections的错误提示，则需要增大该参数值。</span><br><span class="line">max_connections &#x3D; 10240    </span><br><span class="line">#如果MySQL服务器连续接收到来自同一主机的请求且都被拒绝，次数超过max_connect_errors的设定值时，MySQL服务器就会阻止这台主机后续的所有请求。</span><br><span class="line">max_connect_errors &#x3D; 1000000</span><br><span class="line">#表文件描述符的缓存大小。</span><br><span class="line">table_open_cache &#x3D; 20480</span><br><span class="line">#可以存储在定义高速缓存中的表定义（来自文件）的数量 。</span><br><span class="line">table_definition_cache &#x3D; 20480</span><br><span class="line">#打开表缓存实例的数量。</span><br><span class="line">table_open_cache_instances &#x3D; 64</span><br><span class="line">#每个线程的堆栈大小。</span><br><span class="line">thread_stack &#x3D; 512K</span><br><span class="line">#跳过外部锁定。如果是单服务器环境，则将其禁用即可,如果是多服务器环境,则注释掉这一行即可。</span><br><span class="line">external-locking &#x3D; FALSE</span><br><span class="line">#限制server接受的数据包大小。</span><br><span class="line">max_allowed_packet &#x3D; 32M</span><br><span class="line">#每个必须执行排序的会话都会分配此大小的缓冲区。</span><br><span class="line">sort_buffer_size &#x3D; 4M</span><br><span class="line">#用于普通索引扫描，范围索引扫描和不使用索引的联接的缓冲区的最小大小，从而执行全表扫描。</span><br><span class="line">join_buffer_size &#x3D; 4M</span><br><span class="line">#服务器应缓存多少线程以供重用。</span><br><span class="line">thread_cache_size &#x3D; 15360</span><br><span class="line">#内部内存临时表的最大大小。</span><br><span class="line">tmp_table_size &#x3D; 32M</span><br><span class="line">#此变量设置MEMORY允许用户创建的表增长到的最大大小。变量的值用于计算MEMORY表MAX_ROWS值。</span><br><span class="line">max_heap_table_size &#x3D; 32M</span><br><span class="line">#此变量指定尝试获取元数据锁定的超时（以秒为单位）。</span><br><span class="line">lock_wait_timeout &#x3D; 3600</span><br><span class="line">#此变量确定服务器对列中的默认值和NULL-value处理启用某些非标准行为TIMESTAMP。</span><br><span class="line">explicit_defaults_for_timestamp &#x3D; 1</span><br><span class="line">#每个必须执行排序的会话都会分配此大小的缓冲区。</span><br><span class="line">sort_buffer_size &#x3D; 33554432</span><br></pre></td></tr></table></figure></li></ul><h4 id="log-settings"><a href="#log-settings" class="headerlink" title="log settings"></a>log settings</h4><ul><li><p>slow_query_log_file 可以根据实际磁盘挂载的目录进行调整</p></li><li><p>log-bin 可以根据实际磁盘挂载的目录进行调整</p></li><li><p>log-error 可以根据实际磁盘挂载的目录进行调整</p></li><li><p>long_query_time 俗称定义慢sql的标准,可以根据实际项目定义具体标准</p></li><li><p>log_throttle_queries_not_using_indexes需要log_queries_not_using_indexes启用</p></li><li><p>expire_logs_days Binlog 自动清理时间</p></li><li><p>max_binlog_cache_size 推荐的最大值为4GB。这是由于MySQL当前无法使用大于4GB的二进制日志位置。</p></li><li><p>binlog_format 在MySQL 5.7.7和更高版本中，默认值为ROW。</p></li><li><p>sync_binlog=1：启用在提交事务之前将二进制日志同步到磁盘。这是最安全的设置，但由于磁盘写入次数增加，可能会对性能产生负面影响。</p></li><li><p>sync_binlog=0：禁用MySQL服务器将二进制日志同步到磁盘的功能。取而代之的是，MySQL服务器依靠操作系统不时地将二进制日志刷新到磁盘上，就像处理其他任何文件一样。此设置提供最佳性能，但是在电源故障或操作系统崩溃的情况下，服务器可能提交了尚未同步到二进制日志的事务。</p></li><li><p>sync_binlog=N，其中N的值不是0或1：是N二进制日志提交组已收集之后，二进制日志将同步到磁盘 。在电源故障或操作系统崩溃的情况下，服务器可能提交了尚未刷新到二进制日志的事务。由于磁盘写入次数的增加，此设置可能会对性能产生负面影响。较高的值可以提高性能，但会增加数据丢失的风险。</p></li><li><p>为了在InnoDB与事务一起使用的复制设置中获得最大的持久性和一致性，请使用以下设置：sync_binlog=1。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">########log settings########</span><br><span class="line">#慢查询日志文件的名称</span><br><span class="line">slow_query_log_file &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql3306&#x2F;logs&#x2F;slow.log</span><br><span class="line">#错误日志输出目标。如果目标是控制台，则值为stderr。否则，目标是文件，log_error值是文件名。</span><br><span class="line">log-error &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql3306&#x2F;logs&#x2F;error.log</span><br><span class="line">#启用二进制日志记录。启用二进制日志记录后，服务器会将所有更改数据的语句记录到二进制日志中，该日志用于备份和复制。</span><br><span class="line">log-bin &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql3306&#x2F;logs&#x2F;mybinlog</span><br><span class="line">#是否启用慢速查询日志。该值可以是0（或OFF）以禁用日志，也可以是 1（或 ON）以启用日志。</span><br><span class="line">slow_query_log &#x3D; 1</span><br><span class="line">#此变量控制写入错误日志的消息以及通常写入文件的查询日志和慢速查询日志消息中时间戳的时区。设置为SYSTEM（本地系统时区）。</span><br><span class="line">log_timestamps &#x3D; SYSTEM</span><br><span class="line">#如果查询所花的时间超过许多秒，则服务器将增加Slow_queries状态变量,如果启用了慢查询日志，则查询将记录到慢查询日志文件中。俗称定义慢sql的标准</span><br><span class="line">long_query_time &#x3D; 1</span><br><span class="line">#如果在启用慢查询日志的情况下启用此变量，则会记录预期将检索所有行的查询。</span><br><span class="line">log_queries_not_using_indexes &#x3D;1</span><br><span class="line">#如果 log_queries_not_using_indexes启用，该变量将限制每分钟可写入慢速查询日志的此类查询的数量。</span><br><span class="line">log_throttle_queries_not_using_indexes &#x3D; 60</span><br><span class="line">#检查少于此行数的查询不会记录到慢查询日志中。</span><br><span class="line">min_examined_row_limit &#x3D; 100</span><br><span class="line">#开启后，在写入慢速查询日志的语句中包括慢速管理语句，包括ALTER TABLE， ANALYZE TABLE， CHECK TABLE， CREATE INDEX， DROP INDEX， OPTIMIZE TABLE，和 REPAIR TABLE。</span><br><span class="line">log_slow_admin_statements &#x3D; 1</span><br><span class="line">#启用慢速查询日志后，此变量将启用日志记录，以记录long_query_time在从属服务器上执行了超过几秒钟的查询 。</span><br><span class="line">log_slow_slave_statements &#x3D; 1</span><br><span class="line">#binlog7天自动清理</span><br><span class="line">expire_logs_days &#x3D; 7</span><br><span class="line">#是否对错误日志生成其他警告消息。</span><br><span class="line">log_warnings &#x3D; 1</span><br><span class="line">#在事务期间，用于保存对二进制日志的更改的缓存的大小。</span><br><span class="line">binlog_cache_size &#x3D; 4M</span><br><span class="line">#如果事务需要的内存字节数超过此数量，则服务器将生成多语句事务，而该语句需要的存储数超过“max_binlog_cache_size”字节。</span><br><span class="line">max_binlog_cache_size &#x3D; 4G</span><br><span class="line">#如果对二进制日志的写入导致当前日志文件的大小超过此变量的值，则服务器将旋转二进制日志（关闭当前文件并打开下一个日志）。</span><br><span class="line">max_binlog_size &#x3D; 1G</span><br><span class="line">#启用后，此变量使主服务器在二进制日志中为每个事件写入一个校正和。</span><br><span class="line">binlog_checksum &#x3D; 1</span><br><span class="line">#此变量设置二进制日志格式，并且可以是任何一个STATEMENT，ROW或MIXED。</span><br><span class="line">binlog_format &#x3D; row</span><br><span class="line">#控制MySQL服务器将二进制日志同步到磁盘的频率。</span><br><span class="line">sync_binlog &#x3D; 1</span><br></pre></td></tr></table></figure></li></ul><h4 id="replication-settings"><a href="#replication-settings" class="headerlink" title="replication settings"></a>replication settings</h4><p>如果你不搭建主从集群可以跳过这项。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">########replication settings########</span><br><span class="line">#服务器ID。在主服务器和每个从属服务器上，必须设置server_id系统变量以在1到2 32 − 1 的范围内建立唯一的复制ID 。</span><br><span class="line">server-id &#x3D; 213306</span><br><span class="line">#此变量的设置确定从属服务器是将主服务器状态和连接信息记录到FILE（master.info）还是TABLE （mysql.slave_master_info）上。仅当没有复制线程正在执行时，才能更改此变量的值。</span><br><span class="line">master_info_repository &#x3D; TABLE</span><br><span class="line">#该变量确定从站在继电器日志中的位置是写入FILE（relay-log.info）还是写入TABLE（mysql.slave_relay_log_info）。仅当没有复制线程正在执行时，才能更改此变量的值。</span><br><span class="line">relay_log_info_repository &#x3D; TABLE</span><br><span class="line">#控制是否启用基于GTID的日志记录以及日志可以包含的事务类型。</span><br><span class="line">gtid_mode &#x3D; on</span><br><span class="line">#根据此变量的值，服务器通过仅允许执行可以使用GTID安全记录的语句来实现GTID一致性。</span><br><span class="line">enforce-gtid-consistency &#x3D; on</span><br><span class="line">#从服务器从主服务器收到的更新是否应记录到从服务器自己的二进制日志中。</span><br><span class="line">log_slave_updates  &#x3D; on</span><br><span class="line">根据此变量的值，服务器通过仅允许执行可以使用GTID安全记录的语句来实现GTID一致性。</span><br><span class="line">enforce_gtid_consistency &#x3D; 1</span><br><span class="line">#中继日志文件的基本名称。</span><br><span class="line">relay_log &#x3D; relay.log</span><br><span class="line">#如果启用，此变量将在服务器启动后立即启用自动中继日志恢复。</span><br><span class="line">relay_log_recovery &#x3D; 1</span><br><span class="line">#一旦不再需要中继日志文件，则禁用或启用它们的自动清除。</span><br><span class="line">relay-log-purge &#x3D; 1</span><br><span class="line">#此变量控制MySQL启动或重新启动时在搜索GTID期间如何迭代二进制日志文件。</span><br><span class="line">binlog_gtid_simple_recovery &#x3D; 1</span><br><span class="line">#通常，当从属服务器发生错误时，复制会停止，这使您有机会手动解决数据中的不一致问题。</span><br><span class="line">slave_skip_errors &#x3D; ddl_exist_errors</span><br><span class="line">#在为基础行的日志记录和复制准备副本行时，此变量控制如何在行中搜索匹配项，特别是是否使用哈希扫描。  </span><br><span class="line">slave-rows-search-algorithms &#x3D; &#39;INDEX_SCAN,HASH_SCAN&#39;</span><br></pre></td></tr></table></figure><h4 id="innodb-settings"><a href="#innodb-settings" class="headerlink" title="innodb settings"></a>innodb settings</h4><ul><li><p>innodb_undo_directory 可以根据实际磁盘挂载的目录进行调整</p></li><li><p>innodb_buffer_pool_size 如果机器内存较低，可以将此参数调低。参数是动态的，它允许您在不重新启动服务器的情况下调整缓冲池的大小。</p></li><li><p>innodb_buffer_pool_instances 此选项仅在设置innodb_buffer_pool_size为1GB或更大时才生效 。总缓冲池大小在所有缓冲池之间分配。为了获得最佳效率，指定的组合 innodb_buffer_pool_instances 和innodb_buffer_pool_size ，使得每个缓冲池实例是至少为1GB。</p></li><li><p>innodb_log_file_size  通常，日志文件的总大小应足够大，以使服务器可以消除工作负载活动中的高峰和低谷，这通常意味着有足够的重做日志空间来处理一个小时以上的写活动。值越大，缓冲池中需要的检查点刷新活动越少，从而节省了磁盘I / O。</p></li><li><p>innodb_io_capacity、innodb_io_capacity_max  根据服务器IOPS能力适当调整，一般配普通SSD盘的话，可以调整到 10000 - 20000，配置高端PCIe SSD卡的话，则可以调整的更高，比如 50000 - 80000</p></li><li><p>innodb_lru_scan_depth 小于默认值（    1024）的设置通常适用于大多数工作负载。高于必要值的值可能会影响性能。仅在典型工作负载下具有备用I / O容量时，才考虑增加该值。相反，如果写密集型工作负载使您的I / O容量饱和，请减小该值，尤其是在大型缓冲池的情况下。</p></li><li><p>innodb_status_output、innodb_status_output_locks 开启可能会导致log-error文件增长较快</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line">########innodb settings########</span><br><span class="line">#InnoDB创建撤消表空间的路径。通常用于将撤消日志放置在其他存储设备上。</span><br><span class="line">innodb_undo_directory &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql3306&#x2F;data&#x2F;undolog</span><br><span class="line">#磁盘上内部临时表的存储引擎。允许的值为MYISAM和INNODB （默认值）。</span><br><span class="line">internal_tmp_disk_storage_engine &#x3D; InnoDB</span><br><span class="line">#指定InnoDB表的大小。</span><br><span class="line">innodb_page_size &#x3D; 8192</span><br><span class="line">#innodb_buffer_pool_chunk_size定义InnoDB缓冲池大小调整操作的块大小</span><br><span class="line">innodb_buffer_pool_size &#x3D; 40960m</span><br><span class="line"># InnoDB 池缓冲划分为的区域数。 </span><br><span class="line">innodb_buffer_pool_instances &#x3D; 4</span><br><span class="line">#指定在MySQL服务器启动时，通过加载先前保存的相同页面来自动预热InnoDB 缓冲池。</span><br><span class="line">innodb_buffer_pool_load_at_startup &#x3D; 1</span><br><span class="line">#指定在关闭MySQL服务器时是否记录InnoDB缓冲池中缓存的页面，以缩短下次重启时的预热过程。</span><br><span class="line">innodb_buffer_pool_dump_at_shutdown &#x3D; 1</span><br><span class="line">#定义InnoDB系统表空间数据文件的名称，大小和属性 。</span><br><span class="line">innodb_data_file_path &#x3D; ibdata1:1G:autoextend</span><br><span class="line">#每秒钟写入并刷新日志N。。</span><br><span class="line">innodb_flush_log_at_trx_commit &#x3D; 1</span><br><span class="line">#InnoDB 用于写入磁盘上的日志文件的缓冲区的大小。</span><br><span class="line">innodb_log_buffer_size &#x3D; 32M</span><br><span class="line">#在每个字节大小日志文件在日志组。</span><br><span class="line">innodb_log_file_size &#x3D; 1G</span><br><span class="line">#日志文件中日志组数量，InnoDB以循环方式写入文件。</span><br><span class="line">innodb_log_files_in_group &#x3D; 4</span><br><span class="line">#定义撤消表空间的阈值大小。</span><br><span class="line">innodb_max_undo_log_size &#x3D; 4G</span><br><span class="line">#所使用的撤消表空间的InnoDB数量。</span><br><span class="line">innodb_undo_tablespaces &#x3D; 95</span><br><span class="line">#变量定义了可用于InnoDB后台任务的IOPS，例如从缓冲池刷新页面和合并来自更改缓冲区的数据。</span><br><span class="line">innodb_io_capacity &#x3D; 2000</span><br><span class="line">#如果刷新较慢，则InnoDB可以比innodb_io_capacity变量定义更高的IOPS更积极地进行刷新。</span><br><span class="line">innodb_io_capacity_max &#x3D; 4000</span><br><span class="line">#0为遵守innodb_io_capacity定义 1为不遵守innodb_io_capacity定义 。</span><br><span class="line">innodb_flush_sync &#x3D; 0</span><br><span class="line">#指定是否冲洗从一个页面InnoDB 缓冲池也可以清空其他脏页在相同的程度。</span><br><span class="line">innodb_flush_neighbors &#x3D; 0</span><br><span class="line">#一个影响缓冲池刷新操作的算法和启发式方法的参数。</span><br><span class="line">innodb_lru_scan_depth &#x3D; 4000</span><br><span class="line">#InnoDB 事务在放弃之前等待行锁定的时间长度（以秒为单位）。</span><br><span class="line">innodb_lock_wait_timeout &#x3D; 5</span><br><span class="line">#写入操作的I &#x2F; O线程数 InnoDB。</span><br><span class="line">innodb_write_io_threads &#x3D; 8</span><br><span class="line">#读取操作的I &#x2F; O线程数 InnoDB。</span><br><span class="line">innodb_read_io_threads &#x3D; 8</span><br><span class="line">#专用于InnoDB清除操作的后台线程数 。</span><br><span class="line">innodb_purge_threads &#x3D; 4</span><br><span class="line">#从缓冲池实例中刷新脏页面的页面清洁程序线程数。</span><br><span class="line">innodb_page_cleaners &#x3D; 4</span><br><span class="line">#InnoDB尝试从缓冲池刷新数据，使脏页百分比不超过此值。</span><br><span class="line">innodb_max_dirty_pages_pct &#x3D; 50</span><br><span class="line">#定义用于将数据刷新到InnoDB数据文件和日志文件的方法，这会影响I&#x2F;O吞吐量。</span><br><span class="line">innodb_flush_method &#x3D; O_DIRECT</span><br><span class="line">#指定如何生成和验证存储在表空间的磁盘块中的校验。</span><br><span class="line">innodb_checksum_algorithm &#x3D; crc32</span><br><span class="line">#InnoDB 默认情况下，仅回滚事务超时上的最后一条语句。</span><br><span class="line">innodb_rollback_on_timeout &#x3D; 1</span><br><span class="line">#当启用该选项，所有信息死锁在InnoDB用户交易被记录在 mysqld 错误日志。</span><br><span class="line">innodb_print_all_deadlocks &#x3D; 1</span><br><span class="line">#当innodb_file_per_table启用时，在文件的每个表的表空间默认创建的表。</span><br><span class="line">innodb_file_per_table &#x3D; 1</span><br><span class="line">#指定在表的在线DDL操作期间使用的临时日志文件的大小的上限（以字节为单位）InnoDB。</span><br><span class="line">innodb_online_alter_log_max_size &#x3D; 4G</span><br><span class="line">#仅当优化器统计信息配置为非持久性时，此选项才适用 。</span><br><span class="line">innodb_stats_on_metadata &#x3D; 0</span><br><span class="line">#InnoDB可以在从磁盘读取的所有表空间页上使用校验和验证，以确保对硬件故障或损坏的数据文件具有额外的容错能力。</span><br><span class="line">innodb_checksums &#x3D; 1</span><br><span class="line">#定义所使用的回滚段数 InnoDB。</span><br><span class="line">innodb_undo_logs &#x3D; 128</span><br><span class="line">##启用InnoDB的status file，便于管理员查看以及监控等</span><br><span class="line">innodb_status_file &#x3D; 1</span><br><span class="line">#启用或禁用标准InnoDBMonitor的定期输出。</span><br><span class="line">innodb_status_output &#x3D; 0</span><br><span class="line">#启用或禁用InnoDB锁定监视器</span><br><span class="line">innodb_status_output_locks &#x3D; 0</span><br><span class="line">#启用此选项后InnoDB，使用DYNAMIC 或 COMPRESSED 行格式的表 允许长度超过767字节（最大3072字节）的索引键前缀 。</span><br><span class="line">innodb_large_prefix &#x3D; 1</span><br><span class="line">#InnoDB尝试使内部并发的操作系统线程数保持InnoDB小于或等于此变量给定的限制（InnoDB使用操作系统线程来处理用户事务）值0（默认值）被解释为无限并发（不进行并发检查）</span><br><span class="line">innodb_thread_concurrency &#x3D; 0</span><br><span class="line">#InnoDB线程在挂起线程之前 等待 互斥量释放的次数。</span><br><span class="line">innodb_sync_spin_loops &#x3D; 100</span><br><span class="line">#自旋锁定的 两次轮询之间的最大延迟 </span><br><span class="line">innodb_spin_wait_delay &#x3D; 30</span><br><span class="line">#指定MySQL可同时打开.ibd文件的最大个数，最小为10，默认300。此选项只针对InnoDB表打开的.ibd文件描述符，独立于open_files_limit。</span><br><span class="line">innodb_open_files &#x3D; 655350  </span><br><span class="line">#当innodb_strict_mode启用时，InnoDB将返回错误，而不是警告了一定的条件。</span><br><span class="line">innodb_strict_mode &#x3D; 1</span><br><span class="line">#指定在创建InnoDB索引期间用于对数据进行排序的排序缓冲区的大小。</span><br><span class="line">innodb_sort_buffer_size &#x3D; 67108864 </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#innodb monitor</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_innodb&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_server&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_dml&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_ddl&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_trx&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_os&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_purge&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_log&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_lock&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_buffer&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_index&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_ibuf_system&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_buffer_page&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_adaptive_hash&quot;</span><br></pre></td></tr></table></figure></li></ul><h3 id="总结配置文件"><a href="#总结配置文件" class="headerlink" title="总结配置文件"></a>总结配置文件</h3><p>vim /etc/my.cnf<br>复制粘贴下面的配置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br></pre></td><td class="code"><pre><span class="line">[client]   </span><br><span class="line">user&#x3D;root</span><br><span class="line">password&#x3D;123456</span><br><span class="line">port    &#x3D; 3306</span><br><span class="line">socket &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql3306&#x2F;data&#x2F;mysql.sock </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">[mysql] </span><br><span class="line">prompt&#x3D;&quot;\u@dev-data-01 \R:\m:\s [\d]&gt; &quot; </span><br><span class="line">no-auto-rehash </span><br><span class="line">default-character-set&#x3D;utf8mb4  </span><br><span class="line"></span><br><span class="line">[mysqld] </span><br><span class="line">########basic settings########</span><br><span class="line">user    &#x3D; mysql</span><br><span class="line">port    &#x3D; 3306</span><br><span class="line">basedir &#x3D; &#x2F;usr&#x2F;local&#x2F;mysql</span><br><span class="line">datadir &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql3306&#x2F;data</span><br><span class="line">socket  &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql3306&#x2F;mysql.sock</span><br><span class="line">secure_file_priv&#x3D;&#x2F;data&#x2F;mysql&#x2F;</span><br><span class="line">performance_schema &#x3D; 1</span><br><span class="line">character_set_server&#x3D;utf8mb4   </span><br><span class="line">open_files_limit &#x3D; 655350  </span><br><span class="line">transaction_isolation &#x3D; READ-COMMITTED</span><br><span class="line">interactive_timeout &#x3D; 31536000</span><br><span class="line">wait_timeout &#x3D; 31536000</span><br><span class="line">skip_name_resolve &#x3D; 1  </span><br><span class="line">lower_case_table_names&#x3D;1    </span><br><span class="line">back_log &#x3D; 1024</span><br><span class="line">max_connections &#x3D; 10240    </span><br><span class="line">max_connect_errors &#x3D; 1000000</span><br><span class="line">table_open_cache &#x3D; 20480</span><br><span class="line">table_definition_cache &#x3D; 20480</span><br><span class="line">table_open_cache_instances &#x3D; 64</span><br><span class="line">thread_stack &#x3D; 512K</span><br><span class="line">external-locking &#x3D; FALSE</span><br><span class="line">max_allowed_packet &#x3D; 32M</span><br><span class="line">sort_buffer_size &#x3D; 4M</span><br><span class="line">join_buffer_size &#x3D; 4M</span><br><span class="line">thread_cache_size &#x3D; 15360</span><br><span class="line">tmp_table_size &#x3D; 32M</span><br><span class="line">max_heap_table_size &#x3D; 32M</span><br><span class="line">lock_wait_timeout &#x3D; 3600</span><br><span class="line">explicit_defaults_for_timestamp &#x3D; 1</span><br><span class="line">sort_buffer_size &#x3D; 33554432</span><br><span class="line"></span><br><span class="line">########log settings########</span><br><span class="line">slow_query_log_file &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql3306&#x2F;slow.log</span><br><span class="line">log-error &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql3306&#x2F;error.log</span><br><span class="line">log-bin &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql3306&#x2F;logs&#x2F;mybinlog</span><br><span class="line">slow_query_log &#x3D; 1</span><br><span class="line">log_timestamps &#x3D; SYSTEM</span><br><span class="line">long_query_time &#x3D; 1</span><br><span class="line">log_queries_not_using_indexes &#x3D;1</span><br><span class="line">log_throttle_queries_not_using_indexes &#x3D; 60</span><br><span class="line">min_examined_row_limit &#x3D; 100</span><br><span class="line">log_slow_admin_statements &#x3D; 1</span><br><span class="line">log_slow_slave_statements &#x3D; 1</span><br><span class="line">expire_logs_days &#x3D; 7</span><br><span class="line">log_warnings &#x3D; 1</span><br><span class="line">binlog_cache_size &#x3D; 4M</span><br><span class="line">max_binlog_cache_size &#x3D; 4G</span><br><span class="line">max_binlog_size &#x3D; 1G</span><br><span class="line">binlog_checksum &#x3D; 1</span><br><span class="line">binlog_format &#x3D; row</span><br><span class="line">sync_binlog &#x3D; 1</span><br><span class="line"></span><br><span class="line">########replication settings########</span><br><span class="line">server-id &#x3D; 213306</span><br><span class="line">master_info_repository &#x3D; TABLE</span><br><span class="line">relay_log_info_repository &#x3D; TABLE</span><br><span class="line">gtid_mode &#x3D; on</span><br><span class="line">enforce-gtid-consistency &#x3D; on</span><br><span class="line">log_slave_updates  &#x3D; on</span><br><span class="line">enforce_gtid_consistency &#x3D; 1</span><br><span class="line">relay_log &#x3D; relay.log</span><br><span class="line">relay_log_recovery &#x3D; 1</span><br><span class="line">relay-log-purge &#x3D; 1</span><br><span class="line">binlog_gtid_simple_recovery &#x3D; 1</span><br><span class="line">slave_skip_errors &#x3D; ddl_exist_errors</span><br><span class="line">slave-rows-search-algorithms &#x3D; &#39;INDEX_SCAN,HASH_SCAN&#39;</span><br><span class="line"></span><br><span class="line">########innodb settings########</span><br><span class="line">innodb_undo_directory &#x3D; &#x2F;data&#x2F;mysql&#x2F;mysql3306&#x2F;data&#x2F;undolog</span><br><span class="line">internal_tmp_disk_storage_engine &#x3D; InnoDB</span><br><span class="line">innodb_page_size &#x3D; 8192</span><br><span class="line">innodb_buffer_pool_size &#x3D; 40960m </span><br><span class="line">innodb_buffer_pool_instances &#x3D; 4</span><br><span class="line">innodb_buffer_pool_load_at_startup &#x3D; 1</span><br><span class="line">innodb_buffer_pool_dump_at_shutdown &#x3D; 1</span><br><span class="line">innodb_data_file_path &#x3D; ibdata1:1G:autoextend</span><br><span class="line">innodb_flush_log_at_trx_commit &#x3D; 1</span><br><span class="line">innodb_log_buffer_size &#x3D; 32M</span><br><span class="line">innodb_log_file_size &#x3D; 1G</span><br><span class="line">innodb_log_files_in_group &#x3D; 4</span><br><span class="line">innodb_max_undo_log_size &#x3D; 4G</span><br><span class="line">innodb_undo_tablespaces &#x3D; 95</span><br><span class="line">innodb_io_capacity &#x3D; 2000</span><br><span class="line">innodb_io_capacity_max &#x3D; 4000</span><br><span class="line">innodb_flush_sync &#x3D; 0</span><br><span class="line">innodb_flush_neighbors &#x3D; 0</span><br><span class="line">innodb_lru_scan_depth &#x3D; 4000</span><br><span class="line">innodb_lock_wait_timeout &#x3D; 5</span><br><span class="line">innodb_write_io_threads &#x3D; 8</span><br><span class="line">innodb_read_io_threads &#x3D; 8</span><br><span class="line">innodb_purge_threads &#x3D; 4</span><br><span class="line">innodb_page_cleaners &#x3D; 4</span><br><span class="line">innodb_max_dirty_pages_pct &#x3D; 50</span><br><span class="line">innodb_flush_method &#x3D; O_DIRECT</span><br><span class="line">innodb_checksum_algorithm &#x3D; crc32</span><br><span class="line">innodb_rollback_on_timeout &#x3D; 1</span><br><span class="line">innodb_print_all_deadlocks &#x3D; 1</span><br><span class="line">innodb_file_per_table &#x3D; 1</span><br><span class="line">innodb_online_alter_log_max_size &#x3D; 4G</span><br><span class="line">innodb_stats_on_metadata &#x3D; 0</span><br><span class="line">innodb_checksums &#x3D; 1</span><br><span class="line">innodb_undo_logs &#x3D; 128</span><br><span class="line">innodb_status_file &#x3D; 1</span><br><span class="line">innodb_status_output &#x3D; 0</span><br><span class="line">innodb_status_output_locks &#x3D; 0</span><br><span class="line">innodb_large_prefix &#x3D; 1</span><br><span class="line">innodb_thread_concurrency &#x3D; 0</span><br><span class="line">innodb_sync_spin_loops &#x3D; 100</span><br><span class="line">innodb_spin_wait_delay &#x3D; 30</span><br><span class="line">innodb_open_files &#x3D; 655350  </span><br><span class="line">innodb_strict_mode &#x3D; 1</span><br><span class="line">innodb_sort_buffer_size &#x3D; 67108864 </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_innodb&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_server&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_dml&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_ddl&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_trx&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_os&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_purge&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_log&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_lock&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_buffer&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_index&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_ibuf_system&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_buffer_page&quot;</span><br><span class="line">innodb_monitor_enable&#x3D;&quot;module_adaptive_hash&quot;</span><br></pre></td></tr></table></figure><h2 id="启动"><a href="#启动" class="headerlink" title="启动"></a>启动</h2><p>配置环境变量 vim /etc/profile</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export PATH&#x3D;&#x2F;usr&#x2F;lib64&#x2F;qt-3.3&#x2F;bin:&#x2F;usr&#x2F;local&#x2F;sbin:&#x2F;usr&#x2F;local&#x2F;bin:&#x2F;sbin:&#x2F;bin:&#x2F;usr&#x2F;sbin:&#x2F;usr&#x2F;bin:&#x2F;root&#x2F;bin:&#x2F;usr&#x2F;local&#x2F;mysql&#x2F;bin</span><br></pre></td></tr></table></figure><p>加载配置文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; cd &#x2F;usr&#x2F;local&#x2F;mysql</span><br><span class="line">shell&gt; bin&#x2F;mysqld  --defaults-file&#x3D;&#x2F;etc&#x2F;my.cnf --basedir&#x3D;&#x2F;usr&#x2F;local&#x2F;mysql&#x2F; --datadir&#x3D;&#x2F;data&#x2F;mysql&#x2F;mysql3306&#x2F;data&#x2F; --user&#x3D;mysql  --initialize</span><br><span class="line">shell&gt; cp support-files&#x2F;mysql.server &#x2F;etc&#x2F;init.d&#x2F;mysql.server</span><br></pre></td></tr></table></figure><p>初始化数据库（为了安全管理，root账号只能本机登陆）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">shell&gt; &#x2F;etc&#x2F;init.d&#x2F;mysql.server start&#x2F;stop</span><br><span class="line">#启动&#x2F;关闭mysql</span><br><span class="line">shell&gt; cat &#x2F;data&#x2F;mysql&#x2F;mysql3306&#x2F;data&#x2F;error.log|grep pass</span><br><span class="line">#查询的密码是第一次登陆的密码</span><br><span class="line">mysql -u root -p</span><br><span class="line">#密码为cat到的密码</span><br><span class="line">root@dev-data-01 15:49:  [(none)]&gt; set password&#x3D;&#39;123456&#39;;</span><br><span class="line">#进入数据库第一次需要修改密码</span><br><span class="line"></span><br><span class="line">添加超级管理员并且支持远程登陆</span><br><span class="line">GRANT ALL PRIVILEGES ON *.* TO &#39;admin&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39; WITH GRANT OPTION;</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure><h1 id="至此，mysql安装已完成"><a href="#至此，mysql安装已完成" class="headerlink" title="至此，mysql安装已完成"></a>至此，mysql安装已完成</h1><p>有建议或疑问欢迎留言</p><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://dev.mysql.com/doc/refman/5.7/en/mysqldump-sql-format.html" target="_blank" rel="noopener">mysql官方文档</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>免费申请证书的方法</title>
      <link href="2020/04/30/ssl/ssl-request/"/>
      <url>2020/04/30/ssl/ssl-request/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="申请地址"><a href="#申请地址" class="headerlink" title="申请地址"></a>申请地址</h1><p><a href="https://freessl.cn/" target="_blank" rel="noopener">https://freessl.cn/</a></p><h1 id="申请步骤"><a href="#申请步骤" class="headerlink" title="申请步骤"></a>申请步骤</h1><h2 id="选择需要申请SSL证书域名"><a href="#选择需要申请SSL证书域名" class="headerlink" title="选择需要申请SSL证书域名"></a>选择需要申请SSL证书域名</h2><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/SSL/SSL01.jpg"  alt="SSL01.jpg"></p><h2 id="选择证书类型并创建"><a href="#选择证书类型并创建" class="headerlink" title="选择证书类型并创建"></a>选择证书类型并创建</h2><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/SSL/SSL02.jpg"  alt="SSL02.jpg"></p><h2 id="下载KeyManager客户端"><a href="#下载KeyManager客户端" class="headerlink" title="下载KeyManager客户端"></a>下载KeyManager客户端</h2><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/SSL/SSL03.jpg"  alt="SSL03.jpg"></p><h2 id="DNS验证"><a href="#DNS验证" class="headerlink" title="DNS验证"></a>DNS验证</h2><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/SSL/SSL04.jpg"  alt="SSL04.jpg"></p><h2 id="导出证书"><a href="#导出证书" class="headerlink" title="导出证书"></a>导出证书</h2><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/SSL/SSL05.jpg"  alt="SSL05.jpg"></p><h1 id="配置证书"><a href="#配置证书" class="headerlink" title="配置证书"></a>配置证书</h1><h2 id="Nginx配置"><a href="#Nginx配置" class="headerlink" title="Nginx配置"></a>Nginx配置</h2><p>解压证书并放到服务器文件里，解压完的文件有2个:xxx.crt、xxx.key</p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/SSL/SSL06.jpg"  alt="SSL06.jpg"></p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@nginx CA]#cd &#x2F;CA</span><br><span class="line">[root@nginx CA]# ll</span><br><span class="line">total 8</span><br><span class="line">-rw-r--r-- 1 root root 3570 Apr 30 14:15 xxx.crt</span><br><span class="line">-rw-r--r-- 1 root root 1679 Apr 30 14:15 xxx.key</span><br></pre></td></tr></table></figure><p>配置nginx.conf 添加此证书</p><pre><code>server {    listen       443 ssl http2;    server_name  xxx.com;    root         /usr/share/nginx/html;    ssl_certificate &quot;/ca/xxx.crt&quot;;    ssl_certificate_key &quot;/ca/xxx.key&quot;;    ssl_session_cache shared:SSL:1m;    ssl_session_timeout  10m;    ssl_ciphers HIGH:!aNULL:!MD5;    ssl_prefer_server_ciphers on;    include /etc/nginx/default.d/*.conf;    location / {        proxy_pass http://172.31.22.31:8082;        proxy_set_header   Host             $proxy_host;        proxy_set_header   X-Real-IP        $remote_addr;        proxy_set_header   X-Forwarded-For  $proxy_add_x_forwarded_for;        proxy_set_header   X-Forwarded-Host $host;        proxy_set_header   X-Forwarded-Server $host;        client_max_body_size 100m;        client_body_buffer_size 100m;    }    error_page 404 /404.html;        location = /40x.html {    }    error_page 500 502 503 504 /50x.html;        location = /50x.html {    }}</code></pre><p>添加完成后需要重启nginx</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nginx -s stop</span><br><span class="line">nginx</span><br></pre></td></tr></table></figure><h2 id="kubernetes集群添加证书"><a href="#kubernetes集群添加证书" class="headerlink" title="kubernetes集群添加证书"></a>kubernetes集群添加证书</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@dev-master-01 CA]#cd &#x2F;CA</span><br><span class="line">[root@dev-master-01 CA]# ll</span><br><span class="line">total 8</span><br><span class="line">-rw-r--r-- 1 root root 3570 Apr 30 14:15 xxx.crt</span><br><span class="line">-rw-r--r-- 1 root root 1679 Apr 30 14:15 xxx.key</span><br><span class="line"></span><br><span class="line">kubectl create secret tls xxx.com --cert&#x3D;xxx.crt --key&#x3D;xxx.key</span><br></pre></td></tr></table></figure><h2 id="腾讯云平台添加证书"><a href="#腾讯云平台添加证书" class="headerlink" title="腾讯云平台添加证书"></a>腾讯云平台添加证书</h2><p>登陆腾讯云<br><a href="https://console.cloud.tencent.com/ssl" target="_blank" rel="noopener">https://console.cloud.tencent.com/ssl</a><br><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/SSL/SSL07.jpg"  alt="SSL07.jpg"><br>上传证书保存即可</p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> SSL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SSL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>运维手册——Mysql导入导出亿条数据（排坑篇）</title>
      <link href="2020/04/28/bug/mysql-climbing/"/>
      <url>2020/04/28/bug/mysql-climbing/</url>
      
        <content type="html"><![CDATA[<p>声明:这是我在大学毕业后进入第一家互联网公司学习的内容</p><hr><h1 id="背景：公司业务需要给某个活动的支付宝用户发送模板消息"><a href="#背景：公司业务需要给某个活动的支付宝用户发送模板消息" class="headerlink" title="背景：公司业务需要给某个活动的支付宝用户发送模板消息"></a>背景：公司业务需要给某个活动的支付宝用户发送模板消息</h1><p>经调查发现，此次活动的用户数量大约2亿，为了模拟生产环境，领导让我把生产库的用户信息（脱敏）拉到开发库，让开发写好程序读取数据并推送消息。</p><h2 id="排坑1：Navicat"><a href="#排坑1：Navicat" class="headerlink" title="排坑1：Navicat"></a>排坑1：Navicat</h2><p>由于我对Mysql不是很了解，在数据同步前我事先问了下公司的DBA应该如何操作：使用navicat的数据传输功能。</p><h3 id="环境：Navicat-Premium-12"><a href="#环境：Navicat-Premium-12" class="headerlink" title="环境：Navicat Premium 12"></a>环境：Navicat Premium 12</h3><ul><li>操作：</li><li>1.点击工具列表的数据传输 </li><li>2.选择源数据库及目标数据库</li><li>3.选择表（默认全表）</li><li>4.点击开始<br><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Mysql/navicat/mysql01.jpg"  alt="mysql01.jpg"></li></ul><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Mysql/navicat/mysql02.jpg"  alt="mysql02.jpg"></p><p><img src="/" class="lazyload" data-src="https://cdn.jsdelivr.net/gh/chenyu1st/chenyu-cdn@master/rugod.cn/Mysql/navicat/mysql03.jpg"  alt="mysql03.jpg"></p><h3 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h3><p>数据传输速度大约1分钟20w条数据，传完大概得8个多小时，我挂机了一段时间后再看进度发现数据传输到百分之11的时候失败了，报错如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Multi-statement transaction required more than ‘max_binlog_cache_size’ bytes of storage; increase this mysqld variable and try again</span><br></pre></td></tr></table></figure><p>百度之后发现<br>这是由于更新和删除的大事务会写入大量binlog，可能会造成binlog cache过小而导致执行失败。</p><p>具体解决方法为如下：</p><p>查看max_binlog_cache_size大小。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &#39;max_binlog_cache_size&#39;;</span><br><span class="line">+-----------------------+-----------+</span><br><span class="line">| Variable_name         | Value     |</span><br><span class="line">+-----------------------+-----------+</span><br><span class="line">| max_binlog_cache_size | 134217728 |</span><br><span class="line">+-----------------------+-----------+</span><br></pre></td></tr></table></figure><p>查看该参数设置为134217728B，即128MB。</p><p>此参数可以动态修改，修改该参数为40GB。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set global max_binlog_cache_size&#x3D;40*1024*1024*1024;</span><br><span class="line">Query OK, 0 rows affected (0.05 sec)</span><br></pre></td></tr></table></figure><p>为了防止数据库重启后还出现此问题，还需要在/etc/my.cnf里修改max_binlog_cache_size的值。</p><h2 id="排坑2：mysqldump"><a href="#排坑2：mysqldump" class="headerlink" title="排坑2：mysqldump"></a>排坑2：mysqldump</h2><p>由于用navicat传输速度实在过慢，听取DBA建议后直接采用mysqldump的方式。</p><p>基本用法如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">导出</span><br><span class="line">mysqldump -uxxx -pxx 库名   表名  &gt; bak.sql</span><br><span class="line">还原</span><br><span class="line">mysql -uxxx -pxxx 库名 &lt; bak.sql</span><br></pre></td></tr></table></figure><p>导出完之后再还原到目标数据库后出现了和上个坑一样的问题：max_binlog_cache_size过小。</p><h2 id="排坑3：select-into-outfile"><a href="#排坑3：select-into-outfile" class="headerlink" title="排坑3：select into outfile"></a>排坑3：select into outfile</h2><p>在上述问题还没找到解决方法的时候继续百度发现了还有一种方法可以解决问题。</p><p>MySQL自带的导出语句：select into outfile语句</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SELECT * FROM db --可以加where条件</span><br><span class="line">INTO OUTFILE &quot;&#x2F;data&#x2F;bak.txt&quot; --导出文件位置</span><br><span class="line">FIELDS TERMINATED BY &#39;,&#39; OPTIONALLY ENCLOSED BY &#39;&quot;&#39; -- 字段分割符和包含符</span><br><span class="line">LINES TERMINATED BY &#39;\n&#39;;--换行符</span><br></pre></td></tr></table></figure><p>但是在执行的时候出现报错：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ERROR 1290 (HY000): The MySQL server is running with the --secure-file-priv option so it cannot execute this statement</span><br></pre></td></tr></table></figure><p>查看官方文档，secure_file_priv参数用于限制LOAD DATA, SELECT …OUTFILE, LOAD_FILE()传到哪个指定目录。</p><ul><li>secure_file_priv 为 null 时，表示限制mysqld不允许导入或导出。</li><li>secure_file_priv 为 /tmp 时，表示限制mysqld只能在/tmp目录中执行导入导出，其他目录不能执行。</li><li>secure_file_priv 没有值时，表示不限制mysqld在任意目录的导入导出。</li></ul><p>查看secure_file_priv命令如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show global variables like &#39;%secure_file_priv%&#39;;</span><br></pre></td></tr></table></figure><p>而且此参数不能直接修改，必须在/ete/my.cnf里添加（默认没有这个参数）并且重启mysql。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">secure_file_priv&#x3D;&#39;&#x2F;data&#39;</span><br></pre></td></tr></table></figure><p>然后执行完导出语句后发现又报错：文件权限不足，原因是data文件夹是root所有，而mysql导出到文件的执行者为mysql用户</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">chmod 777 &#x2F;data</span><br></pre></td></tr></table></figure><p>赋权后导出文件终于没问题了，然后再执行导入文件的的命令。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">load data infile &#39;&#x2F;data&#x2F;bak.txt&#39; --默认指定服务器文件夹</span><br><span class="line">ignore into table xx --允许重复记录插入</span><br><span class="line">fields terminated by &#39;,&#39;  --判断字段通过逗号标识来分隔开</span><br><span class="line">lines terminated by &#39;\n&#39;(CustID,DeviceNo,logintype);--通过换行标识来解析成为每一条数据和插入到我指定的字段</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>2亿多条数据的文件29G，导出速度最快的还是mysqldump方法，但是导入最稳定的我认为还是select into outfile方法，因为容错高，mysqldump的文件就一句insert（29G<br>的数据），执行失败就浪费了太多时间，但是select into outfile即使执行失败也能插入执行成功的数据（要是一条都没插进去当我没说- -）不会太浪费时间。最后提醒大家，大数据量的传输千万不要用navicat，很容易假死。最后补一句：太依赖可视化界面的软件很难成长起来，以后我尽量进服务器敲命令。</p><p>任务总算完成了，花了不少时间，趁机补习了好多mysql的知识，对于上面的问题其实还有优化的思路，只不过没时间去实验了，如果有幸看到我的博客并且也出现了我遇到的问题可以尝试下我的想法。</p><ul><li>临时关闭binlog日志。</li><li>如果你的目标表数据为空，可以先删索引，再导入数据，最后再加上索引。</li></ul><h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://blog.csdn.net/qq_21108311/java/article/details/82559119" target="_blank" rel="noopener">MySQL 亿级数据导入导出/数据迁移笔记</a></p><p><a href="https://www.cnblogs.com/gjc592/p/12774209.html" target="_blank" rel="noopener">mysql参数max_binlog_cache_size设置不当引发的血案</a></p><p><a href="https://dev.mysql.com/doc/refman/5.7/en/mysqldump-sql-format.html" target="_blank" rel="noopener">mysql官方文档</a></p><hr><p>版权声明：</p><p>原创不易，洗文可耻。除非注明，本博文章均为原创，转载请以链接形式标明本文地址。</p>]]></content>
      
      
      <categories>
          
          <category> Mysql </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
            <tag> Operation Manual </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
